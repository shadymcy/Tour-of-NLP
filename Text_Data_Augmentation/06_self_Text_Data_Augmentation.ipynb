{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwtCjsf4sTwU",
        "outputId": "7f00cee8-272d-4a1e-a97f-c2146ddcc3ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue May 17 12:05:20 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6XY-7WNswSL",
        "outputId": "60d2c288-1ff4-4aaa-f8c5-844dcc9fb3f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import sys\n",
        "drive.mount('/content/drive')\n",
        "#设置路径\n",
        "sys.path.append('/content/drive/MyDrive/Colab Notebooks')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqvtiNDuuAxi",
        "outputId": "10ee5a01-d5a4-4c7b-f22a-3398288b3299"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting synonyms\n",
            "  Downloading synonyms-3.16.0.tar.gz (10.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.7 MB 25.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from synonyms) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.13.1 in /usr/local/lib/python3.7/dist-packages (from synonyms) (1.21.6)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from synonyms) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from synonyms) (1.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.1->synonyms) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.1->synonyms) (1.1.0)\n",
            "Building wheels for collected packages: synonyms\n",
            "  Building wheel for synonyms (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for synonyms: filename=synonyms-3.16.0-py3-none-any.whl size=10832785 sha256=aae711a1c4fdeb9fe86d52460ef5a6b0f9540ecbf7206dcf29d7561c9f54c014\n",
            "  Stored in directory: /root/.cache/pip/wheels/e4/cd/43/b4548753509a94471fc946967a07116252d49aeeb689db8f7c\n",
            "Successfully built synonyms\n",
            "Installing collected packages: synonyms\n",
            "Successfully installed synonyms-3.16.0\n"
          ]
        }
      ],
      "source": [
        "! pip install -U synonyms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KiToP8FDIuC",
        "outputId": "f3ace42f-9e27-4720-c95b-ec1a465254e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==1.6.0\n",
            "  Downloading torch-1.6.0-cp37-cp37m-manylinux1_x86_64.whl (748.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 748.8 MB 19 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0) (1.21.6)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0) (0.16.0)\n",
            "Installing collected packages: torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.11.0+cu113\n",
            "    Uninstalling torch-1.11.0+cu113:\n",
            "      Successfully uninstalled torch-1.11.0+cu113\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.12.0+cu113 requires torch==1.11.0, but you have torch 1.6.0 which is incompatible.\n",
            "torchtext 0.12.0 requires torch==1.11.0, but you have torch 1.6.0 which is incompatible.\n",
            "torchaudio 0.11.0+cu113 requires torch==1.11.0, but you have torch 1.6.0 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.6.0\n"
          ]
        }
      ],
      "source": [
        "! pip install torch==1.6.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6Cl5K2sDNPT",
        "outputId": "064cd55a-abe2-4b3f-fa4f-0fb3b0e3f524"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers==4.0.1\n",
            "  Downloading transformers-4.0.1-py3-none-any.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 29.1 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 65.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==4.0.1) (1.21.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.0.1) (3.6.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.0.1) (21.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.0.1) (4.64.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.0.1) (2.23.0)\n",
            "Collecting tokenizers==0.9.4\n",
            "  Downloading tokenizers-0.9.4-cp37-cp37m-manylinux2010_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 62.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.0.1) (2019.12.20)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.0.1) (3.0.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.0.1) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.0.1) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.0.1) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.0.1) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.0.1) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.0.1) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.0.1) (1.1.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=81dc69b6f9fc9b21aa1547850d203135a4ff7ffafac62f232decec6d9b3156d5\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.53 tokenizers-0.9.4 transformers-4.0.1\n"
          ]
        }
      ],
      "source": [
        "! pip install transformers==4.0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h10xpanIu7nh",
        "outputId": "13ec46e6-4a99-46d2-b991-a88713778821"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[jieba] default dict file path ../data/vocab.txt\n",
            "[jieba] default dict file path ../data/vocab.txt\n",
            "[jieba] load default dict ../data/vocab.txt ...\n",
            "[jieba] load default dict ../data/vocab.txt ...\n",
            ">> Synonyms load wordseg dict [/usr/local/lib/python3.7/dist-packages/synonyms/data/vocab.txt] ... \n",
            ">> Synonyms on loading stopwords [/usr/local/lib/python3.7/dist-packages/synonyms/data/stopwords.txt] ...\n",
            "[Synonyms] on loading vectors [/usr/local/lib/python3.7/dist-packages/synonyms/data/words.vector.gz] ...\n",
            "\n",
            "[Synonyms] downloading data from https://github.com/chatopera/Synonyms/releases/download/3.15.0/words.vector.gz to /usr/local/lib/python3.7/dist-packages/synonyms/data/words.vector.gz ... \n",
            " this only happens if SYNONYMS_WORD2VEC_BIN_URL_ZH_CN is not present and Synonyms initialization for the first time. \n",
            " It would take minutes that depends on network.\n",
            "\n",
            "[Synonyms] downloaded.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import synonyms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9mOaqDkfvPU8",
        "outputId": "3cd9d5b7-fdb6-4695-9883-602866d2a9d4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['篮球', '橄榄球', '排球', '棒球', '美式足球', '冰球', '拳击', '网球', '高尔夫球', '高球'],\n",
              " [1.0,\n",
              "  0.81482756,\n",
              "  0.78554475,\n",
              "  0.7845952,\n",
              "  0.7815255,\n",
              "  0.7550466,\n",
              "  0.7411452,\n",
              "  0.7350726,\n",
              "  0.72586256,\n",
              "  0.7199612])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "synonyms.nearby('篮球')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JE5-bWj3NWHP"
      },
      "source": [
        "# EDA(Easy Data Augmentation)\n",
        "![UDA1](https://img-blog.csdnimg.cn/c5ffcca4482c4c42beb6f1215e37657c.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTI4NzA2MA==,size_16,color_FFFFFF,t_70)\n",
        "### EDA：用于提高文本分类任务性能的简单数据增强技术。 EDA 由四个简单但功能强大的操作组成：同义词替换、随机插入、随机交换和随机删除。\n",
        "### 之前的工作已经提出了一些 NLP 中数据增强的技术，回译通过将句子翻译成法语然后再翻译成英语来生成新数据。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnQO5mqsO2BQ"
      },
      "source": [
        "### 对于训练集中的给定句子，随机选择并执行以下操作之一：\n",
        "* 同义词替换（SR）：从句子中随机选择 n 个不是停用词的词。 用随机选择的同义词之一替换这些单词中的每一个。\n",
        "* 随机插入 (RI)：在句子中随机找到一个词，并找出其同义词，且该同义词不是停用词。 将该同义词插入句子中的随机位置。 这样做n次。\n",
        "* 随机交换（RS）：随机选择句子中的两个单词并交换它们的位置。 这样做n次。\n",
        "* 随机删除（RD）：以概率 p 随机删除句子中的每个单词。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3M9EIDDO3Bf"
      },
      "source": [
        "### 停用词 stop word\n",
        "\n",
        "停用词是指在信息检索中，为节省存储空间和提高搜索效率，在处理自然语言数据（或文本）之前或之后会自动过滤掉某些字或词，这些字或词即被称为Stop Words（停用词）\n",
        "```\n",
        "str = \"00000003210Runoob01230000000\"; \n",
        "print str.strip( '0' );  # 去除首尾字符 0\n",
        "\n",
        "str2 = \"   Runoob      \";   # 去除首尾空格\n",
        "print str2.strip();\n",
        "\n",
        "3210Runoob0123\n",
        "Runoob\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "LXVB0xAdPdzO"
      },
      "outputs": [],
      "source": [
        "# strip() 方法用于移除字符串头尾指定的字符（默认为空格或换行符）或字符序列。\n",
        "stop_words = {word.strip() for word in open('/content/drive/MyDrive/Colab Notebooks/dataset/baidu_stopwords.txt', 'r', encoding='utf8').readlines()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "jUQPnSQXQGEP"
      },
      "outputs": [],
      "source": [
        "# 同义词替换（SR）：从句子中随机选择 n 个不是停用词的词。 用随机选择的同义词之一替换这些单词中的每一个。\n",
        "import random\n",
        "def get_synonyms(word):\n",
        "  # (['mama'],['0.9'])\n",
        "  #取出元组第0个元素（['mama']），并去重\n",
        "  sys = set(synonyms.nearby(word)[0])\n",
        "  #将word从同义词列表中去除\n",
        "  if word in sys:\n",
        "    sys.remove(word)\n",
        "  return list(sys)\n",
        "  # 如果输入\"给力\" 可能没有同义词（同义词只有他自己） 则返回  ([],[])\n",
        "\n",
        "\n",
        "def synonym_replacement(words, n):\n",
        "  new_words = words.copy()\n",
        "  # 遍历句子中的每个词，并且这个词不是停用词\n",
        "  # set()去重， 以列表形式返回\n",
        "  random_word_list = list(set([word for word in words if word not in stop_words]))\n",
        "  # 打乱\n",
        "  random.shuffle(random_word_list)\n",
        "  num_replaced = 0\n",
        "  for random_word in random_word_list:\n",
        "    # 得到近义词列表\n",
        "    synonyms = get_synonyms(random_word)\n",
        "    if len(synonyms) >= 1:\n",
        "      # 随机取出一个同义词\n",
        "      synonym = random.choice(list(synonyms))\n",
        "      # 用synonym替换原词\n",
        "      new_words = [synonym if word == random_word else word for word in new_words]\n",
        "      num_replaced += 1\n",
        "    if num_replaced >= n:\n",
        "      break\n",
        "  # new_words 已经是个列表了 下一块代码举例\n",
        "  sentence = ' '.join(new_words)\n",
        "  new_words = sentence.split(' ')\n",
        "  return new_words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbDtk6R6YltF"
      },
      "source": [
        "### 存在一种情况  \n",
        "*有近义词：**actor** -> **film star** 一个单词的近义词是两个单词*\n",
        "\n",
        "sentence = ['in', 'actor']\n",
        "\n",
        "*默认new_words = ['in', 'film star']*\n",
        "\n",
        "*希望有如下表示：*\n",
        "new_words = ['in', 'film', 'star']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "5bkLsC96Zn5V"
      },
      "outputs": [],
      "source": [
        "# 随机删除（RD）：以概率 p 随机删除句子中的每个单词。\n",
        "def random_deletion(words, p):\n",
        "  if len(words) == 1:\n",
        "    return words\n",
        "  new_words = []\n",
        "  for word in words:\n",
        "    # 概率\n",
        "    r = random.uniform(0, 1)\n",
        "    # r>p 保留\n",
        "    if r > p:\n",
        "      new_words.append(word)\n",
        "  # 如果都删没了 随机返回一个词\n",
        "  if len(new_words) == 0:\n",
        "    random_int = random.randint(0, len(words) - 1)\n",
        "    return [words[random_int]]\n",
        "  return new_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "547rlZnwbGfO"
      },
      "outputs": [],
      "source": [
        "# 随机交换（RS）：随机选择句子中的两个单词并交换它们的位置。 这样做n次。\n",
        "def swap_word(new_words):\n",
        "  random_idx_1 = random.randint(0, len(new_words) - 1)\n",
        "  random_idx_2 = random_idx_1\n",
        "  \n",
        "  count = 0\n",
        "  # 两者相等重新取idx_2\n",
        "  while random_idx_2 == random_idx_1:\n",
        "    random_idx_2 - random.randint(0, len(new_words) - 1)\n",
        "    count += 1\n",
        "    # 取了三次还是相等 立即推\n",
        "    if count > 3:\n",
        "      return new_words\n",
        "\n",
        "  new_words[random_idx_1], new_words[random_idx_2] = new_words[random_idx_2], new_words[random_idx_1] \n",
        "  return new_words\n",
        "\n",
        "def random_swap(words, n):\n",
        "  new_words = words.copy()\n",
        "  for _ in range(n):\n",
        "    new_words = swap_word(new_words)\n",
        "  return new_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "3j4gTLdNm0La"
      },
      "outputs": [],
      "source": [
        "# 随机插入 (RI)：在句子中随机找到一个词，并找出其同义词，且该同义词不是停用词。 将该同义词插入句子中的随机位置。 这样做n次。\n",
        "def add_word(new_words):\n",
        "  # 同义词列表\n",
        "  synonyms = []\n",
        "  count = 0\n",
        "  while len(synonyms) < 1:\n",
        "    # 在句子中随机找到一个词\n",
        "    random_word = new_words[random.randint(0, len(new_words) - 1)]\n",
        "    synonyms = get_synonyms(random_word)\n",
        "    count += 1\n",
        "    # 找了10次同义词数量仍小于1，立即推\n",
        "    if count >= 10:\n",
        "      return \n",
        "  #将同义词表中第一个插入\n",
        "  random_synonym = synonyms[0]\n",
        "  # 取出要插入的位置  \n",
        "  random_idx = random.randint(0, len(new_words) - 1)\n",
        "  new_words.insert(random_idx, random_synonym)\n",
        "\n",
        "def random_insert(words, n):\n",
        "  new_words = words.copy()\n",
        "  for i in range(n):\n",
        "    add_word(new_words)\n",
        "  return new_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okqcsY-ivdK5",
        "outputId": "f4186f6d-f998-48b4-db62-b688e966e488"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(['目前', '华为', '部分', '型号', '的', '手机', '产品', '出现', '货', '少', '的', '现象'], ['t', 'nr', 'n', 'n', 'uj', 'n', 'n', 'v', 'n', 'a', 'uj', 'n'])\n"
          ]
        }
      ],
      "source": [
        "words = synonyms.seg('目前华为部分型号的手机产品出现货少的现象')\n",
        "print(words)\n",
        "# 后面的是词性"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Lh7LU9vdqV5a"
      },
      "outputs": [],
      "source": [
        "from random import shuffle\n",
        "# EDA方法\n",
        "# 参数num_aug：增加了几条数据\n",
        "def eda(sentence, alpha_sr= 0.1, alpha_ri = 0.1, alpha_rs = 0.1, p_rd = 0.1, num_aug = 9):\n",
        "  words = synonyms.seg(sentence)[0]\n",
        "  num_words = len(words)\n",
        "  augmented_sentence = []\n",
        "  \n",
        "  # 每种技术增加了多少样本\n",
        "  num_new_per_tech = int(num_aug / 4) + 1\n",
        "  # = 3\n",
        "\n",
        "  # 同义词替换数量\n",
        "  n_sr = max(1, int(alpha_sr * num_words))\n",
        "  # 随机插入数量\n",
        "  n_ri = max(1, int(alpha_ri * num_words))\n",
        "  # 随机交换数量\n",
        "  n_rs = max(1, int(alpha_rs * num_words))\n",
        "\n",
        "  # 同义词替换\n",
        "  for i in range(num_new_per_tech):\n",
        "    a_words = synonym_replacement(words, n_sr)\n",
        "    # a_words 是列表 []\n",
        "    # print('a-words(同义词替换):',a_words)\n",
        "    augmented_sentence.append(' '.join(a_words))\n",
        "  # 随机插入\n",
        "  for i in range(num_new_per_tech):\n",
        "    a_words = random_insert(words, n_ri)\n",
        "    augmented_sentence.append(' '.join(a_words))\n",
        "  # 随机交换\n",
        "  for i in range(num_new_per_tech):\n",
        "    a_words = random_swap(words, n_rs)\n",
        "    augmented_sentence.append(' '.join(a_words))\n",
        "  # 随机删除\n",
        "  for i in range(num_new_per_tech):\n",
        "    a_words = random_deletion(words, p_rd)\n",
        "    augmented_sentence.append(' '.join(a_words))\n",
        "\n",
        "  shuffle(augmented_sentence)\n",
        "\n",
        "  if num_aug >= 1:\n",
        "    augmented_sentence = augmented_sentence[:num_aug]\n",
        "  else: # num_aug<1\n",
        "    keep_prob = num_aug / len(augmented_sentence)\n",
        "    # random_delete\n",
        "    augmented_sentence = [s for s in augmented_sentence if random.uniform(0, 1) < keep_prob]\n",
        "\n",
        "  return augmented_sentence\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "a-words(同义词替换): ['9', '月', '15', '日', '以来', '，', '台积电', '、', '高通', '、', '三星', '等', '华为', '的', '重要', '伙伴', '，', '只要', '没有', '美国', '的', '相关', '许可证', '，', '都', '无法', '供应', '显示卡', '给', '华为', '，', '而', '中芯国际', '等', '国产', '显示卡', '企业', '，', '也', '因', '采用', '美国', '技术', '，', '而', '无法', '供货', '给', '华为', '。', '目前', '华为', '部分', '型号', '的', '手机', '产品', '出现', '提货', '缺', '的', '现象', '，', '若', '该', '形势', '持续', '下去', '，', '华为', '手机', '销售业务', '将', '遭受重创', '摧残', '。']\n",
        "a-words(同义词替换): ['9', '月', '15', '日', '以来', '，', '台积电', '、', '高通', '、', '三星', '等', '华为', '的', '重要', '供应商', '，', '只要', '没有', '美国', '的', '相关', '许可证', '，', '虽然', '无法', '市场供应', '集成电路', '给', '华为', '，', '而', '中芯国际', '等', '国产', '集成电路', '企业', '，', '也', '因', '采用', '美国', '技术', '，', '而', '无法', '发货', '给', '华为', '。', '目前', '华为', '部分', '型号', '的', '手机', '产品', '出现', '货', '贵', '的', '现象', '，', '若', '该', '国际形势', '持续', '下去', '，', '华为', '手机', '业务', '将', '遭受', '重创', '。']\n",
        "a-words(同义词替换): ['9', '月', '15', '日', '以来', '，', '台积电', '、', '高通', '、', '三星', '等', 'OPPO', '的', '重要', '合作伙伴', '，', '只要', '没有', '美国', '的', '相关机构', '许可证', '，', '都', '无法', '供应', '芯片', '给', 'OPPO', '，', '而', '卢戈韦', '等', '换代', '芯片', '企业', '，', '也', '因', '采用', '美国', '控制技术', '，', '而', '无法', '接单', '给', 'OPPO', '。', '目前', 'OPPO', '部分', '型号', '的', '手机', '产品', '出现', '装箱', '少', '的', '现象', '，', '若', '该', '形势', '持续', '下去', '，', 'OPPO', '手机', '业务', '将', '遭受', '重创', '。']\n",
        "```"
      ],
      "metadata": {
        "id": "tbQb0T6G5zob"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFV5Q0IP517R",
        "outputId": "df48f7f1-8c4f-459b-ad11-b96831eba6c3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['9 月 15 日 以来 ， 台积电 、 高通 三星 等 华为 的 重要 合作伙伴 ， 只要 没有 美国 的 相关 许可证 ， 都 无法 供应 芯片 给 华为 ， 而 中芯国际 等 国产 芯片 企业 ， 也 因 采用 美国 技术 ， 而 无法 供货 给 。 华为 部分 型号 的 手机 产品 出现 货 少 现象 ， 若 该 形势 下去 ， 华为 手机 业务 将 遭受 重创 。',\n",
              " '9 月 15 日 以来 ， 台积电 、 高通 、 三星 等 华为 的 重要 合作伙伴 ， 只要 没有 美国 的 相关 许可证 ， 都 无法 供应 芯片 给 华为 ， 而 中芯国际 等 国产 芯片 企业 ， 也 因 采用 美国 技术 ， 而 无法 供货 给 华为 。 目前 华为 部分 型号 的 手机 产品 出现 货 少 的 现象 ， 若 该 形势 持续 下去 ， 华为 手机 业务 将 遭受 重创 。',\n",
              " '9 月 15 日 以来 ， 台积电 、 高通 、 三星 等 华为 的 重要 合作伙伴 ， 只要 没有 美国 的 相关 许可证 ， 都 无法 供应 芯片 给 华为 ， 而 中芯国际 等 国产 芯片 企业 ， 也 因 采用 美国 技术 ， 而 无法 供货 给 华为 。 目前 华为 部分 型号 的 手机 产品 出现 货 少 的 现象 ， 若 该 形势 持续 下去 ， 华为 手机 业务 将 遭受 重创 。',\n",
              " '9 月 没 15 日 以来 ， 台积电 、 高通 、 三星 等 华为 的 重要 合作伙伴 甚至 ， 只要 没有 美国 的 相关 许可证 ， 都 无法 供应 芯片 给 华为 ， 而 中芯国际 为此 等 国产 芯片 企业 ， 也 因 采用 美国 技术 ， 而 无法 供货 给 华为 。 目前 太小 华为 部分 型号 的 手机 产品 出现 货 少 如 的 现象 ， 若 该 形势 持续 下去 VIA ， 华为 手机 当前 业务 将 遭受 重创 。',\n",
              " '9 月 15 日 以来 ， 台积电 、 高通 、 三星 等 华为 的 重要 合作伙伴 ， 只要 没有 美国 的 相关 许可证 ， 都 无法 供应 芯片 给 华为 ， 而 中芯国际 等 国产 芯片 企业 ， 也 因 采用 美国 技术 ， 而 无法 供货 给 华为 。 目前 华为 部分 型号 的 手机 产品 出现 货 少 的 现象 ， 若 该 形势 持续 下去 ， 华为 手机 业务 将 遭受 重创 。',\n",
              " '9 月 15 日 以来 ， 台积电 、 高通 、 三星 等 小米 的 重要 合作伙伴 ， 只要 没有 墨西哥 的 相关 营业执照 ， 都 无法 供应 芯片 给 小米 ， 而 中芯国际 等 混动 芯片 企业 ， 也 因 换用 墨西哥 关键技术 ， 而 无法 供货 给 小米 。 目前 小米 部分 型号 的 手机 产品 出现 货 少 的 现象 ， 若 该 形势 持续 下去 ， 小米 手机 业务 将 遭受 沉重打击 。',\n",
              " '9 月 摧残 15 日 以来 ， 台积电 、 高通 、 三星 等 华为 的 重要 合作伙伴 ， 只要 没有 美国 的 相关 许可证 ， 都 无法 供应 芯片 给 华为 ， 而 中芯国际 等 国产 爱立信 芯片 企业 ， 也 因 采用 系列产品 美国 技术 ， 而 无法 能源供应 供货 给 华为 如 。 目前 华为 部分 型号 的 手机 产品 出现 持续性 货 少 的 现象 ， 若 该 形势 持续 下去 ， 华为 手机 业务 将 遭受 爱立信 重创 。',\n",
              " '9 月 15 日 以来 ， 台积电 、 高通 、 三星 等 华为 的 合作伙伴 ， 只要 没有 美国 的 相关 许可证 ， 都 无法 供应 芯片 给 华为 ， 中芯国际 等 国产 芯片 企业 ， 也 因 采用 美国 ， 而 无法 给 华为 。 目前 华为 部分 型号 的 产品 货 少 的 现象 ， 若 该 形势 持续 下去 ， 华为 手机 将 遭受 重创',\n",
              " '9 月 15 日晨 以来 ， 台积电 、 高通 、 三星 等 华为 的 重要 合作伙伴 ， 只要 没有 美国 的 相关 准生证 ， 即使 无法 供应 芯片 给 华为 ， 而 中芯国际 等 国产 芯片 上市公司 ， 也 因 采用 美国 技术 ， 而 无法 供货商 给 华为 。 目前 华为 部分 型号 的 手机 产品 出现 货 少 的 现象 ， 若 该 情势 持续 下去 ， 华为 手机 管理业务 将 遭受 重创 。']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "eda('9月15日以来，台积电、高通、三星等华为的重要合作伙伴，只要没有美国的相关许可证，都无法供应芯片给华为，而中芯国际等国产芯片企业，也因采用美国技术，而无法供货给华为。目前华为部分型号的手机产品出现货少的现象，若该形势持续下去，华为手机业务将遭受重创。')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYUvgIjRujZf"
      },
      "source": [
        "## 闭包数据增强\n",
        "数据集中每条数据有两个句子 \\\n",
        "a, b, 1\\\n",
        "a, c, 1\\\n",
        "a, d, 0\\\n",
        "a-b(相似), a-c => b-c\\\n",
        "a-b, ad不相似 => bd不相似"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "LYi_3K-ktxJf"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "def parse_data(path, data_type='train'):\n",
        "  sentence_a = []\n",
        "  sentence_b = []\n",
        "  labels = []\n",
        "\n",
        "  with open(path, 'r', encoding = 'utf8') as f:\n",
        "    for line in tqdm(f.readlines(), desc=f'Reading {data_type} data'):\n",
        "      line = json.loads(line)\n",
        "      sentence_a.append(line['sentence1'])\n",
        "      sentence_b.append(line['sentence2'])\n",
        "      if data_type != 'test':\n",
        "        labels.append(int(line['label']))\n",
        "      else:\n",
        "        labels.append(0)\n",
        "\n",
        "  df = pd.DataFrame(zip(sentence_a, sentence_b, labels), columns = ['text_a', 'text_b', 'labels'])\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSYW4V-vw5G3",
        "outputId": "79d83199-7b0c-4f88-aa11-f649e97c2d0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reading train data: 100%|██████████| 34334/34334 [00:00<00:00, 249166.86it/s]\n"
          ]
        }
      ],
      "source": [
        "train_df = parse_data('/content/drive/MyDrive/Colab Notebooks/dataset/ESIM/train.json', data_type='train')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "zyeDVsEo1uJ3",
        "outputId": "344f82ca-f950-4d28-fce3-06cb7749b603"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                text_a                                 text_b  labels\n",
              "0    蚂蚁借呗等额还款可以换成先息后本吗                             借呗有先息到期还本吗       0\n",
              "1           蚂蚁花呗说我违约一次                            蚂蚁花呗违约行为是什么       0\n",
              "2     帮我看一下本月花呗账单有没有结清                                 下月花呗账单       0\n",
              "3       蚂蚁借呗多长时间综合评估一次                                借呗得评估多久       0\n",
              "4  我的花呗账单是***，还款怎么是***  我的花呗，月结出来说让我还***元，我自己算了一下详细名单我应该还***元       1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-db5fe334-e127-4de6-9c9b-b66f4961c050\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_a</th>\n",
              "      <th>text_b</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>蚂蚁借呗等额还款可以换成先息后本吗</td>\n",
              "      <td>借呗有先息到期还本吗</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>蚂蚁花呗说我违约一次</td>\n",
              "      <td>蚂蚁花呗违约行为是什么</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>帮我看一下本月花呗账单有没有结清</td>\n",
              "      <td>下月花呗账单</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>蚂蚁借呗多长时间综合评估一次</td>\n",
              "      <td>借呗得评估多久</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>我的花呗账单是***，还款怎么是***</td>\n",
              "      <td>我的花呗，月结出来说让我还***元，我自己算了一下详细名单我应该还***元</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-db5fe334-e127-4de6-9c9b-b66f4961c050')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-db5fe334-e127-4de6-9c9b-b66f4961c050 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-db5fe334-e127-4de6-9c9b-b66f4961c050');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g84ecFQM2TjP",
        "outputId": "01f2ec93-0c63-477f-e0a1-cb7fce4264d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "数据类型: <class 'tuple'>\n",
            "数据长度: 2\n",
            "data[0]: 为什么我开通不了花呗\n",
            "-------\n",
            "data[1]:            text_a                            text_b  labels\n",
            "21     为什么我开通不了花呗  我一直想买苹果***p，没钱，想分期付款，除了花呗，还有什么可以       0\n",
            "1333   为什么我开通不了花呗                        为什么不可以开通花呗       0\n",
            "17994  为什么我开通不了花呗                          我为何打不开花呗       0\n",
            "18096  为什么我开通不了花呗                         我开通不了蚂蚁花呗       1\n",
            "19484  为什么我开通不了花呗           你直接帮我查一下 确实开通不了花呗吗？我的账户       1\n",
            "31930  为什么我开通不了花呗                         电脑端怎么开通花呗       0\n",
            "-------\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 6 entries, 21 to 31930\n",
            "Data columns (total 3 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   text_a  6 non-null      object\n",
            " 1   text_b  6 non-null      object\n",
            " 2   labels  6 non-null      int64 \n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 192.0+ bytes\n",
            "data[1].info(): None\n"
          ]
        }
      ],
      "source": [
        "for data in train_df.groupby(by = ['text_a']):\n",
        "  if len(data[1])>=3:\n",
        "   \n",
        "    print('数据类型:',type(data))\n",
        "    print('数据长度:',len(data))\n",
        "    print('data[0]:',data[0]) # text_a句子\n",
        "    print('-------')\n",
        "    print('data[1]:',data[1]) # 以text_a为主键返回的dataFrame\n",
        "    print('-------')\n",
        "  \n",
        "    print('data[1].info():',data[1].info())\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91fRL87k_TUW"
      },
      "source": [
        "### 举例\n",
        "a : 为什么我开通不了花呗 b: 我一直想买苹果 p，没钱，想分期付款，除了花呗，还有什么可以 c:我开通不了蚂蚁花呗 ab 不相似， ac相似，=》bc不相似"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "hnHJ2iJa7OBW"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "def aug_group_by_a(df):\n",
        "  aug_data = defaultdict(list)\n",
        "  # 以text_a中的句子为g\n",
        "  for g, data in df.groupby(by = ['text_a']):\n",
        "    # 如果只有一条数据 无法数据增强\n",
        "    if len(data) < 2:\n",
        "      continue\n",
        "    # iloc[ : , : ] 行列切片以“，”隔开，前面的冒号就是取行数，后面的冒号是取列数\n",
        "    for i in range(len(data)):\n",
        "      for j in range(i+1, len(data)):\n",
        "        # 取出b的值，a,b的label\n",
        "        row_i_text = data.iloc[i, 1]\n",
        "        row_i_label = data.iloc[i, 2]\n",
        "        # 取出c的值，a,c的label\n",
        "        row_j_text = data.iloc[j, 1]\n",
        "        row_j_label = data.iloc[j, 2]\n",
        "        # 如果 ab ， ac都不相似则不考虑\n",
        "        if row_i_label == row_j_label == 0:\n",
        "          continue\n",
        "        # ab相似， ac也相似， bc就相似\n",
        "        aug_label = 1 if row_i_label == row_j_label == 1 else 0\n",
        "\n",
        "        aug_data['text_a'].append(row_i_text)\n",
        "        aug_data['text_b'].append(row_j_text)\n",
        "        aug_data['labels'].append(aug_label)\n",
        "  return pd.DataFrame(aug_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9po58_K8qg3",
        "outputId": "a1cb0455-aa26-450c-9eaa-80220c9389ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                               text_a                   text_b  labels\n",
            "0    我一直想买苹果***p，没钱，想分期付款，除了花呗，还有什么可以                我开通不了蚂蚁花呗       0\n",
            "1    我一直想买苹果***p，没钱，想分期付款，除了花呗，还有什么可以  你直接帮我查一下 确实开通不了花呗吗？我的账户       0\n",
            "2                          为什么不可以开通花呗                我开通不了蚂蚁花呗       0\n",
            "3                          为什么不可以开通花呗  你直接帮我查一下 确实开通不了花呗吗？我的账户       0\n",
            "4                            我为何打不开花呗                我开通不了蚂蚁花呗       0\n",
            "..                                ...                      ...     ...\n",
            "223                           你是人工服务吗                   需求人工客服       0\n",
            "224                           你是人工服务吗                   联系人工客服       1\n",
            "225                            需求人工客服                   联系人工客服       0\n",
            "226                     身份证过期可以用蚂蚁借呗吗           身份证过期可以注册蚂蚁借呗吗       0\n",
            "227                            人工关闭花呗     一个帐户的花呗关，另一个帐户的花呗怎么开       0\n",
            "\n",
            "[228 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "aug_train_a = aug_group_by_a(train_df)\n",
        "# 看增强了多少条数据\n",
        "print(aug_train_a)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLXQuzEl_cP8"
      },
      "source": [
        "## UDA（Unsupervised Data Augmentation for Consistency Training）用于一致性训练的无监督数据增强\n",
        " ![UDA1](https://img-blog.csdnimg.cn/c9cb603261a1497c8093ee669b7923f2.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTI4NzA2MA==,size_16,color_FFFFFF,t_70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxgwQy4N_1Ab"
      },
      "source": [
        "### 什么是一致性训练？\n",
        "### 数据增强 是 创建 逼近 真实的训练数据，并且不改变其标签\n",
        "### 举例： a, b, 1  a c, 1 -> b, c, 1\n",
        "### 一致性训练：增强前和增强后的标签 应该保持一致，利用这个特性训练"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fbzf5v5_DBrM"
      },
      "source": [
        "![unsupervised data augmentation](https://img-blog.csdnimg.cn/86f3aad1042b4bf381d662e9c3b48f0a.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTI4NzA2MA==,size_16,color_FFFFFF,t_70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBpEE_6nCvLz"
      },
      "source": [
        " 半监督学习利用无标签样本增强模型鲁棒性\n",
        " * 给定输入x, 计算输出分布$p_{\\theta}(y|x)$, 同时，给输入x进行数据增强，计算出分布$p_{\\theta}(y|\\hat x)$.\n",
        " * 给两个分布计算KL散度"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQvETdbrBenT"
      },
      "source": [
        "![UDA5](https://img-blog.csdnimg.cn/9d10da70d1d0467e93ef5bb1267ac87f.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTI4NzA2MA==,size_16,color_FFFFFF,t_70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDB0XgtBDWYj"
      },
      "source": [
        "### 解释上图\n",
        "![code](https://img-blog.csdnimg.cn/d97f35fd41e0485185f40d50f4fd8e8d.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTI4NzA2MA==,size_16,color_FFFFFF,t_70)\n",
        "\n",
        "**ps： unsup_x--(a,b)成为 no_grad_data,不需要反向传播** \\\n",
        "*sup:监督 unsup:无监督*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "HAOjofjfGdKT"
      },
      "outputs": [],
      "source": [
        "from bucket_sampler import SortedSampler, BucketBatchSampler\n",
        "from EMA import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DISLVIJEG4Cj",
        "outputId": "939f4eaa-0a7d-42d4-f62c-6fa1819456ec"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2022"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "config = {\n",
        "        'train_file_path': '/content/drive/MyDrive/Colab Notebooks/dataset/ESIM/train.json',\n",
        "        'dev_file_path': '/content/drive/MyDrive/Colab Notebooks/dataset/ESIM/dev.json',\n",
        "        'test_file_path': '/content/drive/MyDrive/Colab Notebooks/dataset/ESIM/test.json',\n",
        "        'output_path': '.',\n",
        "        'model_path': '/content/drive/MyDrive/Colab Notebooks/dataset/BERT_model',\n",
        "        'batch_size': 16,\n",
        "        'num_epochs': 1,\n",
        "        'max_seq_len': 64,\n",
        "        'learning_rate': 2e-5,\n",
        "        'weight_decay': 0.01,\n",
        "        'use_bucket': True,\n",
        "        'bucket_multiplier': 200,\n",
        "        'unsup_data_ratio': 1.5,\n",
        "        'uda_softmax_temp': 0.4,\n",
        "        'uda_confidence_threshold': 0.8,\n",
        "        'device': 'cuda',\n",
        "        'n_gpus': 0,\n",
        "        'logging_step': 400,\n",
        "        'ema_start_step': 500,\n",
        "        'ema_start': False,\n",
        "        'seed': 2022\n",
        "    }\n",
        "\n",
        "if not torch.cuda.is_available():\n",
        "    config['device'] = 'cpu'\n",
        "else:\n",
        "    config['n_gpus'] = torch.cuda.device_count()\n",
        "    config['batch_size'] *= config['n_gpus']\n",
        "\n",
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    return seed\n",
        "\n",
        "seed_everything(config['seed'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "3rVKA8xzIcZD"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(config['model_path'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "L5TtMUNKmp7j"
      },
      "outputs": [],
      "source": [
        "def build_bert_inputs(inputs, label, sentence_a, sentence_b, tokenizer):\n",
        "  inputs_dict = tokenizer.encode_plus(sentence_a, sentence_b, add_special_tokens = True, return_token_type_ids =True, return_attention_mask = True)\n",
        "\n",
        "  inputs['input_ids'].append(inputs_dict['input_ids'])\n",
        "  inputs['token_type_ids'].append(inputs_dict['token_type_ids'])\n",
        "  inputs['attention_mask'].append(inputs_dict['attention_mask'])\n",
        "  inputs['labels'].append(label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKJOUy9FpRo7"
      },
      "source": [
        "##  对偶数据增强\n",
        "sentence1: a\\\n",
        "sentence2: b\\\n",
        "a, b, 1 变成 b, a, 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "4NVd4iSqodRr"
      },
      "outputs": [],
      "source": [
        "# 无监督BERT输入\n",
        "def build_unsup_bert_inputs(inputs, label, sentence_a, sentence_b, tokenizer):\n",
        "  # 左右\n",
        "  lr_inputs_dict = tokenizer.encode_plus(sentence_a, sentence_b, add_special_tokens = True, return_token_type_ids = True, return_attention_mask = True)\n",
        "  # 右左\n",
        "  rl_inputs_dict = tokenizer.encode_plus(sentence_b, sentence_a, add_special_tokens = True, return_token_type_ids = True, return_attention_mask = True)\n",
        "\n",
        "  # 元组的形式\n",
        "  inputs['input_ids'].append((lr_inputs_dict['input_ids'], rl_inputs_dict['input_ids']))\n",
        "  inputs['token_type_ids'].append((lr_inputs_dict['token_type_ids'], rl_inputs_dict['token_type_ids']))\n",
        "  inputs['attention_mask'].append((lr_inputs_dict['attention_mask'], rl_inputs_dict['attention_mask']))\n",
        "  inputs['labels'].append(label)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "_vphmq44wKQb"
      },
      "outputs": [],
      "source": [
        "def read_data(config, tokenizer):\n",
        "  train_df = parse_data(config['train_file_path'], data_type = 'train')\n",
        "  dev_df = parse_data(config['dev_file_path'], data_type = 'dev')\n",
        "  test_df = parse_data(config['test_file_path'], data_type = 'test')\n",
        "\n",
        "  data_df = {'train': train_df, 'dev': dev_df, 'test': test_df}\n",
        "  processed_data = {}\n",
        "  unsup_data = defaultdict(list)\n",
        "  for data_type, df in data_df.items():\n",
        "    inputs = defaultdict(list)\n",
        "    if data_type == 'train':\n",
        "      reversed_inputs = defaultdict(list)\n",
        "\n",
        "    for i, row in tqdm(df.iterrows(), desc=f'Preprocessing {data_type} data', total = len(df)):\n",
        "      label = 0 if data_type == 'test' else row[2]\n",
        "      sentence_a, sentence_b = row[0], row[1]\n",
        "      build_bert_inputs(inputs, label, sentence_a, sentence_b, tokenizer)\n",
        "\n",
        "      if data_type.startswith('test'):\n",
        "        build_bert_inputs(inputs, label, sentence_b, sentence_a, tokenizer)\n",
        "\n",
        "\n",
        "      build_unsup_bert_inputs(unsup_data, label, sentence_a, sentence_b, tokenizer)\n",
        "\n",
        "    processed_data[data_type] = inputs\n",
        "  processed_data['unsup_data'] = unsup_data\n",
        "  return processed_data\n",
        "\n",
        "# processed_data\n",
        "# {\n",
        "#    'train':,\n",
        "#    'dev':,\n",
        "#    'test':,\n",
        "#    'unsup_data':   # 数据量最大的\n",
        "# }\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-8IxyClCIkT",
        "outputId": "0d04d28a-00a3-4403-b6df-d43bc94c0c2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reading train data: 100%|██████████| 34334/34334 [00:00<00:00, 114355.71it/s]\n",
            "Reading dev data: 100%|██████████| 4316/4316 [00:00<00:00, 150877.77it/s]\n",
            "Reading test data: 100%|██████████| 3861/3861 [00:00<00:00, 108980.72it/s]\n",
            "Preprocessing train data: 100%|██████████| 34334/34334 [00:49<00:00, 695.37it/s]\n",
            "Preprocessing dev data: 100%|██████████| 4316/4316 [00:05<00:00, 761.77it/s]\n",
            "Preprocessing test data: 100%|██████████| 3861/3861 [00:06<00:00, 596.93it/s]\n"
          ]
        }
      ],
      "source": [
        "data = read_data(config, tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "a7GTURcvu-QA"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "class AFQMCDataset(Dataset):\n",
        "  def __init__(self, data_dict):\n",
        "    super(AFQMCDataset, self).__init__()\n",
        "    self.data_dict = data_dict\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    data = (self.data_dict['input_ids'][idx],\n",
        "         self.data_dict['token_type_ids'][idx],\n",
        "         self.data_dict['attention_mask'][idx],\n",
        "         self.data_dict['labels'][idx])\n",
        "    return data\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.data_dict['input_ids'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "UYQSdV9Wwiho"
      },
      "outputs": [],
      "source": [
        "class Collator:\n",
        "  def __init__(self, max_seq_len, tokenizer):\n",
        "    self.max_seq_len = max_seq_len\n",
        "    self.tokenizer = tokenizer\n",
        "\n",
        "  def pad_and_truncate(self, input_ids_list, token_type_ids_list, attention_mask_list, labels_list, max_seq_len):\n",
        "    input_ids = torch.zeros((len(input_ids_list), max_seq_len), dtype = torch.long)\n",
        "    token_type_ids = torch.zeros_like(input_ids)\n",
        "    attention_mask = torch.zeros_like(input_ids)\n",
        "    for i in range(len(input_ids_list)):\n",
        "      seq_len = len(input_ids_list[i])\n",
        "      if seq_len <= max_seq_len:\n",
        "        input_ids[i, :seq_len] = torch.tensor(input_ids_list[i], dtype = torch.long)\n",
        "        token_type_ids[i, :seq_len] = torch.tensor(token_type_ids_list[i], dtype = torch.long)\n",
        "        attention_mask[i, :seq_len] = torch.tensor(attention_mask_list[i], dtype = torch.long)\n",
        "\n",
        "      else:\n",
        "        input_ids[i] = torch.tensor(input_ids_list[i][:max_seq_len - 1] + [self.tokenizer.sep_token_id], dtype = torch.long)\n",
        "        token_type_ids[i] = torch.tensor(token_type_ids_list[i][:max_seq_len], dtype = torch.long)\n",
        "        attention_mask[i] = torch.tensor(attention_mask_list[i][:max_seq_len], dtype = torch.long)\n",
        "\n",
        "    labels = torch.tensor(labels_list, dtype = torch.long)\n",
        "    return input_ids, token_type_ids, attention_mask, labels\n",
        "\n",
        "  def __call__(self, examples):\n",
        "    input_ids_list, token_type_ids_list, attention_mask_list, labels_list = list(zip(*examples))\n",
        "    cur_max_seq_len = max(len(input_ids) for input_ids in input_ids_list)\n",
        "    max_seq_len = min(cur_max_seq_len, self.max_seq_len)\n",
        "\n",
        "    input_ids, token_type_ids, attention_mask, labels = self.pad_and_truncate(input_ids_list, token_type_ids_list, attention_mask_list, labels_list, max_seq_len)\n",
        "\n",
        "    data_dict = {\n",
        "        'input_ids':input_ids,\n",
        "        'token_type_ids':token_type_ids,\n",
        "        'attention_mask':attention_mask,\n",
        "        'labels':labels\n",
        "    }\n",
        "    return data_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "gyz3hzqlCeaP"
      },
      "outputs": [],
      "source": [
        "collate_fn = Collator(config['max_seq_len'], tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "44ByblIdChtN"
      },
      "outputs": [],
      "source": [
        "# UDA 无监督重新构造dataset 和 collator\n",
        "class UnsupAFQMCDataset(Dataset):\n",
        "  def __init__(self, data_dict):\n",
        "    super(UnsupAFQMCDataset, self).__init__()\n",
        "    self.data_dict = data_dict\n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "    input_ids = self.data_dict['input_ids'][idx]\n",
        "    token_type_ids = self.data_dict['token_type_ids'][idx]\n",
        "    attention_mask = self.data_dict['attention_mask'][idx]\n",
        "    labels = self.data_dict['labels'][idx]\n",
        "    # input_ids[0]：lr_inputs_dict['input_ids']    (build_unsup_bert_inputs)\n",
        "    # input_ids[1]：rl_inputs_dict['input_ids']\n",
        "    return (input_ids[0], token_type_ids[0], attention_mask[0],\n",
        "         input_ids[1], token_type_ids[1], attention_mask[1],\n",
        "         labels)\n",
        "    \n",
        "  def __len__(self):\n",
        "    return len(self.data_dict['input_ids'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "rUAzhxjSGl8G"
      },
      "outputs": [],
      "source": [
        "class UnsupCollator(Collator):\n",
        "  def __init__(self, max_seq_len, tokenizer):\n",
        "    self.max_seq_len = max_seq_len\n",
        "    self.tokenizer = tokenizer\n",
        "\n",
        "  def __call__(self, examples):\n",
        "    # 根据UnsupAFQMCDataset的getitem 有七个数据\n",
        "    (ab_input_ids_list, ab_token_type_ids_list, ab_attention_mask_list,\n",
        "     ba_input_ids_list, ba_token_type_ids_list, ba_attention_mask_list,\n",
        "     labels_list) = list(zip(*examples))\n",
        "    cur_max_seq_len = max(len(input_ids) for input_ids in ab_input_ids_list)\n",
        "    max_seq_len = min(cur_max_seq_len, self.max_seq_len)\n",
        "    # 分批整ab, ba（填充与截断）\n",
        "    ab_input_ids, ab_token_type_ids, ab_attention_mask, labels = self.pad_and_truncate(ab_input_ids_list, ab_token_type_ids_list, ab_attention_mask_list, labels_list, max_seq_len)\n",
        "    ba_input_ids, ba_token_type_ids, ba_attention_mask, labels = self.pad_and_truncate(ba_input_ids_list, ba_token_type_ids_list, ba_attention_mask_list, labels_list, max_seq_len)\n",
        "\n",
        "\n",
        "    data_dict = {\n",
        "        'ab_input_ids':ab_input_ids,\n",
        "        'ab_token_type_ids':ab_token_type_ids,\n",
        "        'ab_attention_mask':ab_attention_mask,\n",
        "        'ba_input_ids':ba_input_ids,\n",
        "        'ba_token_type_ids':ba_token_type_ids,\n",
        "        'ba_attention_mask':ba_attention_mask,\n",
        "        'labels':labels\n",
        "    }\n",
        "    return data_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "nLh3AuKA2XjC"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler\n",
        "def build_dataloader(config, data, tokenizer):\n",
        "  train_dataset = AFQMCDataset(data['train'])\n",
        "  dev_dataset = AFQMCDataset(data['dev'])\n",
        "  test_dataset = AFQMCDataset(data['test'])\n",
        "  unsup_dataset = UnsupAFQMCDataset(data['unsup_data'])\n",
        "\n",
        "  collate_fn = Collator(config['max_seq_len'], tokenizer)\n",
        "  unsup_collate_fn = UnsupCollator(config['max_seq_len'], tokenizer)\n",
        "\n",
        "  # 使用桶采样\n",
        "  if config['use_bucket']:\n",
        "    # 监督数据\n",
        "    # 基采样器RandomSampler\n",
        "    train_sampler = RandomSampler(train_dataset)\n",
        "    # drop_last 最后一个batch小于size 丢弃\n",
        "    bucket_sampler = BucketBatchSampler(train_sampler, batch_size = config['batch_size'],\n",
        "                      drop_last = False, sort_key = lambda x: len(train_dataset[x][0]),# 以 input_id 长度作为排序的指标\n",
        "                      bucket_size_multiplier = config['bucket_multiplier'])\n",
        "    train_dataloader = DataLoader(dataset = train_dataset, batch_sampler = bucket_sampler, num_workers = 4, collate_fn = collate_fn)\n",
        "    # 无监督数据 \n",
        "    # grad_data中(图) 有监督、无监督一起训练， 无监督数据量大， batchsize可以设置大一点\n",
        "    unsup_sampler = RandomSampler(unsup_dataset)\n",
        "    unsup_bucket_sampler = BucketBatchSampler(unsup_sampler, batch_size = int(config['batch_size'] * config['unsup_data_ratio']),\n",
        "                      drop_last = False, sort_key = lambda x: len(unsup_dataset[x][0]),# 以 input_id 长度作为排序的指标\n",
        "                      bucket_size_multiplier = config['bucket_multiplier'])\n",
        "    \n",
        "    unsup_dataloader = DataLoader(dataset = unsup_dataset, batch_sampler = unsup_bucket_sampler, num_workers = 4, collate_fn = unsup_collate_fn)\n",
        "  # 不使用桶采样\n",
        "  else:\n",
        "    # 监督数据\n",
        "    train_dataloader = DataLoader(dataset = train_dataset, batch_size = config['batch_size'], shuffle = True, num_workers = 4, collate_fn = collate_fn)\n",
        "    # 无监督数据\n",
        "    unsup_dataloader = DataLoader(dataset = unsup_dataset, batch_size = int(config['batch_size'] * config['unsup_data_ratio']), \n",
        "                    shuffle = True, num_workers = 4, collate_fn = unsup_collate_fn)\n",
        "  # 验证集、测试集dataloader 与桶采样无关 因为shuffle=false  \n",
        "  dev_dataloader = DataLoader(dataset = dev_dataset, batch_size = config['batch_size'], shuffle = False, num_workers = 4, collate_fn = collate_fn)\n",
        "  test_dataloader = DataLoader(dataset = test_dataset, batch_size = config['batch_size'], shuffle = False, num_workers = 4, collate_fn = collate_fn)\n",
        "\n",
        "  return unsup_dataloader, train_dataloader, dev_dataloader, test_dataloader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "vqM3e3pT6fnq"
      },
      "outputs": [],
      "source": [
        "unsup_dataloader, train_dataloader, dev_dataloader, test_dataloader = build_dataloader(config, data, tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sh0MvETX6phS",
        "outputId": "1f626c26-a179-4150-a265-da24b7f59b23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "traindaloader中一条数据: {'input_ids': tensor([[ 101, 5709, 1446,  711,  784,  720, 6206, 1914, 2807, 2769,  671, 4636,\n",
            "         1914, 1779,  102, 2769,  736, 3299,  819, 4638, 5709, 1446,  677, 7361,\n",
            "         3221,  115,  115,  115,  711,  784,  720, 6820, 2807,  749, 2769,  115,\n",
            "          115,  115, 2571, 1914,  102],\n",
            "        [ 101, 6010, 6009,  955, 1446,  955, 1914,  719,  711,  784,  720, 1372,\n",
            "         3300,  115,  115,  115,  702, 3299, 6821,  671,  702, 6848, 7555,  749,\n",
            "          102,  711,  784,  720,  955, 1446, 1146, 3309, 1372, 5543,  115,  115,\n",
            "          115,  702, 3299,  749,  102],\n",
            "        [ 101, 2769,  791, 1921, 1157, 6820,  749, 5709, 1446, 2582,  720, 3766,\n",
            "         4692, 1168, 7583, 2428, 2612, 1908,  102, 2582,  720, 6651, 1139,  702,\n",
            "         5709, 1446,  749, 2769, 3300, 7178, 2769, 6820, 4500, 6821,  702, 8024,\n",
            "         3766, 1762, 2692, 4692,  102],\n",
            "        [ 101,  711,  784,  720, 2769, 4638, 3905, 2140, 5709, 1446, 1146, 3309,\n",
            "         4500,  679,  749,  102,  711,  784,  720, 6631, 6814,  115,  115,  115,\n",
            "          679, 1377,  809, 5709, 1446, 1146, 3309, 8043, 3766, 3300, 3227, 4850,\n",
            "         5709, 1446, 1146, 3309,  102],\n",
            "        [ 101, 4385, 1762, 6821,  702, 2797, 3322,  677, 3766, 3300, 5709, 1446,\n",
            "         8024, 2582,  720, 1343, 6820,  809, 1184, 4638, 3621,  102,  711,  784,\n",
            "          720,  671, 4684, 3300, 5709, 1446, 6820, 3621,  928, 2622, 1355, 1168,\n",
            "         2769, 2797, 3322,  677,  102],\n",
            "        [ 101, 3300, 6874, 3309, 5279, 2497,  784,  720, 3198,  952, 2798, 1377,\n",
            "          809, 7028, 3173,  886, 4500, 6010, 6009, 5709, 1446,  102, 7309,  678,\n",
            "         2769, 4638, 5709, 1446,  784,  720, 3198,  952, 2798, 5543, 7028, 3173,\n",
            "         2458, 1423,  886, 4500,  102],\n",
            "        [ 101, 5709, 1446, 6820, 3621, 1400, 4509, 6435, 6842, 3621,  711,  784,\n",
            "          720, 6842, 1168,  749, 5709, 1446,  102, 2769, 4638, 5709, 1446, 2347,\n",
            "         5307, 6820, 3926, 8024,  852, 3221, 4509, 6435, 6842, 3621, 6842, 1168,\n",
            "          784,  720, 1765, 3175,  102],\n",
            "        [ 101, 2797, 3322, 1384, 4772, 2940,  749, 8024, 6820, 3221,  809, 1184,\n",
            "         4638, 3118,  802, 2140, 8024, 3221,  679, 3221, 2218,  679, 5543,  886,\n",
            "         4500, 5709, 1446,  749,  102, 2797, 3322, 1384, 4772, 3291, 2940, 5709,\n",
            "         1446, 4500,  679,  749,  102],\n",
            "        [ 101, 2769, 2347, 5307, 2828, 5709, 1446, 4500,  749, 4638, 6963, 2347,\n",
            "         5307, 6820,  749, 8024,  711,  784,  720, 6820, 6842, 1726, 5709, 1446,\n",
            "         4638,  102, 5709, 1446, 2347, 6820, 3926, 8024, 6842, 3621, 6432, 6842,\n",
            "         1726,  749, 5709, 1446,  102],\n",
            "        [ 101, 6010, 6009,  955, 1446, 2990, 1184, 6820,  749, 1146, 3309, 8024,\n",
            "         1168, 3309, 1400, 6820, 6206, 6820, 6821, 3309, 1408,  102,  955, 1446,\n",
            "         2990, 1184, 6820, 3621, 8024, 1168, 7564, 3309, 6820, 3621, 6820, 7444,\n",
            "         6206, 6820, 3621, 1658,  102],\n",
            "        [ 101, 1068, 2957, 1369,  671,  702, 6572, 1384, 5709, 1446, 8024, 2458,\n",
            "         6858, 6821,  702, 3118,  802, 2140,  102,  671, 2476, 6716,  819, 6395,\n",
            "         2458,  697,  702, 3118,  802, 2140, 8024, 5709, 1446, 3221,  679, 3221,\n",
            "          679, 1962, 1872, 1217,  102],\n",
            "        [ 101, 4802, 6371, 3119, 6573, 1400, 4157, 1140, 3118,  802, 2140, 2166,\n",
            "         4772, 3221, 3118,  802, 2140,  802, 3621, 6820, 3221, 5709, 1446,  802,\n",
            "         3621,  102, 6010, 6009, 5709, 1446, 3221, 1762, 4802, 2141, 3119, 6573,\n",
            "         1400, 2807, 3621, 1408,  102],\n",
            "        [ 101, 2769, 3300, 5709, 1446, 8024, 6929, 2797, 3322, 2957,  749, 8024,\n",
            "         4385, 1762, 4633, 2497,  679,  749, 2582,  720, 6820,  102, 2797, 3322,\n",
            "          696,  749, 8024, 3905, 2140, 3118,  802, 2140, 4633,  679,  749, 5709,\n",
            "         1446, 2582,  720, 6820,  102],\n",
            "        [ 101, 1555, 2157,  679, 2458, 6858, 5709, 1446, 3119, 7178, 8024, 3119,\n",
            "         3621, 3198, 6878, 1168,  928, 4500, 1305,  802, 3621, 4638, 6206, 2797,\n",
            "         5330, 6589, 1408,  102, 1555, 2157, 2797, 5709, 1446, 3119, 3621, 6206,\n",
            "         2797, 5330, 6589, 1408,  102],\n",
            "        [ 101,  955, 1446, 4638, 7178, 3766, 3300, 2802, 1168, 7213, 6121, 1305,\n",
            "         1316, 3227, 4850, 2347, 1168, 6572,  102, 6010, 6009,  955, 1446, 3227,\n",
            "         4850, 2768, 1216, 8024,  852, 1724, 2207, 3198, 6814, 1343,  749, 3766,\n",
            "         1168, 7213, 6121, 1305,  102],\n",
            "        [ 101, 1555, 2157,  886, 4500, 5709, 1446, 3119, 3621, 2553, 7557, 4500,\n",
            "         3118,  802, 2140, 5314, 4638, 3119, 7178, 4772, 1408,  102, 3119, 7178,\n",
            "         4772, 2247,  754, 1555, 2157, 6820, 3221,  702,  782, 8024, 1377,  809,\n",
            "         4500, 5709, 1446, 1408,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'labels': tensor([1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0])}\n"
          ]
        }
      ],
      "source": [
        "for i in train_dataloader:\n",
        "  print('traindaloader中一条数据:',i)\n",
        "  break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "3GRdXPnX23w4"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "def evaluation(config, model, val_dataloader):\n",
        "  model.eval()\n",
        "  preds = []\n",
        "  labels = []\n",
        "  val_loss = 0.\n",
        "  val_iterator = tqdm(val_dataloader, desc = 'Evaluation', total = len(val_dataloader))\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for batch in val_iterator:\n",
        "      labels.append(batch['labels'])\n",
        "      batch_cuda = {item: value.to(config['device']) for item, value in list(batch.items())}\n",
        "      batch_cuda['mode'] = 'val'\n",
        "      loss, logits = model(**batch_cuda)[:2]\n",
        "\n",
        "      if config['n_gpus'] > 1:\n",
        "        loss = loss.mean()\n",
        "\n",
        "      val_loss += loss.item()\n",
        "      preds.append(logits.argmax(dim = -1).detach().cpu())\n",
        "\n",
        "  avg_val_loss = val_loss / len(val_dataloader)\n",
        "  labels = torch.cat(labels, dim = 0).numpy()\n",
        "  preds = torch.cat(preds, dim = 0).numpy()\n",
        "  f1 = f1_score(labels, preds)\n",
        "  acc = accuracy_score(labels, preds)\n",
        "  return avg_val_loss, f1, acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yIptil95rf4"
      },
      "source": [
        "### 使用BertForSequenceClassification模型\n",
        "(需要复写)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wkyak05D5AL2"
      },
      "source": [
        "![BertForSequenceClassification](https://img-blog.csdnimg.cn/65a419a6c58a4b07883a3c91084e7cde.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTI4NzA2MA==,size_16,color_FFFFFF,t_70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPYrh5x25DDX"
      },
      "source": [
        "![BertForSequenceClassification1](https://img-blog.csdnimg.cn/0c2a5f0612aa4e42a1dfdf0e0352e0f2.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTI4NzA2MA==,size_16,color_FFFFFF,t_70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgrMImx9l1fU"
      },
      "source": [
        "## X.view\n",
        "```\n",
        "a = torch.randn(3,5,2)\n",
        "print(a)\n",
        "print(a.view(-1))\n",
        "```\n",
        "执行结果：\n",
        "```\n",
        "tensor([[[-0.6887,  0.2203],\n",
        "         [-1.6103, -0.7423],\n",
        "         [ 0.3097, -2.9694],\n",
        "         [ 1.2073, -0.3370],\n",
        "         [-0.5506,  0.4753]],\n",
        "\n",
        "        [[-1.3605,  1.9303],\n",
        "         [-1.5382, -1.0865],\n",
        "         [-0.9208, -0.1754],\n",
        "         [ 0.1476, -0.8866],\n",
        "         [ 0.4519,  0.2771]],\n",
        "\n",
        "        [[ 0.6662,  1.1027],\n",
        "         [-0.0912, -0.6284],\n",
        "         [-1.0253, -0.3542],\n",
        "         [ 0.6909, -1.3905],\n",
        "         [-2.1140,  1.3426]]])\n",
        "tensor([-0.6887,  0.2203, -1.6103, -0.7423,  0.3097, -2.9694,  1.2073, -0.3370,\n",
        "        -0.5506,  0.4753, -1.3605,  1.9303, -1.5382, -1.0865, -0.9208, -0.1754,\n",
        "         0.1476, -0.8866,  0.4519,  0.2771,  0.6662,  1.1027, -0.0912, -0.6284,\n",
        "        -1.0253, -0.3542,  0.6909, -1.3905, -2.1140,  1.3426])\n",
        "```\n",
        "X.view(-1)中的-1本意是根据另外一个数来自动调整维度，但是这里只有一个维度，因此就会将X里面的所有维度数据转化成一维的，并且按先后顺序排列。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "-QOVsMA849Fw"
      },
      "outputs": [],
      "source": [
        "from transformers import BertForSequenceClassification\n",
        "import torch.nn as nn\n",
        "class BertForAFQMC(BertForSequenceClassification):\n",
        "   # 复写forward\n",
        "   def forward(self, input_ids, token_type_ids, attention_mask, labels = None, mode= 'train'):\n",
        "\n",
        "     outputs = self.bert(input_ids, token_type_ids = token_type_ids, attention_mask = attention_mask, output_hidden_states = True)\n",
        "     # 维度：[batch_size, hidden_size]\n",
        "     pooled_output = outputs[1]\n",
        "     pooled_output = self.dropout(pooled_output)\n",
        "\n",
        "     logits = self.classifier(pooled_output)\n",
        "     # print('BertForAFQMC中logits：',logits)\n",
        "     outputs = (logits, )\n",
        "     # print('BertForAFQMC中outputs：',outputs)\n",
        "\n",
        "     if mode == 'val':\n",
        "       loss_fct = nn.CrossEntropyLoss()\n",
        "       # X.view(-1)中的-1本意是根据另外一个数来自动调整维度\n",
        "       loss = loss_fct(logits, labels.view(-1))\n",
        "\n",
        "       outputs = (loss, ) + outputs\n",
        "     return outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1RhTMTINzAYK"
      },
      "source": [
        "一组中：\n",
        "```\n",
        "BertForAFQMC中logits： tensor([[-0.8202,  0.0187],\n",
        "        [-0.7462,  0.2740],\n",
        "        [-0.8858,  0.3251],\n",
        "        [-0.5850, -0.0393],\n",
        "        [ 0.1496,  0.2556],\n",
        "        [-0.9169, -0.1298],\n",
        "        [-0.8008,  0.0615],\n",
        "        [-0.7671,  0.1412],\n",
        "        [-1.0368,  0.1229],\n",
        "        [-0.7881,  0.0400],\n",
        "        [-0.6721, -0.3433],\n",
        "        [-1.3198, -0.2528],\n",
        "        [-0.4168,  0.2610],\n",
        "        [-1.0321,  0.5436],\n",
        "        [-0.9334, -0.1720],\n",
        "        [-0.7633, -0.2436],\n",
        "        [-1.0511,  0.0330],\n",
        "        [-0.6819, -0.0422],\n",
        "        [-0.7017,  0.3001],\n",
        "        [-0.6800, -0.2233],\n",
        "        [-0.6387,  0.0239],\n",
        "        [-0.8804, -0.3109],\n",
        "        [-0.9353, -0.0015],\n",
        "        [-0.7683, -0.2950]], device='cuda:0')\n",
        "```\n",
        "```\n",
        "BertForAFQMC中outputs： (tensor([[-0.8202,  0.0187],\n",
        "        [-0.7462,  0.2740],\n",
        "        [-0.8858,  0.3251],\n",
        "        [-0.5850, -0.0393],\n",
        "        [ 0.1496,  0.2556],\n",
        "        [-0.9169, -0.1298],\n",
        "        [-0.8008,  0.0615],\n",
        "        [-0.7671,  0.1412],\n",
        "        [-1.0368,  0.1229],\n",
        "        [-0.7881,  0.0400],\n",
        "        [-0.6721, -0.3433],\n",
        "        [-1.3198, -0.2528],\n",
        "        [-0.4168,  0.2610],\n",
        "        [-1.0321,  0.5436],\n",
        "        [-0.9334, -0.1720],\n",
        "        [-0.7633, -0.2436],\n",
        "        [-1.0511,  0.0330],\n",
        "        [-0.6819, -0.0422],\n",
        "        [-0.7017,  0.3001],\n",
        "        [-0.6800, -0.2233],\n",
        "        [-0.6387,  0.0239],\n",
        "        [-0.8804, -0.3109],\n",
        "        [-0.9353, -0.0015],\n",
        "        [-0.7683, -0.2950]], device='cuda:0'),)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8df1pqx2m9_8"
      },
      "source": [
        "## --------------------------------------------------下回分解------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "VdEcXP8im3yt"
      },
      "outputs": [],
      "source": [
        "def get_tsa_threshold(total_steps, global_steps):\n",
        "    return np.exp((global_steps / total_steps - 1) * 5) / 2 + 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "1d89wJ2VqzT0"
      },
      "outputs": [],
      "source": [
        "# 返回 grad_data：需要计算梯度，需要进行反向传播的数据\n",
        "# 返回 no_grad_data: 不需要计算梯度，不需要进行反向传播的数据\n",
        "def get_data(sup_batch, unsup_batch, config):\n",
        "    grad_data = {}\n",
        "    no_grad_data = {}\n",
        "    # sup_batch [bs, seq_len]\n",
        "    # unsup_batch [bs, seq_len]\n",
        "    # 监督数据的 最长 长度\n",
        "    sup_max_len = sup_batch['input_ids'].size(1)\n",
        "\n",
        "    # 无监督数据 的最长 长度\n",
        "    unsup_max_len = unsup_batch['ba_input_ids'].size(1)\n",
        "\n",
        "    # 当前数据 的最长 长度\n",
        "    cur_max_len = max(sup_max_len, unsup_max_len)\n",
        "\n",
        "    for item, sup_value in sup_batch.items():\n",
        "        if item == 'labels':\n",
        "            grad_data[item] = sup_value.to(config['device'])\n",
        "            continue\n",
        "        \n",
        "        ba_unsup_value = unsup_batch[f'ba_{item}']\n",
        "        ab_unsup_value = unsup_batch[f'ab_{item}']\n",
        "\n",
        "        # 谁短补谁，ba_unsup_value短\n",
        "        if sup_max_len == cur_max_len:\n",
        "            padding_value = torch.zeros((ba_unsup_value.size(0), cur_max_len - unsup_max_len),\n",
        "                                        dtype=ba_unsup_value.dtype)\n",
        "            ba_unsup_value = torch.cat([ba_unsup_value, padding_value], dim=-1)\n",
        "\n",
        "        else:\n",
        "            padding_value = torch.zeros((sup_value.size(0), cur_max_len - sup_max_len),\n",
        "                                        dtype=sup_value.dtype)\n",
        "            sup_value = torch.cat([sup_value, padding_value], dim=-1)\n",
        "        \n",
        "        # 把 sup_batch 和 ba 的 数据放在一起\n",
        "        grad_value = torch.cat([sup_value, ba_unsup_value], dim=0)\n",
        "\n",
        "        grad_data[item] = grad_value.to(config['device'])\n",
        "        no_grad_data[item] = ab_unsup_value.to(config['device'])\n",
        "\n",
        "    return grad_data, no_grad_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "taHw45WuqrMM"
      },
      "outputs": [],
      "source": [
        "def forward_no_grad(no_grad_data, config, model):\n",
        "    with torch.no_grad():\n",
        "        np_grad_logits = model(**no_grad_data)[0]\n",
        "        # ----------- sharpen -------------#\n",
        "        no_grad_probs = torch.softmax(np_grad_logits / config['uda_softmax_temp'], dim=-1)\n",
        "        # ----------- sharpen -------------#\n",
        "        # largest_probs [B] [0.879, 0.987, 0.234, 0.768, 0.333]\n",
        "        largest_probs, _= no_grad_probs.max(dim=-1)\n",
        "        unsup_loss_mask = largest_probs.gt(config['uda_confidence_threshold']).float()\n",
        "        # unsup_loss_mask tensor([True, True, False, True, False])\n",
        "    return unsup_loss_mask, no_grad_probs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "-gGKeVo_q3Ik"
      },
      "outputs": [],
      "source": [
        "def forward_with_grad(unsup_loss_mask, unsup_probs, config, cur_bs, \n",
        "    model, grad_data, total_steps, global_steps):\n",
        "    # 得到\\eta值， 随着训练的进行，阈值逐渐变大，最后是1，把所有监督数据都用上了\n",
        "    tsa_threshold = get_tsa_threshold(total_steps, global_steps)\n",
        "    \n",
        "    logits = model(**grad_data)[0]\n",
        "    # --------- 有监督损失 -------#\n",
        "    # cur_bs 无监督 ba 的 batch_size\n",
        "    # 前面一部分是 train 的 sup_data, 后面是unsup_data\n",
        "    sup_logits, unsup_logits = logits.split([logits.size(0)-cur_bs, cur_bs])\n",
        "\n",
        "    # 得到 sup_labels\n",
        "    sup_labels = grad_data['labels'][:logits.size(0)-cur_bs]\n",
        "\n",
        "    per_example_loss = nn.CrossEntropyLoss(reduction='none')(sup_logits, sup_labels)\n",
        "    \n",
        "    # 拿出 正确标签 对应的概率\n",
        "    correct_label_probs = torch.softmax(sup_logits, dim=-1).gather(dim=-1, index=sup_labels.view(-1, 1))\n",
        "    \n",
        "    # 监督数据 过于自信不要，留下小于等于 tsa_threshold 的计算损失\n",
        "    sup_loss_mask = correct_label_probs.le(tsa_threshold).squeeze().float()\n",
        "    \n",
        "    # 应用mask掩盖有监督数据过度自信的样本损失\n",
        "    per_example_loss *= sup_loss_mask\n",
        "    \n",
        "    # 有效监督样本的平均损失\n",
        "    sup_loss = per_example_loss.sum()/max(sup_loss_mask.sum(), 1) # max(sup_loss_mask.sum(), 1) 有效个数\n",
        "    # --------- 有监督损失 -------#\n",
        "\n",
        "\n",
        "    # --------- 无监督损失 -------#\n",
        "    unsup_log_probs = torch.log_softmax(unsup_logits, dim=-1)\n",
        "    # input 希望是一个对数概率\n",
        "    # Target 目标为概率值\n",
        "    per_example_kl_loss = nn.KLDivLoss(reduction='none')(unsup_log_probs, unsup_probs).sum(dim=-1)\n",
        "\n",
        "    # 应用mask掩盖无监督数据中不自信的样本损失\n",
        "    per_example_kl_loss *= unsup_loss_mask\n",
        "\n",
        "    # 计算无监督样本的平均损失\n",
        "    unsup_loss = per_example_kl_loss.sum()/max(unsup_loss_mask.sum(), 1)\n",
        "    # --------- 无监督损失 -------#\n",
        "\n",
        "    # 加权两种损失\n",
        "    loss = sup_loss + unsup_loss\n",
        "\n",
        "    # 多卡取平均\n",
        "    if config['n_gpus']>1:\n",
        "        loss = loss.mean()\n",
        "        sup_loss = sup_loss.mean()\n",
        "        unsup_loss = unsup_loss.mean()\n",
        "    \n",
        "    return loss, tsa_threshold, unsup_loss, sup_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "TZtbDPxOm82t"
      },
      "outputs": [],
      "source": [
        "from transformers import AdamW\n",
        "from tqdm import trange\n",
        "import os\n",
        "def train(config, train_dataloader, dev_dataloader, unsup_dataloader=None):\n",
        "    model = BertForAFQMC.from_pretrained(config['model_path'])\n",
        "\n",
        "    optimizer = AdamW(model.parameters(), lr=config['learning_rate'], weight_decay=config['weight_decay'])\n",
        "    model.to(config['device'])\n",
        "    # unsup_dataloader train, dev, test\n",
        "    # 使用 unsup_dataloader，因为unsup_dataloader比较大\n",
        "    total_steps = len(unsup_dataloader) * config['num_epochs']\n",
        "    epoch_iterator = trange(config['num_epochs'])\n",
        "    global_steps = 0\n",
        "    train_loss = 0.\n",
        "    logging_loss = 0.\n",
        "    best_acc = 0.\n",
        "    best_model_path = ''\n",
        "\n",
        "    if config['n_gpus'] > 1:\n",
        "        model = nn.DataParallel(model)\n",
        "\n",
        "    train_iterator = iter(train_dataloader)\n",
        "    for _ in epoch_iterator:\n",
        "        unsup_iterator = tqdm(unsup_dataloader, desc='Training', total=len(unsup_dataloader))\n",
        "        model.train()\n",
        "        # ----------------------- new ----------------------#\n",
        "        for unsup_batch in unsup_iterator:\n",
        "            cur_bs = unsup_batch['ab_input_ids'].size(0)\n",
        "            try:\n",
        "                sup_batch = next(train_iterator)\n",
        "            except StopIteration:\n",
        "                train_iterator = iter(train_dataloader)\n",
        "                sup_batch = next(train_iterator)\n",
        "            \n",
        "            # 返回 grad_data：需要计算梯度，需要进行反向传播的数据\n",
        "            # 返回 no_grad_data: 不需要计算梯度，不需要进行反向传播的数据\n",
        "            grad_data, no_grad_data = get_data(sup_batch, unsup_batch, config)\n",
        "            \n",
        "            # 无监督数据 (ab) 只需要正向传播\n",
        "            # mask, ab_logits\n",
        "            unsup_loss_mask, unsup_probs = forward_no_grad(no_grad_data, config, model)\n",
        "             \n",
        "            # 得出loss\n",
        "            loss, tsa_threshold, unsup_loss, sup_loss = forward_with_grad(\n",
        "                unsup_loss_mask, unsup_probs, config, cur_bs, model, grad_data, total_steps, global_steps\n",
        "            )\n",
        "            \n",
        "\n",
        "            model.zero_grad()\n",
        "            loss.backward()\n",
        "\n",
        "            nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            optimizer.step()\n",
        "\n",
        "            if config['ema_start']:\n",
        "                ema.update()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "            global_steps += 1\n",
        "\n",
        "            unsup_iterator.set_postfix_str(f'running training loss: {loss.item():.4f}')\n",
        "        \n",
        "            if global_steps % config['logging_step'] == 0:\n",
        "                if global_steps >= config['ema_start_step'] and not config['ema_start']:\n",
        "                    print('\\n>>> EMA starting ...')\n",
        "                    config['ema_start'] = True\n",
        "                    ema = EMA(model.module if hasattr(model, 'module') else model, decay=0.999)\n",
        "\n",
        "                print_train_loss = (train_loss - logging_loss) / config['logging_step']\n",
        "                logging_loss = train_loss\n",
        "\n",
        "                if config['ema_start']:\n",
        "                    ema.apply_shadow()\n",
        "                val_loss, f1, acc = evaluation(config, model, dev_dataloader)\n",
        "\n",
        "                print_log = f'\\n>>> training loss: {print_train_loss:.6f}, valid loss: {val_loss:.6f}, '\n",
        "\n",
        "                if acc > best_acc:\n",
        "                    model_save_path = os.path.join(config['output_path'],\n",
        "                                                   f'checkpoint-{global_steps}-{acc:.6f}')\n",
        "                    model_to_save = model.module if hasattr(model, 'module') else model\n",
        "                    model_to_save.save_pretrained(model_save_path)\n",
        "                    best_acc = acc\n",
        "                    best_model_path = model_save_path\n",
        "\n",
        "                print_log += f'valid f1: {f1:.6f}, valid acc: {acc:.6f}'\n",
        "\n",
        "                print(print_log)\n",
        "                model.train()\n",
        "                if config['ema_start']:\n",
        "                    ema.restore()\n",
        "\n",
        "    return model, best_model_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Eoo6QvUnEBV",
        "outputId": "3d453378-cf98-4d8e-d4d7-8a015d4a6ae7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at /content/drive/MyDrive/Colab Notebooks/dataset/BERT_model were not used when initializing BertForAFQMC: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForAFQMC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForAFQMC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForAFQMC were not initialized from the model checkpoint at /content/drive/MyDrive/Colab Notebooks/dataset/BERT_model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "Training:   0%|          | 0/1772 [00:00<?, ?it/s]\u001b[A\n",
            "Training:   0%|          | 0/1772 [00:00<?, ?it/s, running training loss: 1.0623]\u001b[A\n",
            "Training:   0%|          | 1/1772 [00:00<23:09,  1.27it/s, running training loss: 1.0623]\u001b[A\n",
            "Training:   0%|          | 1/1772 [00:01<23:09,  1.27it/s, running training loss: 0.8257]\u001b[A\n",
            "Training:   0%|          | 2/1772 [00:01<14:19,  2.06it/s, running training loss: 0.8257]\u001b[A\n",
            "Training:   0%|          | 2/1772 [00:01<14:19,  2.06it/s, running training loss: 1.1751]\u001b[A\n",
            "Training:   0%|          | 3/1772 [00:01<11:22,  2.59it/s, running training loss: 1.1751]\u001b[A\n",
            "Training:   0%|          | 3/1772 [00:01<11:22,  2.59it/s, running training loss: 1.0525]\u001b[A\n",
            "Training:   0%|          | 4/1772 [00:01<11:00,  2.68it/s, running training loss: 1.0525]\u001b[A\n",
            "Training:   0%|          | 4/1772 [00:02<11:00,  2.68it/s, running training loss: 1.1249]\u001b[A\n",
            "Training:   0%|          | 5/1772 [00:02<10:57,  2.69it/s, running training loss: 1.1249]\u001b[A\n",
            "Training:   0%|          | 5/1772 [00:02<10:57,  2.69it/s, running training loss: 1.0534]\u001b[A\n",
            "Training:   0%|          | 6/1772 [00:02<10:44,  2.74it/s, running training loss: 1.0534]\u001b[A\n",
            "Training:   0%|          | 6/1772 [00:02<10:44,  2.74it/s, running training loss: 1.0247]\u001b[A\n",
            "Training:   0%|          | 7/1772 [00:02<11:26,  2.57it/s, running training loss: 1.0247]\u001b[A\n",
            "Training:   0%|          | 7/1772 [00:03<11:26,  2.57it/s, running training loss: 1.0334]\u001b[A\n",
            "Training:   0%|          | 8/1772 [00:03<10:25,  2.82it/s, running training loss: 1.0334]\u001b[A\n",
            "Training:   0%|          | 8/1772 [00:03<10:25,  2.82it/s, running training loss: 1.0414]\u001b[A\n",
            "Training:   1%|          | 9/1772 [00:03<09:21,  3.14it/s, running training loss: 1.0414]\u001b[A\n",
            "Training:   1%|          | 9/1772 [00:03<09:21,  3.14it/s, running training loss: 0.9884]\u001b[A\n",
            "Training:   1%|          | 10/1772 [00:03<08:55,  3.29it/s, running training loss: 0.9884]\u001b[A\n",
            "Training:   1%|          | 10/1772 [00:03<08:55,  3.29it/s, running training loss: 1.1281]\u001b[A\n",
            "Training:   1%|          | 11/1772 [00:03<08:37,  3.40it/s, running training loss: 1.1281]\u001b[A\n",
            "Training:   1%|          | 11/1772 [00:04<08:37,  3.40it/s, running training loss: 1.0044]\u001b[A\n",
            "Training:   1%|          | 12/1772 [00:04<08:53,  3.30it/s, running training loss: 1.0044]\u001b[A\n",
            "Training:   1%|          | 12/1772 [00:04<08:53,  3.30it/s, running training loss: 1.0510]\u001b[A\n",
            "Training:   1%|          | 13/1772 [00:04<08:25,  3.48it/s, running training loss: 1.0510]\u001b[A\n",
            "Training:   1%|          | 13/1772 [00:04<08:25,  3.48it/s, running training loss: 1.2043]\u001b[A\n",
            "Training:   1%|          | 14/1772 [00:04<08:13,  3.56it/s, running training loss: 1.2043]\u001b[A\n",
            "Training:   1%|          | 14/1772 [00:05<08:13,  3.56it/s, running training loss: 0.9311]\u001b[A\n",
            "Training:   1%|          | 15/1772 [00:05<08:57,  3.27it/s, running training loss: 0.9311]\u001b[A\n",
            "Training:   1%|          | 15/1772 [00:05<08:57,  3.27it/s, running training loss: 0.9935]\u001b[A\n",
            "Training:   1%|          | 16/1772 [00:05<08:29,  3.45it/s, running training loss: 0.9935]\u001b[A\n",
            "Training:   1%|          | 16/1772 [00:05<08:29,  3.45it/s, running training loss: 1.0920]\u001b[A\n",
            "Training:   1%|          | 17/1772 [00:05<08:24,  3.48it/s, running training loss: 1.0920]\u001b[A\n",
            "Training:   1%|          | 17/1772 [00:05<08:24,  3.48it/s, running training loss: 0.9854]\u001b[A\n",
            "Training:   1%|          | 18/1772 [00:05<08:36,  3.40it/s, running training loss: 0.9854]\u001b[A\n",
            "Training:   1%|          | 18/1772 [00:06<08:36,  3.40it/s, running training loss: 0.8835]\u001b[A\n",
            "Training:   1%|          | 19/1772 [00:06<08:46,  3.33it/s, running training loss: 0.8835]\u001b[A\n",
            "Training:   1%|          | 19/1772 [00:06<08:46,  3.33it/s, running training loss: 0.8670]\u001b[A\n",
            "Training:   1%|          | 20/1772 [00:06<09:22,  3.11it/s, running training loss: 0.8670]\u001b[A\n",
            "Training:   1%|          | 20/1772 [00:06<09:22,  3.11it/s, running training loss: 0.9966]\u001b[A\n",
            "Training:   1%|          | 21/1772 [00:06<08:42,  3.35it/s, running training loss: 0.9966]\u001b[A\n",
            "Training:   1%|          | 21/1772 [00:07<08:42,  3.35it/s, running training loss: 0.9919]\u001b[A\n",
            "Training:   1%|          | 22/1772 [00:07<10:04,  2.89it/s, running training loss: 0.9919]\u001b[A\n",
            "Training:   1%|          | 22/1772 [00:07<10:04,  2.89it/s, running training loss: 1.1801]\u001b[A\n",
            "Training:   1%|▏         | 23/1772 [00:07<09:02,  3.22it/s, running training loss: 1.1801]\u001b[A\n",
            "Training:   1%|▏         | 23/1772 [00:07<09:02,  3.22it/s, running training loss: 1.1378]\u001b[A\n",
            "Training:   1%|▏         | 24/1772 [00:07<08:38,  3.37it/s, running training loss: 1.1378]\u001b[A\n",
            "Training:   1%|▏         | 24/1772 [00:08<08:38,  3.37it/s, running training loss: 0.9305]\u001b[A\n",
            "Training:   1%|▏         | 25/1772 [00:08<09:06,  3.20it/s, running training loss: 0.9305]\u001b[A\n",
            "Training:   1%|▏         | 25/1772 [00:08<09:06,  3.20it/s, running training loss: 1.0068]\u001b[A\n",
            "Training:   1%|▏         | 26/1772 [00:08<08:18,  3.50it/s, running training loss: 1.0068]\u001b[A\n",
            "Training:   1%|▏         | 26/1772 [00:08<08:18,  3.50it/s, running training loss: 1.1043]\u001b[A\n",
            "Training:   2%|▏         | 27/1772 [00:08<07:52,  3.69it/s, running training loss: 1.1043]\u001b[A\n",
            "Training:   2%|▏         | 27/1772 [00:09<07:52,  3.69it/s, running training loss: 1.1038]\u001b[A\n",
            "Training:   2%|▏         | 28/1772 [00:09<09:48,  2.96it/s, running training loss: 1.1038]\u001b[A\n",
            "Training:   2%|▏         | 28/1772 [00:09<09:48,  2.96it/s, running training loss: 1.0665]\u001b[A\n",
            "Training:   2%|▏         | 29/1772 [00:09<09:32,  3.05it/s, running training loss: 1.0665]\u001b[A\n",
            "Training:   2%|▏         | 29/1772 [00:09<09:32,  3.05it/s, running training loss: 1.0144]\u001b[A\n",
            "Training:   2%|▏         | 30/1772 [00:09<09:05,  3.19it/s, running training loss: 1.0144]\u001b[A\n",
            "Training:   2%|▏         | 30/1772 [00:10<09:05,  3.19it/s, running training loss: 0.9881]\u001b[A\n",
            "Training:   2%|▏         | 31/1772 [00:10<09:19,  3.11it/s, running training loss: 0.9881]\u001b[A\n",
            "Training:   2%|▏         | 31/1772 [00:10<09:19,  3.11it/s, running training loss: 0.9633]\u001b[A\n",
            "Training:   2%|▏         | 32/1772 [00:10<09:23,  3.09it/s, running training loss: 0.9633]\u001b[A\n",
            "Training:   2%|▏         | 32/1772 [00:10<09:23,  3.09it/s, running training loss: 1.0209]\u001b[A\n",
            "Training:   2%|▏         | 33/1772 [00:10<08:44,  3.32it/s, running training loss: 1.0209]\u001b[A\n",
            "Training:   2%|▏         | 33/1772 [00:10<08:44,  3.32it/s, running training loss: 0.9410]\u001b[A\n",
            "Training:   2%|▏         | 34/1772 [00:10<08:24,  3.44it/s, running training loss: 0.9410]\u001b[A\n",
            "Training:   2%|▏         | 34/1772 [00:11<08:24,  3.44it/s, running training loss: 1.0531]\u001b[A\n",
            "Training:   2%|▏         | 35/1772 [00:11<08:08,  3.56it/s, running training loss: 1.0531]\u001b[A\n",
            "Training:   2%|▏         | 35/1772 [00:11<08:08,  3.56it/s, running training loss: 1.0053]\u001b[A\n",
            "Training:   2%|▏         | 36/1772 [00:11<08:38,  3.35it/s, running training loss: 1.0053]\u001b[A\n",
            "Training:   2%|▏         | 36/1772 [00:11<08:38,  3.35it/s, running training loss: 1.0380]\u001b[A\n",
            "Training:   2%|▏         | 37/1772 [00:11<08:18,  3.48it/s, running training loss: 1.0380]\u001b[A\n",
            "Training:   2%|▏         | 37/1772 [00:11<08:18,  3.48it/s, running training loss: 1.0093]\u001b[A\n",
            "Training:   2%|▏         | 38/1772 [00:11<07:51,  3.68it/s, running training loss: 1.0093]\u001b[A\n",
            "Training:   2%|▏         | 38/1772 [00:12<07:51,  3.68it/s, running training loss: 1.1516]\u001b[A\n",
            "Training:   2%|▏         | 39/1772 [00:12<07:43,  3.73it/s, running training loss: 1.1516]\u001b[A\n",
            "Training:   2%|▏         | 39/1772 [00:12<07:43,  3.73it/s, running training loss: 0.9991]\u001b[A\n",
            "Training:   2%|▏         | 40/1772 [00:12<07:40,  3.76it/s, running training loss: 0.9991]\u001b[A\n",
            "Training:   2%|▏         | 40/1772 [00:12<07:40,  3.76it/s, running training loss: 1.0377]\u001b[A\n",
            "Training:   2%|▏         | 41/1772 [00:12<07:44,  3.73it/s, running training loss: 1.0377]\u001b[A\n",
            "Training:   2%|▏         | 41/1772 [00:13<07:44,  3.73it/s, running training loss: 1.0154]\u001b[A\n",
            "Training:   2%|▏         | 42/1772 [00:13<07:31,  3.83it/s, running training loss: 1.0154]\u001b[A\n",
            "Training:   2%|▏         | 42/1772 [00:13<07:31,  3.83it/s, running training loss: 1.2238]\u001b[A\n",
            "Training:   2%|▏         | 43/1772 [00:13<07:50,  3.67it/s, running training loss: 1.2238]\u001b[A\n",
            "Training:   2%|▏         | 43/1772 [00:13<07:50,  3.67it/s, running training loss: 1.0184]\u001b[A\n",
            "Training:   2%|▏         | 44/1772 [00:13<08:19,  3.46it/s, running training loss: 1.0184]\u001b[A\n",
            "Training:   2%|▏         | 44/1772 [00:13<08:19,  3.46it/s, running training loss: 1.0559]\u001b[A\n",
            "Training:   3%|▎         | 45/1772 [00:13<08:02,  3.58it/s, running training loss: 1.0559]\u001b[A\n",
            "Training:   3%|▎         | 45/1772 [00:14<08:02,  3.58it/s, running training loss: 1.0652]\u001b[A\n",
            "Training:   3%|▎         | 46/1772 [00:14<08:10,  3.52it/s, running training loss: 1.0652]\u001b[A\n",
            "Training:   3%|▎         | 46/1772 [00:14<08:10,  3.52it/s, running training loss: 1.1525]\u001b[A\n",
            "Training:   3%|▎         | 47/1772 [00:14<08:17,  3.47it/s, running training loss: 1.1525]\u001b[A\n",
            "Training:   3%|▎         | 47/1772 [00:14<08:17,  3.47it/s, running training loss: 1.0923]\u001b[A\n",
            "Training:   3%|▎         | 48/1772 [00:14<08:12,  3.50it/s, running training loss: 1.0923]\u001b[A\n",
            "Training:   3%|▎         | 48/1772 [00:15<08:12,  3.50it/s, running training loss: 0.9052]\u001b[A\n",
            "Training:   3%|▎         | 49/1772 [00:15<08:00,  3.59it/s, running training loss: 0.9052]\u001b[A\n",
            "Training:   3%|▎         | 49/1772 [00:15<08:00,  3.59it/s, running training loss: 0.9547]\u001b[A\n",
            "Training:   3%|▎         | 50/1772 [00:15<07:56,  3.61it/s, running training loss: 0.9547]\u001b[A\n",
            "Training:   3%|▎         | 50/1772 [00:15<07:56,  3.61it/s, running training loss: 1.0391]\u001b[A\n",
            "Training:   3%|▎         | 51/1772 [00:15<07:26,  3.86it/s, running training loss: 1.0391]\u001b[A\n",
            "Training:   3%|▎         | 51/1772 [00:15<07:26,  3.86it/s, running training loss: 1.0607]\u001b[A\n",
            "Training:   3%|▎         | 52/1772 [00:15<08:27,  3.39it/s, running training loss: 1.0607]\u001b[A\n",
            "Training:   3%|▎         | 52/1772 [00:16<08:27,  3.39it/s, running training loss: 0.7831]\u001b[A\n",
            "Training:   3%|▎         | 53/1772 [00:16<07:52,  3.64it/s, running training loss: 0.7831]\u001b[A\n",
            "Training:   3%|▎         | 53/1772 [00:16<07:52,  3.64it/s, running training loss: 0.9740]\u001b[A\n",
            "Training:   3%|▎         | 54/1772 [00:16<07:58,  3.59it/s, running training loss: 0.9740]\u001b[A\n",
            "Training:   3%|▎         | 54/1772 [00:16<07:58,  3.59it/s, running training loss: 0.8661]\u001b[A\n",
            "Training:   3%|▎         | 55/1772 [00:16<08:15,  3.47it/s, running training loss: 0.8661]\u001b[A\n",
            "Training:   3%|▎         | 55/1772 [00:17<08:15,  3.47it/s, running training loss: 1.0161]\u001b[A\n",
            "Training:   3%|▎         | 56/1772 [00:17<09:36,  2.98it/s, running training loss: 1.0161]\u001b[A\n",
            "Training:   3%|▎         | 56/1772 [00:17<09:36,  2.98it/s, running training loss: 0.9827]\u001b[A\n",
            "Training:   3%|▎         | 57/1772 [00:17<08:55,  3.20it/s, running training loss: 0.9827]\u001b[A\n",
            "Training:   3%|▎         | 57/1772 [00:17<08:55,  3.20it/s, running training loss: 0.8100]\u001b[A\n",
            "Training:   3%|▎         | 58/1772 [00:17<08:26,  3.38it/s, running training loss: 0.8100]\u001b[A\n",
            "Training:   3%|▎         | 58/1772 [00:17<08:26,  3.38it/s, running training loss: 1.0353]\u001b[A\n",
            "Training:   3%|▎         | 59/1772 [00:17<08:07,  3.52it/s, running training loss: 1.0353]\u001b[A\n",
            "Training:   3%|▎         | 59/1772 [00:18<08:07,  3.52it/s, running training loss: 1.0074]\u001b[A\n",
            "Training:   3%|▎         | 60/1772 [00:18<08:19,  3.43it/s, running training loss: 1.0074]\u001b[A\n",
            "Training:   3%|▎         | 60/1772 [00:18<08:19,  3.43it/s, running training loss: 1.0235]\u001b[A\n",
            "Training:   3%|▎         | 61/1772 [00:18<09:42,  2.94it/s, running training loss: 1.0235]\u001b[A\n",
            "Training:   3%|▎         | 61/1772 [00:19<09:42,  2.94it/s, running training loss: 0.9271]\u001b[A\n",
            "Training:   3%|▎         | 62/1772 [00:19<09:43,  2.93it/s, running training loss: 0.9271]\u001b[A\n",
            "Training:   3%|▎         | 62/1772 [00:19<09:43,  2.93it/s, running training loss: 0.9895]\u001b[A\n",
            "Training:   4%|▎         | 63/1772 [00:19<09:25,  3.02it/s, running training loss: 0.9895]\u001b[A\n",
            "Training:   4%|▎         | 63/1772 [00:19<09:25,  3.02it/s, running training loss: 1.0060]\u001b[A\n",
            "Training:   4%|▎         | 64/1772 [00:19<09:47,  2.91it/s, running training loss: 1.0060]\u001b[A\n",
            "Training:   4%|▎         | 64/1772 [00:20<09:47,  2.91it/s, running training loss: 1.1815]\u001b[A\n",
            "Training:   4%|▎         | 65/1772 [00:20<09:37,  2.95it/s, running training loss: 1.1815]\u001b[A\n",
            "Training:   4%|▎         | 65/1772 [00:20<09:37,  2.95it/s, running training loss: 0.9763]\u001b[A\n",
            "Training:   4%|▎         | 66/1772 [00:20<08:49,  3.22it/s, running training loss: 0.9763]\u001b[A\n",
            "Training:   4%|▎         | 66/1772 [00:20<08:49,  3.22it/s, running training loss: 1.0771]\u001b[A\n",
            "Training:   4%|▍         | 67/1772 [00:20<08:30,  3.34it/s, running training loss: 1.0771]\u001b[A\n",
            "Training:   4%|▍         | 67/1772 [00:21<08:30,  3.34it/s, running training loss: 0.9852]\u001b[A\n",
            "Training:   4%|▍         | 68/1772 [00:21<09:41,  2.93it/s, running training loss: 0.9852]\u001b[A\n",
            "Training:   4%|▍         | 68/1772 [00:21<09:41,  2.93it/s, running training loss: 0.8948]\u001b[A\n",
            "Training:   4%|▍         | 69/1772 [00:21<09:14,  3.07it/s, running training loss: 0.8948]\u001b[A\n",
            "Training:   4%|▍         | 69/1772 [00:21<09:14,  3.07it/s, running training loss: 0.9768]\u001b[A\n",
            "Training:   4%|▍         | 70/1772 [00:21<09:21,  3.03it/s, running training loss: 0.9768]\u001b[A\n",
            "Training:   4%|▍         | 70/1772 [00:22<09:21,  3.03it/s, running training loss: 1.0556]\u001b[A\n",
            "Training:   4%|▍         | 71/1772 [00:22<09:34,  2.96it/s, running training loss: 1.0556]\u001b[A\n",
            "Training:   4%|▍         | 71/1772 [00:22<09:34,  2.96it/s, running training loss: 1.0188]\u001b[A\n",
            "Training:   4%|▍         | 72/1772 [00:22<09:05,  3.12it/s, running training loss: 1.0188]\u001b[A\n",
            "Training:   4%|▍         | 72/1772 [00:22<09:05,  3.12it/s, running training loss: 0.8966]\u001b[A\n",
            "Training:   4%|▍         | 73/1772 [00:22<08:33,  3.31it/s, running training loss: 0.8966]\u001b[A\n",
            "Training:   4%|▍         | 73/1772 [00:22<08:33,  3.31it/s, running training loss: 1.2116]\u001b[A\n",
            "Training:   4%|▍         | 74/1772 [00:22<08:21,  3.38it/s, running training loss: 1.2116]\u001b[A\n",
            "Training:   4%|▍         | 74/1772 [00:23<08:21,  3.38it/s, running training loss: 1.1382]\u001b[A\n",
            "Training:   4%|▍         | 75/1772 [00:23<08:06,  3.49it/s, running training loss: 1.1382]\u001b[A\n",
            "Training:   4%|▍         | 75/1772 [00:23<08:06,  3.49it/s, running training loss: 1.1347]\u001b[A\n",
            "Training:   4%|▍         | 76/1772 [00:23<09:29,  2.98it/s, running training loss: 1.1347]\u001b[A\n",
            "Training:   4%|▍         | 76/1772 [00:23<09:29,  2.98it/s, running training loss: 0.9913]\u001b[A\n",
            "Training:   4%|▍         | 77/1772 [00:23<09:36,  2.94it/s, running training loss: 0.9913]\u001b[A\n",
            "Training:   4%|▍         | 77/1772 [00:24<09:36,  2.94it/s, running training loss: 0.9348]\u001b[A\n",
            "Training:   4%|▍         | 78/1772 [00:24<08:51,  3.19it/s, running training loss: 0.9348]\u001b[A\n",
            "Training:   4%|▍         | 78/1772 [00:24<08:51,  3.19it/s, running training loss: 1.0849]\u001b[A\n",
            "Training:   4%|▍         | 79/1772 [00:24<09:47,  2.88it/s, running training loss: 1.0849]\u001b[A\n",
            "Training:   4%|▍         | 79/1772 [00:24<09:47,  2.88it/s, running training loss: 1.3818]\u001b[A\n",
            "Training:   5%|▍         | 80/1772 [00:24<09:00,  3.13it/s, running training loss: 1.3818]\u001b[A\n",
            "Training:   5%|▍         | 80/1772 [00:25<09:00,  3.13it/s, running training loss: 0.9796]\u001b[A\n",
            "Training:   5%|▍         | 81/1772 [00:25<09:28,  2.97it/s, running training loss: 0.9796]\u001b[A\n",
            "Training:   5%|▍         | 81/1772 [00:25<09:28,  2.97it/s, running training loss: 1.1245]\u001b[A\n",
            "Training:   5%|▍         | 82/1772 [00:25<09:09,  3.08it/s, running training loss: 1.1245]\u001b[A\n",
            "Training:   5%|▍         | 82/1772 [00:25<09:09,  3.08it/s, running training loss: 1.1080]\u001b[A\n",
            "Training:   5%|▍         | 83/1772 [00:25<08:24,  3.35it/s, running training loss: 1.1080]\u001b[A\n",
            "Training:   5%|▍         | 83/1772 [00:25<08:24,  3.35it/s, running training loss: 1.0683]\u001b[A\n",
            "Training:   5%|▍         | 84/1772 [00:25<07:48,  3.61it/s, running training loss: 1.0683]\u001b[A\n",
            "Training:   5%|▍         | 84/1772 [00:26<07:48,  3.61it/s, running training loss: 0.8997]\u001b[A\n",
            "Training:   5%|▍         | 85/1772 [00:26<07:58,  3.53it/s, running training loss: 0.8997]\u001b[A\n",
            "Training:   5%|▍         | 85/1772 [00:26<07:58,  3.53it/s, running training loss: 0.9484]\u001b[A\n",
            "Training:   5%|▍         | 86/1772 [00:26<07:41,  3.66it/s, running training loss: 0.9484]\u001b[A\n",
            "Training:   5%|▍         | 86/1772 [00:26<07:41,  3.66it/s, running training loss: 0.9117]\u001b[A\n",
            "Training:   5%|▍         | 87/1772 [00:26<08:41,  3.23it/s, running training loss: 0.9117]\u001b[A\n",
            "Training:   5%|▍         | 87/1772 [00:27<08:41,  3.23it/s, running training loss: 1.0538]\u001b[A\n",
            "Training:   5%|▍         | 88/1772 [00:27<09:05,  3.09it/s, running training loss: 1.0538]\u001b[A\n",
            "Training:   5%|▍         | 88/1772 [00:27<09:05,  3.09it/s, running training loss: 0.9227]\u001b[A\n",
            "Training:   5%|▌         | 89/1772 [00:27<09:23,  2.99it/s, running training loss: 0.9227]\u001b[A\n",
            "Training:   5%|▌         | 89/1772 [00:27<09:23,  2.99it/s, running training loss: 1.0136]\u001b[A\n",
            "Training:   5%|▌         | 90/1772 [00:27<09:11,  3.05it/s, running training loss: 1.0136]\u001b[A\n",
            "Training:   5%|▌         | 90/1772 [00:28<09:11,  3.05it/s, running training loss: 0.8661]\u001b[A\n",
            "Training:   5%|▌         | 91/1772 [00:28<09:18,  3.01it/s, running training loss: 0.8661]\u001b[A\n",
            "Training:   5%|▌         | 91/1772 [00:28<09:18,  3.01it/s, running training loss: 0.8578]\u001b[A\n",
            "Training:   5%|▌         | 92/1772 [00:28<09:06,  3.07it/s, running training loss: 0.8578]\u001b[A\n",
            "Training:   5%|▌         | 92/1772 [00:28<09:06,  3.07it/s, running training loss: 0.9598]\u001b[A\n",
            "Training:   5%|▌         | 93/1772 [00:28<08:41,  3.22it/s, running training loss: 0.9598]\u001b[A\n",
            "Training:   5%|▌         | 93/1772 [00:29<08:41,  3.22it/s, running training loss: 0.9796]\u001b[A\n",
            "Training:   5%|▌         | 94/1772 [00:29<08:17,  3.37it/s, running training loss: 0.9796]\u001b[A\n",
            "Training:   5%|▌         | 94/1772 [00:29<08:17,  3.37it/s, running training loss: 0.9720]\u001b[A\n",
            "Training:   5%|▌         | 95/1772 [00:29<08:46,  3.19it/s, running training loss: 0.9720]\u001b[A\n",
            "Training:   5%|▌         | 95/1772 [00:29<08:46,  3.19it/s, running training loss: 0.9155]\u001b[A\n",
            "Training:   5%|▌         | 96/1772 [00:29<08:43,  3.20it/s, running training loss: 0.9155]\u001b[A\n",
            "Training:   5%|▌         | 96/1772 [00:30<08:43,  3.20it/s, running training loss: 0.8588]\u001b[A\n",
            "Training:   5%|▌         | 97/1772 [00:30<08:28,  3.29it/s, running training loss: 0.8588]\u001b[A\n",
            "Training:   5%|▌         | 97/1772 [00:30<08:28,  3.29it/s, running training loss: 1.8821]\u001b[A\n",
            "Training:   6%|▌         | 98/1772 [00:30<09:02,  3.09it/s, running training loss: 1.8821]\u001b[A\n",
            "Training:   6%|▌         | 98/1772 [00:30<09:02,  3.09it/s, running training loss: 1.5642]\u001b[A\n",
            "Training:   6%|▌         | 99/1772 [00:30<09:41,  2.88it/s, running training loss: 1.5642]\u001b[A\n",
            "Training:   6%|▌         | 99/1772 [00:31<09:41,  2.88it/s, running training loss: 2.1431]\u001b[A\n",
            "Training:   6%|▌         | 100/1772 [00:31<10:01,  2.78it/s, running training loss: 2.1431]\u001b[A\n",
            "Training:   6%|▌         | 100/1772 [00:31<10:01,  2.78it/s, running training loss: 1.5602]\u001b[A\n",
            "Training:   6%|▌         | 101/1772 [00:31<09:12,  3.02it/s, running training loss: 1.5602]\u001b[A\n",
            "Training:   6%|▌         | 101/1772 [00:31<09:12,  3.02it/s, running training loss: 1.6841]\u001b[A\n",
            "Training:   6%|▌         | 102/1772 [00:31<08:41,  3.20it/s, running training loss: 1.6841]\u001b[A\n",
            "Training:   6%|▌         | 102/1772 [00:32<08:41,  3.20it/s, running training loss: 1.8108]\u001b[A\n",
            "Training:   6%|▌         | 103/1772 [00:32<08:44,  3.18it/s, running training loss: 1.8108]\u001b[A\n",
            "Training:   6%|▌         | 103/1772 [00:32<08:44,  3.18it/s, running training loss: 1.6022]\u001b[A\n",
            "Training:   6%|▌         | 104/1772 [00:32<09:55,  2.80it/s, running training loss: 1.6022]\u001b[A\n",
            "Training:   6%|▌         | 104/1772 [00:32<09:55,  2.80it/s, running training loss: 1.9816]\u001b[A\n",
            "Training:   6%|▌         | 105/1772 [00:32<09:15,  3.00it/s, running training loss: 1.9816]\u001b[A\n",
            "Training:   6%|▌         | 105/1772 [00:33<09:15,  3.00it/s, running training loss: 0.9428]\u001b[A\n",
            "Training:   6%|▌         | 106/1772 [00:33<09:00,  3.09it/s, running training loss: 0.9428]\u001b[A\n",
            "Training:   6%|▌         | 106/1772 [00:33<09:00,  3.09it/s, running training loss: 1.4956]\u001b[A\n",
            "Training:   6%|▌         | 107/1772 [00:33<08:30,  3.26it/s, running training loss: 1.4956]\u001b[A\n",
            "Training:   6%|▌         | 107/1772 [00:33<08:30,  3.26it/s, running training loss: 1.6339]\u001b[A\n",
            "Training:   6%|▌         | 108/1772 [00:33<07:49,  3.55it/s, running training loss: 1.6339]\u001b[A\n",
            "Training:   6%|▌         | 108/1772 [00:33<07:49,  3.55it/s, running training loss: 1.2281]\u001b[A\n",
            "Training:   6%|▌         | 109/1772 [00:33<07:35,  3.65it/s, running training loss: 1.2281]\u001b[A\n",
            "Training:   6%|▌         | 109/1772 [00:34<07:35,  3.65it/s, running training loss: 1.1344]\u001b[A\n",
            "Training:   6%|▌         | 110/1772 [00:34<09:35,  2.89it/s, running training loss: 1.1344]\u001b[A\n",
            "Training:   6%|▌         | 110/1772 [00:34<09:35,  2.89it/s, running training loss: 1.1545]\u001b[A\n",
            "Training:   6%|▋         | 111/1772 [00:34<09:17,  2.98it/s, running training loss: 1.1545]\u001b[A\n",
            "Training:   6%|▋         | 111/1772 [00:34<09:17,  2.98it/s, running training loss: 1.0288]\u001b[A\n",
            "Training:   6%|▋         | 112/1772 [00:34<08:29,  3.26it/s, running training loss: 1.0288]\u001b[A\n",
            "Training:   6%|▋         | 112/1772 [00:35<08:29,  3.26it/s, running training loss: 0.9615]\u001b[A\n",
            "Training:   6%|▋         | 113/1772 [00:35<08:30,  3.25it/s, running training loss: 0.9615]\u001b[A\n",
            "Training:   6%|▋         | 113/1772 [00:35<08:30,  3.25it/s, running training loss: 1.1828]\u001b[A\n",
            "Training:   6%|▋         | 114/1772 [00:35<08:09,  3.39it/s, running training loss: 1.1828]\u001b[A\n",
            "Training:   6%|▋         | 114/1772 [00:35<08:09,  3.39it/s, running training loss: 1.0017]\u001b[A\n",
            "Training:   6%|▋         | 115/1772 [00:35<08:41,  3.18it/s, running training loss: 1.0017]\u001b[A\n",
            "Training:   6%|▋         | 115/1772 [00:36<08:41,  3.18it/s, running training loss: 1.0422]\u001b[A\n",
            "Training:   7%|▋         | 116/1772 [00:36<08:21,  3.30it/s, running training loss: 1.0422]\u001b[A\n",
            "Training:   7%|▋         | 116/1772 [00:36<08:21,  3.30it/s, running training loss: 0.9655]\u001b[A\n",
            "Training:   7%|▋         | 117/1772 [00:36<08:00,  3.44it/s, running training loss: 0.9655]\u001b[A\n",
            "Training:   7%|▋         | 117/1772 [00:36<08:00,  3.44it/s, running training loss: 1.1389]\u001b[A\n",
            "Training:   7%|▋         | 118/1772 [00:36<08:19,  3.31it/s, running training loss: 1.1389]\u001b[A\n",
            "Training:   7%|▋         | 118/1772 [00:36<08:19,  3.31it/s, running training loss: 1.0427]\u001b[A\n",
            "Training:   7%|▋         | 119/1772 [00:36<07:44,  3.56it/s, running training loss: 1.0427]\u001b[A\n",
            "Training:   7%|▋         | 119/1772 [00:37<07:44,  3.56it/s, running training loss: 1.1057]\u001b[A\n",
            "Training:   7%|▋         | 120/1772 [00:37<07:27,  3.70it/s, running training loss: 1.1057]\u001b[A\n",
            "Training:   7%|▋         | 120/1772 [00:37<07:27,  3.70it/s, running training loss: 1.0941]\u001b[A\n",
            "Training:   7%|▋         | 121/1772 [00:37<08:30,  3.23it/s, running training loss: 1.0941]\u001b[A\n",
            "Training:   7%|▋         | 121/1772 [00:37<08:30,  3.23it/s, running training loss: 0.9840]\u001b[A\n",
            "Training:   7%|▋         | 122/1772 [00:37<07:54,  3.48it/s, running training loss: 0.9840]\u001b[A\n",
            "Training:   7%|▋         | 122/1772 [00:38<07:54,  3.48it/s, running training loss: 0.8997]\u001b[A\n",
            "Training:   7%|▋         | 123/1772 [00:38<07:59,  3.44it/s, running training loss: 0.8997]\u001b[A\n",
            "Training:   7%|▋         | 123/1772 [00:38<07:59,  3.44it/s, running training loss: 1.0563]\u001b[A\n",
            "Training:   7%|▋         | 124/1772 [00:38<07:41,  3.57it/s, running training loss: 1.0563]\u001b[A\n",
            "Training:   7%|▋         | 124/1772 [00:38<07:41,  3.57it/s, running training loss: 0.9656]\u001b[A\n",
            "Training:   7%|▋         | 125/1772 [00:38<07:34,  3.62it/s, running training loss: 0.9656]\u001b[A\n",
            "Training:   7%|▋         | 125/1772 [00:38<07:34,  3.62it/s, running training loss: 0.9507]\u001b[A\n",
            "Training:   7%|▋         | 126/1772 [00:38<07:46,  3.53it/s, running training loss: 0.9507]\u001b[A\n",
            "Training:   7%|▋         | 126/1772 [00:39<07:46,  3.53it/s, running training loss: 1.1641]\u001b[A\n",
            "Training:   7%|▋         | 127/1772 [00:39<07:21,  3.72it/s, running training loss: 1.1641]\u001b[A\n",
            "Training:   7%|▋         | 127/1772 [00:39<07:21,  3.72it/s, running training loss: 1.0191]\u001b[A\n",
            "Training:   7%|▋         | 128/1772 [00:39<07:20,  3.73it/s, running training loss: 1.0191]\u001b[A\n",
            "Training:   7%|▋         | 128/1772 [00:39<07:20,  3.73it/s, running training loss: 1.0329]\u001b[A\n",
            "Training:   7%|▋         | 129/1772 [00:39<07:13,  3.79it/s, running training loss: 1.0329]\u001b[A\n",
            "Training:   7%|▋         | 129/1772 [00:40<07:13,  3.79it/s, running training loss: 1.4692]\u001b[A\n",
            "Training:   7%|▋         | 130/1772 [00:40<07:45,  3.53it/s, running training loss: 1.4692]\u001b[A\n",
            "Training:   7%|▋         | 130/1772 [00:40<07:45,  3.53it/s, running training loss: 1.0468]\u001b[A\n",
            "Training:   7%|▋         | 131/1772 [00:40<07:42,  3.55it/s, running training loss: 1.0468]\u001b[A\n",
            "Training:   7%|▋         | 131/1772 [00:40<07:42,  3.55it/s, running training loss: 1.0325]\u001b[A\n",
            "Training:   7%|▋         | 132/1772 [00:40<07:51,  3.48it/s, running training loss: 1.0325]\u001b[A\n",
            "Training:   7%|▋         | 132/1772 [00:40<07:51,  3.48it/s, running training loss: 1.3829]\u001b[A\n",
            "Training:   8%|▊         | 133/1772 [00:40<08:13,  3.32it/s, running training loss: 1.3829]\u001b[A\n",
            "Training:   8%|▊         | 133/1772 [00:41<08:13,  3.32it/s, running training loss: 0.9879]\u001b[A\n",
            "Training:   8%|▊         | 134/1772 [00:41<08:00,  3.41it/s, running training loss: 0.9879]\u001b[A\n",
            "Training:   8%|▊         | 134/1772 [00:41<08:00,  3.41it/s, running training loss: 0.9250]\u001b[A\n",
            "Training:   8%|▊         | 135/1772 [00:41<07:50,  3.48it/s, running training loss: 0.9250]\u001b[A\n",
            "Training:   8%|▊         | 135/1772 [00:41<07:50,  3.48it/s, running training loss: 1.1550]\u001b[A\n",
            "Training:   8%|▊         | 136/1772 [00:41<07:33,  3.60it/s, running training loss: 1.1550]\u001b[A\n",
            "Training:   8%|▊         | 136/1772 [00:42<07:33,  3.60it/s, running training loss: 1.1069]\u001b[A\n",
            "Training:   8%|▊         | 137/1772 [00:42<07:33,  3.60it/s, running training loss: 1.1069]\u001b[A\n",
            "Training:   8%|▊         | 137/1772 [00:42<07:33,  3.60it/s, running training loss: 1.5322]\u001b[A\n",
            "Training:   8%|▊         | 138/1772 [00:42<07:24,  3.67it/s, running training loss: 1.5322]\u001b[A\n",
            "Training:   8%|▊         | 138/1772 [00:42<07:24,  3.67it/s, running training loss: 1.3642]\u001b[A\n",
            "Training:   8%|▊         | 139/1772 [00:42<06:51,  3.97it/s, running training loss: 1.3642]\u001b[A\n",
            "Training:   8%|▊         | 139/1772 [00:42<06:51,  3.97it/s, running training loss: 1.4704]\u001b[A\n",
            "Training:   8%|▊         | 140/1772 [00:42<06:51,  3.97it/s, running training loss: 1.4704]\u001b[A\n",
            "Training:   8%|▊         | 140/1772 [00:43<06:51,  3.97it/s, running training loss: 0.9320]\u001b[A\n",
            "Training:   8%|▊         | 141/1772 [00:43<07:37,  3.56it/s, running training loss: 0.9320]\u001b[A\n",
            "Training:   8%|▊         | 141/1772 [00:43<07:37,  3.56it/s, running training loss: 1.3707]\u001b[A\n",
            "Training:   8%|▊         | 142/1772 [00:43<07:12,  3.77it/s, running training loss: 1.3707]\u001b[A\n",
            "Training:   8%|▊         | 142/1772 [00:43<07:12,  3.77it/s, running training loss: 1.0319]\u001b[A\n",
            "Training:   8%|▊         | 143/1772 [00:43<07:14,  3.75it/s, running training loss: 1.0319]\u001b[A\n",
            "Training:   8%|▊         | 143/1772 [00:43<07:14,  3.75it/s, running training loss: 1.1277]\u001b[A\n",
            "Training:   8%|▊         | 144/1772 [00:43<07:50,  3.46it/s, running training loss: 1.1277]\u001b[A\n",
            "Training:   8%|▊         | 144/1772 [00:44<07:50,  3.46it/s, running training loss: 1.3350]\u001b[A\n",
            "Training:   8%|▊         | 145/1772 [00:44<08:10,  3.32it/s, running training loss: 1.3350]\u001b[A\n",
            "Training:   8%|▊         | 145/1772 [00:44<08:10,  3.32it/s, running training loss: 1.1594]\u001b[A\n",
            "Training:   8%|▊         | 146/1772 [00:44<08:03,  3.36it/s, running training loss: 1.1594]\u001b[A\n",
            "Training:   8%|▊         | 146/1772 [00:44<08:03,  3.36it/s, running training loss: 1.2849]\u001b[A\n",
            "Training:   8%|▊         | 147/1772 [00:44<08:02,  3.37it/s, running training loss: 1.2849]\u001b[A\n",
            "Training:   8%|▊         | 147/1772 [00:45<08:02,  3.37it/s, running training loss: 1.1860]\u001b[A\n",
            "Training:   8%|▊         | 148/1772 [00:45<08:14,  3.28it/s, running training loss: 1.1860]\u001b[A\n",
            "Training:   8%|▊         | 148/1772 [00:45<08:14,  3.28it/s, running training loss: 1.2224]\u001b[A\n",
            "Training:   8%|▊         | 149/1772 [00:45<07:43,  3.50it/s, running training loss: 1.2224]\u001b[A\n",
            "Training:   8%|▊         | 149/1772 [00:45<07:43,  3.50it/s, running training loss: 1.1530]\u001b[A\n",
            "Training:   8%|▊         | 150/1772 [00:45<07:19,  3.69it/s, running training loss: 1.1530]\u001b[A\n",
            "Training:   8%|▊         | 150/1772 [00:45<07:19,  3.69it/s, running training loss: 1.0896]\u001b[A\n",
            "Training:   9%|▊         | 151/1772 [00:45<07:25,  3.64it/s, running training loss: 1.0896]\u001b[A\n",
            "Training:   9%|▊         | 151/1772 [00:46<07:25,  3.64it/s, running training loss: 1.0147]\u001b[A\n",
            "Training:   9%|▊         | 152/1772 [00:46<07:29,  3.61it/s, running training loss: 1.0147]\u001b[A\n",
            "Training:   9%|▊         | 152/1772 [00:46<07:29,  3.61it/s, running training loss: 1.0421]\u001b[A\n",
            "Training:   9%|▊         | 153/1772 [00:46<07:28,  3.61it/s, running training loss: 1.0421]\u001b[A\n",
            "Training:   9%|▊         | 153/1772 [00:46<07:28,  3.61it/s, running training loss: 1.1471]\u001b[A\n",
            "Training:   9%|▊         | 154/1772 [00:46<07:43,  3.49it/s, running training loss: 1.1471]\u001b[A\n",
            "Training:   9%|▊         | 154/1772 [00:47<07:43,  3.49it/s, running training loss: 1.1322]\u001b[A\n",
            "Training:   9%|▊         | 155/1772 [00:47<07:34,  3.55it/s, running training loss: 1.1322]\u001b[A\n",
            "Training:   9%|▊         | 155/1772 [00:47<07:34,  3.55it/s, running training loss: 1.0293]\u001b[A\n",
            "Training:   9%|▉         | 156/1772 [00:47<07:23,  3.65it/s, running training loss: 1.0293]\u001b[A\n",
            "Training:   9%|▉         | 156/1772 [00:47<07:23,  3.65it/s, running training loss: 0.9788]\u001b[A\n",
            "Training:   9%|▉         | 157/1772 [00:47<07:58,  3.38it/s, running training loss: 0.9788]\u001b[A\n",
            "Training:   9%|▉         | 157/1772 [00:48<07:58,  3.38it/s, running training loss: 1.0753]\u001b[A\n",
            "Training:   9%|▉         | 158/1772 [00:48<09:40,  2.78it/s, running training loss: 1.0753]\u001b[A\n",
            "Training:   9%|▉         | 158/1772 [00:48<09:40,  2.78it/s, running training loss: 1.0106]\u001b[A\n",
            "Training:   9%|▉         | 159/1772 [00:48<09:20,  2.88it/s, running training loss: 1.0106]\u001b[A\n",
            "Training:   9%|▉         | 159/1772 [00:48<09:20,  2.88it/s, running training loss: 0.9044]\u001b[A\n",
            "Training:   9%|▉         | 160/1772 [00:48<09:03,  2.97it/s, running training loss: 0.9044]\u001b[A\n",
            "Training:   9%|▉         | 160/1772 [00:49<09:03,  2.97it/s, running training loss: 1.2063]\u001b[A\n",
            "Training:   9%|▉         | 161/1772 [00:49<08:23,  3.20it/s, running training loss: 1.2063]\u001b[A\n",
            "Training:   9%|▉         | 161/1772 [00:49<08:23,  3.20it/s, running training loss: 1.2907]\u001b[A\n",
            "Training:   9%|▉         | 162/1772 [00:49<09:10,  2.92it/s, running training loss: 1.2907]\u001b[A\n",
            "Training:   9%|▉         | 162/1772 [00:49<09:10,  2.92it/s, running training loss: 1.1964]\u001b[A\n",
            "Training:   9%|▉         | 163/1772 [00:49<09:26,  2.84it/s, running training loss: 1.1964]\u001b[A\n",
            "Training:   9%|▉         | 163/1772 [00:50<09:26,  2.84it/s, running training loss: 1.1329]\u001b[A\n",
            "Training:   9%|▉         | 164/1772 [00:50<09:04,  2.95it/s, running training loss: 1.1329]\u001b[A\n",
            "Training:   9%|▉         | 164/1772 [00:50<09:04,  2.95it/s, running training loss: 1.2431]\u001b[A\n",
            "Training:   9%|▉         | 165/1772 [00:50<09:03,  2.96it/s, running training loss: 1.2431]\u001b[A\n",
            "Training:   9%|▉         | 165/1772 [00:50<09:03,  2.96it/s, running training loss: 1.4420]\u001b[A\n",
            "Training:   9%|▉         | 166/1772 [00:50<08:52,  3.02it/s, running training loss: 1.4420]\u001b[A\n",
            "Training:   9%|▉         | 166/1772 [00:51<08:52,  3.02it/s, running training loss: 1.2449]\u001b[A\n",
            "Training:   9%|▉         | 167/1772 [00:51<08:32,  3.13it/s, running training loss: 1.2449]\u001b[A\n",
            "Training:   9%|▉         | 167/1772 [00:51<08:32,  3.13it/s, running training loss: 1.1692]\u001b[A\n",
            "Training:   9%|▉         | 168/1772 [00:51<08:33,  3.12it/s, running training loss: 1.1692]\u001b[A\n",
            "Training:   9%|▉         | 168/1772 [00:51<08:33,  3.12it/s, running training loss: 1.2542]\u001b[A\n",
            "Training:  10%|▉         | 169/1772 [00:51<08:33,  3.12it/s, running training loss: 1.2542]\u001b[A\n",
            "Training:  10%|▉         | 169/1772 [00:52<08:33,  3.12it/s, running training loss: 1.2182]\u001b[A\n",
            "Training:  10%|▉         | 170/1772 [00:52<09:18,  2.87it/s, running training loss: 1.2182]\u001b[A\n",
            "Training:  10%|▉         | 170/1772 [00:52<09:18,  2.87it/s, running training loss: 1.1636]\u001b[A\n",
            "Training:  10%|▉         | 171/1772 [00:52<08:47,  3.03it/s, running training loss: 1.1636]\u001b[A\n",
            "Training:  10%|▉         | 171/1772 [00:52<08:47,  3.03it/s, running training loss: 1.1241]\u001b[A\n",
            "Training:  10%|▉         | 172/1772 [00:52<08:21,  3.19it/s, running training loss: 1.1241]\u001b[A\n",
            "Training:  10%|▉         | 172/1772 [00:52<08:21,  3.19it/s, running training loss: 1.0790]\u001b[A\n",
            "Training:  10%|▉         | 173/1772 [00:53<07:44,  3.44it/s, running training loss: 1.0790]\u001b[A\n",
            "Training:  10%|▉         | 173/1772 [00:53<07:44,  3.44it/s, running training loss: 1.1349]\u001b[A\n",
            "Training:  10%|▉         | 174/1772 [00:53<07:38,  3.49it/s, running training loss: 1.1349]\u001b[A\n",
            "Training:  10%|▉         | 174/1772 [00:53<07:38,  3.49it/s, running training loss: 1.1275]\u001b[A\n",
            "Training:  10%|▉         | 175/1772 [00:53<09:15,  2.88it/s, running training loss: 1.1275]\u001b[A\n",
            "Training:  10%|▉         | 175/1772 [00:54<09:15,  2.88it/s, running training loss: 1.0124]\u001b[A\n",
            "Training:  10%|▉         | 176/1772 [00:54<08:32,  3.12it/s, running training loss: 1.0124]\u001b[A\n",
            "Training:  10%|▉         | 176/1772 [00:54<08:32,  3.12it/s, running training loss: 0.9121]\u001b[A\n",
            "Training:  10%|▉         | 177/1772 [00:54<08:37,  3.08it/s, running training loss: 0.9121]\u001b[A\n",
            "Training:  10%|▉         | 177/1772 [00:54<08:37,  3.08it/s, running training loss: 0.9994]\u001b[A\n",
            "Training:  10%|█         | 178/1772 [00:54<07:52,  3.38it/s, running training loss: 0.9994]\u001b[A\n",
            "Training:  10%|█         | 178/1772 [00:54<07:52,  3.38it/s, running training loss: 1.0492]\u001b[A\n",
            "Training:  10%|█         | 179/1772 [00:54<08:09,  3.26it/s, running training loss: 1.0492]\u001b[A\n",
            "Training:  10%|█         | 179/1772 [00:55<08:09,  3.26it/s, running training loss: 0.9753]\u001b[A\n",
            "Training:  10%|█         | 180/1772 [00:55<07:32,  3.52it/s, running training loss: 0.9753]\u001b[A\n",
            "Training:  10%|█         | 180/1772 [00:55<07:32,  3.52it/s, running training loss: 1.0825]\u001b[A\n",
            "Training:  10%|█         | 181/1772 [00:55<07:25,  3.57it/s, running training loss: 1.0825]\u001b[A\n",
            "Training:  10%|█         | 181/1772 [00:55<07:25,  3.57it/s, running training loss: 1.0231]\u001b[A\n",
            "Training:  10%|█         | 182/1772 [00:55<07:49,  3.39it/s, running training loss: 1.0231]\u001b[A\n",
            "Training:  10%|█         | 182/1772 [00:56<07:49,  3.39it/s, running training loss: 1.2012]\u001b[A\n",
            "Training:  10%|█         | 183/1772 [00:56<07:47,  3.40it/s, running training loss: 1.2012]\u001b[A\n",
            "Training:  10%|█         | 183/1772 [00:56<07:47,  3.40it/s, running training loss: 0.9840]\u001b[A\n",
            "Training:  10%|█         | 184/1772 [00:56<07:38,  3.47it/s, running training loss: 0.9840]\u001b[A\n",
            "Training:  10%|█         | 184/1772 [00:56<07:38,  3.47it/s, running training loss: 1.0391]\u001b[A\n",
            "Training:  10%|█         | 185/1772 [00:56<07:38,  3.46it/s, running training loss: 1.0391]\u001b[A\n",
            "Training:  10%|█         | 185/1772 [00:56<07:38,  3.46it/s, running training loss: 0.9072]\u001b[A\n",
            "Training:  10%|█         | 186/1772 [00:56<07:20,  3.60it/s, running training loss: 0.9072]\u001b[A\n",
            "Training:  10%|█         | 186/1772 [00:57<07:20,  3.60it/s, running training loss: 1.0253]\u001b[A\n",
            "Training:  11%|█         | 187/1772 [00:57<09:01,  2.93it/s, running training loss: 1.0253]\u001b[A\n",
            "Training:  11%|█         | 187/1772 [00:57<09:01,  2.93it/s, running training loss: 1.0477]\u001b[A\n",
            "Training:  11%|█         | 188/1772 [00:57<08:26,  3.13it/s, running training loss: 1.0477]\u001b[A\n",
            "Training:  11%|█         | 188/1772 [00:57<08:26,  3.13it/s, running training loss: 1.0230]\u001b[A\n",
            "Training:  11%|█         | 189/1772 [00:57<08:16,  3.19it/s, running training loss: 1.0230]\u001b[A\n",
            "Training:  11%|█         | 189/1772 [00:58<08:16,  3.19it/s, running training loss: 0.8913]\u001b[A\n",
            "Training:  11%|█         | 190/1772 [00:58<08:47,  3.00it/s, running training loss: 0.8913]\u001b[A\n",
            "Training:  11%|█         | 190/1772 [00:58<08:47,  3.00it/s, running training loss: 0.9017]\u001b[A\n",
            "Training:  11%|█         | 191/1772 [00:58<08:50,  2.98it/s, running training loss: 0.9017]\u001b[A\n",
            "Training:  11%|█         | 191/1772 [00:58<08:50,  2.98it/s, running training loss: 1.0534]\u001b[A\n",
            "Training:  11%|█         | 192/1772 [00:58<08:44,  3.01it/s, running training loss: 1.0534]\u001b[A\n",
            "Training:  11%|█         | 192/1772 [00:59<08:44,  3.01it/s, running training loss: 0.9960]\u001b[A\n",
            "Training:  11%|█         | 193/1772 [00:59<08:21,  3.15it/s, running training loss: 0.9960]\u001b[A\n",
            "Training:  11%|█         | 193/1772 [00:59<08:21,  3.15it/s, running training loss: 0.9925]\u001b[A\n",
            "Training:  11%|█         | 194/1772 [00:59<07:56,  3.31it/s, running training loss: 0.9925]\u001b[A\n",
            "Training:  11%|█         | 194/1772 [00:59<07:56,  3.31it/s, running training loss: 1.2187]\u001b[A\n",
            "Training:  11%|█         | 195/1772 [00:59<08:10,  3.21it/s, running training loss: 1.2187]\u001b[A\n",
            "Training:  11%|█         | 195/1772 [01:00<08:10,  3.21it/s, running training loss: 1.1288]\u001b[A\n",
            "Training:  11%|█         | 196/1772 [01:00<07:50,  3.35it/s, running training loss: 1.1288]\u001b[A\n",
            "Training:  11%|█         | 196/1772 [01:00<07:50,  3.35it/s, running training loss: 0.9518]\u001b[A\n",
            "Training:  11%|█         | 197/1772 [01:00<07:22,  3.56it/s, running training loss: 0.9518]\u001b[A\n",
            "Training:  11%|█         | 197/1772 [01:00<07:22,  3.56it/s, running training loss: 0.9881]\u001b[A\n",
            "Training:  11%|█         | 198/1772 [01:00<07:26,  3.52it/s, running training loss: 0.9881]\u001b[A\n",
            "Training:  11%|█         | 198/1772 [01:00<07:26,  3.52it/s, running training loss: 1.1107]\u001b[A\n",
            "Training:  11%|█         | 199/1772 [01:00<07:48,  3.36it/s, running training loss: 1.1107]\u001b[A\n",
            "Training:  11%|█         | 199/1772 [01:01<07:48,  3.36it/s, running training loss: 0.9979]\u001b[A\n",
            "Training:  11%|█▏        | 200/1772 [01:01<08:38,  3.03it/s, running training loss: 0.9979]\u001b[A\n",
            "Training:  11%|█▏        | 200/1772 [01:01<08:38,  3.03it/s, running training loss: 1.1019]\u001b[A\n",
            "Training:  11%|█▏        | 201/1772 [01:01<08:04,  3.24it/s, running training loss: 1.1019]\u001b[A\n",
            "Training:  11%|█▏        | 201/1772 [01:01<08:04,  3.24it/s, running training loss: 1.1064]\u001b[A\n",
            "Training:  11%|█▏        | 202/1772 [01:01<07:28,  3.50it/s, running training loss: 1.1064]\u001b[A\n",
            "Training:  11%|█▏        | 202/1772 [01:02<07:28,  3.50it/s, running training loss: 1.0670]\u001b[A\n",
            "Training:  11%|█▏        | 203/1772 [01:02<07:26,  3.52it/s, running training loss: 1.0670]\u001b[A\n",
            "Training:  11%|█▏        | 203/1772 [01:02<07:26,  3.52it/s, running training loss: 1.1245]\u001b[A\n",
            "Training:  12%|█▏        | 204/1772 [01:02<07:50,  3.33it/s, running training loss: 1.1245]\u001b[A\n",
            "Training:  12%|█▏        | 204/1772 [01:02<07:50,  3.33it/s, running training loss: 0.9262]\u001b[A\n",
            "Training:  12%|█▏        | 205/1772 [01:02<07:16,  3.59it/s, running training loss: 0.9262]\u001b[A\n",
            "Training:  12%|█▏        | 205/1772 [01:02<07:16,  3.59it/s, running training loss: 0.9503]\u001b[A\n",
            "Training:  12%|█▏        | 206/1772 [01:03<07:16,  3.59it/s, running training loss: 0.9503]\u001b[A\n",
            "Training:  12%|█▏        | 206/1772 [01:03<07:16,  3.59it/s, running training loss: 0.9204]\u001b[A\n",
            "Training:  12%|█▏        | 207/1772 [01:03<06:55,  3.77it/s, running training loss: 0.9204]\u001b[A\n",
            "Training:  12%|█▏        | 207/1772 [01:03<06:55,  3.77it/s, running training loss: 1.0115]\u001b[A\n",
            "Training:  12%|█▏        | 208/1772 [01:03<07:16,  3.58it/s, running training loss: 1.0115]\u001b[A\n",
            "Training:  12%|█▏        | 208/1772 [01:03<07:16,  3.58it/s, running training loss: 0.9654]\u001b[A\n",
            "Training:  12%|█▏        | 209/1772 [01:03<07:20,  3.55it/s, running training loss: 0.9654]\u001b[A\n",
            "Training:  12%|█▏        | 209/1772 [01:04<07:20,  3.55it/s, running training loss: 0.9396]\u001b[A\n",
            "Training:  12%|█▏        | 210/1772 [01:04<07:09,  3.64it/s, running training loss: 0.9396]\u001b[A\n",
            "Training:  12%|█▏        | 210/1772 [01:04<07:09,  3.64it/s, running training loss: 1.0811]\u001b[A\n",
            "Training:  12%|█▏        | 211/1772 [01:04<06:54,  3.76it/s, running training loss: 1.0811]\u001b[A\n",
            "Training:  12%|█▏        | 211/1772 [01:04<06:54,  3.76it/s, running training loss: 1.1604]\u001b[A\n",
            "Training:  12%|█▏        | 212/1772 [01:04<06:57,  3.74it/s, running training loss: 1.1604]\u001b[A\n",
            "Training:  12%|█▏        | 212/1772 [01:04<06:57,  3.74it/s, running training loss: 1.0764]\u001b[A\n",
            "Training:  12%|█▏        | 213/1772 [01:04<07:02,  3.69it/s, running training loss: 1.0764]\u001b[A\n",
            "Training:  12%|█▏        | 213/1772 [01:05<07:02,  3.69it/s, running training loss: 1.1322]\u001b[A\n",
            "Training:  12%|█▏        | 214/1772 [01:05<06:40,  3.89it/s, running training loss: 1.1322]\u001b[A\n",
            "Training:  12%|█▏        | 214/1772 [01:05<06:40,  3.89it/s, running training loss: 1.1398]\u001b[A\n",
            "Training:  12%|█▏        | 215/1772 [01:05<06:36,  3.93it/s, running training loss: 1.1398]\u001b[A\n",
            "Training:  12%|█▏        | 215/1772 [01:05<06:36,  3.93it/s, running training loss: 1.1223]\u001b[A\n",
            "Training:  12%|█▏        | 216/1772 [01:05<08:42,  2.98it/s, running training loss: 1.1223]\u001b[A\n",
            "Training:  12%|█▏        | 216/1772 [01:06<08:42,  2.98it/s, running training loss: 1.1605]\u001b[A\n",
            "Training:  12%|█▏        | 217/1772 [01:06<08:41,  2.98it/s, running training loss: 1.1605]\u001b[A\n",
            "Training:  12%|█▏        | 217/1772 [01:06<08:41,  2.98it/s, running training loss: 0.9543]\u001b[A\n",
            "Training:  12%|█▏        | 218/1772 [01:06<08:13,  3.15it/s, running training loss: 0.9543]\u001b[A\n",
            "Training:  12%|█▏        | 218/1772 [01:06<08:13,  3.15it/s, running training loss: 1.1107]\u001b[A\n",
            "Training:  12%|█▏        | 219/1772 [01:06<07:59,  3.24it/s, running training loss: 1.1107]\u001b[A\n",
            "Training:  12%|█▏        | 219/1772 [01:07<07:59,  3.24it/s, running training loss: 0.9254]\u001b[A\n",
            "Training:  12%|█▏        | 220/1772 [01:07<08:37,  3.00it/s, running training loss: 0.9254]\u001b[A\n",
            "Training:  12%|█▏        | 220/1772 [01:07<08:37,  3.00it/s, running training loss: 0.9366]\u001b[A\n",
            "Training:  12%|█▏        | 221/1772 [01:07<08:20,  3.10it/s, running training loss: 0.9366]\u001b[A\n",
            "Training:  12%|█▏        | 221/1772 [01:07<08:20,  3.10it/s, running training loss: 0.8424]\u001b[A\n",
            "Training:  13%|█▎        | 222/1772 [01:07<07:58,  3.24it/s, running training loss: 0.8424]\u001b[A\n",
            "Training:  13%|█▎        | 222/1772 [01:08<07:58,  3.24it/s, running training loss: 1.0180]\u001b[A\n",
            "Training:  13%|█▎        | 223/1772 [01:08<07:37,  3.39it/s, running training loss: 1.0180]\u001b[A\n",
            "Training:  13%|█▎        | 223/1772 [01:08<07:37,  3.39it/s, running training loss: 1.0355]\u001b[A\n",
            "Training:  13%|█▎        | 224/1772 [01:08<07:38,  3.37it/s, running training loss: 1.0355]\u001b[A\n",
            "Training:  13%|█▎        | 224/1772 [01:08<07:38,  3.37it/s, running training loss: 1.1412]\u001b[A\n",
            "Training:  13%|█▎        | 225/1772 [01:08<07:21,  3.51it/s, running training loss: 1.1412]\u001b[A\n",
            "Training:  13%|█▎        | 225/1772 [01:08<07:21,  3.51it/s, running training loss: 1.2880]\u001b[A\n",
            "Training:  13%|█▎        | 226/1772 [01:08<07:00,  3.68it/s, running training loss: 1.2880]\u001b[A\n",
            "Training:  13%|█▎        | 226/1772 [01:09<07:00,  3.68it/s, running training loss: 1.2619]\u001b[A\n",
            "Training:  13%|█▎        | 227/1772 [01:09<07:23,  3.48it/s, running training loss: 1.2619]\u001b[A\n",
            "Training:  13%|█▎        | 227/1772 [01:09<07:23,  3.48it/s, running training loss: 1.2037]\u001b[A\n",
            "Training:  13%|█▎        | 228/1772 [01:09<07:47,  3.30it/s, running training loss: 1.2037]\u001b[A\n",
            "Training:  13%|█▎        | 228/1772 [01:09<07:47,  3.30it/s, running training loss: 1.0868]\u001b[A\n",
            "Training:  13%|█▎        | 229/1772 [01:09<07:47,  3.30it/s, running training loss: 1.0868]\u001b[A\n",
            "Training:  13%|█▎        | 229/1772 [01:10<07:47,  3.30it/s, running training loss: 1.0567]\u001b[A\n",
            "Training:  13%|█▎        | 230/1772 [01:10<07:32,  3.40it/s, running training loss: 1.0567]\u001b[A\n",
            "Training:  13%|█▎        | 230/1772 [01:10<07:32,  3.40it/s, running training loss: 1.0301]\u001b[A\n",
            "Training:  13%|█▎        | 231/1772 [01:10<08:55,  2.88it/s, running training loss: 1.0301]\u001b[A\n",
            "Training:  13%|█▎        | 231/1772 [01:10<08:55,  2.88it/s, running training loss: 1.0686]\u001b[A\n",
            "Training:  13%|█▎        | 232/1772 [01:10<09:25,  2.72it/s, running training loss: 1.0686]\u001b[A\n",
            "Training:  13%|█▎        | 232/1772 [01:11<09:25,  2.72it/s, running training loss: 0.9570]\u001b[A\n",
            "Training:  13%|█▎        | 233/1772 [01:11<08:33,  3.00it/s, running training loss: 0.9570]\u001b[A\n",
            "Training:  13%|█▎        | 233/1772 [01:11<08:33,  3.00it/s, running training loss: 1.0447]\u001b[A\n",
            "Training:  13%|█▎        | 234/1772 [01:11<09:25,  2.72it/s, running training loss: 1.0447]\u001b[A\n",
            "Training:  13%|█▎        | 234/1772 [01:11<09:25,  2.72it/s, running training loss: 1.0490]\u001b[A\n",
            "Training:  13%|█▎        | 235/1772 [01:11<09:16,  2.76it/s, running training loss: 1.0490]\u001b[A\n",
            "Training:  13%|█▎        | 235/1772 [01:12<09:16,  2.76it/s, running training loss: 0.8026]\u001b[A\n",
            "Training:  13%|█▎        | 236/1772 [01:12<09:09,  2.79it/s, running training loss: 0.8026]\u001b[A\n",
            "Training:  13%|█▎        | 236/1772 [01:12<09:09,  2.79it/s, running training loss: 0.9594]\u001b[A\n",
            "Training:  13%|█▎        | 237/1772 [01:12<08:13,  3.11it/s, running training loss: 0.9594]\u001b[A\n",
            "Training:  13%|█▎        | 237/1772 [01:12<08:13,  3.11it/s, running training loss: 0.7723]\u001b[A\n",
            "Training:  13%|█▎        | 238/1772 [01:12<07:51,  3.25it/s, running training loss: 0.7723]\u001b[A\n",
            "Training:  13%|█▎        | 238/1772 [01:13<07:51,  3.25it/s, running training loss: 1.0510]\u001b[A\n",
            "Training:  13%|█▎        | 239/1772 [01:13<07:40,  3.33it/s, running training loss: 1.0510]\u001b[A\n",
            "Training:  13%|█▎        | 239/1772 [01:13<07:40,  3.33it/s, running training loss: 0.9691]\u001b[A\n",
            "Training:  14%|█▎        | 240/1772 [01:13<07:35,  3.36it/s, running training loss: 0.9691]\u001b[A\n",
            "Training:  14%|█▎        | 240/1772 [01:13<07:35,  3.36it/s, running training loss: 1.0251]\u001b[A\n",
            "Training:  14%|█▎        | 241/1772 [01:13<07:16,  3.51it/s, running training loss: 1.0251]\u001b[A\n",
            "Training:  14%|█▎        | 241/1772 [01:13<07:16,  3.51it/s, running training loss: 1.2687]\u001b[A\n",
            "Training:  14%|█▎        | 242/1772 [01:13<07:11,  3.54it/s, running training loss: 1.2687]\u001b[A\n",
            "Training:  14%|█▎        | 242/1772 [01:14<07:11,  3.54it/s, running training loss: 1.0638]\u001b[A\n",
            "Training:  14%|█▎        | 243/1772 [01:14<07:30,  3.39it/s, running training loss: 1.0638]\u001b[A\n",
            "Training:  14%|█▎        | 243/1772 [01:14<07:30,  3.39it/s, running training loss: 0.9483]\u001b[A\n",
            "Training:  14%|█▍        | 244/1772 [01:14<07:59,  3.19it/s, running training loss: 0.9483]\u001b[A\n",
            "Training:  14%|█▍        | 244/1772 [01:14<07:59,  3.19it/s, running training loss: 1.1608]\u001b[A\n",
            "Training:  14%|█▍        | 245/1772 [01:14<08:05,  3.15it/s, running training loss: 1.1608]\u001b[A\n",
            "Training:  14%|█▍        | 245/1772 [01:15<08:05,  3.15it/s, running training loss: 0.8920]\u001b[A\n",
            "Training:  14%|█▍        | 246/1772 [01:15<08:17,  3.07it/s, running training loss: 0.8920]\u001b[A\n",
            "Training:  14%|█▍        | 246/1772 [01:15<08:17,  3.07it/s, running training loss: 0.9463]\u001b[A\n",
            "Training:  14%|█▍        | 247/1772 [01:15<07:50,  3.24it/s, running training loss: 0.9463]\u001b[A\n",
            "Training:  14%|█▍        | 247/1772 [01:15<07:50,  3.24it/s, running training loss: 1.0281]\u001b[A\n",
            "Training:  14%|█▍        | 248/1772 [01:15<08:05,  3.14it/s, running training loss: 1.0281]\u001b[A\n",
            "Training:  14%|█▍        | 248/1772 [01:16<08:05,  3.14it/s, running training loss: 1.0983]\u001b[A\n",
            "Training:  14%|█▍        | 249/1772 [01:16<07:24,  3.43it/s, running training loss: 1.0983]\u001b[A\n",
            "Training:  14%|█▍        | 249/1772 [01:16<07:24,  3.43it/s, running training loss: 0.9904]\u001b[A\n",
            "Training:  14%|█▍        | 250/1772 [01:16<07:32,  3.36it/s, running training loss: 0.9904]\u001b[A\n",
            "Training:  14%|█▍        | 250/1772 [01:16<07:32,  3.36it/s, running training loss: 1.0263]\u001b[A\n",
            "Training:  14%|█▍        | 251/1772 [01:16<07:44,  3.28it/s, running training loss: 1.0263]\u001b[A\n",
            "Training:  14%|█▍        | 251/1772 [01:17<07:44,  3.28it/s, running training loss: 0.9489]\u001b[A\n",
            "Training:  14%|█▍        | 252/1772 [01:17<08:14,  3.07it/s, running training loss: 0.9489]\u001b[A\n",
            "Training:  14%|█▍        | 252/1772 [01:17<08:14,  3.07it/s, running training loss: 0.9530]\u001b[A\n",
            "Training:  14%|█▍        | 253/1772 [01:17<07:41,  3.29it/s, running training loss: 0.9530]\u001b[A\n",
            "Training:  14%|█▍        | 253/1772 [01:17<07:41,  3.29it/s, running training loss: 1.0263]\u001b[A\n",
            "Training:  14%|█▍        | 254/1772 [01:17<08:57,  2.82it/s, running training loss: 1.0263]\u001b[A\n",
            "Training:  14%|█▍        | 254/1772 [01:18<08:57,  2.82it/s, running training loss: 1.0594]\u001b[A\n",
            "Training:  14%|█▍        | 255/1772 [01:18<08:44,  2.89it/s, running training loss: 1.0594]\u001b[A\n",
            "Training:  14%|█▍        | 255/1772 [01:18<08:44,  2.89it/s, running training loss: 1.0801]\u001b[A\n",
            "Training:  14%|█▍        | 256/1772 [01:18<08:49,  2.86it/s, running training loss: 1.0801]\u001b[A\n",
            "Training:  14%|█▍        | 256/1772 [01:18<08:49,  2.86it/s, running training loss: 1.0094]\u001b[A\n",
            "Training:  15%|█▍        | 257/1772 [01:18<08:09,  3.10it/s, running training loss: 1.0094]\u001b[A\n",
            "Training:  15%|█▍        | 257/1772 [01:19<08:09,  3.10it/s, running training loss: 1.1093]\u001b[A\n",
            "Training:  15%|█▍        | 258/1772 [01:19<08:06,  3.11it/s, running training loss: 1.1093]\u001b[A\n",
            "Training:  15%|█▍        | 258/1772 [01:19<08:06,  3.11it/s, running training loss: 1.0260]\u001b[A\n",
            "Training:  15%|█▍        | 259/1772 [01:19<07:46,  3.25it/s, running training loss: 1.0260]\u001b[A\n",
            "Training:  15%|█▍        | 259/1772 [01:19<07:46,  3.25it/s, running training loss: 1.0074]\u001b[A\n",
            "Training:  15%|█▍        | 260/1772 [01:19<08:41,  2.90it/s, running training loss: 1.0074]\u001b[A\n",
            "Training:  15%|█▍        | 260/1772 [01:20<08:41,  2.90it/s, running training loss: 0.9270]\u001b[A\n",
            "Training:  15%|█▍        | 261/1772 [01:20<08:18,  3.03it/s, running training loss: 0.9270]\u001b[A\n",
            "Training:  15%|█▍        | 261/1772 [01:20<08:18,  3.03it/s, running training loss: 1.0590]\u001b[A\n",
            "Training:  15%|█▍        | 262/1772 [01:20<08:17,  3.04it/s, running training loss: 1.0590]\u001b[A\n",
            "Training:  15%|█▍        | 262/1772 [01:20<08:17,  3.04it/s, running training loss: 0.9822]\u001b[A\n",
            "Training:  15%|█▍        | 263/1772 [01:20<08:54,  2.82it/s, running training loss: 0.9822]\u001b[A\n",
            "Training:  15%|█▍        | 263/1772 [01:21<08:54,  2.82it/s, running training loss: 1.1074]\u001b[A\n",
            "Training:  15%|█▍        | 264/1772 [01:21<08:06,  3.10it/s, running training loss: 1.1074]\u001b[A\n",
            "Training:  15%|█▍        | 264/1772 [01:21<08:06,  3.10it/s, running training loss: 1.0488]\u001b[A\n",
            "Training:  15%|█▍        | 265/1772 [01:21<07:39,  3.28it/s, running training loss: 1.0488]\u001b[A\n",
            "Training:  15%|█▍        | 265/1772 [01:21<07:39,  3.28it/s, running training loss: 0.9857]\u001b[A\n",
            "Training:  15%|█▌        | 266/1772 [01:21<07:22,  3.40it/s, running training loss: 0.9857]\u001b[A\n",
            "Training:  15%|█▌        | 266/1772 [01:22<07:22,  3.40it/s, running training loss: 1.0129]\u001b[A\n",
            "Training:  15%|█▌        | 267/1772 [01:22<08:03,  3.11it/s, running training loss: 1.0129]\u001b[A\n",
            "Training:  15%|█▌        | 267/1772 [01:22<08:03,  3.11it/s, running training loss: 1.1045]\u001b[A\n",
            "Training:  15%|█▌        | 268/1772 [01:22<07:52,  3.18it/s, running training loss: 1.1045]\u001b[A\n",
            "Training:  15%|█▌        | 268/1772 [01:22<07:52,  3.18it/s, running training loss: 1.0843]\u001b[A\n",
            "Training:  15%|█▌        | 269/1772 [01:22<07:51,  3.19it/s, running training loss: 1.0843]\u001b[A\n",
            "Training:  15%|█▌        | 269/1772 [01:22<07:51,  3.19it/s, running training loss: 1.1139]\u001b[A\n",
            "Training:  15%|█▌        | 270/1772 [01:22<07:57,  3.15it/s, running training loss: 1.1139]\u001b[A\n",
            "Training:  15%|█▌        | 270/1772 [01:23<07:57,  3.15it/s, running training loss: 0.9624]\u001b[A\n",
            "Training:  15%|█▌        | 271/1772 [01:23<08:02,  3.11it/s, running training loss: 0.9624]\u001b[A\n",
            "Training:  15%|█▌        | 271/1772 [01:23<08:02,  3.11it/s, running training loss: 1.0591]\u001b[A\n",
            "Training:  15%|█▌        | 272/1772 [01:23<07:46,  3.22it/s, running training loss: 1.0591]\u001b[A\n",
            "Training:  15%|█▌        | 272/1772 [01:23<07:46,  3.22it/s, running training loss: 1.0946]\u001b[A\n",
            "Training:  15%|█▌        | 273/1772 [01:23<07:59,  3.12it/s, running training loss: 1.0946]\u001b[A\n",
            "Training:  15%|█▌        | 273/1772 [01:24<07:59,  3.12it/s, running training loss: 1.0259]\u001b[A\n",
            "Training:  15%|█▌        | 274/1772 [01:24<07:26,  3.35it/s, running training loss: 1.0259]\u001b[A\n",
            "Training:  15%|█▌        | 274/1772 [01:24<07:26,  3.35it/s, running training loss: 1.0110]\u001b[A\n",
            "Training:  16%|█▌        | 275/1772 [01:24<07:17,  3.42it/s, running training loss: 1.0110]\u001b[A\n",
            "Training:  16%|█▌        | 275/1772 [01:24<07:17,  3.42it/s, running training loss: 0.8923]\u001b[A\n",
            "Training:  16%|█▌        | 276/1772 [01:24<06:52,  3.63it/s, running training loss: 0.8923]\u001b[A\n",
            "Training:  16%|█▌        | 276/1772 [01:25<06:52,  3.63it/s, running training loss: 1.0112]\u001b[A\n",
            "Training:  16%|█▌        | 277/1772 [01:25<08:05,  3.08it/s, running training loss: 1.0112]\u001b[A\n",
            "Training:  16%|█▌        | 277/1772 [01:25<08:05,  3.08it/s, running training loss: 0.8732]\u001b[A\n",
            "Training:  16%|█▌        | 278/1772 [01:25<07:50,  3.18it/s, running training loss: 0.8732]\u001b[A\n",
            "Training:  16%|█▌        | 278/1772 [01:25<07:50,  3.18it/s, running training loss: 1.0153]\u001b[A\n",
            "Training:  16%|█▌        | 279/1772 [01:25<07:17,  3.41it/s, running training loss: 1.0153]\u001b[A\n",
            "Training:  16%|█▌        | 279/1772 [01:26<07:17,  3.41it/s, running training loss: 0.8673]\u001b[A\n",
            "Training:  16%|█▌        | 280/1772 [01:26<07:59,  3.11it/s, running training loss: 0.8673]\u001b[A\n",
            "Training:  16%|█▌        | 280/1772 [01:26<07:59,  3.11it/s, running training loss: 0.9261]\u001b[A\n",
            "Training:  16%|█▌        | 281/1772 [01:26<07:29,  3.32it/s, running training loss: 0.9261]\u001b[A\n",
            "Training:  16%|█▌        | 281/1772 [01:26<07:29,  3.32it/s, running training loss: 0.9902]\u001b[A\n",
            "Training:  16%|█▌        | 282/1772 [01:26<07:32,  3.30it/s, running training loss: 0.9902]\u001b[A\n",
            "Training:  16%|█▌        | 282/1772 [01:26<07:32,  3.30it/s, running training loss: 1.1233]\u001b[A\n",
            "Training:  16%|█▌        | 283/1772 [01:27<08:03,  3.08it/s, running training loss: 1.1233]\u001b[A\n",
            "Training:  16%|█▌        | 283/1772 [01:27<08:03,  3.08it/s, running training loss: 1.1334]\u001b[A\n",
            "Training:  16%|█▌        | 284/1772 [01:27<08:02,  3.08it/s, running training loss: 1.1334]\u001b[A\n",
            "Training:  16%|█▌        | 284/1772 [01:27<08:02,  3.08it/s, running training loss: 1.0294]\u001b[A\n",
            "Training:  16%|█▌        | 285/1772 [01:27<08:01,  3.09it/s, running training loss: 1.0294]\u001b[A\n",
            "Training:  16%|█▌        | 285/1772 [01:27<08:01,  3.09it/s, running training loss: 0.9772]\u001b[A\n",
            "Training:  16%|█▌        | 286/1772 [01:27<07:34,  3.27it/s, running training loss: 0.9772]\u001b[A\n",
            "Training:  16%|█▌        | 286/1772 [01:28<07:34,  3.27it/s, running training loss: 0.9675]\u001b[A\n",
            "Training:  16%|█▌        | 287/1772 [01:28<07:40,  3.23it/s, running training loss: 0.9675]\u001b[A\n",
            "Training:  16%|█▌        | 287/1772 [01:28<07:40,  3.23it/s, running training loss: 1.0340]\u001b[A\n",
            "Training:  16%|█▋        | 288/1772 [01:28<07:32,  3.28it/s, running training loss: 1.0340]\u001b[A\n",
            "Training:  16%|█▋        | 288/1772 [01:28<07:32,  3.28it/s, running training loss: 1.0146]\u001b[A\n",
            "Training:  16%|█▋        | 289/1772 [01:28<08:02,  3.07it/s, running training loss: 1.0146]\u001b[A\n",
            "Training:  16%|█▋        | 289/1772 [01:29<08:02,  3.07it/s, running training loss: 1.2468]\u001b[A\n",
            "Training:  16%|█▋        | 290/1772 [01:29<07:38,  3.23it/s, running training loss: 1.2468]\u001b[A\n",
            "Training:  16%|█▋        | 290/1772 [01:29<07:38,  3.23it/s, running training loss: 0.8848]\u001b[A\n",
            "Training:  16%|█▋        | 291/1772 [01:29<07:41,  3.21it/s, running training loss: 0.8848]\u001b[A\n",
            "Training:  16%|█▋        | 291/1772 [01:29<07:41,  3.21it/s, running training loss: 1.0921]\u001b[A\n",
            "Training:  16%|█▋        | 292/1772 [01:29<07:10,  3.44it/s, running training loss: 1.0921]\u001b[A\n",
            "Training:  16%|█▋        | 292/1772 [01:30<07:10,  3.44it/s, running training loss: 1.1194]\u001b[A\n",
            "Training:  17%|█▋        | 293/1772 [01:30<07:03,  3.49it/s, running training loss: 1.1194]\u001b[A\n",
            "Training:  17%|█▋        | 293/1772 [01:30<07:03,  3.49it/s, running training loss: 1.0426]\u001b[A\n",
            "Training:  17%|█▋        | 294/1772 [01:30<06:52,  3.59it/s, running training loss: 1.0426]\u001b[A\n",
            "Training:  17%|█▋        | 294/1772 [01:30<06:52,  3.59it/s, running training loss: 1.2553]\u001b[A\n",
            "Training:  17%|█▋        | 295/1772 [01:30<07:23,  3.33it/s, running training loss: 1.2553]\u001b[A\n",
            "Training:  17%|█▋        | 295/1772 [01:30<07:23,  3.33it/s, running training loss: 0.9697]\u001b[A\n",
            "Training:  17%|█▋        | 296/1772 [01:30<07:33,  3.26it/s, running training loss: 0.9697]\u001b[A\n",
            "Training:  17%|█▋        | 296/1772 [01:31<07:33,  3.26it/s, running training loss: 0.9943]\u001b[A\n",
            "Training:  17%|█▋        | 297/1772 [01:31<07:23,  3.32it/s, running training loss: 0.9943]\u001b[A\n",
            "Training:  17%|█▋        | 297/1772 [01:31<07:23,  3.32it/s, running training loss: 1.1307]\u001b[A\n",
            "Training:  17%|█▋        | 298/1772 [01:31<09:00,  2.72it/s, running training loss: 1.1307]\u001b[A\n",
            "Training:  17%|█▋        | 298/1772 [01:32<09:00,  2.72it/s, running training loss: 1.2152]\u001b[A\n",
            "Training:  17%|█▋        | 299/1772 [01:32<09:04,  2.71it/s, running training loss: 1.2152]\u001b[A\n",
            "Training:  17%|█▋        | 299/1772 [01:32<09:04,  2.71it/s, running training loss: 0.9763]\u001b[A\n",
            "Training:  17%|█▋        | 300/1772 [01:32<09:16,  2.65it/s, running training loss: 0.9763]\u001b[A\n",
            "Training:  17%|█▋        | 300/1772 [01:32<09:16,  2.65it/s, running training loss: 0.9925]\u001b[A\n",
            "Training:  17%|█▋        | 301/1772 [01:32<08:19,  2.94it/s, running training loss: 0.9925]\u001b[A\n",
            "Training:  17%|█▋        | 301/1772 [01:33<08:19,  2.94it/s, running training loss: 1.1917]\u001b[A\n",
            "Training:  17%|█▋        | 302/1772 [01:33<07:54,  3.10it/s, running training loss: 1.1917]\u001b[A\n",
            "Training:  17%|█▋        | 302/1772 [01:33<07:54,  3.10it/s, running training loss: 1.0422]\u001b[A\n",
            "Training:  17%|█▋        | 303/1772 [01:33<07:32,  3.25it/s, running training loss: 1.0422]\u001b[A\n",
            "Training:  17%|█▋        | 303/1772 [01:33<07:32,  3.25it/s, running training loss: 1.5610]\u001b[A\n",
            "Training:  17%|█▋        | 304/1772 [01:33<08:41,  2.81it/s, running training loss: 1.5610]\u001b[A\n",
            "Training:  17%|█▋        | 304/1772 [01:34<08:41,  2.81it/s, running training loss: 1.1496]\u001b[A\n",
            "Training:  17%|█▋        | 305/1772 [01:34<08:28,  2.89it/s, running training loss: 1.1496]\u001b[A\n",
            "Training:  17%|█▋        | 305/1772 [01:34<08:28,  2.89it/s, running training loss: 1.1172]\u001b[A\n",
            "Training:  17%|█▋        | 306/1772 [01:34<09:26,  2.59it/s, running training loss: 1.1172]\u001b[A\n",
            "Training:  17%|█▋        | 306/1772 [01:34<09:26,  2.59it/s, running training loss: 1.2280]\u001b[A\n",
            "Training:  17%|█▋        | 307/1772 [01:34<08:23,  2.91it/s, running training loss: 1.2280]\u001b[A\n",
            "Training:  17%|█▋        | 307/1772 [01:35<08:23,  2.91it/s, running training loss: 0.9876]\u001b[A\n",
            "Training:  17%|█▋        | 308/1772 [01:35<07:48,  3.13it/s, running training loss: 0.9876]\u001b[A\n",
            "Training:  17%|█▋        | 308/1772 [01:35<07:48,  3.13it/s, running training loss: 1.0287]\u001b[A\n",
            "Training:  17%|█▋        | 309/1772 [01:35<07:21,  3.32it/s, running training loss: 1.0287]\u001b[A\n",
            "Training:  17%|█▋        | 309/1772 [01:35<07:21,  3.32it/s, running training loss: 0.9925]\u001b[A\n",
            "Training:  17%|█▋        | 310/1772 [01:35<07:18,  3.33it/s, running training loss: 0.9925]\u001b[A\n",
            "Training:  17%|█▋        | 310/1772 [01:35<07:18,  3.33it/s, running training loss: 1.0477]\u001b[A\n",
            "Training:  18%|█▊        | 311/1772 [01:35<07:03,  3.45it/s, running training loss: 1.0477]\u001b[A\n",
            "Training:  18%|█▊        | 311/1772 [01:36<07:03,  3.45it/s, running training loss: 0.8535]\u001b[A\n",
            "Training:  18%|█▊        | 312/1772 [01:36<07:08,  3.41it/s, running training loss: 0.8535]\u001b[A\n",
            "Training:  18%|█▊        | 312/1772 [01:36<07:08,  3.41it/s, running training loss: 0.9138]\u001b[A\n",
            "Training:  18%|█▊        | 313/1772 [01:36<08:16,  2.94it/s, running training loss: 0.9138]\u001b[A\n",
            "Training:  18%|█▊        | 313/1772 [01:36<08:16,  2.94it/s, running training loss: 0.9623]\u001b[A\n",
            "Training:  18%|█▊        | 314/1772 [01:36<07:45,  3.14it/s, running training loss: 0.9623]\u001b[A\n",
            "Training:  18%|█▊        | 314/1772 [01:37<07:45,  3.14it/s, running training loss: 0.9449]\u001b[A\n",
            "Training:  18%|█▊        | 315/1772 [01:37<07:11,  3.37it/s, running training loss: 0.9449]\u001b[A\n",
            "Training:  18%|█▊        | 315/1772 [01:37<07:11,  3.37it/s, running training loss: 0.8319]\u001b[A\n",
            "Training:  18%|█▊        | 316/1772 [01:37<07:21,  3.30it/s, running training loss: 0.8319]\u001b[A\n",
            "Training:  18%|█▊        | 316/1772 [01:37<07:21,  3.30it/s, running training loss: 0.8818]\u001b[A\n",
            "Training:  18%|█▊        | 317/1772 [01:37<07:09,  3.38it/s, running training loss: 0.8818]\u001b[A\n",
            "Training:  18%|█▊        | 317/1772 [01:38<07:09,  3.38it/s, running training loss: 0.9679]\u001b[A\n",
            "Training:  18%|█▊        | 318/1772 [01:38<07:10,  3.38it/s, running training loss: 0.9679]\u001b[A\n",
            "Training:  18%|█▊        | 318/1772 [01:38<07:10,  3.38it/s, running training loss: 0.9835]\u001b[A\n",
            "Training:  18%|█▊        | 319/1772 [01:38<07:39,  3.16it/s, running training loss: 0.9835]\u001b[A\n",
            "Training:  18%|█▊        | 319/1772 [01:38<07:39,  3.16it/s, running training loss: 0.9434]\u001b[A\n",
            "Training:  18%|█▊        | 320/1772 [01:38<07:51,  3.08it/s, running training loss: 0.9434]\u001b[A\n",
            "Training:  18%|█▊        | 320/1772 [01:39<07:51,  3.08it/s, running training loss: 1.2869]\u001b[A\n",
            "Training:  18%|█▊        | 321/1772 [01:39<07:54,  3.06it/s, running training loss: 1.2869]\u001b[A\n",
            "Training:  18%|█▊        | 321/1772 [01:39<07:54,  3.06it/s, running training loss: 1.1116]\u001b[A\n",
            "Training:  18%|█▊        | 322/1772 [01:39<08:28,  2.85it/s, running training loss: 1.1116]\u001b[A\n",
            "Training:  18%|█▊        | 322/1772 [01:39<08:28,  2.85it/s, running training loss: 1.0242]\u001b[A\n",
            "Training:  18%|█▊        | 323/1772 [01:39<07:53,  3.06it/s, running training loss: 1.0242]\u001b[A\n",
            "Training:  18%|█▊        | 323/1772 [01:40<07:53,  3.06it/s, running training loss: 1.0291]\u001b[A\n",
            "Training:  18%|█▊        | 324/1772 [01:40<09:08,  2.64it/s, running training loss: 1.0291]\u001b[A\n",
            "Training:  18%|█▊        | 324/1772 [01:40<09:08,  2.64it/s, running training loss: 1.0531]\u001b[A\n",
            "Training:  18%|█▊        | 325/1772 [01:40<08:11,  2.94it/s, running training loss: 1.0531]\u001b[A\n",
            "Training:  18%|█▊        | 325/1772 [01:40<08:11,  2.94it/s, running training loss: 0.9619]\u001b[A\n",
            "Training:  18%|█▊        | 326/1772 [01:40<07:58,  3.02it/s, running training loss: 0.9619]\u001b[A\n",
            "Training:  18%|█▊        | 326/1772 [01:41<07:58,  3.02it/s, running training loss: 0.9001]\u001b[A\n",
            "Training:  18%|█▊        | 327/1772 [01:41<07:31,  3.20it/s, running training loss: 0.9001]\u001b[A\n",
            "Training:  18%|█▊        | 327/1772 [01:41<07:31,  3.20it/s, running training loss: 0.7787]\u001b[A\n",
            "Training:  19%|█▊        | 328/1772 [01:41<07:43,  3.12it/s, running training loss: 0.7787]\u001b[A\n",
            "Training:  19%|█▊        | 328/1772 [01:41<07:43,  3.12it/s, running training loss: 0.9262]\u001b[A\n",
            "Training:  19%|█▊        | 329/1772 [01:41<07:26,  3.23it/s, running training loss: 0.9262]\u001b[A\n",
            "Training:  19%|█▊        | 329/1772 [01:42<07:26,  3.23it/s, running training loss: 0.8678]\u001b[A\n",
            "Training:  19%|█▊        | 330/1772 [01:42<08:29,  2.83it/s, running training loss: 0.8678]\u001b[A\n",
            "Training:  19%|█▊        | 330/1772 [01:42<08:29,  2.83it/s, running training loss: 0.9400]\u001b[A\n",
            "Training:  19%|█▊        | 331/1772 [01:42<07:57,  3.02it/s, running training loss: 0.9400]\u001b[A\n",
            "Training:  19%|█▊        | 331/1772 [01:42<07:57,  3.02it/s, running training loss: 0.8142]\u001b[A\n",
            "Training:  19%|█▊        | 332/1772 [01:42<07:27,  3.22it/s, running training loss: 0.8142]\u001b[A\n",
            "Training:  19%|█▊        | 332/1772 [01:43<07:27,  3.22it/s, running training loss: 0.9929]\u001b[A\n",
            "Training:  19%|█▉        | 333/1772 [01:43<07:06,  3.37it/s, running training loss: 0.9929]\u001b[A\n",
            "Training:  19%|█▉        | 333/1772 [01:43<07:06,  3.37it/s, running training loss: 0.9971]\u001b[A\n",
            "Training:  19%|█▉        | 334/1772 [01:43<06:59,  3.43it/s, running training loss: 0.9971]\u001b[A\n",
            "Training:  19%|█▉        | 334/1772 [01:43<06:59,  3.43it/s, running training loss: 1.0922]\u001b[A\n",
            "Training:  19%|█▉        | 335/1772 [01:43<07:01,  3.41it/s, running training loss: 1.0922]\u001b[A\n",
            "Training:  19%|█▉        | 335/1772 [01:43<07:01,  3.41it/s, running training loss: 1.1097]\u001b[A\n",
            "Training:  19%|█▉        | 336/1772 [01:43<06:36,  3.62it/s, running training loss: 1.1097]\u001b[A\n",
            "Training:  19%|█▉        | 336/1772 [01:44<06:36,  3.62it/s, running training loss: 1.0998]\u001b[A\n",
            "Training:  19%|█▉        | 337/1772 [01:44<06:39,  3.59it/s, running training loss: 1.0998]\u001b[A\n",
            "Training:  19%|█▉        | 337/1772 [01:44<06:39,  3.59it/s, running training loss: 0.9905]\u001b[A\n",
            "Training:  19%|█▉        | 338/1772 [01:44<06:27,  3.70it/s, running training loss: 0.9905]\u001b[A\n",
            "Training:  19%|█▉        | 338/1772 [01:44<06:27,  3.70it/s, running training loss: 0.9530]\u001b[A\n",
            "Training:  19%|█▉        | 339/1772 [01:44<07:35,  3.14it/s, running training loss: 0.9530]\u001b[A\n",
            "Training:  19%|█▉        | 339/1772 [01:45<07:35,  3.14it/s, running training loss: 0.9696]\u001b[A\n",
            "Training:  19%|█▉        | 340/1772 [01:45<07:29,  3.19it/s, running training loss: 0.9696]\u001b[A\n",
            "Training:  19%|█▉        | 340/1772 [01:45<07:29,  3.19it/s, running training loss: 0.9017]\u001b[A\n",
            "Training:  19%|█▉        | 341/1772 [01:45<08:20,  2.86it/s, running training loss: 0.9017]\u001b[A\n",
            "Training:  19%|█▉        | 341/1772 [01:45<08:20,  2.86it/s, running training loss: 0.8676]\u001b[A\n",
            "Training:  19%|█▉        | 342/1772 [01:45<07:46,  3.07it/s, running training loss: 0.8676]\u001b[A\n",
            "Training:  19%|█▉        | 342/1772 [01:46<07:46,  3.07it/s, running training loss: 0.9970]\u001b[A\n",
            "Training:  19%|█▉        | 343/1772 [01:46<07:18,  3.26it/s, running training loss: 0.9970]\u001b[A\n",
            "Training:  19%|█▉        | 343/1772 [01:46<07:18,  3.26it/s, running training loss: 0.9709]\u001b[A\n",
            "Training:  19%|█▉        | 344/1772 [01:46<06:38,  3.58it/s, running training loss: 0.9709]\u001b[A\n",
            "Training:  19%|█▉        | 344/1772 [01:46<06:38,  3.58it/s, running training loss: 1.0032]\u001b[A\n",
            "Training:  19%|█▉        | 345/1772 [01:46<06:29,  3.66it/s, running training loss: 1.0032]\u001b[A\n",
            "Training:  19%|█▉        | 345/1772 [01:46<06:29,  3.66it/s, running training loss: 0.7723]\u001b[A\n",
            "Training:  20%|█▉        | 346/1772 [01:46<06:41,  3.55it/s, running training loss: 0.7723]\u001b[A\n",
            "Training:  20%|█▉        | 346/1772 [01:47<06:41,  3.55it/s, running training loss: 0.7432]\u001b[A\n",
            "Training:  20%|█▉        | 347/1772 [01:47<07:19,  3.25it/s, running training loss: 0.7432]\u001b[A\n",
            "Training:  20%|█▉        | 347/1772 [01:47<07:19,  3.25it/s, running training loss: 0.7691]\u001b[A\n",
            "Training:  20%|█▉        | 348/1772 [01:47<07:50,  3.03it/s, running training loss: 0.7691]\u001b[A\n",
            "Training:  20%|█▉        | 348/1772 [01:47<07:50,  3.03it/s, running training loss: 1.0005]\u001b[A\n",
            "Training:  20%|█▉        | 349/1772 [01:47<07:45,  3.06it/s, running training loss: 1.0005]\u001b[A\n",
            "Training:  20%|█▉        | 349/1772 [01:48<07:45,  3.06it/s, running training loss: 1.1250]\u001b[A\n",
            "Training:  20%|█▉        | 350/1772 [01:48<07:04,  3.35it/s, running training loss: 1.1250]\u001b[A\n",
            "Training:  20%|█▉        | 350/1772 [01:48<07:04,  3.35it/s, running training loss: 0.7703]\u001b[A\n",
            "Training:  20%|█▉        | 351/1772 [01:48<07:17,  3.24it/s, running training loss: 0.7703]\u001b[A\n",
            "Training:  20%|█▉        | 351/1772 [01:48<07:17,  3.24it/s, running training loss: 1.0368]\u001b[A\n",
            "Training:  20%|█▉        | 352/1772 [01:48<07:20,  3.22it/s, running training loss: 1.0368]\u001b[A\n",
            "Training:  20%|█▉        | 352/1772 [01:49<07:20,  3.22it/s, running training loss: 0.8452]\u001b[A\n",
            "Training:  20%|█▉        | 353/1772 [01:49<07:28,  3.16it/s, running training loss: 0.8452]\u001b[A\n",
            "Training:  20%|█▉        | 353/1772 [01:49<07:28,  3.16it/s, running training loss: 1.0643]\u001b[A\n",
            "Training:  20%|█▉        | 354/1772 [01:49<07:17,  3.24it/s, running training loss: 1.0643]\u001b[A\n",
            "Training:  20%|█▉        | 354/1772 [01:49<07:17,  3.24it/s, running training loss: 1.0185]\u001b[A\n",
            "Training:  20%|██        | 355/1772 [01:49<06:57,  3.40it/s, running training loss: 1.0185]\u001b[A\n",
            "Training:  20%|██        | 355/1772 [01:49<06:57,  3.40it/s, running training loss: 0.8440]\u001b[A\n",
            "Training:  20%|██        | 356/1772 [01:49<06:33,  3.60it/s, running training loss: 0.8440]\u001b[A\n",
            "Training:  20%|██        | 356/1772 [01:50<06:33,  3.60it/s, running training loss: 1.1270]\u001b[A\n",
            "Training:  20%|██        | 357/1772 [01:50<08:21,  2.82it/s, running training loss: 1.1270]\u001b[A\n",
            "Training:  20%|██        | 357/1772 [01:50<08:21,  2.82it/s, running training loss: 1.1493]\u001b[A\n",
            "Training:  20%|██        | 358/1772 [01:50<08:01,  2.94it/s, running training loss: 1.1493]\u001b[A\n",
            "Training:  20%|██        | 358/1772 [01:51<08:01,  2.94it/s, running training loss: 1.0993]\u001b[A\n",
            "Training:  20%|██        | 359/1772 [01:51<07:28,  3.15it/s, running training loss: 1.0993]\u001b[A\n",
            "Training:  20%|██        | 359/1772 [01:51<07:28,  3.15it/s, running training loss: 1.0365]\u001b[A\n",
            "Training:  20%|██        | 360/1772 [01:51<07:11,  3.28it/s, running training loss: 1.0365]\u001b[A\n",
            "Training:  20%|██        | 360/1772 [01:51<07:11,  3.28it/s, running training loss: 1.0128]\u001b[A\n",
            "Training:  20%|██        | 361/1772 [01:51<06:36,  3.56it/s, running training loss: 1.0128]\u001b[A\n",
            "Training:  20%|██        | 361/1772 [01:51<06:36,  3.56it/s, running training loss: 0.8907]\u001b[A\n",
            "Training:  20%|██        | 362/1772 [01:51<07:00,  3.35it/s, running training loss: 0.8907]\u001b[A\n",
            "Training:  20%|██        | 362/1772 [01:52<07:00,  3.35it/s, running training loss: 1.0597]\u001b[A\n",
            "Training:  20%|██        | 363/1772 [01:52<06:26,  3.65it/s, running training loss: 1.0597]\u001b[A\n",
            "Training:  20%|██        | 363/1772 [01:52<06:26,  3.65it/s, running training loss: 1.0661]\u001b[A\n",
            "Training:  21%|██        | 364/1772 [01:52<06:12,  3.78it/s, running training loss: 1.0661]\u001b[A\n",
            "Training:  21%|██        | 364/1772 [01:52<06:12,  3.78it/s, running training loss: 1.0206]\u001b[A\n",
            "Training:  21%|██        | 365/1772 [01:52<06:15,  3.74it/s, running training loss: 1.0206]\u001b[A\n",
            "Training:  21%|██        | 365/1772 [01:52<06:15,  3.74it/s, running training loss: 1.0998]\u001b[A\n",
            "Training:  21%|██        | 366/1772 [01:52<06:07,  3.83it/s, running training loss: 1.0998]\u001b[A\n",
            "Training:  21%|██        | 366/1772 [01:53<06:07,  3.83it/s, running training loss: 1.1200]\u001b[A\n",
            "Training:  21%|██        | 367/1772 [01:53<07:42,  3.04it/s, running training loss: 1.1200]\u001b[A\n",
            "Training:  21%|██        | 367/1772 [01:53<07:42,  3.04it/s, running training loss: 0.9860]\u001b[A\n",
            "Training:  21%|██        | 368/1772 [01:53<07:06,  3.29it/s, running training loss: 0.9860]\u001b[A\n",
            "Training:  21%|██        | 368/1772 [01:53<07:06,  3.29it/s, running training loss: 0.9763]\u001b[A\n",
            "Training:  21%|██        | 369/1772 [01:53<07:40,  3.05it/s, running training loss: 0.9763]\u001b[A\n",
            "Training:  21%|██        | 369/1772 [01:54<07:40,  3.05it/s, running training loss: 0.7521]\u001b[A\n",
            "Training:  21%|██        | 370/1772 [01:54<07:46,  3.00it/s, running training loss: 0.7521]\u001b[A\n",
            "Training:  21%|██        | 370/1772 [01:54<07:46,  3.00it/s, running training loss: 1.1384]\u001b[A\n",
            "Training:  21%|██        | 371/1772 [01:54<07:22,  3.17it/s, running training loss: 1.1384]\u001b[A\n",
            "Training:  21%|██        | 371/1772 [01:54<07:22,  3.17it/s, running training loss: 0.7819]\u001b[A\n",
            "Training:  21%|██        | 372/1772 [01:54<07:00,  3.33it/s, running training loss: 0.7819]\u001b[A\n",
            "Training:  21%|██        | 372/1772 [01:55<07:00,  3.33it/s, running training loss: 0.8390]\u001b[A\n",
            "Training:  21%|██        | 373/1772 [01:55<07:47,  2.99it/s, running training loss: 0.8390]\u001b[A\n",
            "Training:  21%|██        | 373/1772 [01:55<07:47,  2.99it/s, running training loss: 0.9761]\u001b[A\n",
            "Training:  21%|██        | 374/1772 [01:55<07:25,  3.14it/s, running training loss: 0.9761]\u001b[A\n",
            "Training:  21%|██        | 374/1772 [01:55<07:25,  3.14it/s, running training loss: 0.7909]\u001b[A\n",
            "Training:  21%|██        | 375/1772 [01:55<07:30,  3.10it/s, running training loss: 0.7909]\u001b[A\n",
            "Training:  21%|██        | 375/1772 [01:56<07:30,  3.10it/s, running training loss: 1.1352]\u001b[A\n",
            "Training:  21%|██        | 376/1772 [01:56<07:24,  3.14it/s, running training loss: 1.1352]\u001b[A\n",
            "Training:  21%|██        | 376/1772 [01:56<07:24,  3.14it/s, running training loss: 0.8352]\u001b[A\n",
            "Training:  21%|██▏       | 377/1772 [01:56<07:13,  3.22it/s, running training loss: 0.8352]\u001b[A\n",
            "Training:  21%|██▏       | 377/1772 [01:56<07:13,  3.22it/s, running training loss: 0.8740]\u001b[A\n",
            "Training:  21%|██▏       | 378/1772 [01:56<07:26,  3.12it/s, running training loss: 0.8740]\u001b[A\n",
            "Training:  21%|██▏       | 378/1772 [01:57<07:26,  3.12it/s, running training loss: 1.0007]\u001b[A\n",
            "Training:  21%|██▏       | 379/1772 [01:57<07:02,  3.29it/s, running training loss: 1.0007]\u001b[A\n",
            "Training:  21%|██▏       | 379/1772 [01:57<07:02,  3.29it/s, running training loss: 0.9577]\u001b[A\n",
            "Training:  21%|██▏       | 380/1772 [01:57<08:20,  2.78it/s, running training loss: 0.9577]\u001b[A\n",
            "Training:  21%|██▏       | 380/1772 [01:57<08:20,  2.78it/s, running training loss: 0.9106]\u001b[A\n",
            "Training:  22%|██▏       | 381/1772 [01:57<07:42,  3.01it/s, running training loss: 0.9106]\u001b[A\n",
            "Training:  22%|██▏       | 381/1772 [01:58<07:42,  3.01it/s, running training loss: 0.8076]\u001b[A\n",
            "Training:  22%|██▏       | 382/1772 [01:58<07:27,  3.11it/s, running training loss: 0.8076]\u001b[A\n",
            "Training:  22%|██▏       | 382/1772 [01:58<07:27,  3.11it/s, running training loss: 0.9762]\u001b[A\n",
            "Training:  22%|██▏       | 383/1772 [01:58<08:21,  2.77it/s, running training loss: 0.9762]\u001b[A\n",
            "Training:  22%|██▏       | 383/1772 [01:58<08:21,  2.77it/s, running training loss: 1.1078]\u001b[A\n",
            "Training:  22%|██▏       | 384/1772 [01:58<08:08,  2.84it/s, running training loss: 1.1078]\u001b[A\n",
            "Training:  22%|██▏       | 384/1772 [01:59<08:08,  2.84it/s, running training loss: 0.8466]\u001b[A\n",
            "Training:  22%|██▏       | 385/1772 [01:59<07:41,  3.00it/s, running training loss: 0.8466]\u001b[A\n",
            "Training:  22%|██▏       | 385/1772 [01:59<07:41,  3.00it/s, running training loss: 1.0165]\u001b[A\n",
            "Training:  22%|██▏       | 386/1772 [01:59<07:28,  3.09it/s, running training loss: 1.0165]\u001b[A\n",
            "Training:  22%|██▏       | 386/1772 [01:59<07:28,  3.09it/s, running training loss: 1.0293]\u001b[A\n",
            "Training:  22%|██▏       | 387/1772 [01:59<07:54,  2.92it/s, running training loss: 1.0293]\u001b[A\n",
            "Training:  22%|██▏       | 387/1772 [02:00<07:54,  2.92it/s, running training loss: 0.9814]\u001b[A\n",
            "Training:  22%|██▏       | 388/1772 [02:00<07:39,  3.01it/s, running training loss: 0.9814]\u001b[A\n",
            "Training:  22%|██▏       | 388/1772 [02:00<07:39,  3.01it/s, running training loss: 1.1401]\u001b[A\n",
            "Training:  22%|██▏       | 389/1772 [02:00<07:17,  3.16it/s, running training loss: 1.1401]\u001b[A\n",
            "Training:  22%|██▏       | 389/1772 [02:00<07:17,  3.16it/s, running training loss: 0.9566]\u001b[A\n",
            "Training:  22%|██▏       | 390/1772 [02:00<07:05,  3.25it/s, running training loss: 0.9566]\u001b[A\n",
            "Training:  22%|██▏       | 390/1772 [02:01<07:05,  3.25it/s, running training loss: 0.7692]\u001b[A\n",
            "Training:  22%|██▏       | 391/1772 [02:01<07:50,  2.94it/s, running training loss: 0.7692]\u001b[A\n",
            "Training:  22%|██▏       | 391/1772 [02:01<07:50,  2.94it/s, running training loss: 0.9057]\u001b[A\n",
            "Training:  22%|██▏       | 392/1772 [02:01<07:56,  2.90it/s, running training loss: 0.9057]\u001b[A\n",
            "Training:  22%|██▏       | 392/1772 [02:01<07:56,  2.90it/s, running training loss: 1.0326]\u001b[A\n",
            "Training:  22%|██▏       | 393/1772 [02:01<07:20,  3.13it/s, running training loss: 1.0326]\u001b[A\n",
            "Training:  22%|██▏       | 393/1772 [02:02<07:20,  3.13it/s, running training loss: 0.9632]\u001b[A\n",
            "Training:  22%|██▏       | 394/1772 [02:02<07:33,  3.04it/s, running training loss: 0.9632]\u001b[A\n",
            "Training:  22%|██▏       | 394/1772 [02:02<07:33,  3.04it/s, running training loss: 1.0319]\u001b[A\n",
            "Training:  22%|██▏       | 395/1772 [02:02<07:44,  2.96it/s, running training loss: 1.0319]\u001b[A\n",
            "Training:  22%|██▏       | 395/1772 [02:02<07:44,  2.96it/s, running training loss: 0.9069]\u001b[A\n",
            "Training:  22%|██▏       | 396/1772 [02:02<07:41,  2.98it/s, running training loss: 0.9069]\u001b[A\n",
            "Training:  22%|██▏       | 396/1772 [02:03<07:41,  2.98it/s, running training loss: 0.9588]\u001b[A\n",
            "Training:  22%|██▏       | 397/1772 [02:03<08:00,  2.86it/s, running training loss: 0.9588]\u001b[A\n",
            "Training:  22%|██▏       | 397/1772 [02:03<08:00,  2.86it/s, running training loss: 0.8223]\u001b[A\n",
            "Training:  22%|██▏       | 398/1772 [02:03<08:38,  2.65it/s, running training loss: 0.8223]\u001b[A\n",
            "Training:  22%|██▏       | 398/1772 [02:03<08:38,  2.65it/s, running training loss: 0.9830]\u001b[A\n",
            "Training:  23%|██▎       | 399/1772 [02:03<08:13,  2.78it/s, running training loss: 0.9830]\u001b[A\n",
            "Training:  23%|██▎       | 399/1772 [02:04<08:13,  2.78it/s, running training loss: 1.0455]\u001b[A\n",
            "\n",
            "Evaluation:   0%|          | 0/270 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   0%|          | 1/270 [00:00<01:19,  3.38it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   1%|          | 3/270 [00:00<00:31,  8.58it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   2%|▏         | 5/270 [00:00<00:22, 11.74it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   3%|▎         | 8/270 [00:00<00:17, 14.97it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   4%|▎         | 10/270 [00:00<00:15, 16.26it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   5%|▍         | 13/270 [00:00<00:13, 18.91it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   6%|▌         | 16/270 [00:01<00:13, 18.93it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   7%|▋         | 18/270 [00:01<00:13, 18.49it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   7%|▋         | 20/270 [00:01<00:13, 17.96it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   9%|▊         | 23/270 [00:01<00:12, 19.83it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  10%|▉         | 26/270 [00:01<00:12, 20.32it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  11%|█         | 29/270 [00:01<00:12, 19.80it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  11%|█▏        | 31/270 [00:01<00:12, 18.99it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  12%|█▏        | 33/270 [00:01<00:12, 19.16it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  13%|█▎        | 35/270 [00:02<00:12, 19.32it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  14%|█▍        | 38/270 [00:02<00:10, 21.10it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  15%|█▌        | 41/270 [00:02<00:11, 20.58it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  16%|█▋        | 44/270 [00:02<00:11, 19.61it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  17%|█▋        | 46/270 [00:02<00:11, 19.24it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  18%|█▊        | 49/270 [00:02<00:11, 19.64it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  19%|█▉        | 51/270 [00:02<00:11, 19.15it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  20%|█▉        | 53/270 [00:02<00:11, 18.99it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  21%|██        | 56/270 [00:03<00:11, 19.39it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  21%|██▏       | 58/270 [00:03<00:11, 19.02it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  22%|██▏       | 60/270 [00:03<00:11, 18.55it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  23%|██▎       | 62/270 [00:03<00:11, 18.58it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  24%|██▎       | 64/270 [00:03<00:11, 18.48it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  25%|██▍       | 67/270 [00:03<00:10, 19.86it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  26%|██▌       | 70/270 [00:03<00:09, 21.18it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  27%|██▋       | 73/270 [00:03<00:09, 20.49it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  28%|██▊       | 76/270 [00:04<00:09, 21.39it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  29%|██▉       | 79/270 [00:04<00:08, 21.30it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  30%|███       | 82/270 [00:04<00:09, 20.02it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  31%|███▏      | 85/270 [00:04<00:09, 19.84it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  32%|███▏      | 87/270 [00:04<00:09, 19.83it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  33%|███▎      | 89/270 [00:04<00:09, 19.04it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  34%|███▎      | 91/270 [00:04<00:09, 18.88it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  35%|███▍      | 94/270 [00:05<00:08, 19.91it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  36%|███▌      | 97/270 [00:05<00:08, 20.53it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  37%|███▋      | 100/270 [00:05<00:08, 20.49it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  38%|███▊      | 103/270 [00:05<00:07, 20.99it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  39%|███▉      | 106/270 [00:05<00:07, 20.65it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  40%|████      | 109/270 [00:05<00:07, 20.50it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  41%|████▏     | 112/270 [00:05<00:07, 20.67it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  43%|████▎     | 115/270 [00:06<00:07, 20.90it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  44%|████▎     | 118/270 [00:06<00:07, 21.02it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  45%|████▍     | 121/270 [00:06<00:07, 20.65it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  46%|████▌     | 124/270 [00:06<00:06, 21.36it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  47%|████▋     | 127/270 [00:06<00:07, 20.00it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  48%|████▊     | 130/270 [00:06<00:07, 19.71it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  49%|████▉     | 132/270 [00:06<00:07, 19.55it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  50%|████▉     | 134/270 [00:06<00:06, 19.47it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  51%|█████     | 137/270 [00:07<00:06, 20.40it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  52%|█████▏    | 140/270 [00:07<00:06, 20.42it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  53%|█████▎    | 143/270 [00:07<00:06, 19.82it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  54%|█████▍    | 146/270 [00:07<00:06, 20.35it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  55%|█████▌    | 149/270 [00:07<00:05, 20.18it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  56%|█████▋    | 152/270 [00:07<00:05, 19.81it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  57%|█████▋    | 154/270 [00:07<00:05, 19.68it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  58%|█████▊    | 156/270 [00:08<00:05, 19.38it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  59%|█████▉    | 159/270 [00:08<00:05, 20.39it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  60%|██████    | 162/270 [00:08<00:05, 19.93it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  61%|██████    | 164/270 [00:08<00:05, 19.59it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  61%|██████▏   | 166/270 [00:08<00:05, 19.65it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  63%|██████▎   | 169/270 [00:08<00:05, 19.36it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  63%|██████▎   | 171/270 [00:08<00:05, 19.25it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  64%|██████▍   | 173/270 [00:08<00:05, 18.90it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  65%|██████▍   | 175/270 [00:09<00:05, 18.51it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  66%|██████▌   | 177/270 [00:09<00:05, 17.74it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  66%|██████▋   | 179/270 [00:09<00:05, 18.13it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  67%|██████▋   | 181/270 [00:09<00:04, 18.09it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  68%|██████▊   | 183/270 [00:09<00:04, 18.21it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  69%|██████▊   | 185/270 [00:09<00:04, 18.12it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  70%|██████▉   | 188/270 [00:09<00:04, 18.46it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  71%|███████   | 191/270 [00:09<00:03, 20.05it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  72%|███████▏  | 194/270 [00:10<00:03, 19.22it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  73%|███████▎  | 196/270 [00:10<00:03, 18.82it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  73%|███████▎  | 198/270 [00:10<00:03, 18.77it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  74%|███████▍  | 200/270 [00:10<00:03, 18.30it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  75%|███████▍  | 202/270 [00:10<00:03, 17.64it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  76%|███████▌  | 205/270 [00:10<00:03, 20.00it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  77%|███████▋  | 208/270 [00:10<00:03, 19.21it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  78%|███████▊  | 210/270 [00:10<00:03, 18.69it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  79%|███████▊  | 212/270 [00:11<00:03, 18.67it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  80%|███████▉  | 215/270 [00:11<00:02, 20.13it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  81%|████████  | 218/270 [00:11<00:02, 20.33it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  82%|████████▏ | 221/270 [00:11<00:02, 20.88it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  83%|████████▎ | 224/270 [00:11<00:02, 21.81it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  84%|████████▍ | 227/270 [00:11<00:01, 21.64it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  85%|████████▌ | 230/270 [00:11<00:02, 19.84it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  86%|████████▋ | 233/270 [00:12<00:01, 20.48it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  87%|████████▋ | 236/270 [00:12<00:01, 20.80it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  89%|████████▊ | 239/270 [00:12<00:01, 20.69it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  90%|████████▉ | 242/270 [00:12<00:01, 20.06it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  91%|█████████ | 245/270 [00:12<00:01, 19.36it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  91%|█████████▏| 247/270 [00:12<00:01, 18.57it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  92%|█████████▏| 249/270 [00:12<00:01, 18.17it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  93%|█████████▎| 251/270 [00:13<00:01, 17.45it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  94%|█████████▎| 253/270 [00:13<00:00, 17.25it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  94%|█████████▍| 255/270 [00:13<00:00, 17.50it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  95%|█████████▌| 257/270 [00:13<00:00, 17.98it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  96%|█████████▋| 260/270 [00:13<00:00, 19.86it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  97%|█████████▋| 262/270 [00:13<00:00, 19.35it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  98%|█████████▊| 264/270 [00:13<00:00, 18.57it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  99%|█████████▊| 266/270 [00:13<00:00, 18.47it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  99%|█████████▉| 268/270 [00:13<00:00, 18.80it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation: 100%|██████████| 270/270 [00:14<00:00, 19.02it/s]\n",
            "\n",
            "Training:  23%|██▎       | 400/1772 [02:20<1:57:07,  5.12s/it, running training loss: 1.0455]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            ">>> training loss: 1.050217, valid loss: 0.686829, valid f1: 0.406597, valid acc: 0.541474\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  23%|██▎       | 400/1772 [02:20<1:57:07,  5.12s/it, running training loss: 0.9886]\u001b[A\n",
            "Training:  23%|██▎       | 401/1772 [02:20<1:24:16,  3.69s/it, running training loss: 0.9886]\u001b[A\n",
            "Training:  23%|██▎       | 401/1772 [02:20<1:24:16,  3.69s/it, running training loss: 1.0833]\u001b[A\n",
            "Training:  23%|██▎       | 402/1772 [02:20<1:00:37,  2.65s/it, running training loss: 1.0833]\u001b[A\n",
            "Training:  23%|██▎       | 402/1772 [02:21<1:00:37,  2.65s/it, running training loss: 1.1472]\u001b[A\n",
            "Training:  23%|██▎       | 403/1772 [02:21<44:42,  1.96s/it, running training loss: 1.1472]  \u001b[A\n",
            "Training:  23%|██▎       | 403/1772 [02:21<44:42,  1.96s/it, running training loss: 1.0683]\u001b[A\n",
            "Training:  23%|██▎       | 404/1772 [02:21<33:46,  1.48s/it, running training loss: 1.0683]\u001b[A\n",
            "Training:  23%|██▎       | 404/1772 [02:21<33:46,  1.48s/it, running training loss: 1.1087]\u001b[A\n",
            "Training:  23%|██▎       | 405/1772 [02:21<26:53,  1.18s/it, running training loss: 1.1087]\u001b[A\n",
            "Training:  23%|██▎       | 405/1772 [02:22<26:53,  1.18s/it, running training loss: 1.1013]\u001b[A\n",
            "Training:  23%|██▎       | 406/1772 [02:22<20:31,  1.11it/s, running training loss: 1.1013]\u001b[A\n",
            "Training:  23%|██▎       | 406/1772 [02:22<20:31,  1.11it/s, running training loss: 0.8654]\u001b[A\n",
            "Training:  23%|██▎       | 407/1772 [02:22<16:17,  1.40it/s, running training loss: 0.8654]\u001b[A\n",
            "Training:  23%|██▎       | 407/1772 [02:22<16:17,  1.40it/s, running training loss: 1.0199]\u001b[A\n",
            "Training:  23%|██▎       | 408/1772 [02:22<13:30,  1.68it/s, running training loss: 1.0199]\u001b[A\n",
            "Training:  23%|██▎       | 408/1772 [02:23<13:30,  1.68it/s, running training loss: 0.9598]\u001b[A\n",
            "Training:  23%|██▎       | 409/1772 [02:23<11:26,  1.99it/s, running training loss: 0.9598]\u001b[A\n",
            "Training:  23%|██▎       | 409/1772 [02:23<11:26,  1.99it/s, running training loss: 1.1263]\u001b[A\n",
            "Training:  23%|██▎       | 410/1772 [02:23<10:21,  2.19it/s, running training loss: 1.1263]\u001b[A\n",
            "Training:  23%|██▎       | 410/1772 [02:23<10:21,  2.19it/s, running training loss: 1.0818]\u001b[A\n",
            "Training:  23%|██▎       | 411/1772 [02:23<09:01,  2.51it/s, running training loss: 1.0818]\u001b[A\n",
            "Training:  23%|██▎       | 411/1772 [02:24<09:01,  2.51it/s, running training loss: 0.8183]\u001b[A\n",
            "Training:  23%|██▎       | 412/1772 [02:24<08:34,  2.64it/s, running training loss: 0.8183]\u001b[A\n",
            "Training:  23%|██▎       | 412/1772 [02:24<08:34,  2.64it/s, running training loss: 1.0870]\u001b[A\n",
            "Training:  23%|██▎       | 413/1772 [02:24<08:49,  2.57it/s, running training loss: 1.0870]\u001b[A\n",
            "Training:  23%|██▎       | 413/1772 [02:24<08:49,  2.57it/s, running training loss: 1.2564]\u001b[A\n",
            "Training:  23%|██▎       | 414/1772 [02:24<08:04,  2.80it/s, running training loss: 1.2564]\u001b[A\n",
            "Training:  23%|██▎       | 414/1772 [02:25<08:04,  2.80it/s, running training loss: 1.1708]\u001b[A\n",
            "Training:  23%|██▎       | 415/1772 [02:25<08:22,  2.70it/s, running training loss: 1.1708]\u001b[A\n",
            "Training:  23%|██▎       | 415/1772 [02:25<08:22,  2.70it/s, running training loss: 1.1069]\u001b[A\n",
            "Training:  23%|██▎       | 416/1772 [02:25<09:04,  2.49it/s, running training loss: 1.1069]\u001b[A\n",
            "Training:  23%|██▎       | 416/1772 [02:25<09:04,  2.49it/s, running training loss: 1.0006]\u001b[A\n",
            "Training:  24%|██▎       | 417/1772 [02:25<08:43,  2.59it/s, running training loss: 1.0006]\u001b[A\n",
            "Training:  24%|██▎       | 417/1772 [02:26<08:43,  2.59it/s, running training loss: 1.0269]\u001b[A\n",
            "Training:  24%|██▎       | 418/1772 [02:26<08:38,  2.61it/s, running training loss: 1.0269]\u001b[A\n",
            "Training:  24%|██▎       | 418/1772 [02:26<08:38,  2.61it/s, running training loss: 1.0196]\u001b[A\n",
            "Training:  24%|██▎       | 419/1772 [02:26<08:15,  2.73it/s, running training loss: 1.0196]\u001b[A\n",
            "Training:  24%|██▎       | 419/1772 [02:26<08:15,  2.73it/s, running training loss: 0.9689]\u001b[A\n",
            "Training:  24%|██▎       | 420/1772 [02:26<07:39,  2.94it/s, running training loss: 0.9689]\u001b[A\n",
            "Training:  24%|██▎       | 420/1772 [02:27<07:39,  2.94it/s, running training loss: 1.0221]\u001b[A\n",
            "Training:  24%|██▍       | 421/1772 [02:27<07:07,  3.16it/s, running training loss: 1.0221]\u001b[A\n",
            "Training:  24%|██▍       | 421/1772 [02:27<07:07,  3.16it/s, running training loss: 0.9457]\u001b[A\n",
            "Training:  24%|██▍       | 422/1772 [02:27<06:49,  3.30it/s, running training loss: 0.9457]\u001b[A\n",
            "Training:  24%|██▍       | 422/1772 [02:27<06:49,  3.30it/s, running training loss: 0.9712]\u001b[A\n",
            "Training:  24%|██▍       | 423/1772 [02:27<07:56,  2.83it/s, running training loss: 0.9712]\u001b[A\n",
            "Training:  24%|██▍       | 423/1772 [02:28<07:56,  2.83it/s, running training loss: 0.8623]\u001b[A\n",
            "Training:  24%|██▍       | 424/1772 [02:28<08:21,  2.69it/s, running training loss: 0.8623]\u001b[A\n",
            "Training:  24%|██▍       | 424/1772 [02:28<08:21,  2.69it/s, running training loss: 1.0496]\u001b[A\n",
            "Training:  24%|██▍       | 425/1772 [02:28<09:26,  2.38it/s, running training loss: 1.0496]\u001b[A\n",
            "Training:  24%|██▍       | 425/1772 [02:29<09:26,  2.38it/s, running training loss: 1.0619]\u001b[A\n",
            "Training:  24%|██▍       | 426/1772 [02:29<08:46,  2.55it/s, running training loss: 1.0619]\u001b[A\n",
            "Training:  24%|██▍       | 426/1772 [02:29<08:46,  2.55it/s, running training loss: 1.0632]\u001b[A\n",
            "Training:  24%|██▍       | 427/1772 [02:29<08:02,  2.79it/s, running training loss: 1.0632]\u001b[A\n",
            "Training:  24%|██▍       | 427/1772 [02:29<08:02,  2.79it/s, running training loss: 0.9905]\u001b[A\n",
            "Training:  24%|██▍       | 428/1772 [02:29<07:30,  2.98it/s, running training loss: 0.9905]\u001b[A\n",
            "Training:  24%|██▍       | 428/1772 [02:30<07:30,  2.98it/s, running training loss: 1.0574]\u001b[A\n",
            "Training:  24%|██▍       | 429/1772 [02:30<07:29,  2.99it/s, running training loss: 1.0574]\u001b[A\n",
            "Training:  24%|██▍       | 429/1772 [02:30<07:29,  2.99it/s, running training loss: 1.0716]\u001b[A\n",
            "Training:  24%|██▍       | 430/1772 [02:30<07:13,  3.09it/s, running training loss: 1.0716]\u001b[A\n",
            "Training:  24%|██▍       | 430/1772 [02:30<07:13,  3.09it/s, running training loss: 1.0872]\u001b[A\n",
            "Training:  24%|██▍       | 431/1772 [02:30<07:09,  3.12it/s, running training loss: 1.0872]\u001b[A\n",
            "Training:  24%|██▍       | 431/1772 [02:31<07:09,  3.12it/s, running training loss: 1.0220]\u001b[A\n",
            "Training:  24%|██▍       | 432/1772 [02:31<07:00,  3.19it/s, running training loss: 1.0220]\u001b[A\n",
            "Training:  24%|██▍       | 432/1772 [02:31<07:00,  3.19it/s, running training loss: 1.0826]\u001b[A\n",
            "Training:  24%|██▍       | 433/1772 [02:31<07:12,  3.09it/s, running training loss: 1.0826]\u001b[A\n",
            "Training:  24%|██▍       | 433/1772 [02:31<07:12,  3.09it/s, running training loss: 1.1416]\u001b[A\n",
            "Training:  24%|██▍       | 434/1772 [02:31<06:51,  3.25it/s, running training loss: 1.1416]\u001b[A\n",
            "Training:  24%|██▍       | 434/1772 [02:31<06:51,  3.25it/s, running training loss: 1.1062]\u001b[A\n",
            "Training:  25%|██▍       | 435/1772 [02:31<06:53,  3.23it/s, running training loss: 1.1062]\u001b[A\n",
            "Training:  25%|██▍       | 435/1772 [02:32<06:53,  3.23it/s, running training loss: 1.2008]\u001b[A\n",
            "Training:  25%|██▍       | 436/1772 [02:32<07:24,  3.01it/s, running training loss: 1.2008]\u001b[A\n",
            "Training:  25%|██▍       | 436/1772 [02:32<07:24,  3.01it/s, running training loss: 0.9516]\u001b[A\n",
            "Training:  25%|██▍       | 437/1772 [02:32<08:48,  2.53it/s, running training loss: 0.9516]\u001b[A\n",
            "Training:  25%|██▍       | 437/1772 [02:33<08:48,  2.53it/s, running training loss: 0.9478]\u001b[A\n",
            "Training:  25%|██▍       | 438/1772 [02:33<08:17,  2.68it/s, running training loss: 0.9478]\u001b[A\n",
            "Training:  25%|██▍       | 438/1772 [02:33<08:17,  2.68it/s, running training loss: 1.1085]\u001b[A\n",
            "Training:  25%|██▍       | 439/1772 [02:33<07:33,  2.94it/s, running training loss: 1.1085]\u001b[A\n",
            "Training:  25%|██▍       | 439/1772 [02:33<07:33,  2.94it/s, running training loss: 1.0622]\u001b[A\n",
            "Training:  25%|██▍       | 440/1772 [02:33<07:07,  3.12it/s, running training loss: 1.0622]\u001b[A\n",
            "Training:  25%|██▍       | 440/1772 [02:33<07:07,  3.12it/s, running training loss: 1.0382]\u001b[A\n",
            "Training:  25%|██▍       | 441/1772 [02:34<06:35,  3.37it/s, running training loss: 1.0382]\u001b[A\n",
            "Training:  25%|██▍       | 441/1772 [02:34<06:35,  3.37it/s, running training loss: 0.9037]\u001b[A\n",
            "Training:  25%|██▍       | 442/1772 [02:34<06:33,  3.38it/s, running training loss: 0.9037]\u001b[A\n",
            "Training:  25%|██▍       | 442/1772 [02:34<06:33,  3.38it/s, running training loss: 0.9440]\u001b[A\n",
            "Training:  25%|██▌       | 443/1772 [02:34<06:37,  3.35it/s, running training loss: 0.9440]\u001b[A\n",
            "Training:  25%|██▌       | 443/1772 [02:35<06:37,  3.35it/s, running training loss: 1.1145]\u001b[A\n",
            "Training:  25%|██▌       | 444/1772 [02:35<07:46,  2.85it/s, running training loss: 1.1145]\u001b[A\n",
            "Training:  25%|██▌       | 444/1772 [02:35<07:46,  2.85it/s, running training loss: 0.8502]\u001b[A\n",
            "Training:  25%|██▌       | 445/1772 [02:35<07:52,  2.81it/s, running training loss: 0.8502]\u001b[A\n",
            "Training:  25%|██▌       | 445/1772 [02:35<07:52,  2.81it/s, running training loss: 0.9761]\u001b[A\n",
            "Training:  25%|██▌       | 446/1772 [02:35<07:29,  2.95it/s, running training loss: 0.9761]\u001b[A\n",
            "Training:  25%|██▌       | 446/1772 [02:36<07:29,  2.95it/s, running training loss: 1.0028]\u001b[A\n",
            "Training:  25%|██▌       | 447/1772 [02:36<07:34,  2.92it/s, running training loss: 1.0028]\u001b[A\n",
            "Training:  25%|██▌       | 447/1772 [02:36<07:34,  2.92it/s, running training loss: 0.8879]\u001b[A\n",
            "Training:  25%|██▌       | 448/1772 [02:36<07:39,  2.88it/s, running training loss: 0.8879]\u001b[A\n",
            "Training:  25%|██▌       | 448/1772 [02:36<07:39,  2.88it/s, running training loss: 1.0913]\u001b[A\n",
            "Training:  25%|██▌       | 449/1772 [02:36<06:42,  3.28it/s, running training loss: 1.0913]\u001b[A\n",
            "Training:  25%|██▌       | 449/1772 [02:36<06:42,  3.28it/s, running training loss: 1.1058]\u001b[A\n",
            "Training:  25%|██▌       | 450/1772 [02:36<06:32,  3.37it/s, running training loss: 1.1058]\u001b[A\n",
            "Training:  25%|██▌       | 450/1772 [02:37<06:32,  3.37it/s, running training loss: 0.9635]\u001b[A\n",
            "Training:  25%|██▌       | 451/1772 [02:37<07:13,  3.05it/s, running training loss: 0.9635]\u001b[A\n",
            "Training:  25%|██▌       | 451/1772 [02:37<07:13,  3.05it/s, running training loss: 1.1440]\u001b[A\n",
            "Training:  26%|██▌       | 452/1772 [02:37<06:53,  3.19it/s, running training loss: 1.1440]\u001b[A\n",
            "Training:  26%|██▌       | 452/1772 [02:37<06:53,  3.19it/s, running training loss: 1.0708]\u001b[A\n",
            "Training:  26%|██▌       | 453/1772 [02:37<07:10,  3.06it/s, running training loss: 1.0708]\u001b[A\n",
            "Training:  26%|██▌       | 453/1772 [02:38<07:10,  3.06it/s, running training loss: 1.0469]\u001b[A\n",
            "Training:  26%|██▌       | 454/1772 [02:38<06:34,  3.34it/s, running training loss: 1.0469]\u001b[A\n",
            "Training:  26%|██▌       | 454/1772 [02:38<06:34,  3.34it/s, running training loss: 1.1363]\u001b[A\n",
            "Training:  26%|██▌       | 455/1772 [02:38<07:08,  3.07it/s, running training loss: 1.1363]\u001b[A\n",
            "Training:  26%|██▌       | 455/1772 [02:38<07:08,  3.07it/s, running training loss: 1.0355]\u001b[A\n",
            "Training:  26%|██▌       | 456/1772 [02:38<07:22,  2.98it/s, running training loss: 1.0355]\u001b[A\n",
            "Training:  26%|██▌       | 456/1772 [02:39<07:22,  2.98it/s, running training loss: 0.9826]\u001b[A\n",
            "Training:  26%|██▌       | 457/1772 [02:39<07:28,  2.93it/s, running training loss: 0.9826]\u001b[A\n",
            "Training:  26%|██▌       | 457/1772 [02:39<07:28,  2.93it/s, running training loss: 1.0456]\u001b[A\n",
            "Training:  26%|██▌       | 458/1772 [02:39<07:23,  2.96it/s, running training loss: 1.0456]\u001b[A\n",
            "Training:  26%|██▌       | 458/1772 [02:39<07:23,  2.96it/s, running training loss: 1.0970]\u001b[A\n",
            "Training:  26%|██▌       | 459/1772 [02:39<06:58,  3.14it/s, running training loss: 1.0970]\u001b[A\n",
            "Training:  26%|██▌       | 459/1772 [02:40<06:58,  3.14it/s, running training loss: 0.8001]\u001b[A\n",
            "Training:  26%|██▌       | 460/1772 [02:40<06:35,  3.32it/s, running training loss: 0.8001]\u001b[A\n",
            "Training:  26%|██▌       | 460/1772 [02:40<06:35,  3.32it/s, running training loss: 0.8060]\u001b[A\n",
            "Training:  26%|██▌       | 461/1772 [02:40<06:51,  3.19it/s, running training loss: 0.8060]\u001b[A\n",
            "Training:  26%|██▌       | 461/1772 [02:40<06:51,  3.19it/s, running training loss: 0.9648]\u001b[A\n",
            "Training:  26%|██▌       | 462/1772 [02:40<06:46,  3.23it/s, running training loss: 0.9648]\u001b[A\n",
            "Training:  26%|██▌       | 462/1772 [02:41<06:46,  3.23it/s, running training loss: 0.9638]\u001b[A\n",
            "Training:  26%|██▌       | 463/1772 [02:41<06:48,  3.20it/s, running training loss: 0.9638]\u001b[A\n",
            "Training:  26%|██▌       | 463/1772 [02:41<06:48,  3.20it/s, running training loss: 0.8924]\u001b[A\n",
            "Training:  26%|██▌       | 464/1772 [02:41<06:38,  3.28it/s, running training loss: 0.8924]\u001b[A\n",
            "Training:  26%|██▌       | 464/1772 [02:41<06:38,  3.28it/s, running training loss: 1.1772]\u001b[A\n",
            "Training:  26%|██▌       | 465/1772 [02:41<06:23,  3.41it/s, running training loss: 1.1772]\u001b[A\n",
            "Training:  26%|██▌       | 465/1772 [02:41<06:23,  3.41it/s, running training loss: 1.0223]\u001b[A\n",
            "Training:  26%|██▋       | 466/1772 [02:41<06:17,  3.46it/s, running training loss: 1.0223]\u001b[A\n",
            "Training:  26%|██▋       | 466/1772 [02:42<06:17,  3.46it/s, running training loss: 0.9754]\u001b[A\n",
            "Training:  26%|██▋       | 467/1772 [02:42<06:20,  3.43it/s, running training loss: 0.9754]\u001b[A\n",
            "Training:  26%|██▋       | 467/1772 [02:42<06:20,  3.43it/s, running training loss: 0.9701]\u001b[A\n",
            "Training:  26%|██▋       | 468/1772 [02:42<06:00,  3.61it/s, running training loss: 0.9701]\u001b[A\n",
            "Training:  26%|██▋       | 468/1772 [02:42<06:00,  3.61it/s, running training loss: 1.0488]\u001b[A\n",
            "Training:  26%|██▋       | 469/1772 [02:42<05:44,  3.79it/s, running training loss: 1.0488]\u001b[A\n",
            "Training:  26%|██▋       | 469/1772 [02:43<05:44,  3.79it/s, running training loss: 1.0795]\u001b[A\n",
            "Training:  27%|██▋       | 470/1772 [02:43<06:09,  3.52it/s, running training loss: 1.0795]\u001b[A\n",
            "Training:  27%|██▋       | 470/1772 [02:43<06:09,  3.52it/s, running training loss: 1.0617]\u001b[A\n",
            "Training:  27%|██▋       | 471/1772 [02:43<07:49,  2.77it/s, running training loss: 1.0617]\u001b[A\n",
            "Training:  27%|██▋       | 471/1772 [02:43<07:49,  2.77it/s, running training loss: 1.0906]\u001b[A\n",
            "Training:  27%|██▋       | 472/1772 [02:43<07:25,  2.92it/s, running training loss: 1.0906]\u001b[A\n",
            "Training:  27%|██▋       | 472/1772 [02:44<07:25,  2.92it/s, running training loss: 0.9014]\u001b[A\n",
            "Training:  27%|██▋       | 473/1772 [02:44<06:57,  3.11it/s, running training loss: 0.9014]\u001b[A\n",
            "Training:  27%|██▋       | 473/1772 [02:44<06:57,  3.11it/s, running training loss: 0.8818]\u001b[A\n",
            "Training:  27%|██▋       | 474/1772 [02:44<07:14,  2.99it/s, running training loss: 0.8818]\u001b[A\n",
            "Training:  27%|██▋       | 474/1772 [02:44<07:14,  2.99it/s, running training loss: 1.1673]\u001b[A\n",
            "Training:  27%|██▋       | 475/1772 [02:44<06:39,  3.24it/s, running training loss: 1.1673]\u001b[A\n",
            "Training:  27%|██▋       | 475/1772 [02:45<06:39,  3.24it/s, running training loss: 1.0741]\u001b[A\n",
            "Training:  27%|██▋       | 476/1772 [02:45<07:28,  2.89it/s, running training loss: 1.0741]\u001b[A\n",
            "Training:  27%|██▋       | 476/1772 [02:45<07:28,  2.89it/s, running training loss: 1.1365]\u001b[A\n",
            "Training:  27%|██▋       | 477/1772 [02:45<06:51,  3.15it/s, running training loss: 1.1365]\u001b[A\n",
            "Training:  27%|██▋       | 477/1772 [02:45<06:51,  3.15it/s, running training loss: 1.1361]\u001b[A\n",
            "Training:  27%|██▋       | 478/1772 [02:45<07:02,  3.06it/s, running training loss: 1.1361]\u001b[A\n",
            "Training:  27%|██▋       | 478/1772 [02:46<07:02,  3.06it/s, running training loss: 0.9453]\u001b[A\n",
            "Training:  27%|██▋       | 479/1772 [02:46<06:40,  3.23it/s, running training loss: 0.9453]\u001b[A\n",
            "Training:  27%|██▋       | 479/1772 [02:46<06:40,  3.23it/s, running training loss: 0.9697]\u001b[A\n",
            "Training:  27%|██▋       | 480/1772 [02:46<06:34,  3.27it/s, running training loss: 0.9697]\u001b[A\n",
            "Training:  27%|██▋       | 480/1772 [02:46<06:34,  3.27it/s, running training loss: 0.8471]\u001b[A\n",
            "Training:  27%|██▋       | 481/1772 [02:46<06:31,  3.30it/s, running training loss: 0.8471]\u001b[A\n",
            "Training:  27%|██▋       | 481/1772 [02:47<06:31,  3.30it/s, running training loss: 1.0339]\u001b[A\n",
            "Training:  27%|██▋       | 482/1772 [02:47<06:53,  3.12it/s, running training loss: 1.0339]\u001b[A\n",
            "Training:  27%|██▋       | 482/1772 [02:47<06:53,  3.12it/s, running training loss: 1.0449]\u001b[A\n",
            "Training:  27%|██▋       | 483/1772 [02:47<06:34,  3.27it/s, running training loss: 1.0449]\u001b[A\n",
            "Training:  27%|██▋       | 483/1772 [02:47<06:34,  3.27it/s, running training loss: 1.0291]\u001b[A\n",
            "Training:  27%|██▋       | 484/1772 [02:47<06:05,  3.52it/s, running training loss: 1.0291]\u001b[A\n",
            "Training:  27%|██▋       | 484/1772 [02:47<06:05,  3.52it/s, running training loss: 1.0409]\u001b[A\n",
            "Training:  27%|██▋       | 485/1772 [02:47<05:55,  3.62it/s, running training loss: 1.0409]\u001b[A\n",
            "Training:  27%|██▋       | 485/1772 [02:48<05:55,  3.62it/s, running training loss: 0.8481]\u001b[A\n",
            "Training:  27%|██▋       | 486/1772 [02:48<06:00,  3.56it/s, running training loss: 0.8481]\u001b[A\n",
            "Training:  27%|██▋       | 486/1772 [02:48<06:00,  3.56it/s, running training loss: 0.9146]\u001b[A\n",
            "Training:  27%|██▋       | 487/1772 [02:48<05:57,  3.59it/s, running training loss: 0.9146]\u001b[A\n",
            "Training:  27%|██▋       | 487/1772 [02:48<05:57,  3.59it/s, running training loss: 1.0066]\u001b[A\n",
            "Training:  28%|██▊       | 488/1772 [02:48<06:37,  3.23it/s, running training loss: 1.0066]\u001b[A\n",
            "Training:  28%|██▊       | 488/1772 [02:49<06:37,  3.23it/s, running training loss: 0.9109]\u001b[A\n",
            "Training:  28%|██▊       | 489/1772 [02:49<06:26,  3.32it/s, running training loss: 0.9109]\u001b[A\n",
            "Training:  28%|██▊       | 489/1772 [02:49<06:26,  3.32it/s, running training loss: 1.0754]\u001b[A\n",
            "Training:  28%|██▊       | 490/1772 [02:49<08:04,  2.64it/s, running training loss: 1.0754]\u001b[A\n",
            "Training:  28%|██▊       | 490/1772 [02:50<08:04,  2.64it/s, running training loss: 0.9437]\u001b[A\n",
            "Training:  28%|██▊       | 491/1772 [02:50<08:14,  2.59it/s, running training loss: 0.9437]\u001b[A\n",
            "Training:  28%|██▊       | 491/1772 [02:50<08:14,  2.59it/s, running training loss: 1.0311]\u001b[A\n",
            "Training:  28%|██▊       | 492/1772 [02:50<07:37,  2.80it/s, running training loss: 1.0311]\u001b[A\n",
            "Training:  28%|██▊       | 492/1772 [02:50<07:37,  2.80it/s, running training loss: 1.0193]\u001b[A\n",
            "Training:  28%|██▊       | 493/1772 [02:50<07:34,  2.82it/s, running training loss: 1.0193]\u001b[A\n",
            "Training:  28%|██▊       | 493/1772 [02:50<07:34,  2.82it/s, running training loss: 1.0457]\u001b[A\n",
            "Training:  28%|██▊       | 494/1772 [02:50<07:01,  3.03it/s, running training loss: 1.0457]\u001b[A\n",
            "Training:  28%|██▊       | 494/1772 [02:51<07:01,  3.03it/s, running training loss: 0.9390]\u001b[A\n",
            "Training:  28%|██▊       | 495/1772 [02:51<06:43,  3.16it/s, running training loss: 0.9390]\u001b[A\n",
            "Training:  28%|██▊       | 495/1772 [02:51<06:43,  3.16it/s, running training loss: 1.0498]\u001b[A\n",
            "Training:  28%|██▊       | 496/1772 [02:51<06:37,  3.21it/s, running training loss: 1.0498]\u001b[A\n",
            "Training:  28%|██▊       | 496/1772 [02:51<06:37,  3.21it/s, running training loss: 1.0139]\u001b[A\n",
            "Training:  28%|██▊       | 497/1772 [02:51<06:19,  3.36it/s, running training loss: 1.0139]\u001b[A\n",
            "Training:  28%|██▊       | 497/1772 [02:52<06:19,  3.36it/s, running training loss: 1.0351]\u001b[A\n",
            "Training:  28%|██▊       | 498/1772 [02:52<07:00,  3.03it/s, running training loss: 1.0351]\u001b[A\n",
            "Training:  28%|██▊       | 498/1772 [02:52<07:00,  3.03it/s, running training loss: 0.9109]\u001b[A\n",
            "Training:  28%|██▊       | 499/1772 [02:52<06:44,  3.15it/s, running training loss: 0.9109]\u001b[A\n",
            "Training:  28%|██▊       | 499/1772 [02:52<06:44,  3.15it/s, running training loss: 1.0553]\u001b[A\n",
            "Training:  28%|██▊       | 500/1772 [02:52<06:46,  3.13it/s, running training loss: 1.0553]\u001b[A\n",
            "Training:  28%|██▊       | 500/1772 [02:53<06:46,  3.13it/s, running training loss: 0.9563]\u001b[A\n",
            "Training:  28%|██▊       | 501/1772 [02:53<06:57,  3.04it/s, running training loss: 0.9563]\u001b[A\n",
            "Training:  28%|██▊       | 501/1772 [02:53<06:57,  3.04it/s, running training loss: 0.8713]\u001b[A\n",
            "Training:  28%|██▊       | 502/1772 [02:53<07:25,  2.85it/s, running training loss: 0.8713]\u001b[A\n",
            "Training:  28%|██▊       | 502/1772 [02:53<07:25,  2.85it/s, running training loss: 1.1951]\u001b[A\n",
            "Training:  28%|██▊       | 503/1772 [02:53<07:08,  2.96it/s, running training loss: 1.1951]\u001b[A\n",
            "Training:  28%|██▊       | 503/1772 [02:54<07:08,  2.96it/s, running training loss: 1.0172]\u001b[A\n",
            "Training:  28%|██▊       | 504/1772 [02:54<07:07,  2.96it/s, running training loss: 1.0172]\u001b[A\n",
            "Training:  28%|██▊       | 504/1772 [02:54<07:07,  2.96it/s, running training loss: 0.9827]\u001b[A\n",
            "Training:  28%|██▊       | 505/1772 [02:54<06:37,  3.18it/s, running training loss: 0.9827]\u001b[A\n",
            "Training:  28%|██▊       | 505/1772 [02:54<06:37,  3.18it/s, running training loss: 0.9784]\u001b[A\n",
            "Training:  29%|██▊       | 506/1772 [02:54<06:14,  3.38it/s, running training loss: 0.9784]\u001b[A\n",
            "Training:  29%|██▊       | 506/1772 [02:54<06:14,  3.38it/s, running training loss: 1.0954]\u001b[A\n",
            "Training:  29%|██▊       | 507/1772 [02:54<05:55,  3.56it/s, running training loss: 1.0954]\u001b[A\n",
            "Training:  29%|██▊       | 507/1772 [02:55<05:55,  3.56it/s, running training loss: 1.0154]\u001b[A\n",
            "Training:  29%|██▊       | 508/1772 [02:55<06:28,  3.25it/s, running training loss: 1.0154]\u001b[A\n",
            "Training:  29%|██▊       | 508/1772 [02:55<06:28,  3.25it/s, running training loss: 1.0049]\u001b[A\n",
            "Training:  29%|██▊       | 509/1772 [02:55<07:10,  2.93it/s, running training loss: 1.0049]\u001b[A\n",
            "Training:  29%|██▊       | 509/1772 [02:56<07:10,  2.93it/s, running training loss: 1.0018]\u001b[A\n",
            "Training:  29%|██▉       | 510/1772 [02:56<06:48,  3.09it/s, running training loss: 1.0018]\u001b[A\n",
            "Training:  29%|██▉       | 510/1772 [02:56<06:48,  3.09it/s, running training loss: 0.8994]\u001b[A\n",
            "Training:  29%|██▉       | 511/1772 [02:56<06:33,  3.21it/s, running training loss: 0.8994]\u001b[A\n",
            "Training:  29%|██▉       | 511/1772 [02:56<06:33,  3.21it/s, running training loss: 0.8350]\u001b[A\n",
            "Training:  29%|██▉       | 512/1772 [02:56<06:47,  3.09it/s, running training loss: 0.8350]\u001b[A\n",
            "Training:  29%|██▉       | 512/1772 [02:56<06:47,  3.09it/s, running training loss: 0.9833]\u001b[A\n",
            "Training:  29%|██▉       | 513/1772 [02:56<06:19,  3.32it/s, running training loss: 0.9833]\u001b[A\n",
            "Training:  29%|██▉       | 513/1772 [02:57<06:19,  3.32it/s, running training loss: 1.1281]\u001b[A\n",
            "Training:  29%|██▉       | 514/1772 [02:57<06:08,  3.41it/s, running training loss: 1.1281]\u001b[A\n",
            "Training:  29%|██▉       | 514/1772 [02:57<06:08,  3.41it/s, running training loss: 1.1924]\u001b[A\n",
            "Training:  29%|██▉       | 515/1772 [02:57<06:08,  3.41it/s, running training loss: 1.1924]\u001b[A\n",
            "Training:  29%|██▉       | 515/1772 [02:57<06:08,  3.41it/s, running training loss: 1.0331]\u001b[A\n",
            "Training:  29%|██▉       | 516/1772 [02:57<06:04,  3.45it/s, running training loss: 1.0331]\u001b[A\n",
            "Training:  29%|██▉       | 516/1772 [02:58<06:04,  3.45it/s, running training loss: 1.1505]\u001b[A\n",
            "Training:  29%|██▉       | 517/1772 [02:58<06:41,  3.12it/s, running training loss: 1.1505]\u001b[A\n",
            "Training:  29%|██▉       | 517/1772 [02:58<06:41,  3.12it/s, running training loss: 0.9920]\u001b[A\n",
            "Training:  29%|██▉       | 518/1772 [02:58<06:30,  3.21it/s, running training loss: 0.9920]\u001b[A\n",
            "Training:  29%|██▉       | 518/1772 [02:58<06:30,  3.21it/s, running training loss: 1.0829]\u001b[A\n",
            "Training:  29%|██▉       | 519/1772 [02:58<06:32,  3.19it/s, running training loss: 1.0829]\u001b[A\n",
            "Training:  29%|██▉       | 519/1772 [02:59<06:32,  3.19it/s, running training loss: 1.1485]\u001b[A\n",
            "Training:  29%|██▉       | 520/1772 [02:59<06:21,  3.28it/s, running training loss: 1.1485]\u001b[A\n",
            "Training:  29%|██▉       | 520/1772 [02:59<06:21,  3.28it/s, running training loss: 0.9326]\u001b[A\n",
            "Training:  29%|██▉       | 521/1772 [02:59<06:07,  3.40it/s, running training loss: 0.9326]\u001b[A\n",
            "Training:  29%|██▉       | 521/1772 [02:59<06:07,  3.40it/s, running training loss: 0.9602]\u001b[A\n",
            "Training:  29%|██▉       | 522/1772 [02:59<06:28,  3.21it/s, running training loss: 0.9602]\u001b[A\n",
            "Training:  29%|██▉       | 522/1772 [03:00<06:28,  3.21it/s, running training loss: 1.0983]\u001b[A\n",
            "Training:  30%|██▉       | 523/1772 [03:00<06:52,  3.03it/s, running training loss: 1.0983]\u001b[A\n",
            "Training:  30%|██▉       | 523/1772 [03:00<06:52,  3.03it/s, running training loss: 0.9148]\u001b[A\n",
            "Training:  30%|██▉       | 524/1772 [03:00<06:55,  3.00it/s, running training loss: 0.9148]\u001b[A\n",
            "Training:  30%|██▉       | 524/1772 [03:00<06:55,  3.00it/s, running training loss: 1.0028]\u001b[A\n",
            "Training:  30%|██▉       | 525/1772 [03:00<06:42,  3.10it/s, running training loss: 1.0028]\u001b[A\n",
            "Training:  30%|██▉       | 525/1772 [03:00<06:42,  3.10it/s, running training loss: 0.8658]\u001b[A\n",
            "Training:  30%|██▉       | 526/1772 [03:00<06:38,  3.13it/s, running training loss: 0.8658]\u001b[A\n",
            "Training:  30%|██▉       | 526/1772 [03:01<06:38,  3.13it/s, running training loss: 1.1258]\u001b[A\n",
            "Training:  30%|██▉       | 527/1772 [03:01<06:49,  3.04it/s, running training loss: 1.1258]\u001b[A\n",
            "Training:  30%|██▉       | 527/1772 [03:01<06:49,  3.04it/s, running training loss: 1.0005]\u001b[A\n",
            "Training:  30%|██▉       | 528/1772 [03:01<06:42,  3.09it/s, running training loss: 1.0005]\u001b[A\n",
            "Training:  30%|██▉       | 528/1772 [03:02<06:42,  3.09it/s, running training loss: 1.0114]\u001b[A\n",
            "Training:  30%|██▉       | 529/1772 [03:02<07:00,  2.96it/s, running training loss: 1.0114]\u001b[A\n",
            "Training:  30%|██▉       | 529/1772 [03:02<07:00,  2.96it/s, running training loss: 1.3069]\u001b[A\n",
            "Training:  30%|██▉       | 530/1772 [03:02<06:36,  3.13it/s, running training loss: 1.3069]\u001b[A\n",
            "Training:  30%|██▉       | 530/1772 [03:02<06:36,  3.13it/s, running training loss: 1.0243]\u001b[A\n",
            "Training:  30%|██▉       | 531/1772 [03:02<07:11,  2.87it/s, running training loss: 1.0243]\u001b[A\n",
            "Training:  30%|██▉       | 531/1772 [03:02<07:11,  2.87it/s, running training loss: 0.9714]\u001b[A\n",
            "Training:  30%|███       | 532/1772 [03:02<06:50,  3.02it/s, running training loss: 0.9714]\u001b[A\n",
            "Training:  30%|███       | 532/1772 [03:03<06:50,  3.02it/s, running training loss: 0.9705]\u001b[A\n",
            "Training:  30%|███       | 533/1772 [03:03<06:27,  3.20it/s, running training loss: 0.9705]\u001b[A\n",
            "Training:  30%|███       | 533/1772 [03:03<06:27,  3.20it/s, running training loss: 0.9339]\u001b[A\n",
            "Training:  30%|███       | 534/1772 [03:03<06:33,  3.15it/s, running training loss: 0.9339]\u001b[A\n",
            "Training:  30%|███       | 534/1772 [03:04<06:33,  3.15it/s, running training loss: 1.0306]\u001b[A\n",
            "Training:  30%|███       | 535/1772 [03:04<07:18,  2.82it/s, running training loss: 1.0306]\u001b[A\n",
            "Training:  30%|███       | 535/1772 [03:04<07:18,  2.82it/s, running training loss: 1.2133]\u001b[A\n",
            "Training:  30%|███       | 536/1772 [03:04<07:02,  2.92it/s, running training loss: 1.2133]\u001b[A\n",
            "Training:  30%|███       | 536/1772 [03:04<07:02,  2.92it/s, running training loss: 0.7856]\u001b[A\n",
            "Training:  30%|███       | 537/1772 [03:04<06:58,  2.95it/s, running training loss: 0.7856]\u001b[A\n",
            "Training:  30%|███       | 537/1772 [03:04<06:58,  2.95it/s, running training loss: 0.7843]\u001b[A\n",
            "Training:  30%|███       | 538/1772 [03:04<06:25,  3.20it/s, running training loss: 0.7843]\u001b[A\n",
            "Training:  30%|███       | 538/1772 [03:05<06:25,  3.20it/s, running training loss: 0.9223]\u001b[A\n",
            "Training:  30%|███       | 539/1772 [03:05<06:28,  3.17it/s, running training loss: 0.9223]\u001b[A\n",
            "Training:  30%|███       | 539/1772 [03:05<06:28,  3.17it/s, running training loss: 0.8885]\u001b[A\n",
            "Training:  30%|███       | 540/1772 [03:05<06:38,  3.09it/s, running training loss: 0.8885]\u001b[A\n",
            "Training:  30%|███       | 540/1772 [03:05<06:38,  3.09it/s, running training loss: 0.9847]\u001b[A\n",
            "Training:  31%|███       | 541/1772 [03:05<06:12,  3.31it/s, running training loss: 0.9847]\u001b[A\n",
            "Training:  31%|███       | 541/1772 [03:06<06:12,  3.31it/s, running training loss: 0.8407]\u001b[A\n",
            "Training:  31%|███       | 542/1772 [03:06<06:17,  3.25it/s, running training loss: 0.8407]\u001b[A\n",
            "Training:  31%|███       | 542/1772 [03:06<06:17,  3.25it/s, running training loss: 0.9944]\u001b[A\n",
            "Training:  31%|███       | 543/1772 [03:06<07:02,  2.91it/s, running training loss: 0.9944]\u001b[A\n",
            "Training:  31%|███       | 543/1772 [03:06<07:02,  2.91it/s, running training loss: 0.7812]\u001b[A\n",
            "Training:  31%|███       | 544/1772 [03:06<06:38,  3.08it/s, running training loss: 0.7812]\u001b[A\n",
            "Training:  31%|███       | 544/1772 [03:07<06:38,  3.08it/s, running training loss: 1.0984]\u001b[A\n",
            "Training:  31%|███       | 545/1772 [03:07<07:19,  2.79it/s, running training loss: 1.0984]\u001b[A\n",
            "Training:  31%|███       | 545/1772 [03:07<07:19,  2.79it/s, running training loss: 0.8302]\u001b[A\n",
            "Training:  31%|███       | 546/1772 [03:07<06:36,  3.09it/s, running training loss: 0.8302]\u001b[A\n",
            "Training:  31%|███       | 546/1772 [03:08<06:36,  3.09it/s, running training loss: 0.8987]\u001b[A\n",
            "Training:  31%|███       | 547/1772 [03:08<07:27,  2.74it/s, running training loss: 0.8987]\u001b[A\n",
            "Training:  31%|███       | 547/1772 [03:08<07:27,  2.74it/s, running training loss: 0.8006]\u001b[A\n",
            "Training:  31%|███       | 548/1772 [03:08<06:34,  3.10it/s, running training loss: 0.8006]\u001b[A\n",
            "Training:  31%|███       | 548/1772 [03:08<06:34,  3.10it/s, running training loss: 1.0798]\u001b[A\n",
            "Training:  31%|███       | 549/1772 [03:08<06:13,  3.27it/s, running training loss: 1.0798]\u001b[A\n",
            "Training:  31%|███       | 549/1772 [03:08<06:13,  3.27it/s, running training loss: 0.8870]\u001b[A\n",
            "Training:  31%|███       | 550/1772 [03:08<05:56,  3.43it/s, running training loss: 0.8870]\u001b[A\n",
            "Training:  31%|███       | 550/1772 [03:09<05:56,  3.43it/s, running training loss: 1.0167]\u001b[A\n",
            "Training:  31%|███       | 551/1772 [03:09<05:44,  3.55it/s, running training loss: 1.0167]\u001b[A\n",
            "Training:  31%|███       | 551/1772 [03:09<05:44,  3.55it/s, running training loss: 0.9790]\u001b[A\n",
            "Training:  31%|███       | 552/1772 [03:09<06:18,  3.22it/s, running training loss: 0.9790]\u001b[A\n",
            "Training:  31%|███       | 552/1772 [03:09<06:18,  3.22it/s, running training loss: 0.9723]\u001b[A\n",
            "Training:  31%|███       | 553/1772 [03:09<06:30,  3.12it/s, running training loss: 0.9723]\u001b[A\n",
            "Training:  31%|███       | 553/1772 [03:10<06:30,  3.12it/s, running training loss: 1.0012]\u001b[A\n",
            "Training:  31%|███▏      | 554/1772 [03:10<06:37,  3.06it/s, running training loss: 1.0012]\u001b[A\n",
            "Training:  31%|███▏      | 554/1772 [03:10<06:37,  3.06it/s, running training loss: 1.1433]\u001b[A\n",
            "Training:  31%|███▏      | 555/1772 [03:10<06:09,  3.29it/s, running training loss: 1.1433]\u001b[A\n",
            "Training:  31%|███▏      | 555/1772 [03:10<06:09,  3.29it/s, running training loss: 1.2792]\u001b[A\n",
            "Training:  31%|███▏      | 556/1772 [03:10<07:20,  2.76it/s, running training loss: 1.2792]\u001b[A\n",
            "Training:  31%|███▏      | 556/1772 [03:11<07:20,  2.76it/s, running training loss: 1.2417]\u001b[A\n",
            "Training:  31%|███▏      | 557/1772 [03:11<06:52,  2.95it/s, running training loss: 1.2417]\u001b[A\n",
            "Training:  31%|███▏      | 557/1772 [03:11<06:52,  2.95it/s, running training loss: 1.0319]\u001b[A\n",
            "Training:  31%|███▏      | 558/1772 [03:11<07:58,  2.54it/s, running training loss: 1.0319]\u001b[A\n",
            "Training:  31%|███▏      | 558/1772 [03:12<07:58,  2.54it/s, running training loss: 0.9824]\u001b[A\n",
            "Training:  32%|███▏      | 559/1772 [03:12<08:01,  2.52it/s, running training loss: 0.9824]\u001b[A\n",
            "Training:  32%|███▏      | 559/1772 [03:12<08:01,  2.52it/s, running training loss: 1.1405]\u001b[A\n",
            "Training:  32%|███▏      | 560/1772 [03:12<07:39,  2.64it/s, running training loss: 1.1405]\u001b[A\n",
            "Training:  32%|███▏      | 560/1772 [03:12<07:39,  2.64it/s, running training loss: 1.0884]\u001b[A\n",
            "Training:  32%|███▏      | 561/1772 [03:12<07:15,  2.78it/s, running training loss: 1.0884]\u001b[A\n",
            "Training:  32%|███▏      | 561/1772 [03:13<07:15,  2.78it/s, running training loss: 0.9563]\u001b[A\n",
            "Training:  32%|███▏      | 562/1772 [03:13<07:16,  2.77it/s, running training loss: 0.9563]\u001b[A\n",
            "Training:  32%|███▏      | 562/1772 [03:13<07:16,  2.77it/s, running training loss: 0.8587]\u001b[A\n",
            "Training:  32%|███▏      | 563/1772 [03:13<06:42,  3.00it/s, running training loss: 0.8587]\u001b[A\n",
            "Training:  32%|███▏      | 563/1772 [03:13<06:42,  3.00it/s, running training loss: 1.0321]\u001b[A\n",
            "Training:  32%|███▏      | 564/1772 [03:13<06:11,  3.25it/s, running training loss: 1.0321]\u001b[A\n",
            "Training:  32%|███▏      | 564/1772 [03:13<06:11,  3.25it/s, running training loss: 1.0495]\u001b[A\n",
            "Training:  32%|███▏      | 565/1772 [03:13<05:49,  3.46it/s, running training loss: 1.0495]\u001b[A\n",
            "Training:  32%|███▏      | 565/1772 [03:14<05:49,  3.46it/s, running training loss: 0.7629]\u001b[A\n",
            "Training:  32%|███▏      | 566/1772 [03:14<05:36,  3.58it/s, running training loss: 0.7629]\u001b[A\n",
            "Training:  32%|███▏      | 566/1772 [03:14<05:36,  3.58it/s, running training loss: 0.9973]\u001b[A\n",
            "Training:  32%|███▏      | 567/1772 [03:14<05:33,  3.61it/s, running training loss: 0.9973]\u001b[A\n",
            "Training:  32%|███▏      | 567/1772 [03:14<05:33,  3.61it/s, running training loss: 0.9194]\u001b[A\n",
            "Training:  32%|███▏      | 568/1772 [03:14<05:17,  3.80it/s, running training loss: 0.9194]\u001b[A\n",
            "Training:  32%|███▏      | 568/1772 [03:14<05:17,  3.80it/s, running training loss: 1.0510]\u001b[A\n",
            "Training:  32%|███▏      | 569/1772 [03:14<05:45,  3.49it/s, running training loss: 1.0510]\u001b[A\n",
            "Training:  32%|███▏      | 569/1772 [03:15<05:45,  3.49it/s, running training loss: 0.9092]\u001b[A\n",
            "Training:  32%|███▏      | 570/1772 [03:15<05:31,  3.63it/s, running training loss: 0.9092]\u001b[A\n",
            "Training:  32%|███▏      | 570/1772 [03:15<05:31,  3.63it/s, running training loss: 0.9240]\u001b[A\n",
            "Training:  32%|███▏      | 571/1772 [03:15<05:43,  3.50it/s, running training loss: 0.9240]\u001b[A\n",
            "Training:  32%|███▏      | 571/1772 [03:15<05:43,  3.50it/s, running training loss: 0.9967]\u001b[A\n",
            "Training:  32%|███▏      | 572/1772 [03:15<05:46,  3.47it/s, running training loss: 0.9967]\u001b[A\n",
            "Training:  32%|███▏      | 572/1772 [03:16<05:46,  3.47it/s, running training loss: 0.8636]\u001b[A\n",
            "Training:  32%|███▏      | 573/1772 [03:16<06:04,  3.29it/s, running training loss: 0.8636]\u001b[A\n",
            "Training:  32%|███▏      | 573/1772 [03:16<06:04,  3.29it/s, running training loss: 1.0371]\u001b[A\n",
            "Training:  32%|███▏      | 574/1772 [03:16<06:26,  3.10it/s, running training loss: 1.0371]\u001b[A\n",
            "Training:  32%|███▏      | 574/1772 [03:16<06:26,  3.10it/s, running training loss: 1.0346]\u001b[A\n",
            "Training:  32%|███▏      | 575/1772 [03:16<06:20,  3.14it/s, running training loss: 1.0346]\u001b[A\n",
            "Training:  32%|███▏      | 575/1772 [03:17<06:20,  3.14it/s, running training loss: 1.1458]\u001b[A\n",
            "Training:  33%|███▎      | 576/1772 [03:17<06:20,  3.14it/s, running training loss: 1.1458]\u001b[A\n",
            "Training:  33%|███▎      | 576/1772 [03:17<06:20,  3.14it/s, running training loss: 1.1909]\u001b[A\n",
            "Training:  33%|███▎      | 577/1772 [03:17<06:13,  3.20it/s, running training loss: 1.1909]\u001b[A\n",
            "Training:  33%|███▎      | 577/1772 [03:17<06:13,  3.20it/s, running training loss: 1.0538]\u001b[A\n",
            "Training:  33%|███▎      | 578/1772 [03:17<05:59,  3.32it/s, running training loss: 1.0538]\u001b[A\n",
            "Training:  33%|███▎      | 578/1772 [03:17<05:59,  3.32it/s, running training loss: 1.0434]\u001b[A\n",
            "Training:  33%|███▎      | 579/1772 [03:17<05:49,  3.41it/s, running training loss: 1.0434]\u001b[A\n",
            "Training:  33%|███▎      | 579/1772 [03:18<05:49,  3.41it/s, running training loss: 1.1462]\u001b[A\n",
            "Training:  33%|███▎      | 580/1772 [03:18<05:52,  3.38it/s, running training loss: 1.1462]\u001b[A\n",
            "Training:  33%|███▎      | 580/1772 [03:18<05:52,  3.38it/s, running training loss: 1.0009]\u001b[A\n",
            "Training:  33%|███▎      | 581/1772 [03:18<05:44,  3.45it/s, running training loss: 1.0009]\u001b[A\n",
            "Training:  33%|███▎      | 581/1772 [03:18<05:44,  3.45it/s, running training loss: 0.9930]\u001b[A\n",
            "Training:  33%|███▎      | 582/1772 [03:18<06:20,  3.13it/s, running training loss: 0.9930]\u001b[A\n",
            "Training:  33%|███▎      | 582/1772 [03:19<06:20,  3.13it/s, running training loss: 1.1349]\u001b[A\n",
            "Training:  33%|███▎      | 583/1772 [03:19<07:27,  2.66it/s, running training loss: 1.1349]\u001b[A\n",
            "Training:  33%|███▎      | 583/1772 [03:19<07:27,  2.66it/s, running training loss: 0.8726]\u001b[A\n",
            "Training:  33%|███▎      | 584/1772 [03:19<07:22,  2.69it/s, running training loss: 0.8726]\u001b[A\n",
            "Training:  33%|███▎      | 584/1772 [03:20<07:22,  2.69it/s, running training loss: 0.9412]\u001b[A\n",
            "Training:  33%|███▎      | 585/1772 [03:20<06:48,  2.90it/s, running training loss: 0.9412]\u001b[A\n",
            "Training:  33%|███▎      | 585/1772 [03:20<06:48,  2.90it/s, running training loss: 0.9589]\u001b[A\n",
            "Training:  33%|███▎      | 586/1772 [03:20<06:13,  3.17it/s, running training loss: 0.9589]\u001b[A\n",
            "Training:  33%|███▎      | 586/1772 [03:20<06:13,  3.17it/s, running training loss: 0.8798]\u001b[A\n",
            "Training:  33%|███▎      | 587/1772 [03:20<07:05,  2.78it/s, running training loss: 0.8798]\u001b[A\n",
            "Training:  33%|███▎      | 587/1772 [03:21<07:05,  2.78it/s, running training loss: 1.0189]\u001b[A\n",
            "Training:  33%|███▎      | 588/1772 [03:21<07:58,  2.47it/s, running training loss: 1.0189]\u001b[A\n",
            "Training:  33%|███▎      | 588/1772 [03:21<07:58,  2.47it/s, running training loss: 0.9463]\u001b[A\n",
            "Training:  33%|███▎      | 589/1772 [03:21<07:15,  2.72it/s, running training loss: 0.9463]\u001b[A\n",
            "Training:  33%|███▎      | 589/1772 [03:21<07:15,  2.72it/s, running training loss: 0.9939]\u001b[A\n",
            "Training:  33%|███▎      | 590/1772 [03:21<06:41,  2.94it/s, running training loss: 0.9939]\u001b[A\n",
            "Training:  33%|███▎      | 590/1772 [03:22<06:41,  2.94it/s, running training loss: 0.9865]\u001b[A\n",
            "Training:  33%|███▎      | 591/1772 [03:22<06:24,  3.07it/s, running training loss: 0.9865]\u001b[A\n",
            "Training:  33%|███▎      | 591/1772 [03:22<06:24,  3.07it/s, running training loss: 1.0781]\u001b[A\n",
            "Training:  33%|███▎      | 592/1772 [03:22<05:59,  3.28it/s, running training loss: 1.0781]\u001b[A\n",
            "Training:  33%|███▎      | 592/1772 [03:22<05:59,  3.28it/s, running training loss: 0.9582]\u001b[A\n",
            "Training:  33%|███▎      | 593/1772 [03:22<06:26,  3.05it/s, running training loss: 0.9582]\u001b[A\n",
            "Training:  33%|███▎      | 593/1772 [03:23<06:26,  3.05it/s, running training loss: 0.8542]\u001b[A\n",
            "Training:  34%|███▎      | 594/1772 [03:23<06:11,  3.18it/s, running training loss: 0.8542]\u001b[A\n",
            "Training:  34%|███▎      | 594/1772 [03:23<06:11,  3.18it/s, running training loss: 1.0818]\u001b[A\n",
            "Training:  34%|███▎      | 595/1772 [03:23<05:53,  3.33it/s, running training loss: 1.0818]\u001b[A\n",
            "Training:  34%|███▎      | 595/1772 [03:23<05:53,  3.33it/s, running training loss: 0.9669]\u001b[A\n",
            "Training:  34%|███▎      | 596/1772 [03:23<05:53,  3.32it/s, running training loss: 0.9669]\u001b[A\n",
            "Training:  34%|███▎      | 596/1772 [03:23<05:53,  3.32it/s, running training loss: 0.9969]\u001b[A\n",
            "Training:  34%|███▎      | 597/1772 [03:23<06:03,  3.23it/s, running training loss: 0.9969]\u001b[A\n",
            "Training:  34%|███▎      | 597/1772 [03:24<06:03,  3.23it/s, running training loss: 1.1267]\u001b[A\n",
            "Training:  34%|███▎      | 598/1772 [03:24<06:26,  3.04it/s, running training loss: 1.1267]\u001b[A\n",
            "Training:  34%|███▎      | 598/1772 [03:24<06:26,  3.04it/s, running training loss: 1.0841]\u001b[A\n",
            "Training:  34%|███▍      | 599/1772 [03:24<06:30,  3.00it/s, running training loss: 1.0841]\u001b[A\n",
            "Training:  34%|███▍      | 599/1772 [03:24<06:30,  3.00it/s, running training loss: 1.0761]\u001b[A\n",
            "Training:  34%|███▍      | 600/1772 [03:24<06:18,  3.09it/s, running training loss: 1.0761]\u001b[A\n",
            "Training:  34%|███▍      | 600/1772 [03:25<06:18,  3.09it/s, running training loss: 1.3822]\u001b[A\n",
            "Training:  34%|███▍      | 601/1772 [03:25<06:02,  3.23it/s, running training loss: 1.3822]\u001b[A\n",
            "Training:  34%|███▍      | 601/1772 [03:25<06:02,  3.23it/s, running training loss: 0.8472]\u001b[A\n",
            "Training:  34%|███▍      | 602/1772 [03:25<07:10,  2.72it/s, running training loss: 0.8472]\u001b[A\n",
            "Training:  34%|███▍      | 602/1772 [03:26<07:10,  2.72it/s, running training loss: 0.8616]\u001b[A\n",
            "Training:  34%|███▍      | 603/1772 [03:26<08:20,  2.34it/s, running training loss: 0.8616]\u001b[A\n",
            "Training:  34%|███▍      | 603/1772 [03:26<08:20,  2.34it/s, running training loss: 1.1054]\u001b[A\n",
            "Training:  34%|███▍      | 604/1772 [03:26<07:31,  2.59it/s, running training loss: 1.1054]\u001b[A\n",
            "Training:  34%|███▍      | 604/1772 [03:26<07:31,  2.59it/s, running training loss: 1.1450]\u001b[A\n",
            "Training:  34%|███▍      | 605/1772 [03:26<06:55,  2.81it/s, running training loss: 1.1450]\u001b[A\n",
            "Training:  34%|███▍      | 605/1772 [03:27<06:55,  2.81it/s, running training loss: 1.1427]\u001b[A\n",
            "Training:  34%|███▍      | 606/1772 [03:27<06:29,  2.99it/s, running training loss: 1.1427]\u001b[A\n",
            "Training:  34%|███▍      | 606/1772 [03:27<06:29,  2.99it/s, running training loss: 1.1294]\u001b[A\n",
            "Training:  34%|███▍      | 607/1772 [03:27<06:34,  2.95it/s, running training loss: 1.1294]\u001b[A\n",
            "Training:  34%|███▍      | 607/1772 [03:27<06:34,  2.95it/s, running training loss: 1.0749]\u001b[A\n",
            "Training:  34%|███▍      | 608/1772 [03:27<06:05,  3.18it/s, running training loss: 1.0749]\u001b[A\n",
            "Training:  34%|███▍      | 608/1772 [03:28<06:05,  3.18it/s, running training loss: 1.0627]\u001b[A\n",
            "Training:  34%|███▍      | 609/1772 [03:28<06:02,  3.20it/s, running training loss: 1.0627]\u001b[A\n",
            "Training:  34%|███▍      | 609/1772 [03:28<06:02,  3.20it/s, running training loss: 0.8697]\u001b[A\n",
            "Training:  34%|███▍      | 610/1772 [03:28<06:23,  3.03it/s, running training loss: 0.8697]\u001b[A\n",
            "Training:  34%|███▍      | 610/1772 [03:28<06:23,  3.03it/s, running training loss: 0.8777]\u001b[A\n",
            "Training:  34%|███▍      | 611/1772 [03:28<06:23,  3.02it/s, running training loss: 0.8777]\u001b[A\n",
            "Training:  34%|███▍      | 611/1772 [03:29<06:23,  3.02it/s, running training loss: 1.2398]\u001b[A\n",
            "Training:  35%|███▍      | 612/1772 [03:29<06:14,  3.10it/s, running training loss: 1.2398]\u001b[A\n",
            "Training:  35%|███▍      | 612/1772 [03:29<06:14,  3.10it/s, running training loss: 0.9614]\u001b[A\n",
            "Training:  35%|███▍      | 613/1772 [03:29<06:00,  3.22it/s, running training loss: 0.9614]\u001b[A\n",
            "Training:  35%|███▍      | 613/1772 [03:29<06:00,  3.22it/s, running training loss: 1.0196]\u001b[A\n",
            "Training:  35%|███▍      | 614/1772 [03:29<06:01,  3.20it/s, running training loss: 1.0196]\u001b[A\n",
            "Training:  35%|███▍      | 614/1772 [03:30<06:01,  3.20it/s, running training loss: 0.9853]\u001b[A\n",
            "Training:  35%|███▍      | 615/1772 [03:30<06:20,  3.04it/s, running training loss: 0.9853]\u001b[A\n",
            "Training:  35%|███▍      | 615/1772 [03:30<06:20,  3.04it/s, running training loss: 1.0506]\u001b[A\n",
            "Training:  35%|███▍      | 616/1772 [03:30<06:22,  3.02it/s, running training loss: 1.0506]\u001b[A\n",
            "Training:  35%|███▍      | 616/1772 [03:30<06:22,  3.02it/s, running training loss: 1.0753]\u001b[A\n",
            "Training:  35%|███▍      | 617/1772 [03:30<06:02,  3.19it/s, running training loss: 1.0753]\u001b[A\n",
            "Training:  35%|███▍      | 617/1772 [03:31<06:02,  3.19it/s, running training loss: 1.0342]\u001b[A\n",
            "Training:  35%|███▍      | 618/1772 [03:31<07:03,  2.72it/s, running training loss: 1.0342]\u001b[A\n",
            "Training:  35%|███▍      | 618/1772 [03:31<07:03,  2.72it/s, running training loss: 0.9414]\u001b[A\n",
            "Training:  35%|███▍      | 619/1772 [03:31<06:45,  2.84it/s, running training loss: 0.9414]\u001b[A\n",
            "Training:  35%|███▍      | 619/1772 [03:31<06:45,  2.84it/s, running training loss: 1.0059]\u001b[A\n",
            "Training:  35%|███▍      | 620/1772 [03:31<07:02,  2.73it/s, running training loss: 1.0059]\u001b[A\n",
            "Training:  35%|███▍      | 620/1772 [03:32<07:02,  2.73it/s, running training loss: 1.0479]\u001b[A\n",
            "Training:  35%|███▌      | 621/1772 [03:32<06:43,  2.85it/s, running training loss: 1.0479]\u001b[A\n",
            "Training:  35%|███▌      | 621/1772 [03:32<06:43,  2.85it/s, running training loss: 0.9170]\u001b[A\n",
            "Training:  35%|███▌      | 622/1772 [03:32<06:46,  2.83it/s, running training loss: 0.9170]\u001b[A\n",
            "Training:  35%|███▌      | 622/1772 [03:32<06:46,  2.83it/s, running training loss: 1.0936]\u001b[A\n",
            "Training:  35%|███▌      | 623/1772 [03:32<06:39,  2.88it/s, running training loss: 1.0936]\u001b[A\n",
            "Training:  35%|███▌      | 623/1772 [03:33<06:39,  2.88it/s, running training loss: 0.9703]\u001b[A\n",
            "Training:  35%|███▌      | 624/1772 [03:33<06:45,  2.83it/s, running training loss: 0.9703]\u001b[A\n",
            "Training:  35%|███▌      | 624/1772 [03:33<06:45,  2.83it/s, running training loss: 1.0809]\u001b[A\n",
            "Training:  35%|███▌      | 625/1772 [03:33<06:20,  3.02it/s, running training loss: 1.0809]\u001b[A\n",
            "Training:  35%|███▌      | 625/1772 [03:33<06:20,  3.02it/s, running training loss: 1.1806]\u001b[A\n",
            "Training:  35%|███▌      | 626/1772 [03:33<06:09,  3.10it/s, running training loss: 1.1806]\u001b[A\n",
            "Training:  35%|███▌      | 626/1772 [03:34<06:09,  3.10it/s, running training loss: 1.0009]\u001b[A\n",
            "Training:  35%|███▌      | 627/1772 [03:34<06:20,  3.01it/s, running training loss: 1.0009]\u001b[A\n",
            "Training:  35%|███▌      | 627/1772 [03:34<06:20,  3.01it/s, running training loss: 1.0019]\u001b[A\n",
            "Training:  35%|███▌      | 628/1772 [03:34<05:53,  3.23it/s, running training loss: 1.0019]\u001b[A\n",
            "Training:  35%|███▌      | 628/1772 [03:34<05:53,  3.23it/s, running training loss: 1.0037]\u001b[A\n",
            "Training:  35%|███▌      | 629/1772 [03:34<06:02,  3.15it/s, running training loss: 1.0037]\u001b[A\n",
            "Training:  35%|███▌      | 629/1772 [03:35<06:02,  3.15it/s, running training loss: 0.9296]\u001b[A\n",
            "Training:  36%|███▌      | 630/1772 [03:35<07:21,  2.59it/s, running training loss: 0.9296]\u001b[A\n",
            "Training:  36%|███▌      | 630/1772 [03:35<07:21,  2.59it/s, running training loss: 0.9951]\u001b[A\n",
            "Training:  36%|███▌      | 631/1772 [03:35<07:11,  2.64it/s, running training loss: 0.9951]\u001b[A\n",
            "Training:  36%|███▌      | 631/1772 [03:36<07:11,  2.64it/s, running training loss: 1.1287]\u001b[A\n",
            "Training:  36%|███▌      | 632/1772 [03:36<07:23,  2.57it/s, running training loss: 1.1287]\u001b[A\n",
            "Training:  36%|███▌      | 632/1772 [03:36<07:23,  2.57it/s, running training loss: 1.0678]\u001b[A\n",
            "Training:  36%|███▌      | 633/1772 [03:36<06:40,  2.85it/s, running training loss: 1.0678]\u001b[A\n",
            "Training:  36%|███▌      | 633/1772 [03:36<06:40,  2.85it/s, running training loss: 0.7415]\u001b[A\n",
            "Training:  36%|███▌      | 634/1772 [03:36<07:11,  2.64it/s, running training loss: 0.7415]\u001b[A\n",
            "Training:  36%|███▌      | 634/1772 [03:37<07:11,  2.64it/s, running training loss: 0.8824]\u001b[A\n",
            "Training:  36%|███▌      | 635/1772 [03:37<07:09,  2.65it/s, running training loss: 0.8824]\u001b[A\n",
            "Training:  36%|███▌      | 635/1772 [03:37<07:09,  2.65it/s, running training loss: 1.0419]\u001b[A\n",
            "Training:  36%|███▌      | 636/1772 [03:37<06:41,  2.83it/s, running training loss: 1.0419]\u001b[A\n",
            "Training:  36%|███▌      | 636/1772 [03:37<06:41,  2.83it/s, running training loss: 1.2676]\u001b[A\n",
            "Training:  36%|███▌      | 637/1772 [03:37<06:42,  2.82it/s, running training loss: 1.2676]\u001b[A\n",
            "Training:  36%|███▌      | 637/1772 [03:38<06:42,  2.82it/s, running training loss: 0.8749]\u001b[A\n",
            "Training:  36%|███▌      | 638/1772 [03:38<06:12,  3.04it/s, running training loss: 0.8749]\u001b[A\n",
            "Training:  36%|███▌      | 638/1772 [03:38<06:12,  3.04it/s, running training loss: 0.8915]\u001b[A\n",
            "Training:  36%|███▌      | 639/1772 [03:38<06:17,  3.01it/s, running training loss: 0.8915]\u001b[A\n",
            "Training:  36%|███▌      | 639/1772 [03:38<06:17,  3.01it/s, running training loss: 0.9700]\u001b[A\n",
            "Training:  36%|███▌      | 640/1772 [03:38<06:14,  3.02it/s, running training loss: 0.9700]\u001b[A\n",
            "Training:  36%|███▌      | 640/1772 [03:39<06:14,  3.02it/s, running training loss: 0.9960]\u001b[A\n",
            "Training:  36%|███▌      | 641/1772 [03:39<06:20,  2.98it/s, running training loss: 0.9960]\u001b[A\n",
            "Training:  36%|███▌      | 641/1772 [03:39<06:20,  2.98it/s, running training loss: 1.0160]\u001b[A\n",
            "Training:  36%|███▌      | 642/1772 [03:39<06:08,  3.07it/s, running training loss: 1.0160]\u001b[A\n",
            "Training:  36%|███▌      | 642/1772 [03:39<06:08,  3.07it/s, running training loss: 0.9670]\u001b[A\n",
            "Training:  36%|███▋      | 643/1772 [03:39<06:53,  2.73it/s, running training loss: 0.9670]\u001b[A\n",
            "Training:  36%|███▋      | 643/1772 [03:40<06:53,  2.73it/s, running training loss: 0.9437]\u001b[A\n",
            "Training:  36%|███▋      | 644/1772 [03:40<06:21,  2.96it/s, running training loss: 0.9437]\u001b[A\n",
            "Training:  36%|███▋      | 644/1772 [03:40<06:21,  2.96it/s, running training loss: 0.9335]\u001b[A\n",
            "Training:  36%|███▋      | 645/1772 [03:40<05:54,  3.18it/s, running training loss: 0.9335]\u001b[A\n",
            "Training:  36%|███▋      | 645/1772 [03:40<05:54,  3.18it/s, running training loss: 0.8924]\u001b[A\n",
            "Training:  36%|███▋      | 646/1772 [03:40<06:03,  3.10it/s, running training loss: 0.8924]\u001b[A\n",
            "Training:  36%|███▋      | 646/1772 [03:41<06:03,  3.10it/s, running training loss: 0.9392]\u001b[A\n",
            "Training:  37%|███▋      | 647/1772 [03:41<06:17,  2.98it/s, running training loss: 0.9392]\u001b[A\n",
            "Training:  37%|███▋      | 647/1772 [03:41<06:17,  2.98it/s, running training loss: 1.0806]\u001b[A\n",
            "Training:  37%|███▋      | 648/1772 [03:41<06:21,  2.94it/s, running training loss: 1.0806]\u001b[A\n",
            "Training:  37%|███▋      | 648/1772 [03:41<06:21,  2.94it/s, running training loss: 0.9153]\u001b[A\n",
            "Training:  37%|███▋      | 649/1772 [03:41<05:49,  3.22it/s, running training loss: 0.9153]\u001b[A\n",
            "Training:  37%|███▋      | 649/1772 [03:42<05:49,  3.22it/s, running training loss: 0.9374]\u001b[A\n",
            "Training:  37%|███▋      | 650/1772 [03:42<05:49,  3.21it/s, running training loss: 0.9374]\u001b[A\n",
            "Training:  37%|███▋      | 650/1772 [03:42<05:49,  3.21it/s, running training loss: 1.0608]\u001b[A\n",
            "Training:  37%|███▋      | 651/1772 [03:42<05:36,  3.33it/s, running training loss: 1.0608]\u001b[A\n",
            "Training:  37%|███▋      | 651/1772 [03:42<05:36,  3.33it/s, running training loss: 1.0330]\u001b[A\n",
            "Training:  37%|███▋      | 652/1772 [03:42<05:29,  3.40it/s, running training loss: 1.0330]\u001b[A\n",
            "Training:  37%|███▋      | 652/1772 [03:42<05:29,  3.40it/s, running training loss: 1.0315]\u001b[A\n",
            "Training:  37%|███▋      | 653/1772 [03:42<05:33,  3.36it/s, running training loss: 1.0315]\u001b[A\n",
            "Training:  37%|███▋      | 653/1772 [03:43<05:33,  3.36it/s, running training loss: 0.9667]\u001b[A\n",
            "Training:  37%|███▋      | 654/1772 [03:43<06:22,  2.92it/s, running training loss: 0.9667]\u001b[A\n",
            "Training:  37%|███▋      | 654/1772 [03:43<06:22,  2.92it/s, running training loss: 1.1061]\u001b[A\n",
            "Training:  37%|███▋      | 655/1772 [03:43<06:02,  3.08it/s, running training loss: 1.1061]\u001b[A\n",
            "Training:  37%|███▋      | 655/1772 [03:43<06:02,  3.08it/s, running training loss: 0.9984]\u001b[A\n",
            "Training:  37%|███▋      | 656/1772 [03:43<05:47,  3.21it/s, running training loss: 0.9984]\u001b[A\n",
            "Training:  37%|███▋      | 656/1772 [03:44<05:47,  3.21it/s, running training loss: 1.1059]\u001b[A\n",
            "Training:  37%|███▋      | 657/1772 [03:44<05:51,  3.17it/s, running training loss: 1.1059]\u001b[A\n",
            "Training:  37%|███▋      | 657/1772 [03:44<05:51,  3.17it/s, running training loss: 1.0183]\u001b[A\n",
            "Training:  37%|███▋      | 658/1772 [03:44<05:46,  3.21it/s, running training loss: 1.0183]\u001b[A\n",
            "Training:  37%|███▋      | 658/1772 [03:44<05:46,  3.21it/s, running training loss: 0.8628]\u001b[A\n",
            "Training:  37%|███▋      | 659/1772 [03:44<05:47,  3.21it/s, running training loss: 0.8628]\u001b[A\n",
            "Training:  37%|███▋      | 659/1772 [03:45<05:47,  3.21it/s, running training loss: 0.9785]\u001b[A\n",
            "Training:  37%|███▋      | 660/1772 [03:45<05:37,  3.29it/s, running training loss: 0.9785]\u001b[A\n",
            "Training:  37%|███▋      | 660/1772 [03:45<05:37,  3.29it/s, running training loss: 0.9225]\u001b[A\n",
            "Training:  37%|███▋      | 661/1772 [03:45<07:04,  2.62it/s, running training loss: 0.9225]\u001b[A\n",
            "Training:  37%|███▋      | 661/1772 [03:46<07:04,  2.62it/s, running training loss: 0.9913]\u001b[A\n",
            "Training:  37%|███▋      | 662/1772 [03:46<06:52,  2.69it/s, running training loss: 0.9913]\u001b[A\n",
            "Training:  37%|███▋      | 662/1772 [03:46<06:52,  2.69it/s, running training loss: 1.0760]\u001b[A\n",
            "Training:  37%|███▋      | 663/1772 [03:46<06:23,  2.89it/s, running training loss: 1.0760]\u001b[A\n",
            "Training:  37%|███▋      | 663/1772 [03:46<06:23,  2.89it/s, running training loss: 1.0900]\u001b[A\n",
            "Training:  37%|███▋      | 664/1772 [03:46<05:39,  3.26it/s, running training loss: 1.0900]\u001b[A\n",
            "Training:  37%|███▋      | 664/1772 [03:46<05:39,  3.26it/s, running training loss: 0.9342]\u001b[A\n",
            "Training:  38%|███▊      | 665/1772 [03:46<05:37,  3.28it/s, running training loss: 0.9342]\u001b[A\n",
            "Training:  38%|███▊      | 665/1772 [03:47<05:37,  3.28it/s, running training loss: 0.9423]\u001b[A\n",
            "Training:  38%|███▊      | 666/1772 [03:47<05:42,  3.23it/s, running training loss: 0.9423]\u001b[A\n",
            "Training:  38%|███▊      | 666/1772 [03:47<05:42,  3.23it/s, running training loss: 0.9130]\u001b[A\n",
            "Training:  38%|███▊      | 667/1772 [03:47<05:51,  3.15it/s, running training loss: 0.9130]\u001b[A\n",
            "Training:  38%|███▊      | 667/1772 [03:47<05:51,  3.15it/s, running training loss: 0.9381]\u001b[A\n",
            "Training:  38%|███▊      | 668/1772 [03:47<05:49,  3.16it/s, running training loss: 0.9381]\u001b[A\n",
            "Training:  38%|███▊      | 668/1772 [03:48<05:49,  3.16it/s, running training loss: 1.0771]\u001b[A\n",
            "Training:  38%|███▊      | 669/1772 [03:48<05:29,  3.35it/s, running training loss: 1.0771]\u001b[A\n",
            "Training:  38%|███▊      | 669/1772 [03:48<05:29,  3.35it/s, running training loss: 1.0063]\u001b[A\n",
            "Training:  38%|███▊      | 670/1772 [03:48<05:26,  3.38it/s, running training loss: 1.0063]\u001b[A\n",
            "Training:  38%|███▊      | 670/1772 [03:48<05:26,  3.38it/s, running training loss: 0.8242]\u001b[A\n",
            "Training:  38%|███▊      | 671/1772 [03:48<05:43,  3.21it/s, running training loss: 0.8242]\u001b[A\n",
            "Training:  38%|███▊      | 671/1772 [03:48<05:43,  3.21it/s, running training loss: 0.7823]\u001b[A\n",
            "Training:  38%|███▊      | 672/1772 [03:48<05:23,  3.40it/s, running training loss: 0.7823]\u001b[A\n",
            "Training:  38%|███▊      | 672/1772 [03:49<05:23,  3.40it/s, running training loss: 0.9886]\u001b[A\n",
            "Training:  38%|███▊      | 673/1772 [03:49<05:13,  3.51it/s, running training loss: 0.9886]\u001b[A\n",
            "Training:  38%|███▊      | 673/1772 [03:49<05:13,  3.51it/s, running training loss: 0.8341]\u001b[A\n",
            "Training:  38%|███▊      | 674/1772 [03:49<05:15,  3.48it/s, running training loss: 0.8341]\u001b[A\n",
            "Training:  38%|███▊      | 674/1772 [03:49<05:15,  3.48it/s, running training loss: 0.9213]\u001b[A\n",
            "Training:  38%|███▊      | 675/1772 [03:49<05:32,  3.30it/s, running training loss: 0.9213]\u001b[A\n",
            "Training:  38%|███▊      | 675/1772 [03:50<05:32,  3.30it/s, running training loss: 0.9757]\u001b[A\n",
            "Training:  38%|███▊      | 676/1772 [03:50<05:40,  3.22it/s, running training loss: 0.9757]\u001b[A\n",
            "Training:  38%|███▊      | 676/1772 [03:50<05:40,  3.22it/s, running training loss: 1.0287]\u001b[A\n",
            "Training:  38%|███▊      | 677/1772 [03:50<05:45,  3.17it/s, running training loss: 1.0287]\u001b[A\n",
            "Training:  38%|███▊      | 677/1772 [03:50<05:45,  3.17it/s, running training loss: 1.1651]\u001b[A\n",
            "Training:  38%|███▊      | 678/1772 [03:50<05:29,  3.32it/s, running training loss: 1.1651]\u001b[A\n",
            "Training:  38%|███▊      | 678/1772 [03:51<05:29,  3.32it/s, running training loss: 1.0236]\u001b[A\n",
            "Training:  38%|███▊      | 679/1772 [03:51<05:30,  3.31it/s, running training loss: 1.0236]\u001b[A\n",
            "Training:  38%|███▊      | 679/1772 [03:51<05:30,  3.31it/s, running training loss: 1.0820]\u001b[A\n",
            "Training:  38%|███▊      | 680/1772 [03:51<05:49,  3.12it/s, running training loss: 1.0820]\u001b[A\n",
            "Training:  38%|███▊      | 680/1772 [03:51<05:49,  3.12it/s, running training loss: 0.8646]\u001b[A\n",
            "Training:  38%|███▊      | 681/1772 [03:51<05:40,  3.20it/s, running training loss: 0.8646]\u001b[A\n",
            "Training:  38%|███▊      | 681/1772 [03:52<05:40,  3.20it/s, running training loss: 0.9686]\u001b[A\n",
            "Training:  38%|███▊      | 682/1772 [03:52<05:41,  3.20it/s, running training loss: 0.9686]\u001b[A\n",
            "Training:  38%|███▊      | 682/1772 [03:52<05:41,  3.20it/s, running training loss: 1.0594]\u001b[A\n",
            "Training:  39%|███▊      | 683/1772 [03:52<05:36,  3.24it/s, running training loss: 1.0594]\u001b[A\n",
            "Training:  39%|███▊      | 683/1772 [03:52<05:36,  3.24it/s, running training loss: 1.2326]\u001b[A\n",
            "Training:  39%|███▊      | 684/1772 [03:52<05:16,  3.43it/s, running training loss: 1.2326]\u001b[A\n",
            "Training:  39%|███▊      | 684/1772 [03:53<05:16,  3.43it/s, running training loss: 1.0599]\u001b[A\n",
            "Training:  39%|███▊      | 685/1772 [03:53<05:49,  3.11it/s, running training loss: 1.0599]\u001b[A\n",
            "Training:  39%|███▊      | 685/1772 [03:53<05:49,  3.11it/s, running training loss: 0.9945]\u001b[A\n",
            "Training:  39%|███▊      | 686/1772 [03:53<05:40,  3.19it/s, running training loss: 0.9945]\u001b[A\n",
            "Training:  39%|███▊      | 686/1772 [03:53<05:40,  3.19it/s, running training loss: 0.9849]\u001b[A\n",
            "Training:  39%|███▉      | 687/1772 [03:53<06:44,  2.68it/s, running training loss: 0.9849]\u001b[A\n",
            "Training:  39%|███▉      | 687/1772 [03:54<06:44,  2.68it/s, running training loss: 0.9048]\u001b[A\n",
            "Training:  39%|███▉      | 688/1772 [03:54<06:46,  2.67it/s, running training loss: 0.9048]\u001b[A\n",
            "Training:  39%|███▉      | 688/1772 [03:54<06:46,  2.67it/s, running training loss: 1.0323]\u001b[A\n",
            "Training:  39%|███▉      | 689/1772 [03:54<06:15,  2.89it/s, running training loss: 1.0323]\u001b[A\n",
            "Training:  39%|███▉      | 689/1772 [03:54<06:15,  2.89it/s, running training loss: 1.0310]\u001b[A\n",
            "Training:  39%|███▉      | 690/1772 [03:54<06:35,  2.73it/s, running training loss: 1.0310]\u001b[A\n",
            "Training:  39%|███▉      | 690/1772 [03:55<06:35,  2.73it/s, running training loss: 0.9656]\u001b[A\n",
            "Training:  39%|███▉      | 691/1772 [03:55<07:22,  2.44it/s, running training loss: 0.9656]\u001b[A\n",
            "Training:  39%|███▉      | 691/1772 [03:55<07:22,  2.44it/s, running training loss: 0.8016]\u001b[A\n",
            "Training:  39%|███▉      | 692/1772 [03:55<06:37,  2.72it/s, running training loss: 0.8016]\u001b[A\n",
            "Training:  39%|███▉      | 692/1772 [03:55<06:37,  2.72it/s, running training loss: 1.0045]\u001b[A\n",
            "Training:  39%|███▉      | 693/1772 [03:55<06:07,  2.94it/s, running training loss: 1.0045]\u001b[A\n",
            "Training:  39%|███▉      | 693/1772 [03:56<06:07,  2.94it/s, running training loss: 0.9160]\u001b[A\n",
            "Training:  39%|███▉      | 694/1772 [03:56<05:49,  3.09it/s, running training loss: 0.9160]\u001b[A\n",
            "Training:  39%|███▉      | 694/1772 [03:56<05:49,  3.09it/s, running training loss: 0.9653]\u001b[A\n",
            "Training:  39%|███▉      | 695/1772 [03:56<06:19,  2.84it/s, running training loss: 0.9653]\u001b[A\n",
            "Training:  39%|███▉      | 695/1772 [03:56<06:19,  2.84it/s, running training loss: 0.8625]\u001b[A\n",
            "Training:  39%|███▉      | 696/1772 [03:56<05:55,  3.03it/s, running training loss: 0.8625]\u001b[A\n",
            "Training:  39%|███▉      | 696/1772 [03:57<05:55,  3.03it/s, running training loss: 0.8283]\u001b[A\n",
            "Training:  39%|███▉      | 697/1772 [03:57<06:06,  2.93it/s, running training loss: 0.8283]\u001b[A\n",
            "Training:  39%|███▉      | 697/1772 [03:57<06:06,  2.93it/s, running training loss: 0.9676]\u001b[A\n",
            "Training:  39%|███▉      | 698/1772 [03:57<05:42,  3.13it/s, running training loss: 0.9676]\u001b[A\n",
            "Training:  39%|███▉      | 698/1772 [03:57<05:42,  3.13it/s, running training loss: 1.0949]\u001b[A\n",
            "Training:  39%|███▉      | 699/1772 [03:57<06:10,  2.90it/s, running training loss: 1.0949]\u001b[A\n",
            "Training:  39%|███▉      | 699/1772 [03:58<06:10,  2.90it/s, running training loss: 1.0068]\u001b[A\n",
            "Training:  40%|███▉      | 700/1772 [03:58<06:03,  2.95it/s, running training loss: 1.0068]\u001b[A\n",
            "Training:  40%|███▉      | 700/1772 [03:58<06:03,  2.95it/s, running training loss: 1.0454]\u001b[A\n",
            "Training:  40%|███▉      | 701/1772 [03:58<05:44,  3.11it/s, running training loss: 1.0454]\u001b[A\n",
            "Training:  40%|███▉      | 701/1772 [03:58<05:44,  3.11it/s, running training loss: 1.0159]\u001b[A\n",
            "Training:  40%|███▉      | 702/1772 [03:58<05:37,  3.17it/s, running training loss: 1.0159]\u001b[A\n",
            "Training:  40%|███▉      | 702/1772 [03:59<05:37,  3.17it/s, running training loss: 1.0383]\u001b[A\n",
            "Training:  40%|███▉      | 703/1772 [03:59<05:28,  3.25it/s, running training loss: 1.0383]\u001b[A\n",
            "Training:  40%|███▉      | 703/1772 [03:59<05:28,  3.25it/s, running training loss: 0.9656]\u001b[A\n",
            "Training:  40%|███▉      | 704/1772 [03:59<05:25,  3.28it/s, running training loss: 0.9656]\u001b[A\n",
            "Training:  40%|███▉      | 704/1772 [03:59<05:25,  3.28it/s, running training loss: 0.9626]\u001b[A\n",
            "Training:  40%|███▉      | 705/1772 [03:59<05:09,  3.44it/s, running training loss: 0.9626]\u001b[A\n",
            "Training:  40%|███▉      | 705/1772 [04:00<05:09,  3.44it/s, running training loss: 1.0233]\u001b[A\n",
            "Training:  40%|███▉      | 706/1772 [04:00<05:36,  3.17it/s, running training loss: 1.0233]\u001b[A\n",
            "Training:  40%|███▉      | 706/1772 [04:00<05:36,  3.17it/s, running training loss: 1.0075]\u001b[A\n",
            "Training:  40%|███▉      | 707/1772 [04:00<05:51,  3.03it/s, running training loss: 1.0075]\u001b[A\n",
            "Training:  40%|███▉      | 707/1772 [04:00<05:51,  3.03it/s, running training loss: 0.9969]\u001b[A\n",
            "Training:  40%|███▉      | 708/1772 [04:00<05:41,  3.12it/s, running training loss: 0.9969]\u001b[A\n",
            "Training:  40%|███▉      | 708/1772 [04:01<05:41,  3.12it/s, running training loss: 0.8898]\u001b[A\n",
            "Training:  40%|████      | 709/1772 [04:01<05:59,  2.96it/s, running training loss: 0.8898]\u001b[A\n",
            "Training:  40%|████      | 709/1772 [04:01<05:59,  2.96it/s, running training loss: 1.0737]\u001b[A\n",
            "Training:  40%|████      | 710/1772 [04:01<06:34,  2.70it/s, running training loss: 1.0737]\u001b[A\n",
            "Training:  40%|████      | 710/1772 [04:01<06:34,  2.70it/s, running training loss: 0.9904]\u001b[A\n",
            "Training:  40%|████      | 711/1772 [04:01<06:10,  2.87it/s, running training loss: 0.9904]\u001b[A\n",
            "Training:  40%|████      | 711/1772 [04:02<06:10,  2.87it/s, running training loss: 1.0616]\u001b[A\n",
            "Training:  40%|████      | 712/1772 [04:02<06:15,  2.82it/s, running training loss: 1.0616]\u001b[A\n",
            "Training:  40%|████      | 712/1772 [04:02<06:15,  2.82it/s, running training loss: 0.9719]\u001b[A\n",
            "Training:  40%|████      | 713/1772 [04:02<06:24,  2.76it/s, running training loss: 0.9719]\u001b[A\n",
            "Training:  40%|████      | 713/1772 [04:03<06:24,  2.76it/s, running training loss: 1.1014]\u001b[A\n",
            "Training:  40%|████      | 714/1772 [04:03<06:33,  2.69it/s, running training loss: 1.1014]\u001b[A\n",
            "Training:  40%|████      | 714/1772 [04:03<06:33,  2.69it/s, running training loss: 1.0945]\u001b[A\n",
            "Training:  40%|████      | 715/1772 [04:03<06:11,  2.84it/s, running training loss: 1.0945]\u001b[A\n",
            "Training:  40%|████      | 715/1772 [04:03<06:11,  2.84it/s, running training loss: 1.0941]\u001b[A\n",
            "Training:  40%|████      | 716/1772 [04:03<06:17,  2.80it/s, running training loss: 1.0941]\u001b[A\n",
            "Training:  40%|████      | 716/1772 [04:04<06:17,  2.80it/s, running training loss: 0.7825]\u001b[A\n",
            "Training:  40%|████      | 717/1772 [04:04<06:18,  2.79it/s, running training loss: 0.7825]\u001b[A\n",
            "Training:  40%|████      | 717/1772 [04:04<06:18,  2.79it/s, running training loss: 1.0339]\u001b[A\n",
            "Training:  41%|████      | 718/1772 [04:04<06:15,  2.80it/s, running training loss: 1.0339]\u001b[A\n",
            "Training:  41%|████      | 718/1772 [04:04<06:15,  2.80it/s, running training loss: 0.7589]\u001b[A\n",
            "Training:  41%|████      | 719/1772 [04:04<05:49,  3.01it/s, running training loss: 0.7589]\u001b[A\n",
            "Training:  41%|████      | 719/1772 [04:04<05:49,  3.01it/s, running training loss: 0.7664]\u001b[A\n",
            "Training:  41%|████      | 720/1772 [04:04<05:31,  3.18it/s, running training loss: 0.7664]\u001b[A\n",
            "Training:  41%|████      | 720/1772 [04:05<05:31,  3.18it/s, running training loss: 0.7979]\u001b[A\n",
            "Training:  41%|████      | 721/1772 [04:05<05:16,  3.32it/s, running training loss: 0.7979]\u001b[A\n",
            "Training:  41%|████      | 721/1772 [04:05<05:16,  3.32it/s, running training loss: 0.7258]\u001b[A\n",
            "Training:  41%|████      | 722/1772 [04:05<05:10,  3.38it/s, running training loss: 0.7258]\u001b[A\n",
            "Training:  41%|████      | 722/1772 [04:05<05:10,  3.38it/s, running training loss: 0.7727]\u001b[A\n",
            "Training:  41%|████      | 723/1772 [04:05<05:53,  2.97it/s, running training loss: 0.7727]\u001b[A\n",
            "Training:  41%|████      | 723/1772 [04:06<05:53,  2.97it/s, running training loss: 1.1213]\u001b[A\n",
            "Training:  41%|████      | 724/1772 [04:06<06:00,  2.91it/s, running training loss: 1.1213]\u001b[A\n",
            "Training:  41%|████      | 724/1772 [04:06<06:00,  2.91it/s, running training loss: 0.9225]\u001b[A\n",
            "Training:  41%|████      | 725/1772 [04:06<05:43,  3.05it/s, running training loss: 0.9225]\u001b[A\n",
            "Training:  41%|████      | 725/1772 [04:06<05:43,  3.05it/s, running training loss: 0.7468]\u001b[A\n",
            "Training:  41%|████      | 726/1772 [04:06<05:27,  3.19it/s, running training loss: 0.7468]\u001b[A\n",
            "Training:  41%|████      | 726/1772 [04:07<05:27,  3.19it/s, running training loss: 0.8451]\u001b[A\n",
            "Training:  41%|████      | 727/1772 [04:07<05:20,  3.26it/s, running training loss: 0.8451]\u001b[A\n",
            "Training:  41%|████      | 727/1772 [04:07<05:20,  3.26it/s, running training loss: 0.9974]\u001b[A\n",
            "Training:  41%|████      | 728/1772 [04:07<05:22,  3.24it/s, running training loss: 0.9974]\u001b[A\n",
            "Training:  41%|████      | 728/1772 [04:07<05:22,  3.24it/s, running training loss: 1.0637]\u001b[A\n",
            "Training:  41%|████      | 729/1772 [04:07<06:01,  2.89it/s, running training loss: 1.0637]\u001b[A\n",
            "Training:  41%|████      | 729/1772 [04:08<06:01,  2.89it/s, running training loss: 1.0839]\u001b[A\n",
            "Training:  41%|████      | 730/1772 [04:08<06:37,  2.62it/s, running training loss: 1.0839]\u001b[A\n",
            "Training:  41%|████      | 730/1772 [04:08<06:37,  2.62it/s, running training loss: 1.0195]\u001b[A\n",
            "Training:  41%|████▏     | 731/1772 [04:08<06:18,  2.75it/s, running training loss: 1.0195]\u001b[A\n",
            "Training:  41%|████▏     | 731/1772 [04:09<06:18,  2.75it/s, running training loss: 0.9752]\u001b[A\n",
            "Training:  41%|████▏     | 732/1772 [04:09<07:24,  2.34it/s, running training loss: 0.9752]\u001b[A\n",
            "Training:  41%|████▏     | 732/1772 [04:09<07:24,  2.34it/s, running training loss: 1.0773]\u001b[A\n",
            "Training:  41%|████▏     | 733/1772 [04:09<06:55,  2.50it/s, running training loss: 1.0773]\u001b[A\n",
            "Training:  41%|████▏     | 733/1772 [04:09<06:55,  2.50it/s, running training loss: 0.9779]\u001b[A\n",
            "Training:  41%|████▏     | 734/1772 [04:09<06:00,  2.88it/s, running training loss: 0.9779]\u001b[A\n",
            "Training:  41%|████▏     | 734/1772 [04:10<06:00,  2.88it/s, running training loss: 0.9731]\u001b[A\n",
            "Training:  41%|████▏     | 735/1772 [04:10<05:38,  3.06it/s, running training loss: 0.9731]\u001b[A\n",
            "Training:  41%|████▏     | 735/1772 [04:10<05:38,  3.06it/s, running training loss: 0.8756]\u001b[A\n",
            "Training:  42%|████▏     | 736/1772 [04:10<05:42,  3.03it/s, running training loss: 0.8756]\u001b[A\n",
            "Training:  42%|████▏     | 736/1772 [04:10<05:42,  3.03it/s, running training loss: 0.8496]\u001b[A\n",
            "Training:  42%|████▏     | 737/1772 [04:10<05:27,  3.16it/s, running training loss: 0.8496]\u001b[A\n",
            "Training:  42%|████▏     | 737/1772 [04:11<05:27,  3.16it/s, running training loss: 0.9279]\u001b[A\n",
            "Training:  42%|████▏     | 738/1772 [04:11<05:25,  3.18it/s, running training loss: 0.9279]\u001b[A\n",
            "Training:  42%|████▏     | 738/1772 [04:11<05:25,  3.18it/s, running training loss: 1.0123]\u001b[A\n",
            "Training:  42%|████▏     | 739/1772 [04:11<05:19,  3.23it/s, running training loss: 1.0123]\u001b[A\n",
            "Training:  42%|████▏     | 739/1772 [04:11<05:19,  3.23it/s, running training loss: 1.0473]\u001b[A\n",
            "Training:  42%|████▏     | 740/1772 [04:11<05:28,  3.14it/s, running training loss: 1.0473]\u001b[A\n",
            "Training:  42%|████▏     | 740/1772 [04:12<05:28,  3.14it/s, running training loss: 0.9633]\u001b[A\n",
            "Training:  42%|████▏     | 741/1772 [04:12<05:34,  3.08it/s, running training loss: 0.9633]\u001b[A\n",
            "Training:  42%|████▏     | 741/1772 [04:12<05:34,  3.08it/s, running training loss: 0.9647]\u001b[A\n",
            "Training:  42%|████▏     | 742/1772 [04:12<05:09,  3.33it/s, running training loss: 0.9647]\u001b[A\n",
            "Training:  42%|████▏     | 742/1772 [04:12<05:09,  3.33it/s, running training loss: 0.9582]\u001b[A\n",
            "Training:  42%|████▏     | 743/1772 [04:12<04:58,  3.45it/s, running training loss: 0.9582]\u001b[A\n",
            "Training:  42%|████▏     | 743/1772 [04:12<04:58,  3.45it/s, running training loss: 1.0405]\u001b[A\n",
            "Training:  42%|████▏     | 744/1772 [04:12<05:02,  3.40it/s, running training loss: 1.0405]\u001b[A\n",
            "Training:  42%|████▏     | 744/1772 [04:13<05:02,  3.40it/s, running training loss: 1.0224]\u001b[A\n",
            "Training:  42%|████▏     | 745/1772 [04:13<05:37,  3.05it/s, running training loss: 1.0224]\u001b[A\n",
            "Training:  42%|████▏     | 745/1772 [04:13<05:37,  3.05it/s, running training loss: 0.9727]\u001b[A\n",
            "Training:  42%|████▏     | 746/1772 [04:13<05:39,  3.02it/s, running training loss: 0.9727]\u001b[A\n",
            "Training:  42%|████▏     | 746/1772 [04:14<05:39,  3.02it/s, running training loss: 1.1474]\u001b[A\n",
            "Training:  42%|████▏     | 747/1772 [04:14<06:23,  2.67it/s, running training loss: 1.1474]\u001b[A\n",
            "Training:  42%|████▏     | 747/1772 [04:14<06:23,  2.67it/s, running training loss: 1.0348]\u001b[A\n",
            "Training:  42%|████▏     | 748/1772 [04:14<06:28,  2.64it/s, running training loss: 1.0348]\u001b[A\n",
            "Training:  42%|████▏     | 748/1772 [04:14<06:28,  2.64it/s, running training loss: 1.0661]\u001b[A\n",
            "Training:  42%|████▏     | 749/1772 [04:14<06:19,  2.70it/s, running training loss: 1.0661]\u001b[A\n",
            "Training:  42%|████▏     | 749/1772 [04:15<06:19,  2.70it/s, running training loss: 1.0758]\u001b[A\n",
            "Training:  42%|████▏     | 750/1772 [04:15<05:58,  2.85it/s, running training loss: 1.0758]\u001b[A\n",
            "Training:  42%|████▏     | 750/1772 [04:15<05:58,  2.85it/s, running training loss: 0.8326]\u001b[A\n",
            "Training:  42%|████▏     | 751/1772 [04:15<05:41,  2.99it/s, running training loss: 0.8326]\u001b[A\n",
            "Training:  42%|████▏     | 751/1772 [04:15<05:41,  2.99it/s, running training loss: 1.0354]\u001b[A\n",
            "Training:  42%|████▏     | 752/1772 [04:15<05:28,  3.11it/s, running training loss: 1.0354]\u001b[A\n",
            "Training:  42%|████▏     | 752/1772 [04:15<05:28,  3.11it/s, running training loss: 0.7598]\u001b[A\n",
            "Training:  42%|████▏     | 753/1772 [04:15<05:05,  3.34it/s, running training loss: 0.7598]\u001b[A\n",
            "Training:  42%|████▏     | 753/1772 [04:16<05:05,  3.34it/s, running training loss: 0.8740]\u001b[A\n",
            "Training:  43%|████▎     | 754/1772 [04:16<05:19,  3.18it/s, running training loss: 0.8740]\u001b[A\n",
            "Training:  43%|████▎     | 754/1772 [04:16<05:19,  3.18it/s, running training loss: 0.9002]\u001b[A\n",
            "Training:  43%|████▎     | 755/1772 [04:16<05:38,  3.00it/s, running training loss: 0.9002]\u001b[A\n",
            "Training:  43%|████▎     | 755/1772 [04:16<05:38,  3.00it/s, running training loss: 0.9111]\u001b[A\n",
            "Training:  43%|████▎     | 756/1772 [04:16<05:09,  3.28it/s, running training loss: 0.9111]\u001b[A\n",
            "Training:  43%|████▎     | 756/1772 [04:17<05:09,  3.28it/s, running training loss: 0.9802]\u001b[A\n",
            "Training:  43%|████▎     | 757/1772 [04:17<05:13,  3.24it/s, running training loss: 0.9802]\u001b[A\n",
            "Training:  43%|████▎     | 757/1772 [04:17<05:13,  3.24it/s, running training loss: 1.0012]\u001b[A\n",
            "Training:  43%|████▎     | 758/1772 [04:17<05:18,  3.18it/s, running training loss: 1.0012]\u001b[A\n",
            "Training:  43%|████▎     | 758/1772 [04:17<05:18,  3.18it/s, running training loss: 1.1745]\u001b[A\n",
            "Training:  43%|████▎     | 759/1772 [04:17<04:57,  3.41it/s, running training loss: 1.1745]\u001b[A\n",
            "Training:  43%|████▎     | 759/1772 [04:18<04:57,  3.41it/s, running training loss: 1.0851]\u001b[A\n",
            "Training:  43%|████▎     | 760/1772 [04:18<05:27,  3.09it/s, running training loss: 1.0851]\u001b[A\n",
            "Training:  43%|████▎     | 760/1772 [04:18<05:27,  3.09it/s, running training loss: 1.0669]\u001b[A\n",
            "Training:  43%|████▎     | 761/1772 [04:18<05:48,  2.90it/s, running training loss: 1.0669]\u001b[A\n",
            "Training:  43%|████▎     | 761/1772 [04:18<05:48,  2.90it/s, running training loss: 1.0160]\u001b[A\n",
            "Training:  43%|████▎     | 762/1772 [04:18<05:34,  3.02it/s, running training loss: 1.0160]\u001b[A\n",
            "Training:  43%|████▎     | 762/1772 [04:19<05:34,  3.02it/s, running training loss: 1.0133]\u001b[A\n",
            "Training:  43%|████▎     | 763/1772 [04:19<05:26,  3.09it/s, running training loss: 1.0133]\u001b[A\n",
            "Training:  43%|████▎     | 763/1772 [04:19<05:26,  3.09it/s, running training loss: 0.9456]\u001b[A\n",
            "Training:  43%|████▎     | 764/1772 [04:19<05:08,  3.26it/s, running training loss: 0.9456]\u001b[A\n",
            "Training:  43%|████▎     | 764/1772 [04:19<05:08,  3.26it/s, running training loss: 1.0990]\u001b[A\n",
            "Training:  43%|████▎     | 765/1772 [04:19<05:14,  3.20it/s, running training loss: 1.0990]\u001b[A\n",
            "Training:  43%|████▎     | 765/1772 [04:20<05:14,  3.20it/s, running training loss: 0.9946]\u001b[A\n",
            "Training:  43%|████▎     | 766/1772 [04:20<06:10,  2.72it/s, running training loss: 0.9946]\u001b[A\n",
            "Training:  43%|████▎     | 766/1772 [04:20<06:10,  2.72it/s, running training loss: 0.9859]\u001b[A\n",
            "Training:  43%|████▎     | 767/1772 [04:20<06:00,  2.79it/s, running training loss: 0.9859]\u001b[A\n",
            "Training:  43%|████▎     | 767/1772 [04:20<06:00,  2.79it/s, running training loss: 1.0548]\u001b[A\n",
            "Training:  43%|████▎     | 768/1772 [04:20<05:55,  2.82it/s, running training loss: 1.0548]\u001b[A\n",
            "Training:  43%|████▎     | 768/1772 [04:21<05:55,  2.82it/s, running training loss: 1.0109]\u001b[A\n",
            "Training:  43%|████▎     | 769/1772 [04:21<05:41,  2.94it/s, running training loss: 1.0109]\u001b[A\n",
            "Training:  43%|████▎     | 769/1772 [04:21<05:41,  2.94it/s, running training loss: 0.8720]\u001b[A\n",
            "Training:  43%|████▎     | 770/1772 [04:21<05:33,  3.01it/s, running training loss: 0.8720]\u001b[A\n",
            "Training:  43%|████▎     | 770/1772 [04:21<05:33,  3.01it/s, running training loss: 0.9105]\u001b[A\n",
            "Training:  44%|████▎     | 771/1772 [04:21<05:06,  3.26it/s, running training loss: 0.9105]\u001b[A\n",
            "Training:  44%|████▎     | 771/1772 [04:22<05:06,  3.26it/s, running training loss: 1.1166]\u001b[A\n",
            "Training:  44%|████▎     | 772/1772 [04:22<04:59,  3.34it/s, running training loss: 1.1166]\u001b[A\n",
            "Training:  44%|████▎     | 772/1772 [04:22<04:59,  3.34it/s, running training loss: 0.8530]\u001b[A\n",
            "Training:  44%|████▎     | 773/1772 [04:22<04:58,  3.34it/s, running training loss: 0.8530]\u001b[A\n",
            "Training:  44%|████▎     | 773/1772 [04:22<04:58,  3.34it/s, running training loss: 1.0349]\u001b[A\n",
            "Training:  44%|████▎     | 774/1772 [04:22<04:56,  3.37it/s, running training loss: 1.0349]\u001b[A\n",
            "Training:  44%|████▎     | 774/1772 [04:22<04:56,  3.37it/s, running training loss: 0.9717]\u001b[A\n",
            "Training:  44%|████▎     | 775/1772 [04:22<04:47,  3.47it/s, running training loss: 0.9717]\u001b[A\n",
            "Training:  44%|████▎     | 775/1772 [04:23<04:47,  3.47it/s, running training loss: 0.9465]\u001b[A\n",
            "Training:  44%|████▍     | 776/1772 [04:23<06:01,  2.76it/s, running training loss: 0.9465]\u001b[A\n",
            "Training:  44%|████▍     | 776/1772 [04:23<06:01,  2.76it/s, running training loss: 0.9500]\u001b[A\n",
            "Training:  44%|████▍     | 777/1772 [04:23<06:04,  2.73it/s, running training loss: 0.9500]\u001b[A\n",
            "Training:  44%|████▍     | 777/1772 [04:24<06:04,  2.73it/s, running training loss: 1.0159]\u001b[A\n",
            "Training:  44%|████▍     | 778/1772 [04:24<05:34,  2.97it/s, running training loss: 1.0159]\u001b[A\n",
            "Training:  44%|████▍     | 778/1772 [04:24<05:34,  2.97it/s, running training loss: 1.1366]\u001b[A\n",
            "Training:  44%|████▍     | 779/1772 [04:24<05:32,  2.98it/s, running training loss: 1.1366]\u001b[A\n",
            "Training:  44%|████▍     | 779/1772 [04:24<05:32,  2.98it/s, running training loss: 1.1458]\u001b[A\n",
            "Training:  44%|████▍     | 780/1772 [04:24<05:07,  3.23it/s, running training loss: 1.1458]\u001b[A\n",
            "Training:  44%|████▍     | 780/1772 [04:25<05:07,  3.23it/s, running training loss: 1.1216]\u001b[A\n",
            "Training:  44%|████▍     | 781/1772 [04:25<05:01,  3.29it/s, running training loss: 1.1216]\u001b[A\n",
            "Training:  44%|████▍     | 781/1772 [04:25<05:01,  3.29it/s, running training loss: 1.1782]\u001b[A\n",
            "Training:  44%|████▍     | 782/1772 [04:25<05:18,  3.11it/s, running training loss: 1.1782]\u001b[A\n",
            "Training:  44%|████▍     | 782/1772 [04:25<05:18,  3.11it/s, running training loss: 1.0548]\u001b[A\n",
            "Training:  44%|████▍     | 783/1772 [04:25<05:40,  2.91it/s, running training loss: 1.0548]\u001b[A\n",
            "Training:  44%|████▍     | 783/1772 [04:26<05:40,  2.91it/s, running training loss: 1.0088]\u001b[A\n",
            "Training:  44%|████▍     | 784/1772 [04:26<06:00,  2.74it/s, running training loss: 1.0088]\u001b[A\n",
            "Training:  44%|████▍     | 784/1772 [04:26<06:00,  2.74it/s, running training loss: 0.9545]\u001b[A\n",
            "Training:  44%|████▍     | 785/1772 [04:26<05:42,  2.88it/s, running training loss: 0.9545]\u001b[A\n",
            "Training:  44%|████▍     | 785/1772 [04:26<05:42,  2.88it/s, running training loss: 0.7550]\u001b[A\n",
            "Training:  44%|████▍     | 786/1772 [04:26<05:16,  3.12it/s, running training loss: 0.7550]\u001b[A\n",
            "Training:  44%|████▍     | 786/1772 [04:27<05:16,  3.12it/s, running training loss: 0.9224]\u001b[A\n",
            "Training:  44%|████▍     | 787/1772 [04:27<05:10,  3.17it/s, running training loss: 0.9224]\u001b[A\n",
            "Training:  44%|████▍     | 787/1772 [04:27<05:10,  3.17it/s, running training loss: 0.7056]\u001b[A\n",
            "Training:  44%|████▍     | 788/1772 [04:27<06:09,  2.67it/s, running training loss: 0.7056]\u001b[A\n",
            "Training:  44%|████▍     | 788/1772 [04:27<06:09,  2.67it/s, running training loss: 0.9328]\u001b[A\n",
            "Training:  45%|████▍     | 789/1772 [04:27<06:13,  2.63it/s, running training loss: 0.9328]\u001b[A\n",
            "Training:  45%|████▍     | 789/1772 [04:28<06:13,  2.63it/s, running training loss: 0.9649]\u001b[A\n",
            "Training:  45%|████▍     | 790/1772 [04:28<05:44,  2.85it/s, running training loss: 0.9649]\u001b[A\n",
            "Training:  45%|████▍     | 790/1772 [04:28<05:44,  2.85it/s, running training loss: 0.9722]\u001b[A\n",
            "Training:  45%|████▍     | 791/1772 [04:28<05:36,  2.92it/s, running training loss: 0.9722]\u001b[A\n",
            "Training:  45%|████▍     | 791/1772 [04:28<05:36,  2.92it/s, running training loss: 1.1727]\u001b[A\n",
            "Training:  45%|████▍     | 792/1772 [04:28<05:34,  2.93it/s, running training loss: 1.1727]\u001b[A\n",
            "Training:  45%|████▍     | 792/1772 [04:29<05:34,  2.93it/s, running training loss: 1.0571]\u001b[A\n",
            "Training:  45%|████▍     | 793/1772 [04:29<06:21,  2.56it/s, running training loss: 1.0571]\u001b[A\n",
            "Training:  45%|████▍     | 793/1772 [04:29<06:21,  2.56it/s, running training loss: 1.1673]\u001b[A\n",
            "Training:  45%|████▍     | 794/1772 [04:29<05:30,  2.96it/s, running training loss: 1.1673]\u001b[A\n",
            "Training:  45%|████▍     | 794/1772 [04:29<05:30,  2.96it/s, running training loss: 1.2185]\u001b[A\n",
            "Training:  45%|████▍     | 795/1772 [04:29<05:28,  2.97it/s, running training loss: 1.2185]\u001b[A\n",
            "Training:  45%|████▍     | 795/1772 [04:30<05:28,  2.97it/s, running training loss: 1.1756]\u001b[A\n",
            "Training:  45%|████▍     | 796/1772 [04:30<05:22,  3.03it/s, running training loss: 1.1756]\u001b[A\n",
            "Training:  45%|████▍     | 796/1772 [04:30<05:22,  3.03it/s, running training loss: 1.0581]\u001b[A\n",
            "Training:  45%|████▍     | 797/1772 [04:30<05:00,  3.25it/s, running training loss: 1.0581]\u001b[A\n",
            "Training:  45%|████▍     | 797/1772 [04:30<05:00,  3.25it/s, running training loss: 1.0331]\u001b[A\n",
            "Training:  45%|████▌     | 798/1772 [04:30<05:39,  2.87it/s, running training loss: 1.0331]\u001b[A\n",
            "Training:  45%|████▌     | 798/1772 [04:31<05:39,  2.87it/s, running training loss: 0.9332]\u001b[A\n",
            "Training:  45%|████▌     | 799/1772 [04:31<05:14,  3.09it/s, running training loss: 0.9332]\u001b[A\n",
            "Training:  45%|████▌     | 799/1772 [04:31<05:14,  3.09it/s, running training loss: 0.9592]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            ">>> EMA starting ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Evaluation:   0%|          | 0/270 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   0%|          | 1/270 [00:00<01:21,  3.32it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   1%|          | 3/270 [00:00<00:32,  8.19it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   2%|▏         | 5/270 [00:00<00:23, 11.37it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   3%|▎         | 7/270 [00:00<00:19, 13.71it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   3%|▎         | 9/270 [00:00<00:17, 14.93it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   4%|▍         | 12/270 [00:00<00:14, 17.87it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   5%|▌         | 14/270 [00:00<00:14, 17.99it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   6%|▌         | 16/270 [00:01<00:14, 17.98it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   7%|▋         | 18/270 [00:01<00:14, 17.64it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   7%|▋         | 20/270 [00:01<00:14, 17.24it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   9%|▊         | 23/270 [00:01<00:12, 19.34it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   9%|▉         | 25/270 [00:01<00:12, 19.35it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  10%|█         | 28/270 [00:01<00:12, 19.51it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  11%|█         | 30/270 [00:01<00:12, 18.67it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  12%|█▏        | 32/270 [00:01<00:12, 18.80it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  13%|█▎        | 35/270 [00:02<00:12, 19.01it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  14%|█▍        | 38/270 [00:02<00:11, 20.47it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  15%|█▌        | 41/270 [00:02<00:11, 19.92it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  16%|█▋        | 44/270 [00:02<00:11, 18.96it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  17%|█▋        | 46/270 [00:02<00:11, 18.78it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  18%|█▊        | 49/270 [00:02<00:11, 19.31it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  19%|█▉        | 51/270 [00:02<00:11, 18.73it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  20%|█▉        | 53/270 [00:03<00:11, 18.69it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  21%|██        | 56/270 [00:03<00:11, 18.78it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  21%|██▏       | 58/270 [00:03<00:11, 18.59it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  22%|██▏       | 60/270 [00:03<00:11, 18.57it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  23%|██▎       | 62/270 [00:03<00:11, 18.39it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  24%|██▎       | 64/270 [00:03<00:11, 18.48it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  25%|██▍       | 67/270 [00:03<00:10, 19.47it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  26%|██▌       | 70/270 [00:03<00:09, 20.95it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  27%|██▋       | 73/270 [00:04<00:09, 20.19it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  28%|██▊       | 76/270 [00:04<00:09, 20.99it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  29%|██▉       | 79/270 [00:04<00:09, 20.70it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  30%|███       | 82/270 [00:04<00:09, 19.38it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  31%|███       | 84/270 [00:04<00:09, 19.42it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  32%|███▏      | 87/270 [00:04<00:09, 19.63it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  33%|███▎      | 89/270 [00:04<00:09, 18.73it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  34%|███▎      | 91/270 [00:04<00:09, 18.60it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  35%|███▍      | 94/270 [00:05<00:09, 19.46it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  36%|███▌      | 97/270 [00:05<00:08, 20.04it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  37%|███▋      | 100/270 [00:05<00:08, 19.95it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  38%|███▊      | 103/270 [00:05<00:08, 20.69it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  39%|███▉      | 106/270 [00:05<00:08, 19.99it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  40%|████      | 109/270 [00:05<00:08, 19.76it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  41%|████▏     | 112/270 [00:06<00:07, 20.09it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  43%|████▎     | 115/270 [00:06<00:07, 20.33it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  44%|████▎     | 118/270 [00:06<00:07, 20.28it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  45%|████▍     | 121/270 [00:06<00:07, 20.05it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  46%|████▌     | 124/270 [00:06<00:06, 20.91it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  47%|████▋     | 127/270 [00:06<00:07, 19.55it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  48%|████▊     | 129/270 [00:06<00:07, 18.85it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  49%|████▉     | 132/270 [00:07<00:07, 19.31it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  50%|████▉     | 134/270 [00:07<00:07, 19.32it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  51%|█████     | 137/270 [00:07<00:06, 19.98it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  52%|█████▏    | 140/270 [00:07<00:06, 19.89it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  53%|█████▎    | 142/270 [00:07<00:06, 18.67it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  54%|█████▎    | 145/270 [00:07<00:06, 19.26it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  54%|█████▍    | 147/270 [00:07<00:06, 18.98it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  56%|█████▌    | 150/270 [00:07<00:06, 19.95it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  56%|█████▋    | 152/270 [00:08<00:06, 18.54it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  57%|█████▋    | 154/270 [00:08<00:06, 18.55it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  58%|█████▊    | 156/270 [00:08<00:06, 18.37it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  59%|█████▉    | 159/270 [00:08<00:05, 19.53it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  60%|█████▉    | 161/270 [00:08<00:05, 19.34it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  60%|██████    | 163/270 [00:08<00:05, 18.80it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  61%|██████    | 165/270 [00:08<00:05, 18.46it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  62%|██████▏   | 168/270 [00:08<00:05, 19.53it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  63%|██████▎   | 170/270 [00:09<00:05, 18.91it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  64%|██████▎   | 172/270 [00:09<00:05, 18.82it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  64%|██████▍   | 174/270 [00:09<00:05, 18.00it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  65%|██████▌   | 176/270 [00:09<00:05, 17.40it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  66%|██████▌   | 178/270 [00:09<00:05, 17.75it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  67%|██████▋   | 180/270 [00:09<00:05, 17.10it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  67%|██████▋   | 182/270 [00:09<00:05, 17.44it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  68%|██████▊   | 184/270 [00:09<00:04, 17.68it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  69%|██████▉   | 186/270 [00:09<00:04, 18.19it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  70%|██████▉   | 188/270 [00:10<00:04, 17.85it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  71%|███████   | 191/270 [00:10<00:03, 19.84it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  71%|███████▏  | 193/270 [00:10<00:03, 19.44it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  72%|███████▏  | 195/270 [00:10<00:04, 18.34it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  73%|███████▎  | 197/270 [00:10<00:03, 18.49it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  74%|███████▎  | 199/270 [00:10<00:04, 17.48it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  74%|███████▍  | 201/270 [00:10<00:04, 17.12it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  75%|███████▌  | 203/270 [00:10<00:03, 17.47it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  76%|███████▋  | 206/270 [00:11<00:03, 19.55it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  77%|███████▋  | 208/270 [00:11<00:03, 18.45it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  78%|███████▊  | 210/270 [00:11<00:03, 17.95it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  79%|███████▊  | 212/270 [00:11<00:03, 18.21it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  80%|███████▉  | 215/270 [00:11<00:02, 19.60it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  80%|████████  | 217/270 [00:11<00:02, 19.02it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  81%|████████▏ | 220/270 [00:11<00:02, 19.65it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  83%|████████▎ | 223/270 [00:11<00:02, 20.64it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  84%|████████▎ | 226/270 [00:12<00:02, 21.63it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  85%|████████▍ | 229/270 [00:12<00:02, 19.43it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  86%|████████▌ | 231/270 [00:12<00:02, 18.88it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  87%|████████▋ | 234/270 [00:12<00:01, 20.11it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  88%|████████▊ | 237/270 [00:12<00:01, 20.73it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  89%|████████▉ | 240/270 [00:12<00:01, 19.40it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  90%|████████▉ | 242/270 [00:12<00:01, 19.42it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  90%|█████████ | 244/270 [00:12<00:01, 19.26it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  91%|█████████ | 246/270 [00:13<00:01, 18.41it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  92%|█████████▏| 248/270 [00:13<00:01, 17.50it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  93%|█████████▎| 250/270 [00:13<00:01, 17.35it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  93%|█████████▎| 252/270 [00:13<00:01, 17.32it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  94%|█████████▍| 254/270 [00:13<00:00, 17.24it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  95%|█████████▍| 256/270 [00:13<00:00, 16.77it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  96%|█████████▌| 259/270 [00:13<00:00, 18.73it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  97%|█████████▋| 262/270 [00:13<00:00, 19.19it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  98%|█████████▊| 264/270 [00:14<00:00, 18.36it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  99%|█████████▊| 266/270 [00:14<00:00, 18.05it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  99%|█████████▉| 268/270 [00:14<00:00, 18.27it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation: 100%|██████████| 270/270 [00:14<00:00, 18.47it/s]\n",
            "\n",
            "Training:  45%|████▌     | 800/1772 [04:47<1:23:50,  5.18s/it, running training loss: 0.9592]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            ">>> training loss: 1.002324, valid loss: 0.655381, valid f1: 0.000000, valid acc: 0.689991\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  45%|████▌     | 800/1772 [04:48<1:23:50,  5.18s/it, running training loss: 0.9996]\u001b[A\n",
            "Training:  45%|████▌     | 801/1772 [04:48<1:00:42,  3.75s/it, running training loss: 0.9996]\u001b[A\n",
            "Training:  45%|████▌     | 801/1772 [04:48<1:00:42,  3.75s/it, running training loss: 1.0462]\u001b[A\n",
            "Training:  45%|████▌     | 802/1772 [04:48<44:11,  2.73s/it, running training loss: 1.0462]  \u001b[A\n",
            "Training:  45%|████▌     | 802/1772 [04:48<44:11,  2.73s/it, running training loss: 0.9879]\u001b[A\n",
            "Training:  45%|████▌     | 803/1772 [04:48<33:02,  2.05s/it, running training loss: 0.9879]\u001b[A\n",
            "Training:  45%|████▌     | 803/1772 [04:49<33:02,  2.05s/it, running training loss: 1.0067]\u001b[A\n",
            "Training:  45%|████▌     | 804/1772 [04:49<24:56,  1.55s/it, running training loss: 1.0067]\u001b[A\n",
            "Training:  45%|████▌     | 804/1772 [04:49<24:56,  1.55s/it, running training loss: 1.0508]\u001b[A\n",
            "Training:  45%|████▌     | 805/1772 [04:49<18:46,  1.16s/it, running training loss: 1.0508]\u001b[A\n",
            "Training:  45%|████▌     | 805/1772 [04:49<18:46,  1.16s/it, running training loss: 0.9496]\u001b[A\n",
            "Training:  45%|████▌     | 806/1772 [04:49<14:52,  1.08it/s, running training loss: 0.9496]\u001b[A\n",
            "Training:  45%|████▌     | 806/1772 [04:50<14:52,  1.08it/s, running training loss: 1.0582]\u001b[A\n",
            "Training:  46%|████▌     | 807/1772 [04:50<12:03,  1.33it/s, running training loss: 1.0582]\u001b[A\n",
            "Training:  46%|████▌     | 807/1772 [04:50<12:03,  1.33it/s, running training loss: 1.0129]\u001b[A\n",
            "Training:  46%|████▌     | 808/1772 [04:50<10:23,  1.55it/s, running training loss: 1.0129]\u001b[A\n",
            "Training:  46%|████▌     | 808/1772 [04:51<10:23,  1.55it/s, running training loss: 0.9061]\u001b[A\n",
            "Training:  46%|████▌     | 809/1772 [04:51<08:52,  1.81it/s, running training loss: 0.9061]\u001b[A\n",
            "Training:  46%|████▌     | 809/1772 [04:51<08:52,  1.81it/s, running training loss: 1.0363]\u001b[A\n",
            "Training:  46%|████▌     | 810/1772 [04:51<08:59,  1.78it/s, running training loss: 1.0363]\u001b[A\n",
            "Training:  46%|████▌     | 810/1772 [04:51<08:59,  1.78it/s, running training loss: 1.0726]\u001b[A\n",
            "Training:  46%|████▌     | 811/1772 [04:52<07:58,  2.01it/s, running training loss: 1.0726]\u001b[A\n",
            "Training:  46%|████▌     | 811/1772 [04:52<07:58,  2.01it/s, running training loss: 1.0327]\u001b[A\n",
            "Training:  46%|████▌     | 812/1772 [04:52<07:26,  2.15it/s, running training loss: 1.0327]\u001b[A\n",
            "Training:  46%|████▌     | 812/1772 [04:52<07:26,  2.15it/s, running training loss: 1.0181]\u001b[A\n",
            "Training:  46%|████▌     | 813/1772 [04:52<07:06,  2.25it/s, running training loss: 1.0181]\u001b[A\n",
            "Training:  46%|████▌     | 813/1772 [04:53<07:06,  2.25it/s, running training loss: 0.9905]\u001b[A\n",
            "Training:  46%|████▌     | 814/1772 [04:53<06:45,  2.36it/s, running training loss: 0.9905]\u001b[A\n",
            "Training:  46%|████▌     | 814/1772 [04:53<06:45,  2.36it/s, running training loss: 1.0039]\u001b[A\n",
            "Training:  46%|████▌     | 815/1772 [04:53<06:04,  2.62it/s, running training loss: 1.0039]\u001b[A\n",
            "Training:  46%|████▌     | 815/1772 [04:53<06:04,  2.62it/s, running training loss: 0.7857]\u001b[A\n",
            "Training:  46%|████▌     | 816/1772 [04:53<06:24,  2.48it/s, running training loss: 0.7857]\u001b[A\n",
            "Training:  46%|████▌     | 816/1772 [04:54<06:24,  2.48it/s, running training loss: 0.8989]\u001b[A\n",
            "Training:  46%|████▌     | 817/1772 [04:54<06:18,  2.53it/s, running training loss: 0.8989]\u001b[A\n",
            "Training:  46%|████▌     | 817/1772 [04:54<06:18,  2.53it/s, running training loss: 0.7638]\u001b[A\n",
            "Training:  46%|████▌     | 818/1772 [04:54<05:53,  2.70it/s, running training loss: 0.7638]\u001b[A\n",
            "Training:  46%|████▌     | 818/1772 [04:55<05:53,  2.70it/s, running training loss: 0.8221]\u001b[A\n",
            "Training:  46%|████▌     | 819/1772 [04:55<06:24,  2.48it/s, running training loss: 0.8221]\u001b[A\n",
            "Training:  46%|████▌     | 819/1772 [04:55<06:24,  2.48it/s, running training loss: 1.0437]\u001b[A\n",
            "Training:  46%|████▋     | 820/1772 [04:55<07:15,  2.18it/s, running training loss: 1.0437]\u001b[A\n",
            "Training:  46%|████▋     | 820/1772 [04:55<07:15,  2.18it/s, running training loss: 0.9005]\u001b[A\n",
            "Training:  46%|████▋     | 821/1772 [04:55<06:26,  2.46it/s, running training loss: 0.9005]\u001b[A\n",
            "Training:  46%|████▋     | 821/1772 [04:56<06:26,  2.46it/s, running training loss: 1.0458]\u001b[A\n",
            "Training:  46%|████▋     | 822/1772 [04:56<05:56,  2.67it/s, running training loss: 1.0458]\u001b[A\n",
            "Training:  46%|████▋     | 822/1772 [04:56<05:56,  2.67it/s, running training loss: 1.0961]\u001b[A\n",
            "Training:  46%|████▋     | 823/1772 [04:56<05:21,  2.95it/s, running training loss: 1.0961]\u001b[A\n",
            "Training:  46%|████▋     | 823/1772 [04:56<05:21,  2.95it/s, running training loss: 0.9935]\u001b[A\n",
            "Training:  47%|████▋     | 824/1772 [04:56<05:42,  2.77it/s, running training loss: 0.9935]\u001b[A\n",
            "Training:  47%|████▋     | 824/1772 [04:57<05:42,  2.77it/s, running training loss: 1.0554]\u001b[A\n",
            "Training:  47%|████▋     | 825/1772 [04:57<05:16,  2.99it/s, running training loss: 1.0554]\u001b[A\n",
            "Training:  47%|████▋     | 825/1772 [04:57<05:16,  2.99it/s, running training loss: 1.0346]\u001b[A\n",
            "Training:  47%|████▋     | 826/1772 [04:57<05:29,  2.87it/s, running training loss: 1.0346]\u001b[A\n",
            "Training:  47%|████▋     | 826/1772 [04:57<05:29,  2.87it/s, running training loss: 0.9864]\u001b[A\n",
            "Training:  47%|████▋     | 827/1772 [04:57<05:29,  2.87it/s, running training loss: 0.9864]\u001b[A\n",
            "Training:  47%|████▋     | 827/1772 [04:58<05:29,  2.87it/s, running training loss: 1.0929]\u001b[A\n",
            "Training:  47%|████▋     | 828/1772 [04:58<05:16,  2.98it/s, running training loss: 1.0929]\u001b[A\n",
            "Training:  47%|████▋     | 828/1772 [04:58<05:16,  2.98it/s, running training loss: 1.0114]\u001b[A\n",
            "Training:  47%|████▋     | 829/1772 [04:58<05:27,  2.88it/s, running training loss: 1.0114]\u001b[A\n",
            "Training:  47%|████▋     | 829/1772 [04:58<05:27,  2.88it/s, running training loss: 0.9305]\u001b[A\n",
            "Training:  47%|████▋     | 830/1772 [04:58<05:23,  2.91it/s, running training loss: 0.9305]\u001b[A\n",
            "Training:  47%|████▋     | 830/1772 [04:59<05:23,  2.91it/s, running training loss: 0.9784]\u001b[A\n",
            "Training:  47%|████▋     | 831/1772 [04:59<05:28,  2.86it/s, running training loss: 0.9784]\u001b[A\n",
            "Training:  47%|████▋     | 831/1772 [04:59<05:28,  2.86it/s, running training loss: 0.8232]\u001b[A\n",
            "Training:  47%|████▋     | 832/1772 [04:59<05:20,  2.94it/s, running training loss: 0.8232]\u001b[A\n",
            "Training:  47%|████▋     | 832/1772 [05:00<05:20,  2.94it/s, running training loss: 0.9829]\u001b[A\n",
            "Training:  47%|████▋     | 833/1772 [05:00<05:54,  2.65it/s, running training loss: 0.9829]\u001b[A\n",
            "Training:  47%|████▋     | 833/1772 [05:00<05:54,  2.65it/s, running training loss: 0.8187]\u001b[A\n",
            "Training:  47%|████▋     | 834/1772 [05:00<06:10,  2.53it/s, running training loss: 0.8187]\u001b[A\n",
            "Training:  47%|████▋     | 834/1772 [05:01<06:10,  2.53it/s, running training loss: 1.0055]\u001b[A\n",
            "Training:  47%|████▋     | 835/1772 [05:01<06:50,  2.28it/s, running training loss: 1.0055]\u001b[A\n",
            "Training:  47%|████▋     | 835/1772 [05:01<06:50,  2.28it/s, running training loss: 0.9656]\u001b[A\n",
            "Training:  47%|████▋     | 836/1772 [05:01<06:07,  2.55it/s, running training loss: 0.9656]\u001b[A\n",
            "Training:  47%|████▋     | 836/1772 [05:01<06:07,  2.55it/s, running training loss: 0.9450]\u001b[A\n",
            "Training:  47%|████▋     | 837/1772 [05:01<06:02,  2.58it/s, running training loss: 0.9450]\u001b[A\n",
            "Training:  47%|████▋     | 837/1772 [05:01<06:02,  2.58it/s, running training loss: 1.0340]\u001b[A\n",
            "Training:  47%|████▋     | 838/1772 [05:02<05:35,  2.78it/s, running training loss: 1.0340]\u001b[A\n",
            "Training:  47%|████▋     | 838/1772 [05:02<05:35,  2.78it/s, running training loss: 0.9461]\u001b[A\n",
            "Training:  47%|████▋     | 839/1772 [05:02<05:24,  2.88it/s, running training loss: 0.9461]\u001b[A\n",
            "Training:  47%|████▋     | 839/1772 [05:02<05:24,  2.88it/s, running training loss: 0.9239]\u001b[A\n",
            "Training:  47%|████▋     | 840/1772 [05:02<05:32,  2.81it/s, running training loss: 0.9239]\u001b[A\n",
            "Training:  47%|████▋     | 840/1772 [05:03<05:32,  2.81it/s, running training loss: 0.9064]\u001b[A\n",
            "Training:  47%|████▋     | 841/1772 [05:03<05:17,  2.94it/s, running training loss: 0.9064]\u001b[A\n",
            "Training:  47%|████▋     | 841/1772 [05:03<05:17,  2.94it/s, running training loss: 1.1250]\u001b[A\n",
            "Training:  48%|████▊     | 842/1772 [05:03<04:58,  3.11it/s, running training loss: 1.1250]\u001b[A\n",
            "Training:  48%|████▊     | 842/1772 [05:03<04:58,  3.11it/s, running training loss: 0.9736]\u001b[A\n",
            "Training:  48%|████▊     | 843/1772 [05:03<05:35,  2.77it/s, running training loss: 0.9736]\u001b[A\n",
            "Training:  48%|████▊     | 843/1772 [05:04<05:35,  2.77it/s, running training loss: 0.9742]\u001b[A\n",
            "Training:  48%|████▊     | 844/1772 [05:04<05:36,  2.76it/s, running training loss: 0.9742]\u001b[A\n",
            "Training:  48%|████▊     | 844/1772 [05:04<05:36,  2.76it/s, running training loss: 1.0120]\u001b[A\n",
            "Training:  48%|████▊     | 845/1772 [05:04<05:15,  2.94it/s, running training loss: 1.0120]\u001b[A\n",
            "Training:  48%|████▊     | 845/1772 [05:04<05:15,  2.94it/s, running training loss: 0.9117]\u001b[A\n",
            "Training:  48%|████▊     | 846/1772 [05:04<05:05,  3.03it/s, running training loss: 0.9117]\u001b[A\n",
            "Training:  48%|████▊     | 846/1772 [05:04<05:05,  3.03it/s, running training loss: 1.0588]\u001b[A\n",
            "Training:  48%|████▊     | 847/1772 [05:04<04:55,  3.13it/s, running training loss: 1.0588]\u001b[A\n",
            "Training:  48%|████▊     | 847/1772 [05:05<04:55,  3.13it/s, running training loss: 0.9701]\u001b[A\n",
            "Training:  48%|████▊     | 848/1772 [05:05<04:44,  3.25it/s, running training loss: 0.9701]\u001b[A\n",
            "Training:  48%|████▊     | 848/1772 [05:05<04:44,  3.25it/s, running training loss: 1.0099]\u001b[A\n",
            "Training:  48%|████▊     | 849/1772 [05:05<04:55,  3.13it/s, running training loss: 1.0099]\u001b[A\n",
            "Training:  48%|████▊     | 849/1772 [05:05<04:55,  3.13it/s, running training loss: 0.9286]\u001b[A\n",
            "Training:  48%|████▊     | 850/1772 [05:05<04:52,  3.15it/s, running training loss: 0.9286]\u001b[A\n",
            "Training:  48%|████▊     | 850/1772 [05:06<04:52,  3.15it/s, running training loss: 0.9425]\u001b[A\n",
            "Training:  48%|████▊     | 851/1772 [05:06<04:43,  3.25it/s, running training loss: 0.9425]\u001b[A\n",
            "Training:  48%|████▊     | 851/1772 [05:06<04:43,  3.25it/s, running training loss: 0.9049]\u001b[A\n",
            "Training:  48%|████▊     | 852/1772 [05:06<04:44,  3.24it/s, running training loss: 0.9049]\u001b[A\n",
            "Training:  48%|████▊     | 852/1772 [05:06<04:44,  3.24it/s, running training loss: 1.0941]\u001b[A\n",
            "Training:  48%|████▊     | 853/1772 [05:06<04:53,  3.13it/s, running training loss: 1.0941]\u001b[A\n",
            "Training:  48%|████▊     | 853/1772 [05:07<04:53,  3.13it/s, running training loss: 1.0903]\u001b[A\n",
            "Training:  48%|████▊     | 854/1772 [05:07<05:06,  2.99it/s, running training loss: 1.0903]\u001b[A\n",
            "Training:  48%|████▊     | 854/1772 [05:07<05:06,  2.99it/s, running training loss: 1.0280]\u001b[A\n",
            "Training:  48%|████▊     | 855/1772 [05:07<04:55,  3.11it/s, running training loss: 1.0280]\u001b[A\n",
            "Training:  48%|████▊     | 855/1772 [05:07<04:55,  3.11it/s, running training loss: 0.9123]\u001b[A\n",
            "Training:  48%|████▊     | 856/1772 [05:07<05:04,  3.01it/s, running training loss: 0.9123]\u001b[A\n",
            "Training:  48%|████▊     | 856/1772 [05:08<05:04,  3.01it/s, running training loss: 1.0556]\u001b[A\n",
            "Training:  48%|████▊     | 857/1772 [05:08<04:43,  3.23it/s, running training loss: 1.0556]\u001b[A\n",
            "Training:  48%|████▊     | 857/1772 [05:08<04:43,  3.23it/s, running training loss: 0.8617]\u001b[A\n",
            "Training:  48%|████▊     | 858/1772 [05:08<04:33,  3.34it/s, running training loss: 0.8617]\u001b[A\n",
            "Training:  48%|████▊     | 858/1772 [05:08<04:33,  3.34it/s, running training loss: 0.9877]\u001b[A\n",
            "Training:  48%|████▊     | 859/1772 [05:08<04:44,  3.21it/s, running training loss: 0.9877]\u001b[A\n",
            "Training:  48%|████▊     | 859/1772 [05:09<04:44,  3.21it/s, running training loss: 1.0115]\u001b[A\n",
            "Training:  49%|████▊     | 860/1772 [05:09<04:41,  3.24it/s, running training loss: 1.0115]\u001b[A\n",
            "Training:  49%|████▊     | 860/1772 [05:09<04:41,  3.24it/s, running training loss: 1.0319]\u001b[A\n",
            "Training:  49%|████▊     | 861/1772 [05:09<04:42,  3.22it/s, running training loss: 1.0319]\u001b[A\n",
            "Training:  49%|████▊     | 861/1772 [05:09<04:42,  3.22it/s, running training loss: 0.9211]\u001b[A\n",
            "Training:  49%|████▊     | 862/1772 [05:09<04:36,  3.29it/s, running training loss: 0.9211]\u001b[A\n",
            "Training:  49%|████▊     | 862/1772 [05:10<04:36,  3.29it/s, running training loss: 0.9735]\u001b[A\n",
            "Training:  49%|████▊     | 863/1772 [05:10<04:50,  3.13it/s, running training loss: 0.9735]\u001b[A\n",
            "Training:  49%|████▊     | 863/1772 [05:10<04:50,  3.13it/s, running training loss: 1.0505]\u001b[A\n",
            "Training:  49%|████▉     | 864/1772 [05:10<05:34,  2.71it/s, running training loss: 1.0505]\u001b[A\n",
            "Training:  49%|████▉     | 864/1772 [05:10<05:34,  2.71it/s, running training loss: 1.1579]\u001b[A\n",
            "Training:  49%|████▉     | 865/1772 [05:10<05:20,  2.83it/s, running training loss: 1.1579]\u001b[A\n",
            "Training:  49%|████▉     | 865/1772 [05:11<05:20,  2.83it/s, running training loss: 0.8165]\u001b[A\n",
            "Training:  49%|████▉     | 866/1772 [05:11<05:07,  2.95it/s, running training loss: 0.8165]\u001b[A\n",
            "Training:  49%|████▉     | 866/1772 [05:11<05:07,  2.95it/s, running training loss: 0.9417]\u001b[A\n",
            "Training:  49%|████▉     | 867/1772 [05:11<05:20,  2.82it/s, running training loss: 0.9417]\u001b[A\n",
            "Training:  49%|████▉     | 867/1772 [05:11<05:20,  2.82it/s, running training loss: 1.0192]\u001b[A\n",
            "Training:  49%|████▉     | 868/1772 [05:11<05:33,  2.71it/s, running training loss: 1.0192]\u001b[A\n",
            "Training:  49%|████▉     | 868/1772 [05:12<05:33,  2.71it/s, running training loss: 1.1040]\u001b[A\n",
            "Training:  49%|████▉     | 869/1772 [05:12<05:25,  2.78it/s, running training loss: 1.1040]\u001b[A\n",
            "Training:  49%|████▉     | 869/1772 [05:12<05:25,  2.78it/s, running training loss: 0.9692]\u001b[A\n",
            "Training:  49%|████▉     | 870/1772 [05:12<05:02,  2.98it/s, running training loss: 0.9692]\u001b[A\n",
            "Training:  49%|████▉     | 870/1772 [05:12<05:02,  2.98it/s, running training loss: 1.0246]\u001b[A\n",
            "Training:  49%|████▉     | 871/1772 [05:12<05:09,  2.91it/s, running training loss: 1.0246]\u001b[A\n",
            "Training:  49%|████▉     | 871/1772 [05:13<05:09,  2.91it/s, running training loss: 0.9110]\u001b[A\n",
            "Training:  49%|████▉     | 872/1772 [05:13<05:17,  2.84it/s, running training loss: 0.9110]\u001b[A\n",
            "Training:  49%|████▉     | 872/1772 [05:13<05:17,  2.84it/s, running training loss: 0.8376]\u001b[A\n",
            "Training:  49%|████▉     | 873/1772 [05:13<05:21,  2.80it/s, running training loss: 0.8376]\u001b[A\n",
            "Training:  49%|████▉     | 873/1772 [05:13<05:21,  2.80it/s, running training loss: 1.0192]\u001b[A\n",
            "Training:  49%|████▉     | 874/1772 [05:13<05:06,  2.93it/s, running training loss: 1.0192]\u001b[A\n",
            "Training:  49%|████▉     | 874/1772 [05:14<05:06,  2.93it/s, running training loss: 0.9635]\u001b[A\n",
            "Training:  49%|████▉     | 875/1772 [05:14<05:02,  2.97it/s, running training loss: 0.9635]\u001b[A\n",
            "Training:  49%|████▉     | 875/1772 [05:14<05:02,  2.97it/s, running training loss: 1.0007]\u001b[A\n",
            "Training:  49%|████▉     | 876/1772 [05:14<05:03,  2.95it/s, running training loss: 1.0007]\u001b[A\n",
            "Training:  49%|████▉     | 876/1772 [05:14<05:03,  2.95it/s, running training loss: 0.9726]\u001b[A\n",
            "Training:  49%|████▉     | 877/1772 [05:15<05:14,  2.85it/s, running training loss: 0.9726]\u001b[A\n",
            "Training:  49%|████▉     | 877/1772 [05:15<05:14,  2.85it/s, running training loss: 0.9016]\u001b[A\n",
            "Training:  50%|████▉     | 878/1772 [05:15<05:14,  2.84it/s, running training loss: 0.9016]\u001b[A\n",
            "Training:  50%|████▉     | 878/1772 [05:15<05:14,  2.84it/s, running training loss: 0.9463]\u001b[A\n",
            "Training:  50%|████▉     | 879/1772 [05:15<04:57,  3.01it/s, running training loss: 0.9463]\u001b[A\n",
            "Training:  50%|████▉     | 879/1772 [05:15<04:57,  3.01it/s, running training loss: 1.0929]\u001b[A\n",
            "Training:  50%|████▉     | 880/1772 [05:15<05:00,  2.97it/s, running training loss: 1.0929]\u001b[A\n",
            "Training:  50%|████▉     | 880/1772 [05:16<05:00,  2.97it/s, running training loss: 0.9880]\u001b[A\n",
            "Training:  50%|████▉     | 881/1772 [05:16<05:59,  2.48it/s, running training loss: 0.9880]\u001b[A\n",
            "Training:  50%|████▉     | 881/1772 [05:16<05:59,  2.48it/s, running training loss: 1.1375]\u001b[A\n",
            "Training:  50%|████▉     | 882/1772 [05:16<05:16,  2.81it/s, running training loss: 1.1375]\u001b[A\n",
            "Training:  50%|████▉     | 882/1772 [05:17<05:16,  2.81it/s, running training loss: 1.1199]\u001b[A\n",
            "Training:  50%|████▉     | 883/1772 [05:17<05:08,  2.89it/s, running training loss: 1.1199]\u001b[A\n",
            "Training:  50%|████▉     | 883/1772 [05:17<05:08,  2.89it/s, running training loss: 1.1598]\u001b[A\n",
            "Training:  50%|████▉     | 884/1772 [05:17<05:26,  2.72it/s, running training loss: 1.1598]\u001b[A\n",
            "Training:  50%|████▉     | 884/1772 [05:17<05:26,  2.72it/s, running training loss: 1.2036]\u001b[A\n",
            "Training:  50%|████▉     | 885/1772 [05:17<05:19,  2.77it/s, running training loss: 1.2036]\u001b[A\n",
            "Training:  50%|████▉     | 885/1772 [05:18<05:19,  2.77it/s, running training loss: 0.9582]\u001b[A\n",
            "Training:  50%|█████     | 886/1772 [05:18<04:59,  2.95it/s, running training loss: 0.9582]\u001b[A\n",
            "Training:  50%|█████     | 886/1772 [05:18<04:59,  2.95it/s, running training loss: 0.9978]\u001b[A\n",
            "Training:  50%|█████     | 887/1772 [05:18<05:43,  2.58it/s, running training loss: 0.9978]\u001b[A\n",
            "Training:  50%|█████     | 887/1772 [05:18<05:43,  2.58it/s, running training loss: 0.9594]\u001b[A\n",
            "Training:  50%|█████     | 888/1772 [05:18<05:24,  2.73it/s, running training loss: 0.9594]\u001b[A\n",
            "Training:  50%|█████     | 888/1772 [05:19<05:24,  2.73it/s, running training loss: 0.9745]\u001b[A\n",
            "Training:  50%|█████     | 889/1772 [05:19<06:12,  2.37it/s, running training loss: 0.9745]\u001b[A\n",
            "Training:  50%|█████     | 889/1772 [05:19<06:12,  2.37it/s, running training loss: 0.9186]\u001b[A\n",
            "Training:  50%|█████     | 890/1772 [05:19<05:40,  2.59it/s, running training loss: 0.9186]\u001b[A\n",
            "Training:  50%|█████     | 890/1772 [05:20<05:40,  2.59it/s, running training loss: 1.1371]\u001b[A\n",
            "Training:  50%|█████     | 891/1772 [05:20<05:18,  2.77it/s, running training loss: 1.1371]\u001b[A\n",
            "Training:  50%|█████     | 891/1772 [05:20<05:18,  2.77it/s, running training loss: 0.9124]\u001b[A\n",
            "Training:  50%|█████     | 892/1772 [05:20<04:58,  2.95it/s, running training loss: 0.9124]\u001b[A\n",
            "Training:  50%|█████     | 892/1772 [05:20<04:58,  2.95it/s, running training loss: 1.0848]\u001b[A\n",
            "Training:  50%|█████     | 893/1772 [05:20<04:46,  3.07it/s, running training loss: 1.0848]\u001b[A\n",
            "Training:  50%|█████     | 893/1772 [05:21<04:46,  3.07it/s, running training loss: 0.8904]\u001b[A\n",
            "Training:  50%|█████     | 894/1772 [05:21<04:40,  3.13it/s, running training loss: 0.8904]\u001b[A\n",
            "Training:  50%|█████     | 894/1772 [05:21<04:40,  3.13it/s, running training loss: 1.0038]\u001b[A\n",
            "Training:  51%|█████     | 895/1772 [05:21<05:07,  2.85it/s, running training loss: 1.0038]\u001b[A\n",
            "Training:  51%|█████     | 895/1772 [05:21<05:07,  2.85it/s, running training loss: 0.8989]\u001b[A\n",
            "Training:  51%|█████     | 896/1772 [05:21<04:49,  3.03it/s, running training loss: 0.8989]\u001b[A\n",
            "Training:  51%|█████     | 896/1772 [05:22<04:49,  3.03it/s, running training loss: 0.9880]\u001b[A\n",
            "Training:  51%|█████     | 897/1772 [05:22<04:46,  3.05it/s, running training loss: 0.9880]\u001b[A\n",
            "Training:  51%|█████     | 897/1772 [05:22<04:46,  3.05it/s, running training loss: 0.8313]\u001b[A\n",
            "Training:  51%|█████     | 898/1772 [05:22<04:55,  2.96it/s, running training loss: 0.8313]\u001b[A\n",
            "Training:  51%|█████     | 898/1772 [05:22<04:55,  2.96it/s, running training loss: 0.9679]\u001b[A\n",
            "Training:  51%|█████     | 899/1772 [05:22<04:48,  3.03it/s, running training loss: 0.9679]\u001b[A\n",
            "Training:  51%|█████     | 899/1772 [05:23<04:48,  3.03it/s, running training loss: 1.0304]\u001b[A\n",
            "Training:  51%|█████     | 900/1772 [05:23<05:24,  2.69it/s, running training loss: 1.0304]\u001b[A\n",
            "Training:  51%|█████     | 900/1772 [05:23<05:24,  2.69it/s, running training loss: 1.0485]\u001b[A\n",
            "Training:  51%|█████     | 901/1772 [05:23<05:16,  2.75it/s, running training loss: 1.0485]\u001b[A\n",
            "Training:  51%|█████     | 901/1772 [05:23<05:16,  2.75it/s, running training loss: 0.9833]\u001b[A\n",
            "Training:  51%|█████     | 902/1772 [05:23<05:27,  2.66it/s, running training loss: 0.9833]\u001b[A\n",
            "Training:  51%|█████     | 902/1772 [05:24<05:27,  2.66it/s, running training loss: 0.9626]\u001b[A\n",
            "Training:  51%|█████     | 903/1772 [05:24<05:16,  2.75it/s, running training loss: 0.9626]\u001b[A\n",
            "Training:  51%|█████     | 903/1772 [05:24<05:16,  2.75it/s, running training loss: 0.9901]\u001b[A\n",
            "Training:  51%|█████     | 904/1772 [05:24<05:15,  2.75it/s, running training loss: 0.9901]\u001b[A\n",
            "Training:  51%|█████     | 904/1772 [05:24<05:15,  2.75it/s, running training loss: 0.9615]\u001b[A\n",
            "Training:  51%|█████     | 905/1772 [05:24<04:50,  2.99it/s, running training loss: 0.9615]\u001b[A\n",
            "Training:  51%|█████     | 905/1772 [05:25<04:50,  2.99it/s, running training loss: 1.0110]\u001b[A\n",
            "Training:  51%|█████     | 906/1772 [05:25<05:06,  2.83it/s, running training loss: 1.0110]\u001b[A\n",
            "Training:  51%|█████     | 906/1772 [05:25<05:06,  2.83it/s, running training loss: 0.9215]\u001b[A\n",
            "Training:  51%|█████     | 907/1772 [05:25<05:09,  2.79it/s, running training loss: 0.9215]\u001b[A\n",
            "Training:  51%|█████     | 907/1772 [05:25<05:09,  2.79it/s, running training loss: 0.8473]\u001b[A\n",
            "Training:  51%|█████     | 908/1772 [05:25<04:54,  2.93it/s, running training loss: 0.8473]\u001b[A\n",
            "Training:  51%|█████     | 908/1772 [05:26<04:54,  2.93it/s, running training loss: 0.9230]\u001b[A\n",
            "Training:  51%|█████▏    | 909/1772 [05:26<04:55,  2.93it/s, running training loss: 0.9230]\u001b[A\n",
            "Training:  51%|█████▏    | 909/1772 [05:26<04:55,  2.93it/s, running training loss: 0.9890]\u001b[A\n",
            "Training:  51%|█████▏    | 910/1772 [05:26<04:42,  3.05it/s, running training loss: 0.9890]\u001b[A\n",
            "Training:  51%|█████▏    | 910/1772 [05:27<04:42,  3.05it/s, running training loss: 1.0471]\u001b[A\n",
            "Training:  51%|█████▏    | 911/1772 [05:27<05:03,  2.84it/s, running training loss: 1.0471]\u001b[A\n",
            "Training:  51%|█████▏    | 911/1772 [05:27<05:03,  2.84it/s, running training loss: 0.9503]\u001b[A\n",
            "Training:  51%|█████▏    | 912/1772 [05:27<04:59,  2.87it/s, running training loss: 0.9503]\u001b[A\n",
            "Training:  51%|█████▏    | 912/1772 [05:27<04:59,  2.87it/s, running training loss: 1.1911]\u001b[A\n",
            "Training:  52%|█████▏    | 913/1772 [05:27<04:48,  2.98it/s, running training loss: 1.1911]\u001b[A\n",
            "Training:  52%|█████▏    | 913/1772 [05:27<04:48,  2.98it/s, running training loss: 0.8437]\u001b[A\n",
            "Training:  52%|█████▏    | 914/1772 [05:27<04:38,  3.08it/s, running training loss: 0.8437]\u001b[A\n",
            "Training:  52%|█████▏    | 914/1772 [05:28<04:38,  3.08it/s, running training loss: 0.9917]\u001b[A\n",
            "Training:  52%|█████▏    | 915/1772 [05:28<05:19,  2.68it/s, running training loss: 0.9917]\u001b[A\n",
            "Training:  52%|█████▏    | 915/1772 [05:28<05:19,  2.68it/s, running training loss: 0.9531]\u001b[A\n",
            "Training:  52%|█████▏    | 916/1772 [05:28<05:11,  2.75it/s, running training loss: 0.9531]\u001b[A\n",
            "Training:  52%|█████▏    | 916/1772 [05:29<05:11,  2.75it/s, running training loss: 0.9640]\u001b[A\n",
            "Training:  52%|█████▏    | 917/1772 [05:29<04:54,  2.91it/s, running training loss: 0.9640]\u001b[A\n",
            "Training:  52%|█████▏    | 917/1772 [05:29<04:54,  2.91it/s, running training loss: 0.8797]\u001b[A\n",
            "Training:  52%|█████▏    | 918/1772 [05:29<04:39,  3.06it/s, running training loss: 0.8797]\u001b[A\n",
            "Training:  52%|█████▏    | 918/1772 [05:29<04:39,  3.06it/s, running training loss: 1.0351]\u001b[A\n",
            "Training:  52%|█████▏    | 919/1772 [05:29<05:05,  2.79it/s, running training loss: 1.0351]\u001b[A\n",
            "Training:  52%|█████▏    | 919/1772 [05:30<05:05,  2.79it/s, running training loss: 0.8329]\u001b[A\n",
            "Training:  52%|█████▏    | 920/1772 [05:30<05:05,  2.79it/s, running training loss: 0.8329]\u001b[A\n",
            "Training:  52%|█████▏    | 920/1772 [05:30<05:05,  2.79it/s, running training loss: 0.9045]\u001b[A\n",
            "Training:  52%|█████▏    | 921/1772 [05:30<04:55,  2.88it/s, running training loss: 0.9045]\u001b[A\n",
            "Training:  52%|█████▏    | 921/1772 [05:30<04:55,  2.88it/s, running training loss: 1.0447]\u001b[A\n",
            "Training:  52%|█████▏    | 922/1772 [05:30<05:23,  2.62it/s, running training loss: 1.0447]\u001b[A\n",
            "Training:  52%|█████▏    | 922/1772 [05:31<05:23,  2.62it/s, running training loss: 1.0566]\u001b[A\n",
            "Training:  52%|█████▏    | 923/1772 [05:31<05:28,  2.59it/s, running training loss: 1.0566]\u001b[A\n",
            "Training:  52%|█████▏    | 923/1772 [05:31<05:28,  2.59it/s, running training loss: 0.9296]\u001b[A\n",
            "Training:  52%|█████▏    | 924/1772 [05:31<05:12,  2.72it/s, running training loss: 0.9296]\u001b[A\n",
            "Training:  52%|█████▏    | 924/1772 [05:32<05:12,  2.72it/s, running training loss: 0.9548]\u001b[A\n",
            "Training:  52%|█████▏    | 925/1772 [05:32<05:07,  2.75it/s, running training loss: 0.9548]\u001b[A\n",
            "Training:  52%|█████▏    | 925/1772 [05:32<05:07,  2.75it/s, running training loss: 0.8973]\u001b[A\n",
            "Training:  52%|█████▏    | 926/1772 [05:32<04:56,  2.85it/s, running training loss: 0.8973]\u001b[A\n",
            "Training:  52%|█████▏    | 926/1772 [05:32<04:56,  2.85it/s, running training loss: 1.1104]\u001b[A\n",
            "Training:  52%|█████▏    | 927/1772 [05:32<05:55,  2.38it/s, running training loss: 1.1104]\u001b[A\n",
            "Training:  52%|█████▏    | 927/1772 [05:33<05:55,  2.38it/s, running training loss: 0.9874]\u001b[A\n",
            "Training:  52%|█████▏    | 928/1772 [05:33<05:14,  2.68it/s, running training loss: 0.9874]\u001b[A\n",
            "Training:  52%|█████▏    | 928/1772 [05:33<05:14,  2.68it/s, running training loss: 0.9853]\u001b[A\n",
            "Training:  52%|█████▏    | 929/1772 [05:33<04:57,  2.84it/s, running training loss: 0.9853]\u001b[A\n",
            "Training:  52%|█████▏    | 929/1772 [05:33<04:57,  2.84it/s, running training loss: 0.9583]\u001b[A\n",
            "Training:  52%|█████▏    | 930/1772 [05:33<04:47,  2.93it/s, running training loss: 0.9583]\u001b[A\n",
            "Training:  52%|█████▏    | 930/1772 [05:34<04:47,  2.93it/s, running training loss: 1.1594]\u001b[A\n",
            "Training:  53%|█████▎    | 931/1772 [05:34<04:43,  2.96it/s, running training loss: 1.1594]\u001b[A\n",
            "Training:  53%|█████▎    | 931/1772 [05:34<04:43,  2.96it/s, running training loss: 1.0726]\u001b[A\n",
            "Training:  53%|█████▎    | 932/1772 [05:34<04:25,  3.16it/s, running training loss: 1.0726]\u001b[A\n",
            "Training:  53%|█████▎    | 932/1772 [05:34<04:25,  3.16it/s, running training loss: 0.8812]\u001b[A\n",
            "Training:  53%|█████▎    | 933/1772 [05:34<04:38,  3.01it/s, running training loss: 0.8812]\u001b[A\n",
            "Training:  53%|█████▎    | 933/1772 [05:35<04:38,  3.01it/s, running training loss: 0.9714]\u001b[A\n",
            "Training:  53%|█████▎    | 934/1772 [05:35<04:38,  3.01it/s, running training loss: 0.9714]\u001b[A\n",
            "Training:  53%|█████▎    | 934/1772 [05:35<04:38,  3.01it/s, running training loss: 1.0384]\u001b[A\n",
            "Training:  53%|█████▎    | 935/1772 [05:35<04:15,  3.27it/s, running training loss: 1.0384]\u001b[A\n",
            "Training:  53%|█████▎    | 935/1772 [05:35<04:15,  3.27it/s, running training loss: 1.0176]\u001b[A\n",
            "Training:  53%|█████▎    | 936/1772 [05:35<04:16,  3.26it/s, running training loss: 1.0176]\u001b[A\n",
            "Training:  53%|█████▎    | 936/1772 [05:35<04:16,  3.26it/s, running training loss: 0.9060]\u001b[A\n",
            "Training:  53%|█████▎    | 937/1772 [05:35<04:18,  3.23it/s, running training loss: 0.9060]\u001b[A\n",
            "Training:  53%|█████▎    | 937/1772 [05:36<04:18,  3.23it/s, running training loss: 0.8969]\u001b[A\n",
            "Training:  53%|█████▎    | 938/1772 [05:36<04:14,  3.28it/s, running training loss: 0.8969]\u001b[A\n",
            "Training:  53%|█████▎    | 938/1772 [05:36<04:14,  3.28it/s, running training loss: 1.0445]\u001b[A\n",
            "Training:  53%|█████▎    | 939/1772 [05:36<04:02,  3.44it/s, running training loss: 1.0445]\u001b[A\n",
            "Training:  53%|█████▎    | 939/1772 [05:36<04:02,  3.44it/s, running training loss: 1.0079]\u001b[A\n",
            "Training:  53%|█████▎    | 940/1772 [05:36<04:07,  3.36it/s, running training loss: 1.0079]\u001b[A\n",
            "Training:  53%|█████▎    | 940/1772 [05:37<04:07,  3.36it/s, running training loss: 0.8912]\u001b[A\n",
            "Training:  53%|█████▎    | 941/1772 [05:37<04:08,  3.35it/s, running training loss: 0.8912]\u001b[A\n",
            "Training:  53%|█████▎    | 941/1772 [05:37<04:08,  3.35it/s, running training loss: 0.9428]\u001b[A\n",
            "Training:  53%|█████▎    | 942/1772 [05:37<04:26,  3.11it/s, running training loss: 0.9428]\u001b[A\n",
            "Training:  53%|█████▎    | 942/1772 [05:37<04:26,  3.11it/s, running training loss: 0.9170]\u001b[A\n",
            "Training:  53%|█████▎    | 943/1772 [05:37<04:21,  3.17it/s, running training loss: 0.9170]\u001b[A\n",
            "Training:  53%|█████▎    | 943/1772 [05:38<04:21,  3.17it/s, running training loss: 1.3255]\u001b[A\n",
            "Training:  53%|█████▎    | 944/1772 [05:38<04:30,  3.06it/s, running training loss: 1.3255]\u001b[A\n",
            "Training:  53%|█████▎    | 944/1772 [05:38<04:30,  3.06it/s, running training loss: 0.9618]\u001b[A\n",
            "Training:  53%|█████▎    | 945/1772 [05:38<05:28,  2.52it/s, running training loss: 0.9618]\u001b[A\n",
            "Training:  53%|█████▎    | 945/1772 [05:39<05:28,  2.52it/s, running training loss: 1.1264]\u001b[A\n",
            "Training:  53%|█████▎    | 946/1772 [05:39<05:21,  2.57it/s, running training loss: 1.1264]\u001b[A\n",
            "Training:  53%|█████▎    | 946/1772 [05:39<05:21,  2.57it/s, running training loss: 1.0924]\u001b[A\n",
            "Training:  53%|█████▎    | 947/1772 [05:39<05:13,  2.63it/s, running training loss: 1.0924]\u001b[A\n",
            "Training:  53%|█████▎    | 947/1772 [05:39<05:13,  2.63it/s, running training loss: 1.0887]\u001b[A\n",
            "Training:  53%|█████▎    | 948/1772 [05:39<05:47,  2.37it/s, running training loss: 1.0887]\u001b[A\n",
            "Training:  53%|█████▎    | 948/1772 [05:40<05:47,  2.37it/s, running training loss: 1.0569]\u001b[A\n",
            "Training:  54%|█████▎    | 949/1772 [05:40<05:17,  2.59it/s, running training loss: 1.0569]\u001b[A\n",
            "Training:  54%|█████▎    | 949/1772 [05:40<05:17,  2.59it/s, running training loss: 1.0673]\u001b[A\n",
            "Training:  54%|█████▎    | 950/1772 [05:40<05:04,  2.70it/s, running training loss: 1.0673]\u001b[A\n",
            "Training:  54%|█████▎    | 950/1772 [05:40<05:04,  2.70it/s, running training loss: 1.0306]\u001b[A\n",
            "Training:  54%|█████▎    | 951/1772 [05:40<04:40,  2.93it/s, running training loss: 1.0306]\u001b[A\n",
            "Training:  54%|█████▎    | 951/1772 [05:41<04:40,  2.93it/s, running training loss: 1.2199]\u001b[A\n",
            "Training:  54%|█████▎    | 952/1772 [05:41<04:34,  2.99it/s, running training loss: 1.2199]\u001b[A\n",
            "Training:  54%|█████▎    | 952/1772 [05:41<04:34,  2.99it/s, running training loss: 1.0997]\u001b[A\n",
            "Training:  54%|█████▍    | 953/1772 [05:41<04:30,  3.03it/s, running training loss: 1.0997]\u001b[A\n",
            "Training:  54%|█████▍    | 953/1772 [05:41<04:30,  3.03it/s, running training loss: 0.9992]\u001b[A\n",
            "Training:  54%|█████▍    | 954/1772 [05:41<04:25,  3.08it/s, running training loss: 0.9992]\u001b[A\n",
            "Training:  54%|█████▍    | 954/1772 [05:42<04:25,  3.08it/s, running training loss: 0.9933]\u001b[A\n",
            "Training:  54%|█████▍    | 955/1772 [05:42<04:51,  2.80it/s, running training loss: 0.9933]\u001b[A\n",
            "Training:  54%|█████▍    | 955/1772 [05:42<04:51,  2.80it/s, running training loss: 0.8528]\u001b[A\n",
            "Training:  54%|█████▍    | 956/1772 [05:42<04:33,  2.99it/s, running training loss: 0.8528]\u001b[A\n",
            "Training:  54%|█████▍    | 956/1772 [05:42<04:33,  2.99it/s, running training loss: 0.9982]\u001b[A\n",
            "Training:  54%|█████▍    | 957/1772 [05:42<04:21,  3.12it/s, running training loss: 0.9982]\u001b[A\n",
            "Training:  54%|█████▍    | 957/1772 [05:43<04:21,  3.12it/s, running training loss: 1.0549]\u001b[A\n",
            "Training:  54%|█████▍    | 958/1772 [05:43<04:45,  2.85it/s, running training loss: 1.0549]\u001b[A\n",
            "Training:  54%|█████▍    | 958/1772 [05:43<04:45,  2.85it/s, running training loss: 0.9541]\u001b[A\n",
            "Training:  54%|█████▍    | 959/1772 [05:43<04:36,  2.94it/s, running training loss: 0.9541]\u001b[A\n",
            "Training:  54%|█████▍    | 959/1772 [05:43<04:36,  2.94it/s, running training loss: 0.9870]\u001b[A\n",
            "Training:  54%|█████▍    | 960/1772 [05:43<04:19,  3.13it/s, running training loss: 0.9870]\u001b[A\n",
            "Training:  54%|█████▍    | 960/1772 [05:44<04:19,  3.13it/s, running training loss: 0.9135]\u001b[A\n",
            "Training:  54%|█████▍    | 961/1772 [05:44<04:24,  3.07it/s, running training loss: 0.9135]\u001b[A\n",
            "Training:  54%|█████▍    | 961/1772 [05:44<04:24,  3.07it/s, running training loss: 0.8472]\u001b[A\n",
            "Training:  54%|█████▍    | 962/1772 [05:44<04:37,  2.92it/s, running training loss: 0.8472]\u001b[A\n",
            "Training:  54%|█████▍    | 962/1772 [05:44<04:37,  2.92it/s, running training loss: 1.1535]\u001b[A\n",
            "Training:  54%|█████▍    | 963/1772 [05:44<04:43,  2.86it/s, running training loss: 1.1535]\u001b[A\n",
            "Training:  54%|█████▍    | 963/1772 [05:45<04:43,  2.86it/s, running training loss: 0.9722]\u001b[A\n",
            "Training:  54%|█████▍    | 964/1772 [05:45<05:02,  2.67it/s, running training loss: 0.9722]\u001b[A\n",
            "Training:  54%|█████▍    | 964/1772 [05:45<05:02,  2.67it/s, running training loss: 1.0919]\u001b[A\n",
            "Training:  54%|█████▍    | 965/1772 [05:45<04:46,  2.81it/s, running training loss: 1.0919]\u001b[A\n",
            "Training:  54%|█████▍    | 965/1772 [05:45<04:46,  2.81it/s, running training loss: 1.3741]\u001b[A\n",
            "Training:  55%|█████▍    | 966/1772 [05:45<04:26,  3.03it/s, running training loss: 1.3741]\u001b[A\n",
            "Training:  55%|█████▍    | 966/1772 [05:46<04:26,  3.03it/s, running training loss: 1.1207]\u001b[A\n",
            "Training:  55%|█████▍    | 967/1772 [05:46<04:21,  3.08it/s, running training loss: 1.1207]\u001b[A\n",
            "Training:  55%|█████▍    | 967/1772 [05:46<04:21,  3.08it/s, running training loss: 1.1448]\u001b[A\n",
            "Training:  55%|█████▍    | 968/1772 [05:46<05:04,  2.64it/s, running training loss: 1.1448]\u001b[A\n",
            "Training:  55%|█████▍    | 968/1772 [05:47<05:04,  2.64it/s, running training loss: 1.0385]\u001b[A\n",
            "Training:  55%|█████▍    | 969/1772 [05:47<04:41,  2.86it/s, running training loss: 1.0385]\u001b[A\n",
            "Training:  55%|█████▍    | 969/1772 [05:47<04:41,  2.86it/s, running training loss: 0.9257]\u001b[A\n",
            "Training:  55%|█████▍    | 970/1772 [05:47<04:50,  2.76it/s, running training loss: 0.9257]\u001b[A\n",
            "Training:  55%|█████▍    | 970/1772 [05:47<04:50,  2.76it/s, running training loss: 0.8735]\u001b[A\n",
            "Training:  55%|█████▍    | 971/1772 [05:47<04:34,  2.92it/s, running training loss: 0.8735]\u001b[A\n",
            "Training:  55%|█████▍    | 971/1772 [05:48<04:34,  2.92it/s, running training loss: 0.9147]\u001b[A\n",
            "Training:  55%|█████▍    | 972/1772 [05:48<04:56,  2.69it/s, running training loss: 0.9147]\u001b[A\n",
            "Training:  55%|█████▍    | 972/1772 [05:48<04:56,  2.69it/s, running training loss: 0.9489]\u001b[A\n",
            "Training:  55%|█████▍    | 973/1772 [05:48<05:19,  2.50it/s, running training loss: 0.9489]\u001b[A\n",
            "Training:  55%|█████▍    | 973/1772 [05:48<05:19,  2.50it/s, running training loss: 1.1354]\u001b[A\n",
            "Training:  55%|█████▍    | 974/1772 [05:48<04:53,  2.72it/s, running training loss: 1.1354]\u001b[A\n",
            "Training:  55%|█████▍    | 974/1772 [05:49<04:53,  2.72it/s, running training loss: 0.8594]\u001b[A\n",
            "Training:  55%|█████▌    | 975/1772 [05:49<05:33,  2.39it/s, running training loss: 0.8594]\u001b[A\n",
            "Training:  55%|█████▌    | 975/1772 [05:49<05:33,  2.39it/s, running training loss: 0.9709]\u001b[A\n",
            "Training:  55%|█████▌    | 976/1772 [05:49<05:23,  2.46it/s, running training loss: 0.9709]\u001b[A\n",
            "Training:  55%|█████▌    | 976/1772 [05:50<05:23,  2.46it/s, running training loss: 0.9734]\u001b[A\n",
            "Training:  55%|█████▌    | 977/1772 [05:50<04:47,  2.77it/s, running training loss: 0.9734]\u001b[A\n",
            "Training:  55%|█████▌    | 977/1772 [05:50<04:47,  2.77it/s, running training loss: 0.9929]\u001b[A\n",
            "Training:  55%|█████▌    | 978/1772 [05:50<04:40,  2.83it/s, running training loss: 0.9929]\u001b[A\n",
            "Training:  55%|█████▌    | 978/1772 [05:50<04:40,  2.83it/s, running training loss: 1.1411]\u001b[A\n",
            "Training:  55%|█████▌    | 979/1772 [05:50<04:45,  2.78it/s, running training loss: 1.1411]\u001b[A\n",
            "Training:  55%|█████▌    | 979/1772 [05:51<04:45,  2.78it/s, running training loss: 0.9742]\u001b[A\n",
            "Training:  55%|█████▌    | 980/1772 [05:51<04:38,  2.85it/s, running training loss: 0.9742]\u001b[A\n",
            "Training:  55%|█████▌    | 980/1772 [05:51<04:38,  2.85it/s, running training loss: 1.1816]\u001b[A\n",
            "Training:  55%|█████▌    | 981/1772 [05:51<04:16,  3.08it/s, running training loss: 1.1816]\u001b[A\n",
            "Training:  55%|█████▌    | 981/1772 [05:51<04:16,  3.08it/s, running training loss: 0.9392]\u001b[A\n",
            "Training:  55%|█████▌    | 982/1772 [05:51<04:01,  3.27it/s, running training loss: 0.9392]\u001b[A\n",
            "Training:  55%|█████▌    | 982/1772 [05:52<04:01,  3.27it/s, running training loss: 1.1270]\u001b[A\n",
            "Training:  55%|█████▌    | 983/1772 [05:52<04:11,  3.13it/s, running training loss: 1.1270]\u001b[A\n",
            "Training:  55%|█████▌    | 983/1772 [05:52<04:11,  3.13it/s, running training loss: 0.8210]\u001b[A\n",
            "Training:  56%|█████▌    | 984/1772 [05:52<04:34,  2.87it/s, running training loss: 0.8210]\u001b[A\n",
            "Training:  56%|█████▌    | 984/1772 [05:52<04:34,  2.87it/s, running training loss: 1.2528]\u001b[A\n",
            "Training:  56%|█████▌    | 985/1772 [05:52<04:42,  2.78it/s, running training loss: 1.2528]\u001b[A\n",
            "Training:  56%|█████▌    | 985/1772 [05:53<04:42,  2.78it/s, running training loss: 1.0312]\u001b[A\n",
            "Training:  56%|█████▌    | 986/1772 [05:53<04:45,  2.75it/s, running training loss: 1.0312]\u001b[A\n",
            "Training:  56%|█████▌    | 986/1772 [05:53<04:45,  2.75it/s, running training loss: 0.9823]\u001b[A\n",
            "Training:  56%|█████▌    | 987/1772 [05:53<04:41,  2.79it/s, running training loss: 0.9823]\u001b[A\n",
            "Training:  56%|█████▌    | 987/1772 [05:53<04:41,  2.79it/s, running training loss: 0.8629]\u001b[A\n",
            "Training:  56%|█████▌    | 988/1772 [05:53<04:32,  2.88it/s, running training loss: 0.8629]\u001b[A\n",
            "Training:  56%|█████▌    | 988/1772 [05:54<04:32,  2.88it/s, running training loss: 1.0460]\u001b[A\n",
            "Training:  56%|█████▌    | 989/1772 [05:54<04:24,  2.96it/s, running training loss: 1.0460]\u001b[A\n",
            "Training:  56%|█████▌    | 989/1772 [05:54<04:24,  2.96it/s, running training loss: 1.0017]\u001b[A\n",
            "Training:  56%|█████▌    | 990/1772 [05:54<04:20,  3.00it/s, running training loss: 1.0017]\u001b[A\n",
            "Training:  56%|█████▌    | 990/1772 [05:54<04:20,  3.00it/s, running training loss: 1.0457]\u001b[A\n",
            "Training:  56%|█████▌    | 991/1772 [05:54<04:33,  2.85it/s, running training loss: 1.0457]\u001b[A\n",
            "Training:  56%|█████▌    | 991/1772 [05:55<04:33,  2.85it/s, running training loss: 0.9520]\u001b[A\n",
            "Training:  56%|█████▌    | 992/1772 [05:55<04:25,  2.93it/s, running training loss: 0.9520]\u001b[A\n",
            "Training:  56%|█████▌    | 992/1772 [05:55<04:25,  2.93it/s, running training loss: 1.1319]\u001b[A\n",
            "Training:  56%|█████▌    | 993/1772 [05:55<04:18,  3.01it/s, running training loss: 1.1319]\u001b[A\n",
            "Training:  56%|█████▌    | 993/1772 [05:56<04:18,  3.01it/s, running training loss: 1.0565]\u001b[A\n",
            "Training:  56%|█████▌    | 994/1772 [05:56<04:59,  2.60it/s, running training loss: 1.0565]\u001b[A\n",
            "Training:  56%|█████▌    | 994/1772 [05:56<04:59,  2.60it/s, running training loss: 1.1030]\u001b[A\n",
            "Training:  56%|█████▌    | 995/1772 [05:56<04:35,  2.82it/s, running training loss: 1.1030]\u001b[A\n",
            "Training:  56%|█████▌    | 995/1772 [05:56<04:35,  2.82it/s, running training loss: 1.0694]\u001b[A\n",
            "Training:  56%|█████▌    | 996/1772 [05:56<04:35,  2.82it/s, running training loss: 1.0694]\u001b[A\n",
            "Training:  56%|█████▌    | 996/1772 [05:57<04:35,  2.82it/s, running training loss: 0.8319]\u001b[A\n",
            "Training:  56%|█████▋    | 997/1772 [05:57<04:46,  2.70it/s, running training loss: 0.8319]\u001b[A\n",
            "Training:  56%|█████▋    | 997/1772 [05:57<04:46,  2.70it/s, running training loss: 1.0199]\u001b[A\n",
            "Training:  56%|█████▋    | 998/1772 [05:57<04:35,  2.81it/s, running training loss: 1.0199]\u001b[A\n",
            "Training:  56%|█████▋    | 998/1772 [05:57<04:35,  2.81it/s, running training loss: 1.1722]\u001b[A\n",
            "Training:  56%|█████▋    | 999/1772 [05:57<04:15,  3.02it/s, running training loss: 1.1722]\u001b[A\n",
            "Training:  56%|█████▋    | 999/1772 [05:57<04:15,  3.02it/s, running training loss: 0.8508]\u001b[A\n",
            "Training:  56%|█████▋    | 1000/1772 [05:57<04:07,  3.13it/s, running training loss: 0.8508]\u001b[A\n",
            "Training:  56%|█████▋    | 1000/1772 [05:58<04:07,  3.13it/s, running training loss: 1.0369]\u001b[A\n",
            "Training:  56%|█████▋    | 1001/1772 [05:58<04:06,  3.13it/s, running training loss: 1.0369]\u001b[A\n",
            "Training:  56%|█████▋    | 1001/1772 [05:58<04:06,  3.13it/s, running training loss: 0.9226]\u001b[A\n",
            "Training:  57%|█████▋    | 1002/1772 [05:58<04:05,  3.13it/s, running training loss: 0.9226]\u001b[A\n",
            "Training:  57%|█████▋    | 1002/1772 [05:58<04:05,  3.13it/s, running training loss: 0.9053]\u001b[A\n",
            "Training:  57%|█████▋    | 1003/1772 [05:58<03:59,  3.21it/s, running training loss: 0.9053]\u001b[A\n",
            "Training:  57%|█████▋    | 1003/1772 [05:59<03:59,  3.21it/s, running training loss: 1.0212]\u001b[A\n",
            "Training:  57%|█████▋    | 1004/1772 [05:59<04:16,  3.00it/s, running training loss: 1.0212]\u001b[A\n",
            "Training:  57%|█████▋    | 1004/1772 [05:59<04:16,  3.00it/s, running training loss: 1.2416]\u001b[A\n",
            "Training:  57%|█████▋    | 1005/1772 [05:59<04:17,  2.98it/s, running training loss: 1.2416]\u001b[A\n",
            "Training:  57%|█████▋    | 1005/1772 [05:59<04:17,  2.98it/s, running training loss: 1.1665]\u001b[A\n",
            "Training:  57%|█████▋    | 1006/1772 [05:59<04:14,  3.01it/s, running training loss: 1.1665]\u001b[A\n",
            "Training:  57%|█████▋    | 1006/1772 [06:00<04:14,  3.01it/s, running training loss: 1.3750]\u001b[A\n",
            "Training:  57%|█████▋    | 1007/1772 [06:00<03:53,  3.28it/s, running training loss: 1.3750]\u001b[A\n",
            "Training:  57%|█████▋    | 1007/1772 [06:00<03:53,  3.28it/s, running training loss: 1.2313]\u001b[A\n",
            "Training:  57%|█████▋    | 1008/1772 [06:00<04:12,  3.03it/s, running training loss: 1.2313]\u001b[A\n",
            "Training:  57%|█████▋    | 1008/1772 [06:00<04:12,  3.03it/s, running training loss: 0.9973]\u001b[A\n",
            "Training:  57%|█████▋    | 1009/1772 [06:00<04:12,  3.02it/s, running training loss: 0.9973]\u001b[A\n",
            "Training:  57%|█████▋    | 1009/1772 [06:01<04:12,  3.02it/s, running training loss: 1.0693]\u001b[A\n",
            "Training:  57%|█████▋    | 1010/1772 [06:01<04:55,  2.58it/s, running training loss: 1.0693]\u001b[A\n",
            "Training:  57%|█████▋    | 1010/1772 [06:01<04:55,  2.58it/s, running training loss: 0.9994]\u001b[A\n",
            "Training:  57%|█████▋    | 1011/1772 [06:01<04:27,  2.84it/s, running training loss: 0.9994]\u001b[A\n",
            "Training:  57%|█████▋    | 1011/1772 [06:02<04:27,  2.84it/s, running training loss: 1.0219]\u001b[A\n",
            "Training:  57%|█████▋    | 1012/1772 [06:02<04:23,  2.88it/s, running training loss: 1.0219]\u001b[A\n",
            "Training:  57%|█████▋    | 1012/1772 [06:02<04:23,  2.88it/s, running training loss: 1.0802]\u001b[A\n",
            "Training:  57%|█████▋    | 1013/1772 [06:02<04:10,  3.04it/s, running training loss: 1.0802]\u001b[A\n",
            "Training:  57%|█████▋    | 1013/1772 [06:02<04:10,  3.04it/s, running training loss: 0.9826]\u001b[A\n",
            "Training:  57%|█████▋    | 1014/1772 [06:02<04:08,  3.05it/s, running training loss: 0.9826]\u001b[A\n",
            "Training:  57%|█████▋    | 1014/1772 [06:03<04:08,  3.05it/s, running training loss: 0.9846]\u001b[A\n",
            "Training:  57%|█████▋    | 1015/1772 [06:03<04:25,  2.85it/s, running training loss: 0.9846]\u001b[A\n",
            "Training:  57%|█████▋    | 1015/1772 [06:03<04:25,  2.85it/s, running training loss: 1.0054]\u001b[A\n",
            "Training:  57%|█████▋    | 1016/1772 [06:03<04:10,  3.02it/s, running training loss: 1.0054]\u001b[A\n",
            "Training:  57%|█████▋    | 1016/1772 [06:03<04:10,  3.02it/s, running training loss: 1.0326]\u001b[A\n",
            "Training:  57%|█████▋    | 1017/1772 [06:03<04:00,  3.14it/s, running training loss: 1.0326]\u001b[A\n",
            "Training:  57%|█████▋    | 1017/1772 [06:04<04:00,  3.14it/s, running training loss: 0.9898]\u001b[A\n",
            "Training:  57%|█████▋    | 1018/1772 [06:04<04:10,  3.01it/s, running training loss: 0.9898]\u001b[A\n",
            "Training:  57%|█████▋    | 1018/1772 [06:04<04:10,  3.01it/s, running training loss: 0.9798]\u001b[A\n",
            "Training:  58%|█████▊    | 1019/1772 [06:04<03:55,  3.19it/s, running training loss: 0.9798]\u001b[A\n",
            "Training:  58%|█████▊    | 1019/1772 [06:04<03:55,  3.19it/s, running training loss: 1.0170]\u001b[A\n",
            "Training:  58%|█████▊    | 1020/1772 [06:04<03:59,  3.14it/s, running training loss: 1.0170]\u001b[A\n",
            "Training:  58%|█████▊    | 1020/1772 [06:04<03:59,  3.14it/s, running training loss: 0.8438]\u001b[A\n",
            "Training:  58%|█████▊    | 1021/1772 [06:04<03:53,  3.22it/s, running training loss: 0.8438]\u001b[A\n",
            "Training:  58%|█████▊    | 1021/1772 [06:05<03:53,  3.22it/s, running training loss: 0.9680]\u001b[A\n",
            "Training:  58%|█████▊    | 1022/1772 [06:05<03:44,  3.34it/s, running training loss: 0.9680]\u001b[A\n",
            "Training:  58%|█████▊    | 1022/1772 [06:05<03:44,  3.34it/s, running training loss: 0.9286]\u001b[A\n",
            "Training:  58%|█████▊    | 1023/1772 [06:05<03:57,  3.16it/s, running training loss: 0.9286]\u001b[A\n",
            "Training:  58%|█████▊    | 1023/1772 [06:05<03:57,  3.16it/s, running training loss: 0.9299]\u001b[A\n",
            "Training:  58%|█████▊    | 1024/1772 [06:05<03:52,  3.21it/s, running training loss: 0.9299]\u001b[A\n",
            "Training:  58%|█████▊    | 1024/1772 [06:06<03:52,  3.21it/s, running training loss: 0.9085]\u001b[A\n",
            "Training:  58%|█████▊    | 1025/1772 [06:06<03:45,  3.31it/s, running training loss: 0.9085]\u001b[A\n",
            "Training:  58%|█████▊    | 1025/1772 [06:06<03:45,  3.31it/s, running training loss: 0.9682]\u001b[A\n",
            "Training:  58%|█████▊    | 1026/1772 [06:06<04:16,  2.91it/s, running training loss: 0.9682]\u001b[A\n",
            "Training:  58%|█████▊    | 1026/1772 [06:06<04:16,  2.91it/s, running training loss: 0.8581]\u001b[A\n",
            "Training:  58%|█████▊    | 1027/1772 [06:06<04:36,  2.69it/s, running training loss: 0.8581]\u001b[A\n",
            "Training:  58%|█████▊    | 1027/1772 [06:07<04:36,  2.69it/s, running training loss: 1.1004]\u001b[A\n",
            "Training:  58%|█████▊    | 1028/1772 [06:07<04:32,  2.73it/s, running training loss: 1.1004]\u001b[A\n",
            "Training:  58%|█████▊    | 1028/1772 [06:07<04:32,  2.73it/s, running training loss: 0.9729]\u001b[A\n",
            "Training:  58%|█████▊    | 1029/1772 [06:07<04:16,  2.89it/s, running training loss: 0.9729]\u001b[A\n",
            "Training:  58%|█████▊    | 1029/1772 [06:07<04:16,  2.89it/s, running training loss: 0.9546]\u001b[A\n",
            "Training:  58%|█████▊    | 1030/1772 [06:07<03:58,  3.11it/s, running training loss: 0.9546]\u001b[A\n",
            "Training:  58%|█████▊    | 1030/1772 [06:08<03:58,  3.11it/s, running training loss: 1.0782]\u001b[A\n",
            "Training:  58%|█████▊    | 1031/1772 [06:08<04:31,  2.73it/s, running training loss: 1.0782]\u001b[A\n",
            "Training:  58%|█████▊    | 1031/1772 [06:08<04:31,  2.73it/s, running training loss: 0.9539]\u001b[A\n",
            "Training:  58%|█████▊    | 1032/1772 [06:08<04:14,  2.90it/s, running training loss: 0.9539]\u001b[A\n",
            "Training:  58%|█████▊    | 1032/1772 [06:09<04:14,  2.90it/s, running training loss: 0.9298]\u001b[A\n",
            "Training:  58%|█████▊    | 1033/1772 [06:09<04:54,  2.51it/s, running training loss: 0.9298]\u001b[A\n",
            "Training:  58%|█████▊    | 1033/1772 [06:09<04:54,  2.51it/s, running training loss: 1.1899]\u001b[A\n",
            "Training:  58%|█████▊    | 1034/1772 [06:09<05:32,  2.22it/s, running training loss: 1.1899]\u001b[A\n",
            "Training:  58%|█████▊    | 1034/1772 [06:10<05:32,  2.22it/s, running training loss: 1.1013]\u001b[A\n",
            "Training:  58%|█████▊    | 1035/1772 [06:10<04:55,  2.50it/s, running training loss: 1.1013]\u001b[A\n",
            "Training:  58%|█████▊    | 1035/1772 [06:10<04:55,  2.50it/s, running training loss: 1.1307]\u001b[A\n",
            "Training:  58%|█████▊    | 1036/1772 [06:10<04:44,  2.59it/s, running training loss: 1.1307]\u001b[A\n",
            "Training:  58%|█████▊    | 1036/1772 [06:10<04:44,  2.59it/s, running training loss: 1.1562]\u001b[A\n",
            "Training:  59%|█████▊    | 1037/1772 [06:10<04:40,  2.62it/s, running training loss: 1.1562]\u001b[A\n",
            "Training:  59%|█████▊    | 1037/1772 [06:11<04:40,  2.62it/s, running training loss: 0.9704]\u001b[A\n",
            "Training:  59%|█████▊    | 1038/1772 [06:11<05:09,  2.37it/s, running training loss: 0.9704]\u001b[A\n",
            "Training:  59%|█████▊    | 1038/1772 [06:11<05:09,  2.37it/s, running training loss: 0.9883]\u001b[A\n",
            "Training:  59%|█████▊    | 1039/1772 [06:11<04:56,  2.47it/s, running training loss: 0.9883]\u001b[A\n",
            "Training:  59%|█████▊    | 1039/1772 [06:11<04:56,  2.47it/s, running training loss: 0.9918]\u001b[A\n",
            "Training:  59%|█████▊    | 1040/1772 [06:11<04:30,  2.71it/s, running training loss: 0.9918]\u001b[A\n",
            "Training:  59%|█████▊    | 1040/1772 [06:12<04:30,  2.71it/s, running training loss: 0.9998]\u001b[A\n",
            "Training:  59%|█████▊    | 1041/1772 [06:12<04:15,  2.86it/s, running training loss: 0.9998]\u001b[A\n",
            "Training:  59%|█████▊    | 1041/1772 [06:12<04:15,  2.86it/s, running training loss: 1.0048]\u001b[A\n",
            "Training:  59%|█████▉    | 1042/1772 [06:12<04:21,  2.79it/s, running training loss: 1.0048]\u001b[A\n",
            "Training:  59%|█████▉    | 1042/1772 [06:12<04:21,  2.79it/s, running training loss: 1.0241]\u001b[A\n",
            "Training:  59%|█████▉    | 1043/1772 [06:12<04:10,  2.91it/s, running training loss: 1.0241]\u001b[A\n",
            "Training:  59%|█████▉    | 1043/1772 [06:13<04:10,  2.91it/s, running training loss: 0.8766]\u001b[A\n",
            "Training:  59%|█████▉    | 1044/1772 [06:13<04:15,  2.85it/s, running training loss: 0.8766]\u001b[A\n",
            "Training:  59%|█████▉    | 1044/1772 [06:13<04:15,  2.85it/s, running training loss: 1.0274]\u001b[A\n",
            "Training:  59%|█████▉    | 1045/1772 [06:13<04:22,  2.77it/s, running training loss: 1.0274]\u001b[A\n",
            "Training:  59%|█████▉    | 1045/1772 [06:13<04:22,  2.77it/s, running training loss: 1.0113]\u001b[A\n",
            "Training:  59%|█████▉    | 1046/1772 [06:13<04:10,  2.90it/s, running training loss: 1.0113]\u001b[A\n",
            "Training:  59%|█████▉    | 1046/1772 [06:14<04:10,  2.90it/s, running training loss: 1.1907]\u001b[A\n",
            "Training:  59%|█████▉    | 1047/1772 [06:14<03:52,  3.12it/s, running training loss: 1.1907]\u001b[A\n",
            "Training:  59%|█████▉    | 1047/1772 [06:14<03:52,  3.12it/s, running training loss: 1.0056]\u001b[A\n",
            "Training:  59%|█████▉    | 1048/1772 [06:14<03:53,  3.10it/s, running training loss: 1.0056]\u001b[A\n",
            "Training:  59%|█████▉    | 1048/1772 [06:14<03:53,  3.10it/s, running training loss: 1.0388]\u001b[A\n",
            "Training:  59%|█████▉    | 1049/1772 [06:14<03:44,  3.22it/s, running training loss: 1.0388]\u001b[A\n",
            "Training:  59%|█████▉    | 1049/1772 [06:15<03:44,  3.22it/s, running training loss: 1.1731]\u001b[A\n",
            "Training:  59%|█████▉    | 1050/1772 [06:15<04:17,  2.80it/s, running training loss: 1.1731]\u001b[A\n",
            "Training:  59%|█████▉    | 1050/1772 [06:15<04:17,  2.80it/s, running training loss: 1.1030]\u001b[A\n",
            "Training:  59%|█████▉    | 1051/1772 [06:15<04:49,  2.49it/s, running training loss: 1.1030]\u001b[A\n",
            "Training:  59%|█████▉    | 1051/1772 [06:16<04:49,  2.49it/s, running training loss: 0.8972]\u001b[A\n",
            "Training:  59%|█████▉    | 1052/1772 [06:16<04:29,  2.68it/s, running training loss: 0.8972]\u001b[A\n",
            "Training:  59%|█████▉    | 1052/1772 [06:16<04:29,  2.68it/s, running training loss: 1.0349]\u001b[A\n",
            "Training:  59%|█████▉    | 1053/1772 [06:16<04:39,  2.57it/s, running training loss: 1.0349]\u001b[A\n",
            "Training:  59%|█████▉    | 1053/1772 [06:16<04:39,  2.57it/s, running training loss: 0.9417]\u001b[A\n",
            "Training:  59%|█████▉    | 1054/1772 [06:16<04:18,  2.78it/s, running training loss: 0.9417]\u001b[A\n",
            "Training:  59%|█████▉    | 1054/1772 [06:17<04:18,  2.78it/s, running training loss: 1.0110]\u001b[A\n",
            "Training:  60%|█████▉    | 1055/1772 [06:17<04:08,  2.89it/s, running training loss: 1.0110]\u001b[A\n",
            "Training:  60%|█████▉    | 1055/1772 [06:17<04:08,  2.89it/s, running training loss: 0.9170]\u001b[A\n",
            "Training:  60%|█████▉    | 1056/1772 [06:17<03:57,  3.02it/s, running training loss: 0.9170]\u001b[A\n",
            "Training:  60%|█████▉    | 1056/1772 [06:17<03:57,  3.02it/s, running training loss: 0.9553]\u001b[A\n",
            "Training:  60%|█████▉    | 1057/1772 [06:17<03:59,  2.98it/s, running training loss: 0.9553]\u001b[A\n",
            "Training:  60%|█████▉    | 1057/1772 [06:18<03:59,  2.98it/s, running training loss: 0.9446]\u001b[A\n",
            "Training:  60%|█████▉    | 1058/1772 [06:18<03:52,  3.07it/s, running training loss: 0.9446]\u001b[A\n",
            "Training:  60%|█████▉    | 1058/1772 [06:18<03:52,  3.07it/s, running training loss: 0.9361]\u001b[A\n",
            "Training:  60%|█████▉    | 1059/1772 [06:18<03:41,  3.22it/s, running training loss: 0.9361]\u001b[A\n",
            "Training:  60%|█████▉    | 1059/1772 [06:18<03:41,  3.22it/s, running training loss: 1.0650]\u001b[A\n",
            "Training:  60%|█████▉    | 1060/1772 [06:18<03:45,  3.16it/s, running training loss: 1.0650]\u001b[A\n",
            "Training:  60%|█████▉    | 1060/1772 [06:19<03:45,  3.16it/s, running training loss: 1.1879]\u001b[A\n",
            "Training:  60%|█████▉    | 1061/1772 [06:19<03:46,  3.13it/s, running training loss: 1.1879]\u001b[A\n",
            "Training:  60%|█████▉    | 1061/1772 [06:19<03:46,  3.13it/s, running training loss: 1.0743]\u001b[A\n",
            "Training:  60%|█████▉    | 1062/1772 [06:19<04:14,  2.79it/s, running training loss: 1.0743]\u001b[A\n",
            "Training:  60%|█████▉    | 1062/1772 [06:19<04:14,  2.79it/s, running training loss: 1.0483]\u001b[A\n",
            "Training:  60%|█████▉    | 1063/1772 [06:19<04:23,  2.69it/s, running training loss: 1.0483]\u001b[A\n",
            "Training:  60%|█████▉    | 1063/1772 [06:20<04:23,  2.69it/s, running training loss: 1.1091]\u001b[A\n",
            "Training:  60%|██████    | 1064/1772 [06:20<04:09,  2.84it/s, running training loss: 1.1091]\u001b[A\n",
            "Training:  60%|██████    | 1064/1772 [06:20<04:09,  2.84it/s, running training loss: 1.2146]\u001b[A\n",
            "Training:  60%|██████    | 1065/1772 [06:20<03:56,  2.99it/s, running training loss: 1.2146]\u001b[A\n",
            "Training:  60%|██████    | 1065/1772 [06:20<03:56,  2.99it/s, running training loss: 1.1883]\u001b[A\n",
            "Training:  60%|██████    | 1066/1772 [06:20<03:47,  3.10it/s, running training loss: 1.1883]\u001b[A\n",
            "Training:  60%|██████    | 1066/1772 [06:21<03:47,  3.10it/s, running training loss: 1.0180]\u001b[A\n",
            "Training:  60%|██████    | 1067/1772 [06:21<03:52,  3.03it/s, running training loss: 1.0180]\u001b[A\n",
            "Training:  60%|██████    | 1067/1772 [06:21<03:52,  3.03it/s, running training loss: 0.9456]\u001b[A\n",
            "Training:  60%|██████    | 1068/1772 [06:21<04:13,  2.77it/s, running training loss: 0.9456]\u001b[A\n",
            "Training:  60%|██████    | 1068/1772 [06:21<04:13,  2.77it/s, running training loss: 1.0257]\u001b[A\n",
            "Training:  60%|██████    | 1069/1772 [06:21<04:09,  2.82it/s, running training loss: 1.0257]\u001b[A\n",
            "Training:  60%|██████    | 1069/1772 [06:22<04:09,  2.82it/s, running training loss: 0.8614]\u001b[A\n",
            "Training:  60%|██████    | 1070/1772 [06:22<04:23,  2.67it/s, running training loss: 0.8614]\u001b[A\n",
            "Training:  60%|██████    | 1070/1772 [06:22<04:23,  2.67it/s, running training loss: 0.8271]\u001b[A\n",
            "Training:  60%|██████    | 1071/1772 [06:22<04:48,  2.43it/s, running training loss: 0.8271]\u001b[A\n",
            "Training:  60%|██████    | 1071/1772 [06:23<04:48,  2.43it/s, running training loss: 1.0217]\u001b[A\n",
            "Training:  60%|██████    | 1072/1772 [06:23<04:35,  2.54it/s, running training loss: 1.0217]\u001b[A\n",
            "Training:  60%|██████    | 1072/1772 [06:23<04:35,  2.54it/s, running training loss: 0.9468]\u001b[A\n",
            "Training:  61%|██████    | 1073/1772 [06:23<04:55,  2.36it/s, running training loss: 0.9468]\u001b[A\n",
            "Training:  61%|██████    | 1073/1772 [06:24<04:55,  2.36it/s, running training loss: 0.8566]\u001b[A\n",
            "Training:  61%|██████    | 1074/1772 [06:24<04:35,  2.53it/s, running training loss: 0.8566]\u001b[A\n",
            "Training:  61%|██████    | 1074/1772 [06:24<04:35,  2.53it/s, running training loss: 0.9574]\u001b[A\n",
            "Training:  61%|██████    | 1075/1772 [06:24<04:11,  2.77it/s, running training loss: 0.9574]\u001b[A\n",
            "Training:  61%|██████    | 1075/1772 [06:24<04:11,  2.77it/s, running training loss: 0.9543]\u001b[A\n",
            "Training:  61%|██████    | 1076/1772 [06:24<03:58,  2.92it/s, running training loss: 0.9543]\u001b[A\n",
            "Training:  61%|██████    | 1076/1772 [06:24<03:58,  2.92it/s, running training loss: 0.8616]\u001b[A\n",
            "Training:  61%|██████    | 1077/1772 [06:24<04:07,  2.81it/s, running training loss: 0.8616]\u001b[A\n",
            "Training:  61%|██████    | 1077/1772 [06:25<04:07,  2.81it/s, running training loss: 0.9435]\u001b[A\n",
            "Training:  61%|██████    | 1078/1772 [06:25<04:06,  2.82it/s, running training loss: 0.9435]\u001b[A\n",
            "Training:  61%|██████    | 1078/1772 [06:25<04:06,  2.82it/s, running training loss: 1.1184]\u001b[A\n",
            "Training:  61%|██████    | 1079/1772 [06:25<03:59,  2.90it/s, running training loss: 1.1184]\u001b[A\n",
            "Training:  61%|██████    | 1079/1772 [06:25<03:59,  2.90it/s, running training loss: 0.9805]\u001b[A\n",
            "Training:  61%|██████    | 1080/1772 [06:25<03:48,  3.03it/s, running training loss: 0.9805]\u001b[A\n",
            "Training:  61%|██████    | 1080/1772 [06:26<03:48,  3.03it/s, running training loss: 1.2680]\u001b[A\n",
            "Training:  61%|██████    | 1081/1772 [06:26<03:53,  2.96it/s, running training loss: 1.2680]\u001b[A\n",
            "Training:  61%|██████    | 1081/1772 [06:26<03:53,  2.96it/s, running training loss: 1.0535]\u001b[A\n",
            "Training:  61%|██████    | 1082/1772 [06:26<04:00,  2.87it/s, running training loss: 1.0535]\u001b[A\n",
            "Training:  61%|██████    | 1082/1772 [06:27<04:00,  2.87it/s, running training loss: 1.2722]\u001b[A\n",
            "Training:  61%|██████    | 1083/1772 [06:27<04:28,  2.56it/s, running training loss: 1.2722]\u001b[A\n",
            "Training:  61%|██████    | 1083/1772 [06:27<04:28,  2.56it/s, running training loss: 1.2484]\u001b[A\n",
            "Training:  61%|██████    | 1084/1772 [06:27<04:19,  2.65it/s, running training loss: 1.2484]\u001b[A\n",
            "Training:  61%|██████    | 1084/1772 [06:27<04:19,  2.65it/s, running training loss: 1.2593]\u001b[A\n",
            "Training:  61%|██████    | 1085/1772 [06:27<04:00,  2.85it/s, running training loss: 1.2593]\u001b[A\n",
            "Training:  61%|██████    | 1085/1772 [06:28<04:00,  2.85it/s, running training loss: 1.2415]\u001b[A\n",
            "Training:  61%|██████▏   | 1086/1772 [06:28<04:07,  2.77it/s, running training loss: 1.2415]\u001b[A\n",
            "Training:  61%|██████▏   | 1086/1772 [06:28<04:07,  2.77it/s, running training loss: 1.1015]\u001b[A\n",
            "Training:  61%|██████▏   | 1087/1772 [06:28<03:48,  2.99it/s, running training loss: 1.1015]\u001b[A\n",
            "Training:  61%|██████▏   | 1087/1772 [06:28<03:48,  2.99it/s, running training loss: 1.2426]\u001b[A\n",
            "Training:  61%|██████▏   | 1088/1772 [06:28<03:48,  3.00it/s, running training loss: 1.2426]\u001b[A\n",
            "Training:  61%|██████▏   | 1088/1772 [06:29<03:48,  3.00it/s, running training loss: 0.9962]\u001b[A\n",
            "Training:  61%|██████▏   | 1089/1772 [06:29<03:59,  2.85it/s, running training loss: 0.9962]\u001b[A\n",
            "Training:  61%|██████▏   | 1089/1772 [06:29<03:59,  2.85it/s, running training loss: 0.8672]\u001b[A\n",
            "Training:  62%|██████▏   | 1090/1772 [06:29<04:01,  2.82it/s, running training loss: 0.8672]\u001b[A\n",
            "Training:  62%|██████▏   | 1090/1772 [06:29<04:01,  2.82it/s, running training loss: 1.1306]\u001b[A\n",
            "Training:  62%|██████▏   | 1091/1772 [06:29<03:55,  2.90it/s, running training loss: 1.1306]\u001b[A\n",
            "Training:  62%|██████▏   | 1091/1772 [06:30<03:55,  2.90it/s, running training loss: 0.9303]\u001b[A\n",
            "Training:  62%|██████▏   | 1092/1772 [06:30<03:33,  3.18it/s, running training loss: 0.9303]\u001b[A\n",
            "Training:  62%|██████▏   | 1092/1772 [06:30<03:33,  3.18it/s, running training loss: 0.9991]\u001b[A\n",
            "Training:  62%|██████▏   | 1093/1772 [06:30<03:41,  3.07it/s, running training loss: 0.9991]\u001b[A\n",
            "Training:  62%|██████▏   | 1093/1772 [06:30<03:41,  3.07it/s, running training loss: 0.8964]\u001b[A\n",
            "Training:  62%|██████▏   | 1094/1772 [06:30<03:32,  3.19it/s, running training loss: 0.8964]\u001b[A\n",
            "Training:  62%|██████▏   | 1094/1772 [06:31<03:32,  3.19it/s, running training loss: 0.8607]\u001b[A\n",
            "Training:  62%|██████▏   | 1095/1772 [06:31<03:28,  3.24it/s, running training loss: 0.8607]\u001b[A\n",
            "Training:  62%|██████▏   | 1095/1772 [06:31<03:28,  3.24it/s, running training loss: 0.7918]\u001b[A\n",
            "Training:  62%|██████▏   | 1096/1772 [06:31<03:40,  3.07it/s, running training loss: 0.7918]\u001b[A\n",
            "Training:  62%|██████▏   | 1096/1772 [06:31<03:40,  3.07it/s, running training loss: 0.8498]\u001b[A\n",
            "Training:  62%|██████▏   | 1097/1772 [06:31<03:48,  2.95it/s, running training loss: 0.8498]\u001b[A\n",
            "Training:  62%|██████▏   | 1097/1772 [06:32<03:48,  2.95it/s, running training loss: 0.9581]\u001b[A\n",
            "Training:  62%|██████▏   | 1098/1772 [06:32<03:44,  3.00it/s, running training loss: 0.9581]\u001b[A\n",
            "Training:  62%|██████▏   | 1098/1772 [06:32<03:44,  3.00it/s, running training loss: 1.0104]\u001b[A\n",
            "Training:  62%|██████▏   | 1099/1772 [06:32<03:40,  3.05it/s, running training loss: 1.0104]\u001b[A\n",
            "Training:  62%|██████▏   | 1099/1772 [06:32<03:40,  3.05it/s, running training loss: 1.1641]\u001b[A\n",
            "Training:  62%|██████▏   | 1100/1772 [06:32<03:35,  3.12it/s, running training loss: 1.1641]\u001b[A\n",
            "Training:  62%|██████▏   | 1100/1772 [06:33<03:35,  3.12it/s, running training loss: 1.0314]\u001b[A\n",
            "Training:  62%|██████▏   | 1101/1772 [06:33<03:43,  3.01it/s, running training loss: 1.0314]\u001b[A\n",
            "Training:  62%|██████▏   | 1101/1772 [06:33<03:43,  3.01it/s, running training loss: 1.0747]\u001b[A\n",
            "Training:  62%|██████▏   | 1102/1772 [06:33<03:37,  3.08it/s, running training loss: 1.0747]\u001b[A\n",
            "Training:  62%|██████▏   | 1102/1772 [06:33<03:37,  3.08it/s, running training loss: 1.2468]\u001b[A\n",
            "Training:  62%|██████▏   | 1103/1772 [06:33<03:32,  3.14it/s, running training loss: 1.2468]\u001b[A\n",
            "Training:  62%|██████▏   | 1103/1772 [06:34<03:32,  3.14it/s, running training loss: 1.0141]\u001b[A\n",
            "Training:  62%|██████▏   | 1104/1772 [06:34<03:37,  3.06it/s, running training loss: 1.0141]\u001b[A\n",
            "Training:  62%|██████▏   | 1104/1772 [06:34<03:37,  3.06it/s, running training loss: 0.9698]\u001b[A\n",
            "Training:  62%|██████▏   | 1105/1772 [06:34<03:25,  3.24it/s, running training loss: 0.9698]\u001b[A\n",
            "Training:  62%|██████▏   | 1105/1772 [06:34<03:25,  3.24it/s, running training loss: 1.0676]\u001b[A\n",
            "Training:  62%|██████▏   | 1106/1772 [06:34<04:21,  2.55it/s, running training loss: 1.0676]\u001b[A\n",
            "Training:  62%|██████▏   | 1106/1772 [06:35<04:21,  2.55it/s, running training loss: 1.0080]\u001b[A\n",
            "Training:  62%|██████▏   | 1107/1772 [06:35<04:12,  2.63it/s, running training loss: 1.0080]\u001b[A\n",
            "Training:  62%|██████▏   | 1107/1772 [06:35<04:12,  2.63it/s, running training loss: 1.0715]\u001b[A\n",
            "Training:  63%|██████▎   | 1108/1772 [06:35<04:25,  2.50it/s, running training loss: 1.0715]\u001b[A\n",
            "Training:  63%|██████▎   | 1108/1772 [06:36<04:25,  2.50it/s, running training loss: 1.1382]\u001b[A\n",
            "Training:  63%|██████▎   | 1109/1772 [06:36<04:52,  2.27it/s, running training loss: 1.1382]\u001b[A\n",
            "Training:  63%|██████▎   | 1109/1772 [06:36<04:52,  2.27it/s, running training loss: 0.9376]\u001b[A\n",
            "Training:  63%|██████▎   | 1110/1772 [06:36<04:46,  2.31it/s, running training loss: 0.9376]\u001b[A\n",
            "Training:  63%|██████▎   | 1110/1772 [06:37<04:46,  2.31it/s, running training loss: 0.9391]\u001b[A\n",
            "Training:  63%|██████▎   | 1111/1772 [06:37<04:35,  2.40it/s, running training loss: 0.9391]\u001b[A\n",
            "Training:  63%|██████▎   | 1111/1772 [06:37<04:35,  2.40it/s, running training loss: 0.8661]\u001b[A\n",
            "Training:  63%|██████▎   | 1112/1772 [06:37<04:15,  2.58it/s, running training loss: 0.8661]\u001b[A\n",
            "Training:  63%|██████▎   | 1112/1772 [06:37<04:15,  2.58it/s, running training loss: 0.9853]\u001b[A\n",
            "Training:  63%|██████▎   | 1113/1772 [06:37<04:07,  2.67it/s, running training loss: 0.9853]\u001b[A\n",
            "Training:  63%|██████▎   | 1113/1772 [06:37<04:07,  2.67it/s, running training loss: 0.8799]\u001b[A\n",
            "Training:  63%|██████▎   | 1114/1772 [06:37<03:50,  2.86it/s, running training loss: 0.8799]\u001b[A\n",
            "Training:  63%|██████▎   | 1114/1772 [06:38<03:50,  2.86it/s, running training loss: 0.9829]\u001b[A\n",
            "Training:  63%|██████▎   | 1115/1772 [06:38<03:37,  3.03it/s, running training loss: 0.9829]\u001b[A\n",
            "Training:  63%|██████▎   | 1115/1772 [06:38<03:37,  3.03it/s, running training loss: 1.0174]\u001b[A\n",
            "Training:  63%|██████▎   | 1116/1772 [06:38<03:32,  3.09it/s, running training loss: 1.0174]\u001b[A\n",
            "Training:  63%|██████▎   | 1116/1772 [06:38<03:32,  3.09it/s, running training loss: 1.2329]\u001b[A\n",
            "Training:  63%|██████▎   | 1117/1772 [06:38<03:28,  3.14it/s, running training loss: 1.2329]\u001b[A\n",
            "Training:  63%|██████▎   | 1117/1772 [06:39<03:28,  3.14it/s, running training loss: 1.1082]\u001b[A\n",
            "Training:  63%|██████▎   | 1118/1772 [06:39<03:58,  2.75it/s, running training loss: 1.1082]\u001b[A\n",
            "Training:  63%|██████▎   | 1118/1772 [06:39<03:58,  2.75it/s, running training loss: 1.0811]\u001b[A\n",
            "Training:  63%|██████▎   | 1119/1772 [06:39<03:40,  2.96it/s, running training loss: 1.0811]\u001b[A\n",
            "Training:  63%|██████▎   | 1119/1772 [06:39<03:40,  2.96it/s, running training loss: 1.0169]\u001b[A\n",
            "Training:  63%|██████▎   | 1120/1772 [06:39<03:47,  2.87it/s, running training loss: 1.0169]\u001b[A\n",
            "Training:  63%|██████▎   | 1120/1772 [06:40<03:47,  2.87it/s, running training loss: 1.2169]\u001b[A\n",
            "Training:  63%|██████▎   | 1121/1772 [06:40<03:33,  3.04it/s, running training loss: 1.2169]\u001b[A\n",
            "Training:  63%|██████▎   | 1121/1772 [06:40<03:33,  3.04it/s, running training loss: 1.0268]\u001b[A\n",
            "Training:  63%|██████▎   | 1122/1772 [06:40<03:41,  2.94it/s, running training loss: 1.0268]\u001b[A\n",
            "Training:  63%|██████▎   | 1122/1772 [06:40<03:41,  2.94it/s, running training loss: 0.9987]\u001b[A\n",
            "Training:  63%|██████▎   | 1123/1772 [06:40<03:32,  3.05it/s, running training loss: 0.9987]\u001b[A\n",
            "Training:  63%|██████▎   | 1123/1772 [06:41<03:32,  3.05it/s, running training loss: 0.9374]\u001b[A\n",
            "Training:  63%|██████▎   | 1124/1772 [06:41<03:22,  3.20it/s, running training loss: 0.9374]\u001b[A\n",
            "Training:  63%|██████▎   | 1124/1772 [06:41<03:22,  3.20it/s, running training loss: 0.9230]\u001b[A\n",
            "Training:  63%|██████▎   | 1125/1772 [06:41<04:14,  2.55it/s, running training loss: 0.9230]\u001b[A\n",
            "Training:  63%|██████▎   | 1125/1772 [06:42<04:14,  2.55it/s, running training loss: 1.0192]\u001b[A\n",
            "Training:  64%|██████▎   | 1126/1772 [06:42<04:23,  2.45it/s, running training loss: 1.0192]\u001b[A\n",
            "Training:  64%|██████▎   | 1126/1772 [06:42<04:23,  2.45it/s, running training loss: 0.9902]\u001b[A\n",
            "Training:  64%|██████▎   | 1127/1772 [06:42<04:16,  2.51it/s, running training loss: 0.9902]\u001b[A\n",
            "Training:  64%|██████▎   | 1127/1772 [06:42<04:16,  2.51it/s, running training loss: 0.9601]\u001b[A\n",
            "Training:  64%|██████▎   | 1128/1772 [06:42<04:04,  2.63it/s, running training loss: 0.9601]\u001b[A\n",
            "Training:  64%|██████▎   | 1128/1772 [06:43<04:04,  2.63it/s, running training loss: 1.1139]\u001b[A\n",
            "Training:  64%|██████▎   | 1129/1772 [06:43<04:41,  2.29it/s, running training loss: 1.1139]\u001b[A\n",
            "Training:  64%|██████▎   | 1129/1772 [06:43<04:41,  2.29it/s, running training loss: 0.8195]\u001b[A\n",
            "Training:  64%|██████▍   | 1130/1772 [06:43<04:45,  2.25it/s, running training loss: 0.8195]\u001b[A\n",
            "Training:  64%|██████▍   | 1130/1772 [06:44<04:45,  2.25it/s, running training loss: 1.1005]\u001b[A\n",
            "Training:  64%|██████▍   | 1131/1772 [06:44<04:12,  2.54it/s, running training loss: 1.1005]\u001b[A\n",
            "Training:  64%|██████▍   | 1131/1772 [06:44<04:12,  2.54it/s, running training loss: 0.9980]\u001b[A\n",
            "Training:  64%|██████▍   | 1132/1772 [06:44<03:56,  2.71it/s, running training loss: 0.9980]\u001b[A\n",
            "Training:  64%|██████▍   | 1132/1772 [06:44<03:56,  2.71it/s, running training loss: 0.9922]\u001b[A\n",
            "Training:  64%|██████▍   | 1133/1772 [06:44<03:53,  2.74it/s, running training loss: 0.9922]\u001b[A\n",
            "Training:  64%|██████▍   | 1133/1772 [06:45<03:53,  2.74it/s, running training loss: 0.9354]\u001b[A\n",
            "Training:  64%|██████▍   | 1134/1772 [06:45<03:53,  2.73it/s, running training loss: 0.9354]\u001b[A\n",
            "Training:  64%|██████▍   | 1134/1772 [06:45<03:53,  2.73it/s, running training loss: 0.9653]\u001b[A\n",
            "Training:  64%|██████▍   | 1135/1772 [06:45<03:53,  2.73it/s, running training loss: 0.9653]\u001b[A\n",
            "Training:  64%|██████▍   | 1135/1772 [06:45<03:53,  2.73it/s, running training loss: 0.9381]\u001b[A\n",
            "Training:  64%|██████▍   | 1136/1772 [06:45<03:32,  2.99it/s, running training loss: 0.9381]\u001b[A\n",
            "Training:  64%|██████▍   | 1136/1772 [06:46<03:32,  2.99it/s, running training loss: 0.8657]\u001b[A\n",
            "Training:  64%|██████▍   | 1137/1772 [06:46<03:28,  3.04it/s, running training loss: 0.8657]\u001b[A\n",
            "Training:  64%|██████▍   | 1137/1772 [06:46<03:28,  3.04it/s, running training loss: 0.8588]\u001b[A\n",
            "Training:  64%|██████▍   | 1138/1772 [06:46<03:36,  2.93it/s, running training loss: 0.8588]\u001b[A\n",
            "Training:  64%|██████▍   | 1138/1772 [06:46<03:36,  2.93it/s, running training loss: 1.1094]\u001b[A\n",
            "Training:  64%|██████▍   | 1139/1772 [06:46<03:22,  3.12it/s, running training loss: 1.1094]\u001b[A\n",
            "Training:  64%|██████▍   | 1139/1772 [06:47<03:22,  3.12it/s, running training loss: 0.9880]\u001b[A\n",
            "Training:  64%|██████▍   | 1140/1772 [06:47<03:38,  2.89it/s, running training loss: 0.9880]\u001b[A\n",
            "Training:  64%|██████▍   | 1140/1772 [06:47<03:38,  2.89it/s, running training loss: 1.0261]\u001b[A\n",
            "Training:  64%|██████▍   | 1141/1772 [06:47<03:40,  2.86it/s, running training loss: 1.0261]\u001b[A\n",
            "Training:  64%|██████▍   | 1141/1772 [06:47<03:40,  2.86it/s, running training loss: 1.1307]\u001b[A\n",
            "Training:  64%|██████▍   | 1142/1772 [06:47<03:34,  2.94it/s, running training loss: 1.1307]\u001b[A\n",
            "Training:  64%|██████▍   | 1142/1772 [06:48<03:34,  2.94it/s, running training loss: 1.1268]\u001b[A\n",
            "Training:  65%|██████▍   | 1143/1772 [06:48<03:35,  2.92it/s, running training loss: 1.1268]\u001b[A\n",
            "Training:  65%|██████▍   | 1143/1772 [06:48<03:35,  2.92it/s, running training loss: 1.1122]\u001b[A\n",
            "Training:  65%|██████▍   | 1144/1772 [06:48<03:47,  2.77it/s, running training loss: 1.1122]\u001b[A\n",
            "Training:  65%|██████▍   | 1144/1772 [06:48<03:47,  2.77it/s, running training loss: 1.0464]\u001b[A\n",
            "Training:  65%|██████▍   | 1145/1772 [06:48<03:28,  3.00it/s, running training loss: 1.0464]\u001b[A\n",
            "Training:  65%|██████▍   | 1145/1772 [06:49<03:28,  3.00it/s, running training loss: 1.0128]\u001b[A\n",
            "Training:  65%|██████▍   | 1146/1772 [06:49<03:20,  3.12it/s, running training loss: 1.0128]\u001b[A\n",
            "Training:  65%|██████▍   | 1146/1772 [06:49<03:20,  3.12it/s, running training loss: 0.9129]\u001b[A\n",
            "Training:  65%|██████▍   | 1147/1772 [06:49<03:30,  2.97it/s, running training loss: 0.9129]\u001b[A\n",
            "Training:  65%|██████▍   | 1147/1772 [06:49<03:30,  2.97it/s, running training loss: 1.0187]\u001b[A\n",
            "Training:  65%|██████▍   | 1148/1772 [06:49<03:21,  3.10it/s, running training loss: 1.0187]\u001b[A\n",
            "Training:  65%|██████▍   | 1148/1772 [06:50<03:21,  3.10it/s, running training loss: 0.9871]\u001b[A\n",
            "Training:  65%|██████▍   | 1149/1772 [06:50<03:22,  3.08it/s, running training loss: 0.9871]\u001b[A\n",
            "Training:  65%|██████▍   | 1149/1772 [06:50<03:22,  3.08it/s, running training loss: 0.8581]\u001b[A\n",
            "Training:  65%|██████▍   | 1150/1772 [06:50<03:18,  3.14it/s, running training loss: 0.8581]\u001b[A\n",
            "Training:  65%|██████▍   | 1150/1772 [06:50<03:18,  3.14it/s, running training loss: 0.8407]\u001b[A\n",
            "Training:  65%|██████▍   | 1151/1772 [06:50<03:20,  3.09it/s, running training loss: 0.8407]\u001b[A\n",
            "Training:  65%|██████▍   | 1151/1772 [06:51<03:20,  3.09it/s, running training loss: 0.8968]\u001b[A\n",
            "Training:  65%|██████▌   | 1152/1772 [06:51<03:26,  3.00it/s, running training loss: 0.8968]\u001b[A\n",
            "Training:  65%|██████▌   | 1152/1772 [06:51<03:26,  3.00it/s, running training loss: 0.8942]\u001b[A\n",
            "Training:  65%|██████▌   | 1153/1772 [06:51<03:09,  3.26it/s, running training loss: 0.8942]\u001b[A\n",
            "Training:  65%|██████▌   | 1153/1772 [06:51<03:09,  3.26it/s, running training loss: 0.7816]\u001b[A\n",
            "Training:  65%|██████▌   | 1154/1772 [06:51<03:09,  3.26it/s, running training loss: 0.7816]\u001b[A\n",
            "Training:  65%|██████▌   | 1154/1772 [06:52<03:09,  3.26it/s, running training loss: 0.9452]\u001b[A\n",
            "Training:  65%|██████▌   | 1155/1772 [06:52<03:08,  3.28it/s, running training loss: 0.9452]\u001b[A\n",
            "Training:  65%|██████▌   | 1155/1772 [06:52<03:08,  3.28it/s, running training loss: 1.0043]\u001b[A\n",
            "Training:  65%|██████▌   | 1156/1772 [06:52<03:06,  3.29it/s, running training loss: 1.0043]\u001b[A\n",
            "Training:  65%|██████▌   | 1156/1772 [06:52<03:06,  3.29it/s, running training loss: 0.9239]\u001b[A\n",
            "Training:  65%|██████▌   | 1157/1772 [06:52<03:08,  3.27it/s, running training loss: 0.9239]\u001b[A\n",
            "Training:  65%|██████▌   | 1157/1772 [06:53<03:08,  3.27it/s, running training loss: 1.0799]\u001b[A\n",
            "Training:  65%|██████▌   | 1158/1772 [06:53<03:35,  2.85it/s, running training loss: 1.0799]\u001b[A\n",
            "Training:  65%|██████▌   | 1158/1772 [06:53<03:35,  2.85it/s, running training loss: 1.0014]\u001b[A\n",
            "Training:  65%|██████▌   | 1159/1772 [06:53<03:36,  2.83it/s, running training loss: 1.0014]\u001b[A\n",
            "Training:  65%|██████▌   | 1159/1772 [06:53<03:36,  2.83it/s, running training loss: 1.0632]\u001b[A\n",
            "Training:  65%|██████▌   | 1160/1772 [06:53<03:29,  2.92it/s, running training loss: 1.0632]\u001b[A\n",
            "Training:  65%|██████▌   | 1160/1772 [06:54<03:29,  2.92it/s, running training loss: 1.0499]\u001b[A\n",
            "Training:  66%|██████▌   | 1161/1772 [06:54<03:36,  2.82it/s, running training loss: 1.0499]\u001b[A\n",
            "Training:  66%|██████▌   | 1161/1772 [06:54<03:36,  2.82it/s, running training loss: 0.9873]\u001b[A\n",
            "Training:  66%|██████▌   | 1162/1772 [06:54<03:30,  2.90it/s, running training loss: 0.9873]\u001b[A\n",
            "Training:  66%|██████▌   | 1162/1772 [06:55<03:30,  2.90it/s, running training loss: 0.8048]\u001b[A\n",
            "Training:  66%|██████▌   | 1163/1772 [06:55<03:54,  2.60it/s, running training loss: 0.8048]\u001b[A\n",
            "Training:  66%|██████▌   | 1163/1772 [06:55<03:54,  2.60it/s, running training loss: 0.8550]\u001b[A\n",
            "Training:  66%|██████▌   | 1164/1772 [06:55<03:46,  2.68it/s, running training loss: 0.8550]\u001b[A\n",
            "Training:  66%|██████▌   | 1164/1772 [06:55<03:46,  2.68it/s, running training loss: 0.9442]\u001b[A\n",
            "Training:  66%|██████▌   | 1165/1772 [06:55<03:54,  2.59it/s, running training loss: 0.9442]\u001b[A\n",
            "Training:  66%|██████▌   | 1165/1772 [06:56<03:54,  2.59it/s, running training loss: 0.9387]\u001b[A\n",
            "Training:  66%|██████▌   | 1166/1772 [06:56<03:41,  2.73it/s, running training loss: 0.9387]\u001b[A\n",
            "Training:  66%|██████▌   | 1166/1772 [06:56<03:41,  2.73it/s, running training loss: 0.9735]\u001b[A\n",
            "Training:  66%|██████▌   | 1167/1772 [06:56<03:45,  2.68it/s, running training loss: 0.9735]\u001b[A\n",
            "Training:  66%|██████▌   | 1167/1772 [06:56<03:45,  2.68it/s, running training loss: 0.9661]\u001b[A\n",
            "Training:  66%|██████▌   | 1168/1772 [06:56<03:28,  2.89it/s, running training loss: 0.9661]\u001b[A\n",
            "Training:  66%|██████▌   | 1168/1772 [06:57<03:28,  2.89it/s, running training loss: 1.0332]\u001b[A\n",
            "Training:  66%|██████▌   | 1169/1772 [06:57<03:43,  2.70it/s, running training loss: 1.0332]\u001b[A\n",
            "Training:  66%|██████▌   | 1169/1772 [06:57<03:43,  2.70it/s, running training loss: 0.9822]\u001b[A\n",
            "Training:  66%|██████▌   | 1170/1772 [06:57<04:22,  2.29it/s, running training loss: 0.9822]\u001b[A\n",
            "Training:  66%|██████▌   | 1170/1772 [06:58<04:22,  2.29it/s, running training loss: 1.0246]\u001b[A\n",
            "Training:  66%|██████▌   | 1171/1772 [06:58<03:56,  2.54it/s, running training loss: 1.0246]\u001b[A\n",
            "Training:  66%|██████▌   | 1171/1772 [06:58<03:56,  2.54it/s, running training loss: 0.8857]\u001b[A\n",
            "Training:  66%|██████▌   | 1172/1772 [06:58<03:56,  2.54it/s, running training loss: 0.8857]\u001b[A\n",
            "Training:  66%|██████▌   | 1172/1772 [06:58<03:56,  2.54it/s, running training loss: 1.0140]\u001b[A\n",
            "Training:  66%|██████▌   | 1173/1772 [06:58<03:51,  2.58it/s, running training loss: 1.0140]\u001b[A\n",
            "Training:  66%|██████▌   | 1173/1772 [06:59<03:51,  2.58it/s, running training loss: 1.0679]\u001b[A\n",
            "Training:  66%|██████▋   | 1174/1772 [06:59<03:37,  2.75it/s, running training loss: 1.0679]\u001b[A\n",
            "Training:  66%|██████▋   | 1174/1772 [06:59<03:37,  2.75it/s, running training loss: 0.8111]\u001b[A\n",
            "Training:  66%|██████▋   | 1175/1772 [06:59<03:41,  2.70it/s, running training loss: 0.8111]\u001b[A\n",
            "Training:  66%|██████▋   | 1175/1772 [06:59<03:41,  2.70it/s, running training loss: 1.1645]\u001b[A\n",
            "Training:  66%|██████▋   | 1176/1772 [06:59<03:25,  2.90it/s, running training loss: 1.1645]\u001b[A\n",
            "Training:  66%|██████▋   | 1176/1772 [07:00<03:25,  2.90it/s, running training loss: 0.8759]\u001b[A\n",
            "Training:  66%|██████▋   | 1177/1772 [07:00<03:22,  2.93it/s, running training loss: 0.8759]\u001b[A\n",
            "Training:  66%|██████▋   | 1177/1772 [07:00<03:22,  2.93it/s, running training loss: 0.9890]\u001b[A\n",
            "Training:  66%|██████▋   | 1178/1772 [07:00<03:09,  3.13it/s, running training loss: 0.9890]\u001b[A\n",
            "Training:  66%|██████▋   | 1178/1772 [07:00<03:09,  3.13it/s, running training loss: 1.1195]\u001b[A\n",
            "Training:  67%|██████▋   | 1179/1772 [07:00<03:03,  3.23it/s, running training loss: 1.1195]\u001b[A\n",
            "Training:  67%|██████▋   | 1179/1772 [07:01<03:03,  3.23it/s, running training loss: 0.9673]\u001b[A\n",
            "Training:  67%|██████▋   | 1180/1772 [07:01<03:01,  3.27it/s, running training loss: 0.9673]\u001b[A\n",
            "Training:  67%|██████▋   | 1180/1772 [07:01<03:01,  3.27it/s, running training loss: 1.0975]\u001b[A\n",
            "Training:  67%|██████▋   | 1181/1772 [07:01<03:02,  3.23it/s, running training loss: 1.0975]\u001b[A\n",
            "Training:  67%|██████▋   | 1181/1772 [07:01<03:02,  3.23it/s, running training loss: 0.9824]\u001b[A\n",
            "Training:  67%|██████▋   | 1182/1772 [07:01<03:02,  3.23it/s, running training loss: 0.9824]\u001b[A\n",
            "Training:  67%|██████▋   | 1182/1772 [07:02<03:02,  3.23it/s, running training loss: 0.9368]\u001b[A\n",
            "Training:  67%|██████▋   | 1183/1772 [07:02<03:09,  3.10it/s, running training loss: 0.9368]\u001b[A\n",
            "Training:  67%|██████▋   | 1183/1772 [07:02<03:09,  3.10it/s, running training loss: 0.9430]\u001b[A\n",
            "Training:  67%|██████▋   | 1184/1772 [07:02<03:11,  3.07it/s, running training loss: 0.9430]\u001b[A\n",
            "Training:  67%|██████▋   | 1184/1772 [07:02<03:11,  3.07it/s, running training loss: 0.8820]\u001b[A\n",
            "Training:  67%|██████▋   | 1185/1772 [07:02<03:26,  2.85it/s, running training loss: 0.8820]\u001b[A\n",
            "Training:  67%|██████▋   | 1185/1772 [07:03<03:26,  2.85it/s, running training loss: 1.3001]\u001b[A\n",
            "Training:  67%|██████▋   | 1186/1772 [07:03<03:18,  2.95it/s, running training loss: 1.3001]\u001b[A\n",
            "Training:  67%|██████▋   | 1186/1772 [07:03<03:18,  2.95it/s, running training loss: 1.0516]\u001b[A\n",
            "Training:  67%|██████▋   | 1187/1772 [07:03<03:05,  3.15it/s, running training loss: 1.0516]\u001b[A\n",
            "Training:  67%|██████▋   | 1187/1772 [07:03<03:05,  3.15it/s, running training loss: 1.0897]\u001b[A\n",
            "Training:  67%|██████▋   | 1188/1772 [07:03<03:02,  3.20it/s, running training loss: 1.0897]\u001b[A\n",
            "Training:  67%|██████▋   | 1188/1772 [07:03<03:02,  3.20it/s, running training loss: 1.0434]\u001b[A\n",
            "Training:  67%|██████▋   | 1189/1772 [07:03<03:03,  3.18it/s, running training loss: 1.0434]\u001b[A\n",
            "Training:  67%|██████▋   | 1189/1772 [07:04<03:03,  3.18it/s, running training loss: 0.9986]\u001b[A\n",
            "Training:  67%|██████▋   | 1190/1772 [07:04<03:04,  3.16it/s, running training loss: 0.9986]\u001b[A\n",
            "Training:  67%|██████▋   | 1190/1772 [07:04<03:04,  3.16it/s, running training loss: 1.0638]\u001b[A\n",
            "Training:  67%|██████▋   | 1191/1772 [07:04<03:20,  2.90it/s, running training loss: 1.0638]\u001b[A\n",
            "Training:  67%|██████▋   | 1191/1772 [07:05<03:20,  2.90it/s, running training loss: 0.8824]\u001b[A\n",
            "Training:  67%|██████▋   | 1192/1772 [07:05<03:42,  2.60it/s, running training loss: 0.8824]\u001b[A\n",
            "Training:  67%|██████▋   | 1192/1772 [07:05<03:42,  2.60it/s, running training loss: 0.8658]\u001b[A\n",
            "Training:  67%|██████▋   | 1193/1772 [07:05<03:23,  2.84it/s, running training loss: 0.8658]\u001b[A\n",
            "Training:  67%|██████▋   | 1193/1772 [07:05<03:23,  2.84it/s, running training loss: 0.8981]\u001b[A\n",
            "Training:  67%|██████▋   | 1194/1772 [07:05<03:54,  2.46it/s, running training loss: 0.8981]\u001b[A\n",
            "Training:  67%|██████▋   | 1194/1772 [07:06<03:54,  2.46it/s, running training loss: 0.7983]\u001b[A\n",
            "Training:  67%|██████▋   | 1195/1772 [07:06<03:36,  2.66it/s, running training loss: 0.7983]\u001b[A\n",
            "Training:  67%|██████▋   | 1195/1772 [07:06<03:36,  2.66it/s, running training loss: 0.8216]\u001b[A\n",
            "Training:  67%|██████▋   | 1196/1772 [07:06<03:27,  2.78it/s, running training loss: 0.8216]\u001b[A\n",
            "Training:  67%|██████▋   | 1196/1772 [07:06<03:27,  2.78it/s, running training loss: 0.9765]\u001b[A\n",
            "Training:  68%|██████▊   | 1197/1772 [07:06<03:17,  2.91it/s, running training loss: 0.9765]\u001b[A\n",
            "Training:  68%|██████▊   | 1197/1772 [07:07<03:17,  2.91it/s, running training loss: 0.9539]\u001b[A\n",
            "Training:  68%|██████▊   | 1198/1772 [07:07<03:02,  3.15it/s, running training loss: 0.9539]\u001b[A\n",
            "Training:  68%|██████▊   | 1198/1772 [07:07<03:02,  3.15it/s, running training loss: 0.9354]\u001b[A\n",
            "Training:  68%|██████▊   | 1199/1772 [07:07<02:53,  3.30it/s, running training loss: 0.9354]\u001b[A\n",
            "Training:  68%|██████▊   | 1199/1772 [07:07<02:53,  3.30it/s, running training loss: 0.9620]\u001b[A\n",
            "\n",
            "Evaluation:   0%|          | 0/270 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   0%|          | 1/270 [00:00<01:18,  3.45it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   1%|          | 3/270 [00:00<00:31,  8.37it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   2%|▏         | 5/270 [00:00<00:22, 11.72it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   3%|▎         | 7/270 [00:00<00:18, 14.05it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   3%|▎         | 9/270 [00:00<00:17, 15.28it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   4%|▍         | 12/270 [00:00<00:14, 18.15it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   5%|▌         | 14/270 [00:00<00:14, 18.26it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   6%|▌         | 16/270 [00:01<00:14, 17.96it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   7%|▋         | 18/270 [00:01<00:14, 17.79it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   7%|▋         | 20/270 [00:01<00:14, 17.33it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   9%|▊         | 23/270 [00:01<00:12, 19.47it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   9%|▉         | 25/270 [00:01<00:12, 19.56it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  10%|█         | 28/270 [00:01<00:12, 19.71it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  11%|█         | 30/270 [00:01<00:12, 18.86it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  12%|█▏        | 32/270 [00:01<00:12, 18.87it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  13%|█▎        | 35/270 [00:02<00:12, 18.95it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  14%|█▍        | 38/270 [00:02<00:11, 20.44it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  15%|█▌        | 41/270 [00:02<00:11, 19.67it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  16%|█▌        | 43/270 [00:02<00:12, 18.43it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  17%|█▋        | 46/270 [00:02<00:11, 18.79it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  18%|█▊        | 49/270 [00:02<00:11, 19.39it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  19%|█▉        | 51/270 [00:02<00:11, 18.88it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  20%|█▉        | 53/270 [00:03<00:11, 18.96it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  21%|██        | 56/270 [00:03<00:11, 19.10it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  21%|██▏       | 58/270 [00:03<00:11, 18.90it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  22%|██▏       | 60/270 [00:03<00:11, 18.41it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  23%|██▎       | 62/270 [00:03<00:11, 18.17it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  24%|██▎       | 64/270 [00:03<00:11, 17.99it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  25%|██▍       | 67/270 [00:03<00:10, 19.49it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  26%|██▌       | 70/270 [00:03<00:09, 20.76it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  27%|██▋       | 73/270 [00:04<00:09, 20.05it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  28%|██▊       | 76/270 [00:04<00:09, 20.78it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  29%|██▉       | 79/270 [00:04<00:09, 20.58it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  30%|███       | 82/270 [00:04<00:09, 19.03it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  31%|███       | 84/270 [00:04<00:09, 18.92it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  32%|███▏      | 87/270 [00:04<00:09, 19.05it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  33%|███▎      | 89/270 [00:04<00:09, 18.48it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  34%|███▎      | 91/270 [00:04<00:09, 18.42it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  35%|███▍      | 94/270 [00:05<00:09, 19.31it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  36%|███▌      | 97/270 [00:05<00:08, 19.80it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  37%|███▋      | 100/270 [00:05<00:08, 19.94it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  38%|███▊      | 103/270 [00:05<00:08, 20.74it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  39%|███▉      | 106/270 [00:05<00:08, 20.06it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  40%|████      | 109/270 [00:05<00:08, 19.99it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  41%|████▏     | 112/270 [00:06<00:07, 20.26it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  43%|████▎     | 115/270 [00:06<00:07, 20.55it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  44%|████▎     | 118/270 [00:06<00:07, 20.58it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  45%|████▍     | 121/270 [00:06<00:07, 20.12it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  46%|████▌     | 124/270 [00:06<00:07, 20.66it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  47%|████▋     | 127/270 [00:06<00:07, 19.16it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  48%|████▊     | 129/270 [00:06<00:07, 18.41it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  49%|████▉     | 132/270 [00:07<00:07, 18.94it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  50%|████▉     | 134/270 [00:07<00:07, 18.89it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  51%|█████     | 137/270 [00:07<00:06, 19.84it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  52%|█████▏    | 140/270 [00:07<00:06, 19.74it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  53%|█████▎    | 142/270 [00:07<00:06, 18.53it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  54%|█████▎    | 145/270 [00:07<00:06, 19.25it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  54%|█████▍    | 147/270 [00:07<00:06, 19.01it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  55%|█████▌    | 149/270 [00:07<00:06, 19.17it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  56%|█████▌    | 151/270 [00:08<00:06, 19.36it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  57%|█████▋    | 153/270 [00:08<00:06, 18.39it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  57%|█████▋    | 155/270 [00:08<00:06, 18.38it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  58%|█████▊    | 157/270 [00:08<00:06, 18.76it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  59%|█████▉    | 159/270 [00:08<00:05, 19.06it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  60%|█████▉    | 161/270 [00:08<00:05, 18.84it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  60%|██████    | 163/270 [00:08<00:05, 18.61it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  61%|██████    | 165/270 [00:08<00:05, 18.21it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  62%|██████▏   | 168/270 [00:08<00:05, 19.27it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  63%|██████▎   | 170/270 [00:09<00:05, 18.81it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  64%|██████▎   | 172/270 [00:09<00:05, 18.65it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  64%|██████▍   | 174/270 [00:09<00:05, 17.80it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  65%|██████▌   | 176/270 [00:09<00:05, 17.21it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  66%|██████▌   | 178/270 [00:09<00:05, 17.57it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  67%|██████▋   | 180/270 [00:09<00:05, 16.88it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  67%|██████▋   | 182/270 [00:09<00:05, 17.17it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  68%|██████▊   | 184/270 [00:09<00:04, 17.53it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  69%|██████▉   | 186/270 [00:09<00:04, 18.12it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  70%|██████▉   | 188/270 [00:10<00:04, 17.80it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  71%|███████   | 191/270 [00:10<00:03, 19.87it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  71%|███████▏  | 193/270 [00:10<00:03, 19.35it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  72%|███████▏  | 195/270 [00:10<00:04, 18.41it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  73%|███████▎  | 197/270 [00:10<00:03, 18.72it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  74%|███████▎  | 199/270 [00:10<00:04, 17.48it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  74%|███████▍  | 201/270 [00:10<00:03, 17.46it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  75%|███████▌  | 203/270 [00:10<00:03, 17.89it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  76%|███████▋  | 206/270 [00:11<00:03, 19.74it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  77%|███████▋  | 208/270 [00:11<00:03, 18.75it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  78%|███████▊  | 210/270 [00:11<00:03, 18.08it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  79%|███████▊  | 212/270 [00:11<00:03, 17.96it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  80%|███████▉  | 215/270 [00:11<00:02, 19.86it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  80%|████████  | 217/270 [00:11<00:02, 19.47it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  81%|████████▏ | 220/270 [00:11<00:02, 20.07it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  83%|████████▎ | 223/270 [00:11<00:02, 21.16it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  84%|████████▎ | 226/270 [00:12<00:02, 21.87it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  85%|████████▍ | 229/270 [00:12<00:02, 19.40it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  86%|████████▌ | 231/270 [00:12<00:02, 18.89it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  87%|████████▋ | 234/270 [00:12<00:01, 20.21it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  88%|████████▊ | 237/270 [00:12<00:01, 21.14it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  89%|████████▉ | 240/270 [00:12<00:01, 19.85it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  90%|█████████ | 243/270 [00:12<00:01, 20.39it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  91%|█████████ | 246/270 [00:13<00:01, 18.86it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  92%|█████████▏| 248/270 [00:13<00:01, 17.91it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  93%|█████████▎| 250/270 [00:13<00:01, 17.44it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  93%|█████████▎| 252/270 [00:13<00:01, 17.32it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  94%|█████████▍| 254/270 [00:13<00:00, 17.12it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  95%|█████████▍| 256/270 [00:13<00:00, 16.80it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  96%|█████████▌| 259/270 [00:13<00:00, 18.44it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  97%|█████████▋| 262/270 [00:13<00:00, 18.66it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  98%|█████████▊| 264/270 [00:14<00:00, 18.14it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  99%|█████████▊| 266/270 [00:14<00:00, 18.05it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  99%|█████████▉| 268/270 [00:14<00:00, 18.08it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation: 100%|██████████| 270/270 [00:14<00:00, 18.45it/s]\n",
            "\n",
            "Training:  68%|██████▊   | 1200/1772 [07:22<44:47,  4.70s/it, running training loss: 0.9620]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            ">>> training loss: 1.001852, valid loss: 0.651615, valid f1: 0.000000, valid acc: 0.689991\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  68%|██████▊   | 1200/1772 [07:22<44:47,  4.70s/it, running training loss: 0.9646]\u001b[A\n",
            "Training:  68%|██████▊   | 1201/1772 [07:22<32:20,  3.40s/it, running training loss: 0.9646]\u001b[A\n",
            "Training:  68%|██████▊   | 1201/1772 [07:23<32:20,  3.40s/it, running training loss: 0.8700]\u001b[A\n",
            "Training:  68%|██████▊   | 1202/1772 [07:23<23:46,  2.50s/it, running training loss: 0.8700]\u001b[A\n",
            "Training:  68%|██████▊   | 1202/1772 [07:23<23:46,  2.50s/it, running training loss: 0.9078]\u001b[A\n",
            "Training:  68%|██████▊   | 1203/1772 [07:23<17:32,  1.85s/it, running training loss: 0.9078]\u001b[A\n",
            "Training:  68%|██████▊   | 1203/1772 [07:23<17:32,  1.85s/it, running training loss: 0.9279]\u001b[A\n",
            "Training:  68%|██████▊   | 1204/1772 [07:24<13:40,  1.45s/it, running training loss: 0.9279]\u001b[A\n",
            "Training:  68%|██████▊   | 1204/1772 [07:24<13:40,  1.45s/it, running training loss: 0.7562]\u001b[A\n",
            "Training:  68%|██████▊   | 1205/1772 [07:24<10:44,  1.14s/it, running training loss: 0.7562]\u001b[A\n",
            "Training:  68%|██████▊   | 1205/1772 [07:24<10:44,  1.14s/it, running training loss: 0.9210]\u001b[A\n",
            "Training:  68%|██████▊   | 1206/1772 [07:24<08:20,  1.13it/s, running training loss: 0.9210]\u001b[A\n",
            "Training:  68%|██████▊   | 1206/1772 [07:25<08:20,  1.13it/s, running training loss: 1.0724]\u001b[A\n",
            "Training:  68%|██████▊   | 1207/1772 [07:25<07:04,  1.33it/s, running training loss: 1.0724]\u001b[A\n",
            "Training:  68%|██████▊   | 1207/1772 [07:25<07:04,  1.33it/s, running training loss: 0.8291]\u001b[A\n",
            "Training:  68%|██████▊   | 1208/1772 [07:25<05:44,  1.64it/s, running training loss: 0.8291]\u001b[A\n",
            "Training:  68%|██████▊   | 1208/1772 [07:25<05:44,  1.64it/s, running training loss: 1.0719]\u001b[A\n",
            "Training:  68%|██████▊   | 1209/1772 [07:25<04:56,  1.90it/s, running training loss: 1.0719]\u001b[A\n",
            "Training:  68%|██████▊   | 1209/1772 [07:26<04:56,  1.90it/s, running training loss: 1.0551]\u001b[A\n",
            "Training:  68%|██████▊   | 1210/1772 [07:26<04:24,  2.12it/s, running training loss: 1.0551]\u001b[A\n",
            "Training:  68%|██████▊   | 1210/1772 [07:26<04:24,  2.12it/s, running training loss: 1.1032]\u001b[A\n",
            "Training:  68%|██████▊   | 1211/1772 [07:26<04:12,  2.22it/s, running training loss: 1.1032]\u001b[A\n",
            "Training:  68%|██████▊   | 1211/1772 [07:26<04:12,  2.22it/s, running training loss: 1.0936]\u001b[A\n",
            "Training:  68%|██████▊   | 1212/1772 [07:26<03:41,  2.52it/s, running training loss: 1.0936]\u001b[A\n",
            "Training:  68%|██████▊   | 1212/1772 [07:27<03:41,  2.52it/s, running training loss: 1.0759]\u001b[A\n",
            "Training:  68%|██████▊   | 1213/1772 [07:27<03:25,  2.73it/s, running training loss: 1.0759]\u001b[A\n",
            "Training:  68%|██████▊   | 1213/1772 [07:27<03:25,  2.73it/s, running training loss: 1.0857]\u001b[A\n",
            "Training:  69%|██████▊   | 1214/1772 [07:27<03:25,  2.72it/s, running training loss: 1.0857]\u001b[A\n",
            "Training:  69%|██████▊   | 1214/1772 [07:27<03:25,  2.72it/s, running training loss: 1.0610]\u001b[A\n",
            "Training:  69%|██████▊   | 1215/1772 [07:27<03:13,  2.88it/s, running training loss: 1.0610]\u001b[A\n",
            "Training:  69%|██████▊   | 1215/1772 [07:28<03:13,  2.88it/s, running training loss: 0.9107]\u001b[A\n",
            "Training:  69%|██████▊   | 1216/1772 [07:28<03:09,  2.93it/s, running training loss: 0.9107]\u001b[A\n",
            "Training:  69%|██████▊   | 1216/1772 [07:28<03:09,  2.93it/s, running training loss: 1.0291]\u001b[A\n",
            "Training:  69%|██████▊   | 1217/1772 [07:28<03:23,  2.73it/s, running training loss: 1.0291]\u001b[A\n",
            "Training:  69%|██████▊   | 1217/1772 [07:28<03:23,  2.73it/s, running training loss: 0.8842]\u001b[A\n",
            "Training:  69%|██████▊   | 1218/1772 [07:28<03:16,  2.82it/s, running training loss: 0.8842]\u001b[A\n",
            "Training:  69%|██████▊   | 1218/1772 [07:29<03:16,  2.82it/s, running training loss: 0.8020]\u001b[A\n",
            "Training:  69%|██████▉   | 1219/1772 [07:29<03:09,  2.92it/s, running training loss: 0.8020]\u001b[A\n",
            "Training:  69%|██████▉   | 1219/1772 [07:29<03:09,  2.92it/s, running training loss: 0.9360]\u001b[A\n",
            "Training:  69%|██████▉   | 1220/1772 [07:29<03:04,  2.99it/s, running training loss: 0.9360]\u001b[A\n",
            "Training:  69%|██████▉   | 1220/1772 [07:29<03:04,  2.99it/s, running training loss: 0.8882]\u001b[A\n",
            "Training:  69%|██████▉   | 1221/1772 [07:29<03:35,  2.56it/s, running training loss: 0.8882]\u001b[A\n",
            "Training:  69%|██████▉   | 1221/1772 [07:30<03:35,  2.56it/s, running training loss: 0.8691]\u001b[A\n",
            "Training:  69%|██████▉   | 1222/1772 [07:30<03:23,  2.70it/s, running training loss: 0.8691]\u001b[A\n",
            "Training:  69%|██████▉   | 1222/1772 [07:30<03:23,  2.70it/s, running training loss: 0.9437]\u001b[A\n",
            "Training:  69%|██████▉   | 1223/1772 [07:30<03:07,  2.93it/s, running training loss: 0.9437]\u001b[A\n",
            "Training:  69%|██████▉   | 1223/1772 [07:30<03:07,  2.93it/s, running training loss: 0.8600]\u001b[A\n",
            "Training:  69%|██████▉   | 1224/1772 [07:30<02:59,  3.05it/s, running training loss: 0.8600]\u001b[A\n",
            "Training:  69%|██████▉   | 1224/1772 [07:31<02:59,  3.05it/s, running training loss: 0.9223]\u001b[A\n",
            "Training:  69%|██████▉   | 1225/1772 [07:31<03:02,  2.99it/s, running training loss: 0.9223]\u001b[A\n",
            "Training:  69%|██████▉   | 1225/1772 [07:31<03:02,  2.99it/s, running training loss: 1.0348]\u001b[A\n",
            "Training:  69%|██████▉   | 1226/1772 [07:31<03:12,  2.84it/s, running training loss: 1.0348]\u001b[A\n",
            "Training:  69%|██████▉   | 1226/1772 [07:31<03:12,  2.84it/s, running training loss: 1.1580]\u001b[A\n",
            "Training:  69%|██████▉   | 1227/1772 [07:31<03:14,  2.79it/s, running training loss: 1.1580]\u001b[A\n",
            "Training:  69%|██████▉   | 1227/1772 [07:32<03:14,  2.79it/s, running training loss: 1.1684]\u001b[A\n",
            "Training:  69%|██████▉   | 1228/1772 [07:32<02:54,  3.11it/s, running training loss: 1.1684]\u001b[A\n",
            "Training:  69%|██████▉   | 1228/1772 [07:32<02:54,  3.11it/s, running training loss: 0.9434]\u001b[A\n",
            "Training:  69%|██████▉   | 1229/1772 [07:32<02:51,  3.17it/s, running training loss: 0.9434]\u001b[A\n",
            "Training:  69%|██████▉   | 1229/1772 [07:32<02:51,  3.17it/s, running training loss: 1.1748]\u001b[A\n",
            "Training:  69%|██████▉   | 1230/1772 [07:32<03:00,  3.01it/s, running training loss: 1.1748]\u001b[A\n",
            "Training:  69%|██████▉   | 1230/1772 [07:33<03:00,  3.01it/s, running training loss: 0.8371]\u001b[A\n",
            "Training:  69%|██████▉   | 1231/1772 [07:33<03:20,  2.70it/s, running training loss: 0.8371]\u001b[A\n",
            "Training:  69%|██████▉   | 1231/1772 [07:33<03:20,  2.70it/s, running training loss: 0.7446]\u001b[A\n",
            "Training:  70%|██████▉   | 1232/1772 [07:33<03:13,  2.79it/s, running training loss: 0.7446]\u001b[A\n",
            "Training:  70%|██████▉   | 1232/1772 [07:33<03:13,  2.79it/s, running training loss: 1.0509]\u001b[A\n",
            "Training:  70%|██████▉   | 1233/1772 [07:33<02:54,  3.09it/s, running training loss: 1.0509]\u001b[A\n",
            "Training:  70%|██████▉   | 1233/1772 [07:34<02:54,  3.09it/s, running training loss: 1.0582]\u001b[A\n",
            "Training:  70%|██████▉   | 1234/1772 [07:34<02:53,  3.10it/s, running training loss: 1.0582]\u001b[A\n",
            "Training:  70%|██████▉   | 1234/1772 [07:34<02:53,  3.10it/s, running training loss: 1.2684]\u001b[A\n",
            "Training:  70%|██████▉   | 1235/1772 [07:34<02:47,  3.20it/s, running training loss: 1.2684]\u001b[A\n",
            "Training:  70%|██████▉   | 1235/1772 [07:34<02:47,  3.20it/s, running training loss: 1.1549]\u001b[A\n",
            "Training:  70%|██████▉   | 1236/1772 [07:34<02:59,  2.99it/s, running training loss: 1.1549]\u001b[A\n",
            "Training:  70%|██████▉   | 1236/1772 [07:35<02:59,  2.99it/s, running training loss: 1.0358]\u001b[A\n",
            "Training:  70%|██████▉   | 1237/1772 [07:35<02:57,  3.01it/s, running training loss: 1.0358]\u001b[A\n",
            "Training:  70%|██████▉   | 1237/1772 [07:35<02:57,  3.01it/s, running training loss: 0.9524]\u001b[A\n",
            "Training:  70%|██████▉   | 1238/1772 [07:35<03:03,  2.92it/s, running training loss: 0.9524]\u001b[A\n",
            "Training:  70%|██████▉   | 1238/1772 [07:35<03:03,  2.92it/s, running training loss: 0.9823]\u001b[A\n",
            "Training:  70%|██████▉   | 1239/1772 [07:35<02:50,  3.12it/s, running training loss: 0.9823]\u001b[A\n",
            "Training:  70%|██████▉   | 1239/1772 [07:36<02:50,  3.12it/s, running training loss: 0.8323]\u001b[A\n",
            "Training:  70%|██████▉   | 1240/1772 [07:36<03:23,  2.61it/s, running training loss: 0.8323]\u001b[A\n",
            "Training:  70%|██████▉   | 1240/1772 [07:36<03:23,  2.61it/s, running training loss: 0.8065]\u001b[A\n",
            "Training:  70%|███████   | 1241/1772 [07:36<03:49,  2.31it/s, running training loss: 0.8065]\u001b[A\n",
            "Training:  70%|███████   | 1241/1772 [07:37<03:49,  2.31it/s, running training loss: 0.8264]\u001b[A\n",
            "Training:  70%|███████   | 1242/1772 [07:37<03:39,  2.42it/s, running training loss: 0.8264]\u001b[A\n",
            "Training:  70%|███████   | 1242/1772 [07:37<03:39,  2.42it/s, running training loss: 0.7941]\u001b[A\n",
            "Training:  70%|███████   | 1243/1772 [07:37<03:43,  2.36it/s, running training loss: 0.7941]\u001b[A\n",
            "Training:  70%|███████   | 1243/1772 [07:38<03:43,  2.36it/s, running training loss: 1.0478]\u001b[A\n",
            "Training:  70%|███████   | 1244/1772 [07:38<03:49,  2.30it/s, running training loss: 1.0478]\u001b[A\n",
            "Training:  70%|███████   | 1244/1772 [07:38<03:49,  2.30it/s, running training loss: 0.9427]\u001b[A\n",
            "Training:  70%|███████   | 1245/1772 [07:38<03:36,  2.43it/s, running training loss: 0.9427]\u001b[A\n",
            "Training:  70%|███████   | 1245/1772 [07:39<03:36,  2.43it/s, running training loss: 0.8491]\u001b[A\n",
            "Training:  70%|███████   | 1246/1772 [07:39<03:45,  2.33it/s, running training loss: 0.8491]\u001b[A\n",
            "Training:  70%|███████   | 1246/1772 [07:39<03:45,  2.33it/s, running training loss: 0.9495]\u001b[A\n",
            "Training:  70%|███████   | 1247/1772 [07:39<03:31,  2.48it/s, running training loss: 0.9495]\u001b[A\n",
            "Training:  70%|███████   | 1247/1772 [07:39<03:31,  2.48it/s, running training loss: 0.9626]\u001b[A\n",
            "Training:  70%|███████   | 1248/1772 [07:39<03:16,  2.66it/s, running training loss: 0.9626]\u001b[A\n",
            "Training:  70%|███████   | 1248/1772 [07:40<03:16,  2.66it/s, running training loss: 0.8617]\u001b[A\n",
            "Training:  70%|███████   | 1249/1772 [07:40<03:08,  2.78it/s, running training loss: 0.8617]\u001b[A\n",
            "Training:  70%|███████   | 1249/1772 [07:40<03:08,  2.78it/s, running training loss: 0.9893]\u001b[A\n",
            "Training:  71%|███████   | 1250/1772 [07:40<03:14,  2.69it/s, running training loss: 0.9893]\u001b[A\n",
            "Training:  71%|███████   | 1250/1772 [07:40<03:14,  2.69it/s, running training loss: 0.9306]\u001b[A\n",
            "Training:  71%|███████   | 1251/1772 [07:40<03:04,  2.82it/s, running training loss: 0.9306]\u001b[A\n",
            "Training:  71%|███████   | 1251/1772 [07:41<03:04,  2.82it/s, running training loss: 0.9091]\u001b[A\n",
            "Training:  71%|███████   | 1252/1772 [07:41<03:03,  2.83it/s, running training loss: 0.9091]\u001b[A\n",
            "Training:  71%|███████   | 1252/1772 [07:41<03:03,  2.83it/s, running training loss: 0.8924]\u001b[A\n",
            "Training:  71%|███████   | 1253/1772 [07:41<02:52,  3.00it/s, running training loss: 0.8924]\u001b[A\n",
            "Training:  71%|███████   | 1253/1772 [07:41<02:52,  3.00it/s, running training loss: 0.9576]\u001b[A\n",
            "Training:  71%|███████   | 1254/1772 [07:41<03:24,  2.53it/s, running training loss: 0.9576]\u001b[A\n",
            "Training:  71%|███████   | 1254/1772 [07:42<03:24,  2.53it/s, running training loss: 1.1154]\u001b[A\n",
            "Training:  71%|███████   | 1255/1772 [07:42<03:08,  2.75it/s, running training loss: 1.1154]\u001b[A\n",
            "Training:  71%|███████   | 1255/1772 [07:42<03:08,  2.75it/s, running training loss: 1.0359]\u001b[A\n",
            "Training:  71%|███████   | 1256/1772 [07:42<03:18,  2.60it/s, running training loss: 1.0359]\u001b[A\n",
            "Training:  71%|███████   | 1256/1772 [07:43<03:18,  2.60it/s, running training loss: 1.1201]\u001b[A\n",
            "Training:  71%|███████   | 1257/1772 [07:43<03:34,  2.41it/s, running training loss: 1.1201]\u001b[A\n",
            "Training:  71%|███████   | 1257/1772 [07:43<03:34,  2.41it/s, running training loss: 1.0243]\u001b[A\n",
            "Training:  71%|███████   | 1258/1772 [07:43<03:29,  2.46it/s, running training loss: 1.0243]\u001b[A\n",
            "Training:  71%|███████   | 1258/1772 [07:44<03:29,  2.46it/s, running training loss: 1.0092]\u001b[A\n",
            "Training:  71%|███████   | 1259/1772 [07:44<03:40,  2.32it/s, running training loss: 1.0092]\u001b[A\n",
            "Training:  71%|███████   | 1259/1772 [07:44<03:40,  2.32it/s, running training loss: 1.2050]\u001b[A\n",
            "Training:  71%|███████   | 1260/1772 [07:44<03:17,  2.59it/s, running training loss: 1.2050]\u001b[A\n",
            "Training:  71%|███████   | 1260/1772 [07:44<03:17,  2.59it/s, running training loss: 0.9836]\u001b[A\n",
            "Training:  71%|███████   | 1261/1772 [07:44<03:03,  2.78it/s, running training loss: 0.9836]\u001b[A\n",
            "Training:  71%|███████   | 1261/1772 [07:44<03:03,  2.78it/s, running training loss: 1.1869]\u001b[A\n",
            "Training:  71%|███████   | 1262/1772 [07:44<02:58,  2.86it/s, running training loss: 1.1869]\u001b[A\n",
            "Training:  71%|███████   | 1262/1772 [07:45<02:58,  2.86it/s, running training loss: 1.0700]\u001b[A\n",
            "Training:  71%|███████▏  | 1263/1772 [07:45<03:01,  2.80it/s, running training loss: 1.0700]\u001b[A\n",
            "Training:  71%|███████▏  | 1263/1772 [07:45<03:01,  2.80it/s, running training loss: 0.9751]\u001b[A\n",
            "Training:  71%|███████▏  | 1264/1772 [07:45<02:56,  2.87it/s, running training loss: 0.9751]\u001b[A\n",
            "Training:  71%|███████▏  | 1264/1772 [07:46<02:56,  2.87it/s, running training loss: 0.9083]\u001b[A\n",
            "Training:  71%|███████▏  | 1265/1772 [07:46<03:22,  2.51it/s, running training loss: 0.9083]\u001b[A\n",
            "Training:  71%|███████▏  | 1265/1772 [07:46<03:22,  2.51it/s, running training loss: 0.8544]\u001b[A\n",
            "Training:  71%|███████▏  | 1266/1772 [07:46<03:07,  2.70it/s, running training loss: 0.8544]\u001b[A\n",
            "Training:  71%|███████▏  | 1266/1772 [07:46<03:07,  2.70it/s, running training loss: 0.8644]\u001b[A\n",
            "Training:  72%|███████▏  | 1267/1772 [07:46<02:58,  2.83it/s, running training loss: 0.8644]\u001b[A\n",
            "Training:  72%|███████▏  | 1267/1772 [07:47<02:58,  2.83it/s, running training loss: 1.1578]\u001b[A\n",
            "Training:  72%|███████▏  | 1268/1772 [07:47<02:56,  2.86it/s, running training loss: 1.1578]\u001b[A\n",
            "Training:  72%|███████▏  | 1268/1772 [07:47<02:56,  2.86it/s, running training loss: 0.9786]\u001b[A\n",
            "Training:  72%|███████▏  | 1269/1772 [07:47<02:43,  3.07it/s, running training loss: 0.9786]\u001b[A\n",
            "Training:  72%|███████▏  | 1269/1772 [07:47<02:43,  3.07it/s, running training loss: 0.9152]\u001b[A\n",
            "Training:  72%|███████▏  | 1270/1772 [07:47<02:40,  3.12it/s, running training loss: 0.9152]\u001b[A\n",
            "Training:  72%|███████▏  | 1270/1772 [07:47<02:40,  3.12it/s, running training loss: 0.9928]\u001b[A\n",
            "Training:  72%|███████▏  | 1271/1772 [07:47<02:36,  3.20it/s, running training loss: 0.9928]\u001b[A\n",
            "Training:  72%|███████▏  | 1271/1772 [07:48<02:36,  3.20it/s, running training loss: 0.8385]\u001b[A\n",
            "Training:  72%|███████▏  | 1272/1772 [07:48<02:40,  3.11it/s, running training loss: 0.8385]\u001b[A\n",
            "Training:  72%|███████▏  | 1272/1772 [07:48<02:40,  3.11it/s, running training loss: 1.1373]\u001b[A\n",
            "Training:  72%|███████▏  | 1273/1772 [07:48<02:45,  3.02it/s, running training loss: 1.1373]\u001b[A\n",
            "Training:  72%|███████▏  | 1273/1772 [07:48<02:45,  3.02it/s, running training loss: 1.2058]\u001b[A\n",
            "Training:  72%|███████▏  | 1274/1772 [07:48<02:43,  3.04it/s, running training loss: 1.2058]\u001b[A\n",
            "Training:  72%|███████▏  | 1274/1772 [07:49<02:43,  3.04it/s, running training loss: 0.8545]\u001b[A\n",
            "Training:  72%|███████▏  | 1275/1772 [07:49<02:38,  3.13it/s, running training loss: 0.8545]\u001b[A\n",
            "Training:  72%|███████▏  | 1275/1772 [07:49<02:38,  3.13it/s, running training loss: 0.8518]\u001b[A\n",
            "Training:  72%|███████▏  | 1276/1772 [07:49<02:43,  3.03it/s, running training loss: 0.8518]\u001b[A\n",
            "Training:  72%|███████▏  | 1276/1772 [07:49<02:43,  3.03it/s, running training loss: 0.9370]\u001b[A\n",
            "Training:  72%|███████▏  | 1277/1772 [07:49<02:41,  3.07it/s, running training loss: 0.9370]\u001b[A\n",
            "Training:  72%|███████▏  | 1277/1772 [07:50<02:41,  3.07it/s, running training loss: 1.0083]\u001b[A\n",
            "Training:  72%|███████▏  | 1278/1772 [07:50<02:40,  3.08it/s, running training loss: 1.0083]\u001b[A\n",
            "Training:  72%|███████▏  | 1278/1772 [07:50<02:40,  3.08it/s, running training loss: 1.1285]\u001b[A\n",
            "Training:  72%|███████▏  | 1279/1772 [07:50<03:08,  2.62it/s, running training loss: 1.1285]\u001b[A\n",
            "Training:  72%|███████▏  | 1279/1772 [07:51<03:08,  2.62it/s, running training loss: 1.1978]\u001b[A\n",
            "Training:  72%|███████▏  | 1280/1772 [07:51<03:03,  2.68it/s, running training loss: 1.1978]\u001b[A\n",
            "Training:  72%|███████▏  | 1280/1772 [07:51<03:03,  2.68it/s, running training loss: 1.0384]\u001b[A\n",
            "Training:  72%|███████▏  | 1281/1772 [07:51<02:54,  2.82it/s, running training loss: 1.0384]\u001b[A\n",
            "Training:  72%|███████▏  | 1281/1772 [07:51<02:54,  2.82it/s, running training loss: 1.1772]\u001b[A\n",
            "Training:  72%|███████▏  | 1282/1772 [07:51<02:49,  2.90it/s, running training loss: 1.1772]\u001b[A\n",
            "Training:  72%|███████▏  | 1282/1772 [07:52<02:49,  2.90it/s, running training loss: 1.0310]\u001b[A\n",
            "Training:  72%|███████▏  | 1283/1772 [07:52<02:55,  2.78it/s, running training loss: 1.0310]\u001b[A\n",
            "Training:  72%|███████▏  | 1283/1772 [07:52<02:55,  2.78it/s, running training loss: 1.3542]\u001b[A\n",
            "Training:  72%|███████▏  | 1284/1772 [07:52<02:46,  2.93it/s, running training loss: 1.3542]\u001b[A\n",
            "Training:  72%|███████▏  | 1284/1772 [07:52<02:46,  2.93it/s, running training loss: 1.0303]\u001b[A\n",
            "Training:  73%|███████▎  | 1285/1772 [07:52<02:34,  3.16it/s, running training loss: 1.0303]\u001b[A\n",
            "Training:  73%|███████▎  | 1285/1772 [07:53<02:34,  3.16it/s, running training loss: 0.9421]\u001b[A\n",
            "Training:  73%|███████▎  | 1286/1772 [07:53<02:43,  2.97it/s, running training loss: 0.9421]\u001b[A\n",
            "Training:  73%|███████▎  | 1286/1772 [07:53<02:43,  2.97it/s, running training loss: 1.0308]\u001b[A\n",
            "Training:  73%|███████▎  | 1287/1772 [07:53<03:07,  2.58it/s, running training loss: 1.0308]\u001b[A\n",
            "Training:  73%|███████▎  | 1287/1772 [07:53<03:07,  2.58it/s, running training loss: 0.9174]\u001b[A\n",
            "Training:  73%|███████▎  | 1288/1772 [07:53<02:54,  2.77it/s, running training loss: 0.9174]\u001b[A\n",
            "Training:  73%|███████▎  | 1288/1772 [07:54<02:54,  2.77it/s, running training loss: 1.3045]\u001b[A\n",
            "Training:  73%|███████▎  | 1289/1772 [07:54<02:51,  2.82it/s, running training loss: 1.3045]\u001b[A\n",
            "Training:  73%|███████▎  | 1289/1772 [07:54<02:51,  2.82it/s, running training loss: 0.8465]\u001b[A\n",
            "Training:  73%|███████▎  | 1290/1772 [07:54<02:38,  3.05it/s, running training loss: 0.8465]\u001b[A\n",
            "Training:  73%|███████▎  | 1290/1772 [07:54<02:38,  3.05it/s, running training loss: 1.0112]\u001b[A\n",
            "Training:  73%|███████▎  | 1291/1772 [07:54<02:48,  2.85it/s, running training loss: 1.0112]\u001b[A\n",
            "Training:  73%|███████▎  | 1291/1772 [07:55<02:48,  2.85it/s, running training loss: 0.9106]\u001b[A\n",
            "Training:  73%|███████▎  | 1292/1772 [07:55<02:43,  2.93it/s, running training loss: 0.9106]\u001b[A\n",
            "Training:  73%|███████▎  | 1292/1772 [07:55<02:43,  2.93it/s, running training loss: 1.1027]\u001b[A\n",
            "Training:  73%|███████▎  | 1293/1772 [07:55<02:42,  2.94it/s, running training loss: 1.1027]\u001b[A\n",
            "Training:  73%|███████▎  | 1293/1772 [07:55<02:42,  2.94it/s, running training loss: 0.8982]\u001b[A\n",
            "Training:  73%|███████▎  | 1294/1772 [07:55<02:30,  3.17it/s, running training loss: 0.8982]\u001b[A\n",
            "Training:  73%|███████▎  | 1294/1772 [07:56<02:30,  3.17it/s, running training loss: 0.8967]\u001b[A\n",
            "Training:  73%|███████▎  | 1295/1772 [07:56<02:25,  3.28it/s, running training loss: 0.8967]\u001b[A\n",
            "Training:  73%|███████▎  | 1295/1772 [07:56<02:25,  3.28it/s, running training loss: 1.0261]\u001b[A\n",
            "Training:  73%|███████▎  | 1296/1772 [07:56<02:28,  3.20it/s, running training loss: 1.0261]\u001b[A\n",
            "Training:  73%|███████▎  | 1296/1772 [07:56<02:28,  3.20it/s, running training loss: 1.1253]\u001b[A\n",
            "Training:  73%|███████▎  | 1297/1772 [07:56<02:28,  3.21it/s, running training loss: 1.1253]\u001b[A\n",
            "Training:  73%|███████▎  | 1297/1772 [07:57<02:28,  3.21it/s, running training loss: 0.9727]\u001b[A\n",
            "Training:  73%|███████▎  | 1298/1772 [07:57<02:29,  3.17it/s, running training loss: 0.9727]\u001b[A\n",
            "Training:  73%|███████▎  | 1298/1772 [07:57<02:29,  3.17it/s, running training loss: 0.9170]\u001b[A\n",
            "Training:  73%|███████▎  | 1299/1772 [07:57<02:23,  3.29it/s, running training loss: 0.9170]\u001b[A\n",
            "Training:  73%|███████▎  | 1299/1772 [07:57<02:23,  3.29it/s, running training loss: 0.9092]\u001b[A\n",
            "Training:  73%|███████▎  | 1300/1772 [07:57<02:26,  3.22it/s, running training loss: 0.9092]\u001b[A\n",
            "Training:  73%|███████▎  | 1300/1772 [07:58<02:26,  3.22it/s, running training loss: 0.9340]\u001b[A\n",
            "Training:  73%|███████▎  | 1301/1772 [07:58<02:27,  3.19it/s, running training loss: 0.9340]\u001b[A\n",
            "Training:  73%|███████▎  | 1301/1772 [07:58<02:27,  3.19it/s, running training loss: 0.9856]\u001b[A\n",
            "Training:  73%|███████▎  | 1302/1772 [07:58<02:26,  3.21it/s, running training loss: 0.9856]\u001b[A\n",
            "Training:  73%|███████▎  | 1302/1772 [07:58<02:26,  3.21it/s, running training loss: 1.0213]\u001b[A\n",
            "Training:  74%|███████▎  | 1303/1772 [07:58<02:24,  3.24it/s, running training loss: 1.0213]\u001b[A\n",
            "Training:  74%|███████▎  | 1303/1772 [07:59<02:24,  3.24it/s, running training loss: 1.1746]\u001b[A\n",
            "Training:  74%|███████▎  | 1304/1772 [07:59<02:37,  2.96it/s, running training loss: 1.1746]\u001b[A\n",
            "Training:  74%|███████▎  | 1304/1772 [07:59<02:37,  2.96it/s, running training loss: 0.8627]\u001b[A\n",
            "Training:  74%|███████▎  | 1305/1772 [07:59<02:33,  3.04it/s, running training loss: 0.8627]\u001b[A\n",
            "Training:  74%|███████▎  | 1305/1772 [07:59<02:33,  3.04it/s, running training loss: 0.9542]\u001b[A\n",
            "Training:  74%|███████▎  | 1306/1772 [07:59<02:48,  2.76it/s, running training loss: 0.9542]\u001b[A\n",
            "Training:  74%|███████▎  | 1306/1772 [08:00<02:48,  2.76it/s, running training loss: 1.1414]\u001b[A\n",
            "Training:  74%|███████▍  | 1307/1772 [08:00<02:53,  2.68it/s, running training loss: 1.1414]\u001b[A\n",
            "Training:  74%|███████▍  | 1307/1772 [08:00<02:53,  2.68it/s, running training loss: 1.1382]\u001b[A\n",
            "Training:  74%|███████▍  | 1308/1772 [08:00<02:49,  2.73it/s, running training loss: 1.1382]\u001b[A\n",
            "Training:  74%|███████▍  | 1308/1772 [08:00<02:49,  2.73it/s, running training loss: 1.0358]\u001b[A\n",
            "Training:  74%|███████▍  | 1309/1772 [08:00<02:36,  2.95it/s, running training loss: 1.0358]\u001b[A\n",
            "Training:  74%|███████▍  | 1309/1772 [08:01<02:36,  2.95it/s, running training loss: 0.8410]\u001b[A\n",
            "Training:  74%|███████▍  | 1310/1772 [08:01<03:09,  2.43it/s, running training loss: 0.8410]\u001b[A\n",
            "Training:  74%|███████▍  | 1310/1772 [08:01<03:09,  2.43it/s, running training loss: 0.9473]\u001b[A\n",
            "Training:  74%|███████▍  | 1311/1772 [08:01<03:14,  2.37it/s, running training loss: 0.9473]\u001b[A\n",
            "Training:  74%|███████▍  | 1311/1772 [08:02<03:14,  2.37it/s, running training loss: 0.9596]\u001b[A\n",
            "Training:  74%|███████▍  | 1312/1772 [08:02<03:36,  2.12it/s, running training loss: 0.9596]\u001b[A\n",
            "Training:  74%|███████▍  | 1312/1772 [08:02<03:36,  2.12it/s, running training loss: 1.1365]\u001b[A\n",
            "Training:  74%|███████▍  | 1313/1772 [08:02<03:23,  2.25it/s, running training loss: 1.1365]\u001b[A\n",
            "Training:  74%|███████▍  | 1313/1772 [08:03<03:23,  2.25it/s, running training loss: 0.8702]\u001b[A\n",
            "Training:  74%|███████▍  | 1314/1772 [08:03<03:01,  2.52it/s, running training loss: 0.8702]\u001b[A\n",
            "Training:  74%|███████▍  | 1314/1772 [08:03<03:01,  2.52it/s, running training loss: 0.9986]\u001b[A\n",
            "Training:  74%|███████▍  | 1315/1772 [08:03<02:47,  2.74it/s, running training loss: 0.9986]\u001b[A\n",
            "Training:  74%|███████▍  | 1315/1772 [08:03<02:47,  2.74it/s, running training loss: 0.8698]\u001b[A\n",
            "Training:  74%|███████▍  | 1316/1772 [08:03<02:46,  2.74it/s, running training loss: 0.8698]\u001b[A\n",
            "Training:  74%|███████▍  | 1316/1772 [08:04<02:46,  2.74it/s, running training loss: 0.8102]\u001b[A\n",
            "Training:  74%|███████▍  | 1317/1772 [08:04<02:59,  2.53it/s, running training loss: 0.8102]\u001b[A\n",
            "Training:  74%|███████▍  | 1317/1772 [08:04<02:59,  2.53it/s, running training loss: 0.8009]\u001b[A\n",
            "Training:  74%|███████▍  | 1318/1772 [08:04<02:43,  2.78it/s, running training loss: 0.8009]\u001b[A\n",
            "Training:  74%|███████▍  | 1318/1772 [08:04<02:43,  2.78it/s, running training loss: 0.9844]\u001b[A\n",
            "Training:  74%|███████▍  | 1319/1772 [08:04<02:36,  2.90it/s, running training loss: 0.9844]\u001b[A\n",
            "Training:  74%|███████▍  | 1319/1772 [08:05<02:36,  2.90it/s, running training loss: 1.0280]\u001b[A\n",
            "Training:  74%|███████▍  | 1320/1772 [08:05<02:29,  3.03it/s, running training loss: 1.0280]\u001b[A\n",
            "Training:  74%|███████▍  | 1320/1772 [08:05<02:29,  3.03it/s, running training loss: 1.1681]\u001b[A\n",
            "Training:  75%|███████▍  | 1321/1772 [08:05<02:27,  3.05it/s, running training loss: 1.1681]\u001b[A\n",
            "Training:  75%|███████▍  | 1321/1772 [08:05<02:27,  3.05it/s, running training loss: 0.8654]\u001b[A\n",
            "Training:  75%|███████▍  | 1322/1772 [08:05<02:22,  3.16it/s, running training loss: 0.8654]\u001b[A\n",
            "Training:  75%|███████▍  | 1322/1772 [08:06<02:22,  3.16it/s, running training loss: 0.8770]\u001b[A\n",
            "Training:  75%|███████▍  | 1323/1772 [08:06<02:25,  3.08it/s, running training loss: 0.8770]\u001b[A\n",
            "Training:  75%|███████▍  | 1323/1772 [08:06<02:25,  3.08it/s, running training loss: 1.0940]\u001b[A\n",
            "Training:  75%|███████▍  | 1324/1772 [08:06<02:13,  3.36it/s, running training loss: 1.0940]\u001b[A\n",
            "Training:  75%|███████▍  | 1324/1772 [08:06<02:13,  3.36it/s, running training loss: 1.0161]\u001b[A\n",
            "Training:  75%|███████▍  | 1325/1772 [08:06<02:21,  3.15it/s, running training loss: 1.0161]\u001b[A\n",
            "Training:  75%|███████▍  | 1325/1772 [08:06<02:21,  3.15it/s, running training loss: 0.9003]\u001b[A\n",
            "Training:  75%|███████▍  | 1326/1772 [08:06<02:21,  3.15it/s, running training loss: 0.9003]\u001b[A\n",
            "Training:  75%|███████▍  | 1326/1772 [08:07<02:21,  3.15it/s, running training loss: 0.9094]\u001b[A\n",
            "Training:  75%|███████▍  | 1327/1772 [08:07<02:38,  2.81it/s, running training loss: 0.9094]\u001b[A\n",
            "Training:  75%|███████▍  | 1327/1772 [08:07<02:38,  2.81it/s, running training loss: 1.1423]\u001b[A\n",
            "Training:  75%|███████▍  | 1328/1772 [08:07<02:39,  2.78it/s, running training loss: 1.1423]\u001b[A\n",
            "Training:  75%|███████▍  | 1328/1772 [08:08<02:39,  2.78it/s, running training loss: 0.8901]\u001b[A\n",
            "Training:  75%|███████▌  | 1329/1772 [08:08<02:44,  2.69it/s, running training loss: 0.8901]\u001b[A\n",
            "Training:  75%|███████▌  | 1329/1772 [08:08<02:44,  2.69it/s, running training loss: 0.9947]\u001b[A\n",
            "Training:  75%|███████▌  | 1330/1772 [08:08<02:47,  2.64it/s, running training loss: 0.9947]\u001b[A\n",
            "Training:  75%|███████▌  | 1330/1772 [08:09<02:47,  2.64it/s, running training loss: 0.8557]\u001b[A\n",
            "Training:  75%|███████▌  | 1331/1772 [08:09<03:03,  2.40it/s, running training loss: 0.8557]\u001b[A\n",
            "Training:  75%|███████▌  | 1331/1772 [08:09<03:03,  2.40it/s, running training loss: 0.9609]\u001b[A\n",
            "Training:  75%|███████▌  | 1332/1772 [08:09<02:52,  2.56it/s, running training loss: 0.9609]\u001b[A\n",
            "Training:  75%|███████▌  | 1332/1772 [08:09<02:52,  2.56it/s, running training loss: 1.1338]\u001b[A\n",
            "Training:  75%|███████▌  | 1333/1772 [08:09<02:36,  2.81it/s, running training loss: 1.1338]\u001b[A\n",
            "Training:  75%|███████▌  | 1333/1772 [08:10<02:36,  2.81it/s, running training loss: 1.0625]\u001b[A\n",
            "Training:  75%|███████▌  | 1334/1772 [08:10<02:40,  2.73it/s, running training loss: 1.0625]\u001b[A\n",
            "Training:  75%|███████▌  | 1334/1772 [08:10<02:40,  2.73it/s, running training loss: 0.7062]\u001b[A\n",
            "Training:  75%|███████▌  | 1335/1772 [08:10<02:49,  2.58it/s, running training loss: 0.7062]\u001b[A\n",
            "Training:  75%|███████▌  | 1335/1772 [08:10<02:49,  2.58it/s, running training loss: 1.1365]\u001b[A\n",
            "Training:  75%|███████▌  | 1336/1772 [08:10<02:36,  2.79it/s, running training loss: 1.1365]\u001b[A\n",
            "Training:  75%|███████▌  | 1336/1772 [08:11<02:36,  2.79it/s, running training loss: 0.8179]\u001b[A\n",
            "Training:  75%|███████▌  | 1337/1772 [08:11<02:31,  2.87it/s, running training loss: 0.8179]\u001b[A\n",
            "Training:  75%|███████▌  | 1337/1772 [08:11<02:31,  2.87it/s, running training loss: 1.0015]\u001b[A\n",
            "Training:  76%|███████▌  | 1338/1772 [08:11<02:24,  3.01it/s, running training loss: 1.0015]\u001b[A\n",
            "Training:  76%|███████▌  | 1338/1772 [08:11<02:24,  3.01it/s, running training loss: 1.1466]\u001b[A\n",
            "Training:  76%|███████▌  | 1339/1772 [08:11<02:13,  3.23it/s, running training loss: 1.1466]\u001b[A\n",
            "Training:  76%|███████▌  | 1339/1772 [08:11<02:13,  3.23it/s, running training loss: 1.1878]\u001b[A\n",
            "Training:  76%|███████▌  | 1340/1772 [08:11<02:13,  3.23it/s, running training loss: 1.1878]\u001b[A\n",
            "Training:  76%|███████▌  | 1340/1772 [08:12<02:13,  3.23it/s, running training loss: 1.1886]\u001b[A\n",
            "Training:  76%|███████▌  | 1341/1772 [08:12<02:49,  2.54it/s, running training loss: 1.1886]\u001b[A\n",
            "Training:  76%|███████▌  | 1341/1772 [08:12<02:49,  2.54it/s, running training loss: 0.9684]\u001b[A\n",
            "Training:  76%|███████▌  | 1342/1772 [08:12<02:38,  2.70it/s, running training loss: 0.9684]\u001b[A\n",
            "Training:  76%|███████▌  | 1342/1772 [08:13<02:38,  2.70it/s, running training loss: 1.1439]\u001b[A\n",
            "Training:  76%|███████▌  | 1343/1772 [08:13<02:34,  2.77it/s, running training loss: 1.1439]\u001b[A\n",
            "Training:  76%|███████▌  | 1343/1772 [08:13<02:34,  2.77it/s, running training loss: 0.8005]\u001b[A\n",
            "Training:  76%|███████▌  | 1344/1772 [08:13<02:43,  2.62it/s, running training loss: 0.8005]\u001b[A\n",
            "Training:  76%|███████▌  | 1344/1772 [08:13<02:43,  2.62it/s, running training loss: 1.0528]\u001b[A\n",
            "Training:  76%|███████▌  | 1345/1772 [08:13<02:36,  2.72it/s, running training loss: 1.0528]\u001b[A\n",
            "Training:  76%|███████▌  | 1345/1772 [08:14<02:36,  2.72it/s, running training loss: 0.9214]\u001b[A\n",
            "Training:  76%|███████▌  | 1346/1772 [08:14<02:44,  2.58it/s, running training loss: 0.9214]\u001b[A\n",
            "Training:  76%|███████▌  | 1346/1772 [08:14<02:44,  2.58it/s, running training loss: 0.9834]\u001b[A\n",
            "Training:  76%|███████▌  | 1347/1772 [08:14<02:47,  2.54it/s, running training loss: 0.9834]\u001b[A\n",
            "Training:  76%|███████▌  | 1347/1772 [08:15<02:47,  2.54it/s, running training loss: 0.9525]\u001b[A\n",
            "Training:  76%|███████▌  | 1348/1772 [08:15<02:37,  2.70it/s, running training loss: 0.9525]\u001b[A\n",
            "Training:  76%|███████▌  | 1348/1772 [08:15<02:37,  2.70it/s, running training loss: 0.8111]\u001b[A\n",
            "Training:  76%|███████▌  | 1349/1772 [08:15<02:27,  2.86it/s, running training loss: 0.8111]\u001b[A\n",
            "Training:  76%|███████▌  | 1349/1772 [08:15<02:27,  2.86it/s, running training loss: 1.0624]\u001b[A\n",
            "Training:  76%|███████▌  | 1350/1772 [08:15<02:30,  2.80it/s, running training loss: 1.0624]\u001b[A\n",
            "Training:  76%|███████▌  | 1350/1772 [08:16<02:30,  2.80it/s, running training loss: 0.8647]\u001b[A\n",
            "Training:  76%|███████▌  | 1351/1772 [08:16<02:32,  2.76it/s, running training loss: 0.8647]\u001b[A\n",
            "Training:  76%|███████▌  | 1351/1772 [08:16<02:32,  2.76it/s, running training loss: 0.8944]\u001b[A\n",
            "Training:  76%|███████▋  | 1352/1772 [08:16<02:29,  2.82it/s, running training loss: 0.8944]\u001b[A\n",
            "Training:  76%|███████▋  | 1352/1772 [08:16<02:29,  2.82it/s, running training loss: 0.7981]\u001b[A\n",
            "Training:  76%|███████▋  | 1353/1772 [08:16<02:30,  2.79it/s, running training loss: 0.7981]\u001b[A\n",
            "Training:  76%|███████▋  | 1353/1772 [08:17<02:30,  2.79it/s, running training loss: 0.9936]\u001b[A\n",
            "Training:  76%|███████▋  | 1354/1772 [08:17<02:32,  2.74it/s, running training loss: 0.9936]\u001b[A\n",
            "Training:  76%|███████▋  | 1354/1772 [08:17<02:32,  2.74it/s, running training loss: 1.2198]\u001b[A\n",
            "Training:  76%|███████▋  | 1355/1772 [08:17<02:45,  2.52it/s, running training loss: 1.2198]\u001b[A\n",
            "Training:  76%|███████▋  | 1355/1772 [08:18<02:45,  2.52it/s, running training loss: 1.2437]\u001b[A\n",
            "Training:  77%|███████▋  | 1356/1772 [08:18<02:29,  2.78it/s, running training loss: 1.2437]\u001b[A\n",
            "Training:  77%|███████▋  | 1356/1772 [08:18<02:29,  2.78it/s, running training loss: 1.0663]\u001b[A\n",
            "Training:  77%|███████▋  | 1357/1772 [08:18<02:32,  2.72it/s, running training loss: 1.0663]\u001b[A\n",
            "Training:  77%|███████▋  | 1357/1772 [08:18<02:32,  2.72it/s, running training loss: 1.1048]\u001b[A\n",
            "Training:  77%|███████▋  | 1358/1772 [08:18<02:22,  2.91it/s, running training loss: 1.1048]\u001b[A\n",
            "Training:  77%|███████▋  | 1358/1772 [08:19<02:22,  2.91it/s, running training loss: 0.8414]\u001b[A\n",
            "Training:  77%|███████▋  | 1359/1772 [08:19<02:20,  2.94it/s, running training loss: 0.8414]\u001b[A\n",
            "Training:  77%|███████▋  | 1359/1772 [08:19<02:20,  2.94it/s, running training loss: 0.9569]\u001b[A\n",
            "Training:  77%|███████▋  | 1360/1772 [08:19<02:16,  3.02it/s, running training loss: 0.9569]\u001b[A\n",
            "Training:  77%|███████▋  | 1360/1772 [08:19<02:16,  3.02it/s, running training loss: 0.9910]\u001b[A\n",
            "Training:  77%|███████▋  | 1361/1772 [08:19<02:08,  3.19it/s, running training loss: 0.9910]\u001b[A\n",
            "Training:  77%|███████▋  | 1361/1772 [08:19<02:08,  3.19it/s, running training loss: 1.0129]\u001b[A\n",
            "Training:  77%|███████▋  | 1362/1772 [08:19<02:16,  3.00it/s, running training loss: 1.0129]\u001b[A\n",
            "Training:  77%|███████▋  | 1362/1772 [08:20<02:16,  3.00it/s, running training loss: 0.9552]\u001b[A\n",
            "Training:  77%|███████▋  | 1363/1772 [08:20<02:08,  3.19it/s, running training loss: 0.9552]\u001b[A\n",
            "Training:  77%|███████▋  | 1363/1772 [08:20<02:08,  3.19it/s, running training loss: 0.9465]\u001b[A\n",
            "Training:  77%|███████▋  | 1364/1772 [08:20<02:01,  3.35it/s, running training loss: 0.9465]\u001b[A\n",
            "Training:  77%|███████▋  | 1364/1772 [08:20<02:01,  3.35it/s, running training loss: 0.9651]\u001b[A\n",
            "Training:  77%|███████▋  | 1365/1772 [08:20<02:19,  2.92it/s, running training loss: 0.9651]\u001b[A\n",
            "Training:  77%|███████▋  | 1365/1772 [08:21<02:19,  2.92it/s, running training loss: 0.9293]\u001b[A\n",
            "Training:  77%|███████▋  | 1366/1772 [08:21<02:19,  2.92it/s, running training loss: 0.9293]\u001b[A\n",
            "Training:  77%|███████▋  | 1366/1772 [08:21<02:19,  2.92it/s, running training loss: 1.0357]\u001b[A\n",
            "Training:  77%|███████▋  | 1367/1772 [08:21<02:17,  2.95it/s, running training loss: 1.0357]\u001b[A\n",
            "Training:  77%|███████▋  | 1367/1772 [08:22<02:17,  2.95it/s, running training loss: 0.9546]\u001b[A\n",
            "Training:  77%|███████▋  | 1368/1772 [08:22<02:20,  2.88it/s, running training loss: 0.9546]\u001b[A\n",
            "Training:  77%|███████▋  | 1368/1772 [08:22<02:20,  2.88it/s, running training loss: 0.9261]\u001b[A\n",
            "Training:  77%|███████▋  | 1369/1772 [08:22<02:16,  2.96it/s, running training loss: 0.9261]\u001b[A\n",
            "Training:  77%|███████▋  | 1369/1772 [08:22<02:16,  2.96it/s, running training loss: 0.9819]\u001b[A\n",
            "Training:  77%|███████▋  | 1370/1772 [08:22<02:12,  3.04it/s, running training loss: 0.9819]\u001b[A\n",
            "Training:  77%|███████▋  | 1370/1772 [08:22<02:12,  3.04it/s, running training loss: 0.9370]\u001b[A\n",
            "Training:  77%|███████▋  | 1371/1772 [08:22<02:10,  3.08it/s, running training loss: 0.9370]\u001b[A\n",
            "Training:  77%|███████▋  | 1371/1772 [08:23<02:10,  3.08it/s, running training loss: 1.0586]\u001b[A\n",
            "Training:  77%|███████▋  | 1372/1772 [08:23<02:11,  3.04it/s, running training loss: 1.0586]\u001b[A\n",
            "Training:  77%|███████▋  | 1372/1772 [08:23<02:11,  3.04it/s, running training loss: 0.8894]\u001b[A\n",
            "Training:  77%|███████▋  | 1373/1772 [08:23<02:19,  2.86it/s, running training loss: 0.8894]\u001b[A\n",
            "Training:  77%|███████▋  | 1373/1772 [08:23<02:19,  2.86it/s, running training loss: 1.2290]\u001b[A\n",
            "Training:  78%|███████▊  | 1374/1772 [08:23<02:08,  3.09it/s, running training loss: 1.2290]\u001b[A\n",
            "Training:  78%|███████▊  | 1374/1772 [08:24<02:08,  3.09it/s, running training loss: 0.8362]\u001b[A\n",
            "Training:  78%|███████▊  | 1375/1772 [08:24<02:04,  3.19it/s, running training loss: 0.8362]\u001b[A\n",
            "Training:  78%|███████▊  | 1375/1772 [08:24<02:04,  3.19it/s, running training loss: 0.7096]\u001b[A\n",
            "Training:  78%|███████▊  | 1376/1772 [08:24<02:13,  2.98it/s, running training loss: 0.7096]\u001b[A\n",
            "Training:  78%|███████▊  | 1376/1772 [08:24<02:13,  2.98it/s, running training loss: 0.9996]\u001b[A\n",
            "Training:  78%|███████▊  | 1377/1772 [08:24<02:11,  3.01it/s, running training loss: 0.9996]\u001b[A\n",
            "Training:  78%|███████▊  | 1377/1772 [08:25<02:11,  3.01it/s, running training loss: 1.2925]\u001b[A\n",
            "Training:  78%|███████▊  | 1378/1772 [08:25<02:15,  2.90it/s, running training loss: 1.2925]\u001b[A\n",
            "Training:  78%|███████▊  | 1378/1772 [08:25<02:15,  2.90it/s, running training loss: 1.4094]\u001b[A\n",
            "Training:  78%|███████▊  | 1379/1772 [08:25<02:11,  2.99it/s, running training loss: 1.4094]\u001b[A\n",
            "Training:  78%|███████▊  | 1379/1772 [08:26<02:11,  2.99it/s, running training loss: 1.2531]\u001b[A\n",
            "Training:  78%|███████▊  | 1380/1772 [08:26<02:15,  2.90it/s, running training loss: 1.2531]\u001b[A\n",
            "Training:  78%|███████▊  | 1380/1772 [08:26<02:15,  2.90it/s, running training loss: 0.9083]\u001b[A\n",
            "Training:  78%|███████▊  | 1381/1772 [08:26<02:08,  3.05it/s, running training loss: 0.9083]\u001b[A\n",
            "Training:  78%|███████▊  | 1381/1772 [08:26<02:08,  3.05it/s, running training loss: 1.3752]\u001b[A\n",
            "Training:  78%|███████▊  | 1382/1772 [08:26<02:02,  3.17it/s, running training loss: 1.3752]\u001b[A\n",
            "Training:  78%|███████▊  | 1382/1772 [08:26<02:02,  3.17it/s, running training loss: 1.2648]\u001b[A\n",
            "Training:  78%|███████▊  | 1383/1772 [08:26<02:01,  3.20it/s, running training loss: 1.2648]\u001b[A\n",
            "Training:  78%|███████▊  | 1383/1772 [08:27<02:01,  3.20it/s, running training loss: 0.9807]\u001b[A\n",
            "Training:  78%|███████▊  | 1384/1772 [08:27<02:01,  3.19it/s, running training loss: 0.9807]\u001b[A\n",
            "Training:  78%|███████▊  | 1384/1772 [08:27<02:01,  3.19it/s, running training loss: 0.6661]\u001b[A\n",
            "Training:  78%|███████▊  | 1385/1772 [08:27<01:59,  3.24it/s, running training loss: 0.6661]\u001b[A\n",
            "Training:  78%|███████▊  | 1385/1772 [08:27<01:59,  3.24it/s, running training loss: 1.0969]\u001b[A\n",
            "Training:  78%|███████▊  | 1386/1772 [08:27<01:59,  3.24it/s, running training loss: 1.0969]\u001b[A\n",
            "Training:  78%|███████▊  | 1386/1772 [08:28<01:59,  3.24it/s, running training loss: 1.2480]\u001b[A\n",
            "Training:  78%|███████▊  | 1387/1772 [08:28<01:54,  3.37it/s, running training loss: 1.2480]\u001b[A\n",
            "Training:  78%|███████▊  | 1387/1772 [08:28<01:54,  3.37it/s, running training loss: 0.9085]\u001b[A\n",
            "Training:  78%|███████▊  | 1388/1772 [08:28<01:53,  3.39it/s, running training loss: 0.9085]\u001b[A\n",
            "Training:  78%|███████▊  | 1388/1772 [08:28<01:53,  3.39it/s, running training loss: 1.1163]\u001b[A\n",
            "Training:  78%|███████▊  | 1389/1772 [08:28<01:54,  3.34it/s, running training loss: 1.1163]\u001b[A\n",
            "Training:  78%|███████▊  | 1389/1772 [08:29<01:54,  3.34it/s, running training loss: 0.8216]\u001b[A\n",
            "Training:  78%|███████▊  | 1390/1772 [08:29<02:00,  3.18it/s, running training loss: 0.8216]\u001b[A\n",
            "Training:  78%|███████▊  | 1390/1772 [08:29<02:00,  3.18it/s, running training loss: 0.7862]\u001b[A\n",
            "Training:  78%|███████▊  | 1391/1772 [08:29<01:59,  3.18it/s, running training loss: 0.7862]\u001b[A\n",
            "Training:  78%|███████▊  | 1391/1772 [08:29<01:59,  3.18it/s, running training loss: 0.9677]\u001b[A\n",
            "Training:  79%|███████▊  | 1392/1772 [08:29<02:16,  2.79it/s, running training loss: 0.9677]\u001b[A\n",
            "Training:  79%|███████▊  | 1392/1772 [08:30<02:16,  2.79it/s, running training loss: 0.8792]\u001b[A\n",
            "Training:  79%|███████▊  | 1393/1772 [08:30<02:26,  2.58it/s, running training loss: 0.8792]\u001b[A\n",
            "Training:  79%|███████▊  | 1393/1772 [08:30<02:26,  2.58it/s, running training loss: 0.9392]\u001b[A\n",
            "Training:  79%|███████▊  | 1394/1772 [08:30<02:16,  2.76it/s, running training loss: 0.9392]\u001b[A\n",
            "Training:  79%|███████▊  | 1394/1772 [08:30<02:16,  2.76it/s, running training loss: 0.7399]\u001b[A\n",
            "Training:  79%|███████▊  | 1395/1772 [08:30<02:17,  2.74it/s, running training loss: 0.7399]\u001b[A\n",
            "Training:  79%|███████▊  | 1395/1772 [08:31<02:17,  2.74it/s, running training loss: 0.9554]\u001b[A\n",
            "Training:  79%|███████▉  | 1396/1772 [08:31<02:16,  2.75it/s, running training loss: 0.9554]\u001b[A\n",
            "Training:  79%|███████▉  | 1396/1772 [08:31<02:16,  2.75it/s, running training loss: 0.8044]\u001b[A\n",
            "Training:  79%|███████▉  | 1397/1772 [08:31<02:17,  2.74it/s, running training loss: 0.8044]\u001b[A\n",
            "Training:  79%|███████▉  | 1397/1772 [08:32<02:17,  2.74it/s, running training loss: 0.8901]\u001b[A\n",
            "Training:  79%|███████▉  | 1398/1772 [08:32<02:31,  2.47it/s, running training loss: 0.8901]\u001b[A\n",
            "Training:  79%|███████▉  | 1398/1772 [08:32<02:31,  2.47it/s, running training loss: 0.9724]\u001b[A\n",
            "Training:  79%|███████▉  | 1399/1772 [08:32<02:24,  2.59it/s, running training loss: 0.9724]\u001b[A\n",
            "Training:  79%|███████▉  | 1399/1772 [08:32<02:24,  2.59it/s, running training loss: 0.9647]\u001b[A\n",
            "Training:  79%|███████▉  | 1400/1772 [08:32<02:19,  2.66it/s, running training loss: 0.9647]\u001b[A\n",
            "Training:  79%|███████▉  | 1400/1772 [08:33<02:19,  2.66it/s, running training loss: 1.1703]\u001b[A\n",
            "Training:  79%|███████▉  | 1401/1772 [08:33<02:17,  2.70it/s, running training loss: 1.1703]\u001b[A\n",
            "Training:  79%|███████▉  | 1401/1772 [08:33<02:17,  2.70it/s, running training loss: 0.8319]\u001b[A\n",
            "Training:  79%|███████▉  | 1402/1772 [08:33<02:42,  2.27it/s, running training loss: 0.8319]\u001b[A\n",
            "Training:  79%|███████▉  | 1402/1772 [08:34<02:42,  2.27it/s, running training loss: 0.9078]\u001b[A\n",
            "Training:  79%|███████▉  | 1403/1772 [08:34<02:32,  2.42it/s, running training loss: 0.9078]\u001b[A\n",
            "Training:  79%|███████▉  | 1403/1772 [08:34<02:32,  2.42it/s, running training loss: 1.0675]\u001b[A\n",
            "Training:  79%|███████▉  | 1404/1772 [08:34<02:22,  2.58it/s, running training loss: 1.0675]\u001b[A\n",
            "Training:  79%|███████▉  | 1404/1772 [08:34<02:22,  2.58it/s, running training loss: 1.4171]\u001b[A\n",
            "Training:  79%|███████▉  | 1405/1772 [08:34<02:08,  2.86it/s, running training loss: 1.4171]\u001b[A\n",
            "Training:  79%|███████▉  | 1405/1772 [08:35<02:08,  2.86it/s, running training loss: 1.0266]\u001b[A\n",
            "Training:  79%|███████▉  | 1406/1772 [08:35<02:10,  2.81it/s, running training loss: 1.0266]\u001b[A\n",
            "Training:  79%|███████▉  | 1406/1772 [08:35<02:10,  2.81it/s, running training loss: 1.2158]\u001b[A\n",
            "Training:  79%|███████▉  | 1407/1772 [08:35<02:25,  2.50it/s, running training loss: 1.2158]\u001b[A\n",
            "Training:  79%|███████▉  | 1407/1772 [08:36<02:25,  2.50it/s, running training loss: 1.2158]\u001b[A\n",
            "Training:  79%|███████▉  | 1408/1772 [08:36<02:25,  2.50it/s, running training loss: 1.2158]\u001b[A\n",
            "Training:  79%|███████▉  | 1408/1772 [08:36<02:25,  2.50it/s, running training loss: 1.3182]\u001b[A\n",
            "Training:  80%|███████▉  | 1409/1772 [08:36<02:13,  2.73it/s, running training loss: 1.3182]\u001b[A\n",
            "Training:  80%|███████▉  | 1409/1772 [08:36<02:13,  2.73it/s, running training loss: 1.1901]\u001b[A\n",
            "Training:  80%|███████▉  | 1410/1772 [08:36<02:19,  2.60it/s, running training loss: 1.1901]\u001b[A\n",
            "Training:  80%|███████▉  | 1410/1772 [08:37<02:19,  2.60it/s, running training loss: 1.4392]\u001b[A\n",
            "Training:  80%|███████▉  | 1411/1772 [08:37<02:06,  2.85it/s, running training loss: 1.4392]\u001b[A\n",
            "Training:  80%|███████▉  | 1411/1772 [08:37<02:06,  2.85it/s, running training loss: 1.0794]\u001b[A\n",
            "Training:  80%|███████▉  | 1412/1772 [08:37<01:58,  3.03it/s, running training loss: 1.0794]\u001b[A\n",
            "Training:  80%|███████▉  | 1412/1772 [08:37<01:58,  3.03it/s, running training loss: 0.9200]\u001b[A\n",
            "Training:  80%|███████▉  | 1413/1772 [08:37<02:09,  2.78it/s, running training loss: 0.9200]\u001b[A\n",
            "Training:  80%|███████▉  | 1413/1772 [08:38<02:09,  2.78it/s, running training loss: 0.7003]\u001b[A\n",
            "Training:  80%|███████▉  | 1414/1772 [08:38<02:02,  2.91it/s, running training loss: 0.7003]\u001b[A\n",
            "Training:  80%|███████▉  | 1414/1772 [08:38<02:02,  2.91it/s, running training loss: 0.9745]\u001b[A\n",
            "Training:  80%|███████▉  | 1415/1772 [08:38<02:01,  2.95it/s, running training loss: 0.9745]\u001b[A\n",
            "Training:  80%|███████▉  | 1415/1772 [08:38<02:01,  2.95it/s, running training loss: 0.7936]\u001b[A\n",
            "Training:  80%|███████▉  | 1416/1772 [08:38<02:00,  2.96it/s, running training loss: 0.7936]\u001b[A\n",
            "Training:  80%|███████▉  | 1416/1772 [08:39<02:00,  2.96it/s, running training loss: 1.0472]\u001b[A\n",
            "Training:  80%|███████▉  | 1417/1772 [08:39<02:01,  2.93it/s, running training loss: 1.0472]\u001b[A\n",
            "Training:  80%|███████▉  | 1417/1772 [08:39<02:01,  2.93it/s, running training loss: 0.9868]\u001b[A\n",
            "Training:  80%|████████  | 1418/1772 [08:39<01:55,  3.08it/s, running training loss: 0.9868]\u001b[A\n",
            "Training:  80%|████████  | 1418/1772 [08:39<01:55,  3.08it/s, running training loss: 0.8800]\u001b[A\n",
            "Training:  80%|████████  | 1419/1772 [08:39<01:49,  3.22it/s, running training loss: 0.8800]\u001b[A\n",
            "Training:  80%|████████  | 1419/1772 [08:39<01:49,  3.22it/s, running training loss: 0.9431]\u001b[A\n",
            "Training:  80%|████████  | 1420/1772 [08:39<01:56,  3.01it/s, running training loss: 0.9431]\u001b[A\n",
            "Training:  80%|████████  | 1420/1772 [08:40<01:56,  3.01it/s, running training loss: 0.7786]\u001b[A\n",
            "Training:  80%|████████  | 1421/1772 [08:40<02:00,  2.92it/s, running training loss: 0.7786]\u001b[A\n",
            "Training:  80%|████████  | 1421/1772 [08:40<02:00,  2.92it/s, running training loss: 0.8968]\u001b[A\n",
            "Training:  80%|████████  | 1422/1772 [08:40<01:52,  3.11it/s, running training loss: 0.8968]\u001b[A\n",
            "Training:  80%|████████  | 1422/1772 [08:40<01:52,  3.11it/s, running training loss: 1.1358]\u001b[A\n",
            "Training:  80%|████████  | 1423/1772 [08:40<01:53,  3.06it/s, running training loss: 1.1358]\u001b[A\n",
            "Training:  80%|████████  | 1423/1772 [08:41<01:53,  3.06it/s, running training loss: 0.8312]\u001b[A\n",
            "Training:  80%|████████  | 1424/1772 [08:41<01:55,  3.02it/s, running training loss: 0.8312]\u001b[A\n",
            "Training:  80%|████████  | 1424/1772 [08:41<01:55,  3.02it/s, running training loss: 0.9500]\u001b[A\n",
            "Training:  80%|████████  | 1425/1772 [08:41<01:52,  3.07it/s, running training loss: 0.9500]\u001b[A\n",
            "Training:  80%|████████  | 1425/1772 [08:42<01:52,  3.07it/s, running training loss: 0.8864]\u001b[A\n",
            "Training:  80%|████████  | 1426/1772 [08:42<01:59,  2.90it/s, running training loss: 0.8864]\u001b[A\n",
            "Training:  80%|████████  | 1426/1772 [08:42<01:59,  2.90it/s, running training loss: 1.3927]\u001b[A\n",
            "Training:  81%|████████  | 1427/1772 [08:42<01:51,  3.08it/s, running training loss: 1.3927]\u001b[A\n",
            "Training:  81%|████████  | 1427/1772 [08:42<01:51,  3.08it/s, running training loss: 1.0448]\u001b[A\n",
            "Training:  81%|████████  | 1428/1772 [08:42<01:51,  3.08it/s, running training loss: 1.0448]\u001b[A\n",
            "Training:  81%|████████  | 1428/1772 [08:42<01:51,  3.08it/s, running training loss: 0.7441]\u001b[A\n",
            "Training:  81%|████████  | 1429/1772 [08:42<01:48,  3.16it/s, running training loss: 0.7441]\u001b[A\n",
            "Training:  81%|████████  | 1429/1772 [08:43<01:48,  3.16it/s, running training loss: 1.5153]\u001b[A\n",
            "Training:  81%|████████  | 1430/1772 [08:43<02:08,  2.67it/s, running training loss: 1.5153]\u001b[A\n",
            "Training:  81%|████████  | 1430/1772 [08:43<02:08,  2.67it/s, running training loss: 1.0340]\u001b[A\n",
            "Training:  81%|████████  | 1431/1772 [08:43<02:01,  2.81it/s, running training loss: 1.0340]\u001b[A\n",
            "Training:  81%|████████  | 1431/1772 [08:44<02:01,  2.81it/s, running training loss: 1.1813]\u001b[A\n",
            "Training:  81%|████████  | 1432/1772 [08:44<02:04,  2.74it/s, running training loss: 1.1813]\u001b[A\n",
            "Training:  81%|████████  | 1432/1772 [08:44<02:04,  2.74it/s, running training loss: 1.2528]\u001b[A\n",
            "Training:  81%|████████  | 1433/1772 [08:44<02:06,  2.68it/s, running training loss: 1.2528]\u001b[A\n",
            "Training:  81%|████████  | 1433/1772 [08:44<02:06,  2.68it/s, running training loss: 0.9348]\u001b[A\n",
            "Training:  81%|████████  | 1434/1772 [08:44<02:00,  2.81it/s, running training loss: 0.9348]\u001b[A\n",
            "Training:  81%|████████  | 1434/1772 [08:45<02:00,  2.81it/s, running training loss: 1.0918]\u001b[A\n",
            "Training:  81%|████████  | 1435/1772 [08:45<02:05,  2.70it/s, running training loss: 1.0918]\u001b[A\n",
            "Training:  81%|████████  | 1435/1772 [08:45<02:05,  2.70it/s, running training loss: 0.8551]\u001b[A\n",
            "Training:  81%|████████  | 1436/1772 [08:45<01:58,  2.84it/s, running training loss: 0.8551]\u001b[A\n",
            "Training:  81%|████████  | 1436/1772 [08:46<01:58,  2.84it/s, running training loss: 1.2379]\u001b[A\n",
            "Training:  81%|████████  | 1437/1772 [08:46<02:18,  2.42it/s, running training loss: 1.2379]\u001b[A\n",
            "Training:  81%|████████  | 1437/1772 [08:46<02:18,  2.42it/s, running training loss: 1.1736]\u001b[A\n",
            "Training:  81%|████████  | 1438/1772 [08:46<02:05,  2.67it/s, running training loss: 1.1736]\u001b[A\n",
            "Training:  81%|████████  | 1438/1772 [08:46<02:05,  2.67it/s, running training loss: 1.1118]\u001b[A\n",
            "Training:  81%|████████  | 1439/1772 [08:46<01:58,  2.80it/s, running training loss: 1.1118]\u001b[A\n",
            "Training:  81%|████████  | 1439/1772 [08:47<01:58,  2.80it/s, running training loss: 1.0171]\u001b[A\n",
            "Training:  81%|████████▏ | 1440/1772 [08:47<01:57,  2.82it/s, running training loss: 1.0171]\u001b[A\n",
            "Training:  81%|████████▏ | 1440/1772 [08:47<01:57,  2.82it/s, running training loss: 0.9403]\u001b[A\n",
            "Training:  81%|████████▏ | 1441/1772 [08:47<02:04,  2.65it/s, running training loss: 0.9403]\u001b[A\n",
            "Training:  81%|████████▏ | 1441/1772 [08:47<02:04,  2.65it/s, running training loss: 0.6468]\u001b[A\n",
            "Training:  81%|████████▏ | 1442/1772 [08:47<01:59,  2.77it/s, running training loss: 0.6468]\u001b[A\n",
            "Training:  81%|████████▏ | 1442/1772 [08:48<01:59,  2.77it/s, running training loss: 0.7386]\u001b[A\n",
            "Training:  81%|████████▏ | 1443/1772 [08:48<01:54,  2.89it/s, running training loss: 0.7386]\u001b[A\n",
            "Training:  81%|████████▏ | 1443/1772 [08:48<01:54,  2.89it/s, running training loss: 0.8438]\u001b[A\n",
            "Training:  81%|████████▏ | 1444/1772 [08:48<01:56,  2.81it/s, running training loss: 0.8438]\u001b[A\n",
            "Training:  81%|████████▏ | 1444/1772 [08:48<01:56,  2.81it/s, running training loss: 0.8388]\u001b[A\n",
            "Training:  82%|████████▏ | 1445/1772 [08:48<01:56,  2.80it/s, running training loss: 0.8388]\u001b[A\n",
            "Training:  82%|████████▏ | 1445/1772 [08:49<01:56,  2.80it/s, running training loss: 0.7963]\u001b[A\n",
            "Training:  82%|████████▏ | 1446/1772 [08:49<01:54,  2.86it/s, running training loss: 0.7963]\u001b[A\n",
            "Training:  82%|████████▏ | 1446/1772 [08:49<01:54,  2.86it/s, running training loss: 0.7349]\u001b[A\n",
            "Training:  82%|████████▏ | 1447/1772 [08:49<01:48,  2.99it/s, running training loss: 0.7349]\u001b[A\n",
            "Training:  82%|████████▏ | 1447/1772 [08:49<01:48,  2.99it/s, running training loss: 1.0111]\u001b[A\n",
            "Training:  82%|████████▏ | 1448/1772 [08:49<01:44,  3.10it/s, running training loss: 1.0111]\u001b[A\n",
            "Training:  82%|████████▏ | 1448/1772 [08:50<01:44,  3.10it/s, running training loss: 1.0793]\u001b[A\n",
            "Training:  82%|████████▏ | 1449/1772 [08:50<01:52,  2.87it/s, running training loss: 1.0793]\u001b[A\n",
            "Training:  82%|████████▏ | 1449/1772 [08:50<01:52,  2.87it/s, running training loss: 1.0984]\u001b[A\n",
            "Training:  82%|████████▏ | 1450/1772 [08:50<01:51,  2.89it/s, running training loss: 1.0984]\u001b[A\n",
            "Training:  82%|████████▏ | 1450/1772 [08:50<01:51,  2.89it/s, running training loss: 1.4359]\u001b[A\n",
            "Training:  82%|████████▏ | 1451/1772 [08:50<01:46,  3.01it/s, running training loss: 1.4359]\u001b[A\n",
            "Training:  82%|████████▏ | 1451/1772 [08:51<01:46,  3.01it/s, running training loss: 0.9276]\u001b[A\n",
            "Training:  82%|████████▏ | 1452/1772 [08:51<01:45,  3.02it/s, running training loss: 0.9276]\u001b[A\n",
            "Training:  82%|████████▏ | 1452/1772 [08:51<01:45,  3.02it/s, running training loss: 1.1507]\u001b[A\n",
            "Training:  82%|████████▏ | 1453/1772 [08:51<01:45,  3.01it/s, running training loss: 1.1507]\u001b[A\n",
            "Training:  82%|████████▏ | 1453/1772 [08:51<01:45,  3.01it/s, running training loss: 0.8971]\u001b[A\n",
            "Training:  82%|████████▏ | 1454/1772 [08:51<01:41,  3.15it/s, running training loss: 0.8971]\u001b[A\n",
            "Training:  82%|████████▏ | 1454/1772 [08:52<01:41,  3.15it/s, running training loss: 0.9190]\u001b[A\n",
            "Training:  82%|████████▏ | 1455/1772 [08:52<01:37,  3.26it/s, running training loss: 0.9190]\u001b[A\n",
            "Training:  82%|████████▏ | 1455/1772 [08:52<01:37,  3.26it/s, running training loss: 1.2373]\u001b[A\n",
            "Training:  82%|████████▏ | 1456/1772 [08:52<01:36,  3.28it/s, running training loss: 1.2373]\u001b[A\n",
            "Training:  82%|████████▏ | 1456/1772 [08:52<01:36,  3.28it/s, running training loss: 0.8322]\u001b[A\n",
            "Training:  82%|████████▏ | 1457/1772 [08:52<01:41,  3.10it/s, running training loss: 0.8322]\u001b[A\n",
            "Training:  82%|████████▏ | 1457/1772 [08:53<01:41,  3.10it/s, running training loss: 1.1778]\u001b[A\n",
            "Training:  82%|████████▏ | 1458/1772 [08:53<01:41,  3.08it/s, running training loss: 1.1778]\u001b[A\n",
            "Training:  82%|████████▏ | 1458/1772 [08:53<01:41,  3.08it/s, running training loss: 1.1153]\u001b[A\n",
            "Training:  82%|████████▏ | 1459/1772 [08:53<01:48,  2.89it/s, running training loss: 1.1153]\u001b[A\n",
            "Training:  82%|████████▏ | 1459/1772 [08:53<01:48,  2.89it/s, running training loss: 0.9790]\u001b[A\n",
            "Training:  82%|████████▏ | 1460/1772 [08:53<01:59,  2.62it/s, running training loss: 0.9790]\u001b[A\n",
            "Training:  82%|████████▏ | 1460/1772 [08:54<01:59,  2.62it/s, running training loss: 1.0165]\u001b[A\n",
            "Training:  82%|████████▏ | 1461/1772 [08:54<01:53,  2.74it/s, running training loss: 1.0165]\u001b[A\n",
            "Training:  82%|████████▏ | 1461/1772 [08:54<01:53,  2.74it/s, running training loss: 0.9574]\u001b[A\n",
            "Training:  83%|████████▎ | 1462/1772 [08:54<01:55,  2.68it/s, running training loss: 0.9574]\u001b[A\n",
            "Training:  83%|████████▎ | 1462/1772 [08:54<01:55,  2.68it/s, running training loss: 0.9297]\u001b[A\n",
            "Training:  83%|████████▎ | 1463/1772 [08:54<01:47,  2.88it/s, running training loss: 0.9297]\u001b[A\n",
            "Training:  83%|████████▎ | 1463/1772 [08:55<01:47,  2.88it/s, running training loss: 0.9322]\u001b[A\n",
            "Training:  83%|████████▎ | 1464/1772 [08:55<01:41,  3.03it/s, running training loss: 0.9322]\u001b[A\n",
            "Training:  83%|████████▎ | 1464/1772 [08:55<01:41,  3.03it/s, running training loss: 0.8517]\u001b[A\n",
            "Training:  83%|████████▎ | 1465/1772 [08:55<01:59,  2.57it/s, running training loss: 0.8517]\u001b[A\n",
            "Training:  83%|████████▎ | 1465/1772 [08:56<01:59,  2.57it/s, running training loss: 0.6362]\u001b[A\n",
            "Training:  83%|████████▎ | 1466/1772 [08:56<01:53,  2.70it/s, running training loss: 0.6362]\u001b[A\n",
            "Training:  83%|████████▎ | 1466/1772 [08:56<01:53,  2.70it/s, running training loss: 0.7189]\u001b[A\n",
            "Training:  83%|████████▎ | 1467/1772 [08:56<01:47,  2.85it/s, running training loss: 0.7189]\u001b[A\n",
            "Training:  83%|████████▎ | 1467/1772 [08:56<01:47,  2.85it/s, running training loss: 0.8424]\u001b[A\n",
            "Training:  83%|████████▎ | 1468/1772 [08:56<01:40,  3.01it/s, running training loss: 0.8424]\u001b[A\n",
            "Training:  83%|████████▎ | 1468/1772 [08:56<01:40,  3.01it/s, running training loss: 0.7076]\u001b[A\n",
            "Training:  83%|████████▎ | 1469/1772 [08:56<01:35,  3.18it/s, running training loss: 0.7076]\u001b[A\n",
            "Training:  83%|████████▎ | 1469/1772 [08:57<01:35,  3.18it/s, running training loss: 0.8017]\u001b[A\n",
            "Training:  83%|████████▎ | 1470/1772 [08:57<01:41,  2.97it/s, running training loss: 0.8017]\u001b[A\n",
            "Training:  83%|████████▎ | 1470/1772 [08:57<01:41,  2.97it/s, running training loss: 0.8451]\u001b[A\n",
            "Training:  83%|████████▎ | 1471/1772 [08:57<01:48,  2.78it/s, running training loss: 0.8451]\u001b[A\n",
            "Training:  83%|████████▎ | 1471/1772 [08:58<01:48,  2.78it/s, running training loss: 1.1973]\u001b[A\n",
            "Training:  83%|████████▎ | 1472/1772 [08:58<01:45,  2.84it/s, running training loss: 1.1973]\u001b[A\n",
            "Training:  83%|████████▎ | 1472/1772 [08:58<01:45,  2.84it/s, running training loss: 1.1927]\u001b[A\n",
            "Training:  83%|████████▎ | 1473/1772 [08:58<01:46,  2.81it/s, running training loss: 1.1927]\u001b[A\n",
            "Training:  83%|████████▎ | 1473/1772 [08:58<01:46,  2.81it/s, running training loss: 1.2511]\u001b[A\n",
            "Training:  83%|████████▎ | 1474/1772 [08:58<01:39,  3.01it/s, running training loss: 1.2511]\u001b[A\n",
            "Training:  83%|████████▎ | 1474/1772 [08:59<01:39,  3.01it/s, running training loss: 1.0542]\u001b[A\n",
            "Training:  83%|████████▎ | 1475/1772 [08:59<01:43,  2.87it/s, running training loss: 1.0542]\u001b[A\n",
            "Training:  83%|████████▎ | 1475/1772 [08:59<01:43,  2.87it/s, running training loss: 1.4888]\u001b[A\n",
            "Training:  83%|████████▎ | 1476/1772 [08:59<01:41,  2.92it/s, running training loss: 1.4888]\u001b[A\n",
            "Training:  83%|████████▎ | 1476/1772 [08:59<01:41,  2.92it/s, running training loss: 0.9684]\u001b[A\n",
            "Training:  83%|████████▎ | 1477/1772 [08:59<01:42,  2.87it/s, running training loss: 0.9684]\u001b[A\n",
            "Training:  83%|████████▎ | 1477/1772 [09:00<01:42,  2.87it/s, running training loss: 1.0474]\u001b[A\n",
            "Training:  83%|████████▎ | 1478/1772 [09:00<01:40,  2.91it/s, running training loss: 1.0474]\u001b[A\n",
            "Training:  83%|████████▎ | 1478/1772 [09:00<01:40,  2.91it/s, running training loss: 0.9743]\u001b[A\n",
            "Training:  83%|████████▎ | 1479/1772 [09:00<01:50,  2.65it/s, running training loss: 0.9743]\u001b[A\n",
            "Training:  83%|████████▎ | 1479/1772 [09:00<01:50,  2.65it/s, running training loss: 1.0087]\u001b[A\n",
            "Training:  84%|████████▎ | 1480/1772 [09:00<01:44,  2.79it/s, running training loss: 1.0087]\u001b[A\n",
            "Training:  84%|████████▎ | 1480/1772 [09:01<01:44,  2.79it/s, running training loss: 0.8460]\u001b[A\n",
            "Training:  84%|████████▎ | 1481/1772 [09:01<01:40,  2.89it/s, running training loss: 0.8460]\u001b[A\n",
            "Training:  84%|████████▎ | 1481/1772 [09:01<01:40,  2.89it/s, running training loss: 0.8146]\u001b[A\n",
            "Training:  84%|████████▎ | 1482/1772 [09:01<01:40,  2.89it/s, running training loss: 0.8146]\u001b[A\n",
            "Training:  84%|████████▎ | 1482/1772 [09:01<01:40,  2.89it/s, running training loss: 0.9451]\u001b[A\n",
            "Training:  84%|████████▎ | 1483/1772 [09:01<01:43,  2.78it/s, running training loss: 0.9451]\u001b[A\n",
            "Training:  84%|████████▎ | 1483/1772 [09:02<01:43,  2.78it/s, running training loss: 1.1280]\u001b[A\n",
            "Training:  84%|████████▎ | 1484/1772 [09:02<01:39,  2.91it/s, running training loss: 1.1280]\u001b[A\n",
            "Training:  84%|████████▎ | 1484/1772 [09:02<01:39,  2.91it/s, running training loss: 0.8454]\u001b[A\n",
            "Training:  84%|████████▍ | 1485/1772 [09:02<01:48,  2.64it/s, running training loss: 0.8454]\u001b[A\n",
            "Training:  84%|████████▍ | 1485/1772 [09:03<01:48,  2.64it/s, running training loss: 0.9583]\u001b[A\n",
            "Training:  84%|████████▍ | 1486/1772 [09:03<01:45,  2.72it/s, running training loss: 0.9583]\u001b[A\n",
            "Training:  84%|████████▍ | 1486/1772 [09:03<01:45,  2.72it/s, running training loss: 0.8514]\u001b[A\n",
            "Training:  84%|████████▍ | 1487/1772 [09:03<01:40,  2.84it/s, running training loss: 0.8514]\u001b[A\n",
            "Training:  84%|████████▍ | 1487/1772 [09:03<01:40,  2.84it/s, running training loss: 1.2179]\u001b[A\n",
            "Training:  84%|████████▍ | 1488/1772 [09:03<01:39,  2.86it/s, running training loss: 1.2179]\u001b[A\n",
            "Training:  84%|████████▍ | 1488/1772 [09:04<01:39,  2.86it/s, running training loss: 0.8544]\u001b[A\n",
            "Training:  84%|████████▍ | 1489/1772 [09:04<01:38,  2.88it/s, running training loss: 0.8544]\u001b[A\n",
            "Training:  84%|████████▍ | 1489/1772 [09:04<01:38,  2.88it/s, running training loss: 1.0743]\u001b[A\n",
            "Training:  84%|████████▍ | 1490/1772 [09:04<01:36,  2.93it/s, running training loss: 1.0743]\u001b[A\n",
            "Training:  84%|████████▍ | 1490/1772 [09:04<01:36,  2.93it/s, running training loss: 1.0288]\u001b[A\n",
            "Training:  84%|████████▍ | 1491/1772 [09:04<01:32,  3.03it/s, running training loss: 1.0288]\u001b[A\n",
            "Training:  84%|████████▍ | 1491/1772 [09:05<01:32,  3.03it/s, running training loss: 1.0923]\u001b[A\n",
            "Training:  84%|████████▍ | 1492/1772 [09:05<01:38,  2.85it/s, running training loss: 1.0923]\u001b[A\n",
            "Training:  84%|████████▍ | 1492/1772 [09:05<01:38,  2.85it/s, running training loss: 1.0622]\u001b[A\n",
            "Training:  84%|████████▍ | 1493/1772 [09:05<01:40,  2.77it/s, running training loss: 1.0622]\u001b[A\n",
            "Training:  84%|████████▍ | 1493/1772 [09:05<01:40,  2.77it/s, running training loss: 0.7954]\u001b[A\n",
            "Training:  84%|████████▍ | 1494/1772 [09:05<01:39,  2.80it/s, running training loss: 0.7954]\u001b[A\n",
            "Training:  84%|████████▍ | 1494/1772 [09:06<01:39,  2.80it/s, running training loss: 0.9646]\u001b[A\n",
            "Training:  84%|████████▍ | 1495/1772 [09:06<01:33,  2.98it/s, running training loss: 0.9646]\u001b[A\n",
            "Training:  84%|████████▍ | 1495/1772 [09:06<01:33,  2.98it/s, running training loss: 1.0018]\u001b[A\n",
            "Training:  84%|████████▍ | 1496/1772 [09:06<01:36,  2.87it/s, running training loss: 1.0018]\u001b[A\n",
            "Training:  84%|████████▍ | 1496/1772 [09:06<01:36,  2.87it/s, running training loss: 0.8526]\u001b[A\n",
            "Training:  84%|████████▍ | 1497/1772 [09:06<01:30,  3.04it/s, running training loss: 0.8526]\u001b[A\n",
            "Training:  84%|████████▍ | 1497/1772 [09:07<01:30,  3.04it/s, running training loss: 0.9171]\u001b[A\n",
            "Training:  85%|████████▍ | 1498/1772 [09:07<01:27,  3.13it/s, running training loss: 0.9171]\u001b[A\n",
            "Training:  85%|████████▍ | 1498/1772 [09:07<01:27,  3.13it/s, running training loss: 0.9789]\u001b[A\n",
            "Training:  85%|████████▍ | 1499/1772 [09:07<01:27,  3.13it/s, running training loss: 0.9789]\u001b[A\n",
            "Training:  85%|████████▍ | 1499/1772 [09:07<01:27,  3.13it/s, running training loss: 0.9365]\u001b[A\n",
            "Training:  85%|████████▍ | 1500/1772 [09:07<01:26,  3.14it/s, running training loss: 0.9365]\u001b[A\n",
            "Training:  85%|████████▍ | 1500/1772 [09:08<01:26,  3.14it/s, running training loss: 0.9801]\u001b[A\n",
            "Training:  85%|████████▍ | 1501/1772 [09:08<01:28,  3.05it/s, running training loss: 0.9801]\u001b[A\n",
            "Training:  85%|████████▍ | 1501/1772 [09:08<01:28,  3.05it/s, running training loss: 1.0162]\u001b[A\n",
            "Training:  85%|████████▍ | 1502/1772 [09:08<01:31,  2.96it/s, running training loss: 1.0162]\u001b[A\n",
            "Training:  85%|████████▍ | 1502/1772 [09:08<01:31,  2.96it/s, running training loss: 0.8907]\u001b[A\n",
            "Training:  85%|████████▍ | 1503/1772 [09:08<01:28,  3.03it/s, running training loss: 0.8907]\u001b[A\n",
            "Training:  85%|████████▍ | 1503/1772 [09:09<01:28,  3.03it/s, running training loss: 0.7712]\u001b[A\n",
            "Training:  85%|████████▍ | 1504/1772 [09:09<01:37,  2.75it/s, running training loss: 0.7712]\u001b[A\n",
            "Training:  85%|████████▍ | 1504/1772 [09:09<01:37,  2.75it/s, running training loss: 0.9695]\u001b[A\n",
            "Training:  85%|████████▍ | 1505/1772 [09:09<01:36,  2.78it/s, running training loss: 0.9695]\u001b[A\n",
            "Training:  85%|████████▍ | 1505/1772 [09:09<01:36,  2.78it/s, running training loss: 0.9870]\u001b[A\n",
            "Training:  85%|████████▍ | 1506/1772 [09:09<01:33,  2.85it/s, running training loss: 0.9870]\u001b[A\n",
            "Training:  85%|████████▍ | 1506/1772 [09:10<01:33,  2.85it/s, running training loss: 0.8195]\u001b[A\n",
            "Training:  85%|████████▌ | 1507/1772 [09:10<01:24,  3.12it/s, running training loss: 0.8195]\u001b[A\n",
            "Training:  85%|████████▌ | 1507/1772 [09:10<01:24,  3.12it/s, running training loss: 0.8990]\u001b[A\n",
            "Training:  85%|████████▌ | 1508/1772 [09:10<01:26,  3.04it/s, running training loss: 0.8990]\u001b[A\n",
            "Training:  85%|████████▌ | 1508/1772 [09:10<01:26,  3.04it/s, running training loss: 0.6850]\u001b[A\n",
            "Training:  85%|████████▌ | 1509/1772 [09:10<01:25,  3.06it/s, running training loss: 0.6850]\u001b[A\n",
            "Training:  85%|████████▌ | 1509/1772 [09:11<01:25,  3.06it/s, running training loss: 1.0883]\u001b[A\n",
            "Training:  85%|████████▌ | 1510/1772 [09:11<01:26,  3.04it/s, running training loss: 1.0883]\u001b[A\n",
            "Training:  85%|████████▌ | 1510/1772 [09:11<01:26,  3.04it/s, running training loss: 0.9880]\u001b[A\n",
            "Training:  85%|████████▌ | 1511/1772 [09:11<01:22,  3.16it/s, running training loss: 0.9880]\u001b[A\n",
            "Training:  85%|████████▌ | 1511/1772 [09:11<01:22,  3.16it/s, running training loss: 0.8938]\u001b[A\n",
            "Training:  85%|████████▌ | 1512/1772 [09:11<01:28,  2.92it/s, running training loss: 0.8938]\u001b[A\n",
            "Training:  85%|████████▌ | 1512/1772 [09:12<01:28,  2.92it/s, running training loss: 1.1644]\u001b[A\n",
            "Training:  85%|████████▌ | 1513/1772 [09:12<01:26,  2.99it/s, running training loss: 1.1644]\u001b[A\n",
            "Training:  85%|████████▌ | 1513/1772 [09:12<01:26,  2.99it/s, running training loss: 1.0433]\u001b[A\n",
            "Training:  85%|████████▌ | 1514/1772 [09:12<01:28,  2.91it/s, running training loss: 1.0433]\u001b[A\n",
            "Training:  85%|████████▌ | 1514/1772 [09:12<01:28,  2.91it/s, running training loss: 0.9244]\u001b[A\n",
            "Training:  85%|████████▌ | 1515/1772 [09:12<01:24,  3.03it/s, running training loss: 0.9244]\u001b[A\n",
            "Training:  85%|████████▌ | 1515/1772 [09:13<01:24,  3.03it/s, running training loss: 0.9283]\u001b[A\n",
            "Training:  86%|████████▌ | 1516/1772 [09:13<01:21,  3.14it/s, running training loss: 0.9283]\u001b[A\n",
            "Training:  86%|████████▌ | 1516/1772 [09:13<01:21,  3.14it/s, running training loss: 0.8675]\u001b[A\n",
            "Training:  86%|████████▌ | 1517/1772 [09:13<01:21,  3.13it/s, running training loss: 0.8675]\u001b[A\n",
            "Training:  86%|████████▌ | 1517/1772 [09:13<01:21,  3.13it/s, running training loss: 0.7577]\u001b[A\n",
            "Training:  86%|████████▌ | 1518/1772 [09:13<01:17,  3.29it/s, running training loss: 0.7577]\u001b[A\n",
            "Training:  86%|████████▌ | 1518/1772 [09:13<01:17,  3.29it/s, running training loss: 0.7717]\u001b[A\n",
            "Training:  86%|████████▌ | 1519/1772 [09:13<01:13,  3.42it/s, running training loss: 0.7717]\u001b[A\n",
            "Training:  86%|████████▌ | 1519/1772 [09:14<01:13,  3.42it/s, running training loss: 0.8096]\u001b[A\n",
            "Training:  86%|████████▌ | 1520/1772 [09:14<01:15,  3.32it/s, running training loss: 0.8096]\u001b[A\n",
            "Training:  86%|████████▌ | 1520/1772 [09:14<01:15,  3.32it/s, running training loss: 0.7771]\u001b[A\n",
            "Training:  86%|████████▌ | 1521/1772 [09:14<01:24,  2.95it/s, running training loss: 0.7771]\u001b[A\n",
            "Training:  86%|████████▌ | 1521/1772 [09:14<01:24,  2.95it/s, running training loss: 1.0184]\u001b[A\n",
            "Training:  86%|████████▌ | 1522/1772 [09:14<01:18,  3.20it/s, running training loss: 1.0184]\u001b[A\n",
            "Training:  86%|████████▌ | 1522/1772 [09:15<01:18,  3.20it/s, running training loss: 1.3684]\u001b[A\n",
            "Training:  86%|████████▌ | 1523/1772 [09:15<01:16,  3.27it/s, running training loss: 1.3684]\u001b[A\n",
            "Training:  86%|████████▌ | 1523/1772 [09:15<01:16,  3.27it/s, running training loss: 1.0683]\u001b[A\n",
            "Training:  86%|████████▌ | 1524/1772 [09:15<01:14,  3.31it/s, running training loss: 1.0683]\u001b[A\n",
            "Training:  86%|████████▌ | 1524/1772 [09:15<01:14,  3.31it/s, running training loss: 1.2085]\u001b[A\n",
            "Training:  86%|████████▌ | 1525/1772 [09:15<01:22,  3.01it/s, running training loss: 1.2085]\u001b[A\n",
            "Training:  86%|████████▌ | 1525/1772 [09:16<01:22,  3.01it/s, running training loss: 1.4467]\u001b[A\n",
            "Training:  86%|████████▌ | 1526/1772 [09:16<01:18,  3.12it/s, running training loss: 1.4467]\u001b[A\n",
            "Training:  86%|████████▌ | 1526/1772 [09:16<01:18,  3.12it/s, running training loss: 0.9011]\u001b[A\n",
            "Training:  86%|████████▌ | 1527/1772 [09:16<01:21,  2.99it/s, running training loss: 0.9011]\u001b[A\n",
            "Training:  86%|████████▌ | 1527/1772 [09:16<01:21,  2.99it/s, running training loss: 0.5698]\u001b[A\n",
            "Training:  86%|████████▌ | 1528/1772 [09:16<01:20,  3.03it/s, running training loss: 0.5698]\u001b[A\n",
            "Training:  86%|████████▌ | 1528/1772 [09:17<01:20,  3.03it/s, running training loss: 0.8542]\u001b[A\n",
            "Training:  86%|████████▋ | 1529/1772 [09:17<01:24,  2.89it/s, running training loss: 0.8542]\u001b[A\n",
            "Training:  86%|████████▋ | 1529/1772 [09:17<01:24,  2.89it/s, running training loss: 1.0734]\u001b[A\n",
            "Training:  86%|████████▋ | 1530/1772 [09:17<01:22,  2.93it/s, running training loss: 1.0734]\u001b[A\n",
            "Training:  86%|████████▋ | 1530/1772 [09:18<01:22,  2.93it/s, running training loss: 0.8342]\u001b[A\n",
            "Training:  86%|████████▋ | 1531/1772 [09:18<01:30,  2.67it/s, running training loss: 0.8342]\u001b[A\n",
            "Training:  86%|████████▋ | 1531/1772 [09:18<01:30,  2.67it/s, running training loss: 0.6756]\u001b[A\n",
            "Training:  86%|████████▋ | 1532/1772 [09:18<01:34,  2.55it/s, running training loss: 0.6756]\u001b[A\n",
            "Training:  86%|████████▋ | 1532/1772 [09:18<01:34,  2.55it/s, running training loss: 1.0280]\u001b[A\n",
            "Training:  87%|████████▋ | 1533/1772 [09:18<01:28,  2.69it/s, running training loss: 1.0280]\u001b[A\n",
            "Training:  87%|████████▋ | 1533/1772 [09:19<01:28,  2.69it/s, running training loss: 0.7412]\u001b[A\n",
            "Training:  87%|████████▋ | 1534/1772 [09:19<01:32,  2.58it/s, running training loss: 0.7412]\u001b[A\n",
            "Training:  87%|████████▋ | 1534/1772 [09:19<01:32,  2.58it/s, running training loss: 0.7857]\u001b[A\n",
            "Training:  87%|████████▋ | 1535/1772 [09:19<01:24,  2.81it/s, running training loss: 0.7857]\u001b[A\n",
            "Training:  87%|████████▋ | 1535/1772 [09:19<01:24,  2.81it/s, running training loss: 1.1586]\u001b[A\n",
            "Training:  87%|████████▋ | 1536/1772 [09:19<01:24,  2.79it/s, running training loss: 1.1586]\u001b[A\n",
            "Training:  87%|████████▋ | 1536/1772 [09:20<01:24,  2.79it/s, running training loss: 1.0229]\u001b[A\n",
            "Training:  87%|████████▋ | 1537/1772 [09:20<01:24,  2.80it/s, running training loss: 1.0229]\u001b[A\n",
            "Training:  87%|████████▋ | 1537/1772 [09:20<01:24,  2.80it/s, running training loss: 1.0736]\u001b[A\n",
            "Training:  87%|████████▋ | 1538/1772 [09:20<01:15,  3.09it/s, running training loss: 1.0736]\u001b[A\n",
            "Training:  87%|████████▋ | 1538/1772 [09:20<01:15,  3.09it/s, running training loss: 1.2410]\u001b[A\n",
            "Training:  87%|████████▋ | 1539/1772 [09:20<01:17,  3.00it/s, running training loss: 1.2410]\u001b[A\n",
            "Training:  87%|████████▋ | 1539/1772 [09:21<01:17,  3.00it/s, running training loss: 0.7879]\u001b[A\n",
            "Training:  87%|████████▋ | 1540/1772 [09:21<01:26,  2.69it/s, running training loss: 0.7879]\u001b[A\n",
            "Training:  87%|████████▋ | 1540/1772 [09:21<01:26,  2.69it/s, running training loss: 1.2387]\u001b[A\n",
            "Training:  87%|████████▋ | 1541/1772 [09:21<01:22,  2.81it/s, running training loss: 1.2387]\u001b[A\n",
            "Training:  87%|████████▋ | 1541/1772 [09:21<01:22,  2.81it/s, running training loss: 0.6898]\u001b[A\n",
            "Training:  87%|████████▋ | 1542/1772 [09:21<01:19,  2.91it/s, running training loss: 0.6898]\u001b[A\n",
            "Training:  87%|████████▋ | 1542/1772 [09:22<01:19,  2.91it/s, running training loss: 1.1662]\u001b[A\n",
            "Training:  87%|████████▋ | 1543/1772 [09:22<01:35,  2.39it/s, running training loss: 1.1662]\u001b[A\n",
            "Training:  87%|████████▋ | 1543/1772 [09:22<01:35,  2.39it/s, running training loss: 1.0113]\u001b[A\n",
            "Training:  87%|████████▋ | 1544/1772 [09:22<01:30,  2.51it/s, running training loss: 1.0113]\u001b[A\n",
            "Training:  87%|████████▋ | 1544/1772 [09:23<01:30,  2.51it/s, running training loss: 1.0607]\u001b[A\n",
            "Training:  87%|████████▋ | 1545/1772 [09:23<01:28,  2.56it/s, running training loss: 1.0607]\u001b[A\n",
            "Training:  87%|████████▋ | 1545/1772 [09:23<01:28,  2.56it/s, running training loss: 1.0188]\u001b[A\n",
            "Training:  87%|████████▋ | 1546/1772 [09:23<01:20,  2.82it/s, running training loss: 1.0188]\u001b[A\n",
            "Training:  87%|████████▋ | 1546/1772 [09:24<01:20,  2.82it/s, running training loss: 0.9390]\u001b[A\n",
            "Training:  87%|████████▋ | 1547/1772 [09:24<01:29,  2.50it/s, running training loss: 0.9390]\u001b[A\n",
            "Training:  87%|████████▋ | 1547/1772 [09:24<01:29,  2.50it/s, running training loss: 0.9654]\u001b[A\n",
            "Training:  87%|████████▋ | 1548/1772 [09:24<01:27,  2.55it/s, running training loss: 0.9654]\u001b[A\n",
            "Training:  87%|████████▋ | 1548/1772 [09:24<01:27,  2.55it/s, running training loss: 0.8246]\u001b[A\n",
            "Training:  87%|████████▋ | 1549/1772 [09:24<01:21,  2.74it/s, running training loss: 0.8246]\u001b[A\n",
            "Training:  87%|████████▋ | 1549/1772 [09:24<01:21,  2.74it/s, running training loss: 0.8192]\u001b[A\n",
            "Training:  87%|████████▋ | 1550/1772 [09:25<01:17,  2.86it/s, running training loss: 0.8192]\u001b[A\n",
            "Training:  87%|████████▋ | 1550/1772 [09:25<01:17,  2.86it/s, running training loss: 0.6198]\u001b[A\n",
            "Training:  88%|████████▊ | 1551/1772 [09:25<01:26,  2.55it/s, running training loss: 0.6198]\u001b[A\n",
            "Training:  88%|████████▊ | 1551/1772 [09:25<01:26,  2.55it/s, running training loss: 0.7164]\u001b[A\n",
            "Training:  88%|████████▊ | 1552/1772 [09:25<01:27,  2.52it/s, running training loss: 0.7164]\u001b[A\n",
            "Training:  88%|████████▊ | 1552/1772 [09:26<01:27,  2.52it/s, running training loss: 0.7635]\u001b[A\n",
            "Training:  88%|████████▊ | 1553/1772 [09:26<01:24,  2.59it/s, running training loss: 0.7635]\u001b[A\n",
            "Training:  88%|████████▊ | 1553/1772 [09:26<01:24,  2.59it/s, running training loss: 0.8903]\u001b[A\n",
            "Training:  88%|████████▊ | 1554/1772 [09:26<01:20,  2.70it/s, running training loss: 0.8903]\u001b[A\n",
            "Training:  88%|████████▊ | 1554/1772 [09:27<01:20,  2.70it/s, running training loss: 0.8072]\u001b[A\n",
            "Training:  88%|████████▊ | 1555/1772 [09:27<01:34,  2.29it/s, running training loss: 0.8072]\u001b[A\n",
            "Training:  88%|████████▊ | 1555/1772 [09:27<01:34,  2.29it/s, running training loss: 0.9974]\u001b[A\n",
            "Training:  88%|████████▊ | 1556/1772 [09:27<01:24,  2.54it/s, running training loss: 0.9974]\u001b[A\n",
            "Training:  88%|████████▊ | 1556/1772 [09:27<01:24,  2.54it/s, running training loss: 1.1306]\u001b[A\n",
            "Training:  88%|████████▊ | 1557/1772 [09:27<01:20,  2.66it/s, running training loss: 1.1306]\u001b[A\n",
            "Training:  88%|████████▊ | 1557/1772 [09:28<01:20,  2.66it/s, running training loss: 0.9252]\u001b[A\n",
            "Training:  88%|████████▊ | 1558/1772 [09:28<01:21,  2.63it/s, running training loss: 0.9252]\u001b[A\n",
            "Training:  88%|████████▊ | 1558/1772 [09:28<01:21,  2.63it/s, running training loss: 0.7640]\u001b[A\n",
            "Training:  88%|████████▊ | 1559/1772 [09:28<01:17,  2.76it/s, running training loss: 0.7640]\u001b[A\n",
            "Training:  88%|████████▊ | 1559/1772 [09:28<01:17,  2.76it/s, running training loss: 0.9504]\u001b[A\n",
            "Training:  88%|████████▊ | 1560/1772 [09:28<01:14,  2.84it/s, running training loss: 0.9504]\u001b[A\n",
            "Training:  88%|████████▊ | 1560/1772 [09:29<01:14,  2.84it/s, running training loss: 1.1231]\u001b[A\n",
            "Training:  88%|████████▊ | 1561/1772 [09:29<01:10,  2.97it/s, running training loss: 1.1231]\u001b[A\n",
            "Training:  88%|████████▊ | 1561/1772 [09:29<01:10,  2.97it/s, running training loss: 1.2146]\u001b[A\n",
            "Training:  88%|████████▊ | 1562/1772 [09:29<01:13,  2.88it/s, running training loss: 1.2146]\u001b[A\n",
            "Training:  88%|████████▊ | 1562/1772 [09:30<01:13,  2.88it/s, running training loss: 0.8103]\u001b[A\n",
            "Training:  88%|████████▊ | 1563/1772 [09:30<01:22,  2.53it/s, running training loss: 0.8103]\u001b[A\n",
            "Training:  88%|████████▊ | 1563/1772 [09:30<01:22,  2.53it/s, running training loss: 0.9869]\u001b[A\n",
            "Training:  88%|████████▊ | 1564/1772 [09:30<01:12,  2.88it/s, running training loss: 0.9869]\u001b[A\n",
            "Training:  88%|████████▊ | 1564/1772 [09:30<01:12,  2.88it/s, running training loss: 1.1528]\u001b[A\n",
            "Training:  88%|████████▊ | 1565/1772 [09:30<01:09,  2.97it/s, running training loss: 1.1528]\u001b[A\n",
            "Training:  88%|████████▊ | 1565/1772 [09:31<01:09,  2.97it/s, running training loss: 1.1690]\u001b[A\n",
            "Training:  88%|████████▊ | 1566/1772 [09:31<01:15,  2.72it/s, running training loss: 1.1690]\u001b[A\n",
            "Training:  88%|████████▊ | 1566/1772 [09:31<01:15,  2.72it/s, running training loss: 1.0636]\u001b[A\n",
            "Training:  88%|████████▊ | 1567/1772 [09:31<01:09,  2.94it/s, running training loss: 1.0636]\u001b[A\n",
            "Training:  88%|████████▊ | 1567/1772 [09:31<01:09,  2.94it/s, running training loss: 1.0532]\u001b[A\n",
            "Training:  88%|████████▊ | 1568/1772 [09:31<01:08,  2.96it/s, running training loss: 1.0532]\u001b[A\n",
            "Training:  88%|████████▊ | 1568/1772 [09:31<01:08,  2.96it/s, running training loss: 0.8790]\u001b[A\n",
            "Training:  89%|████████▊ | 1569/1772 [09:31<01:09,  2.92it/s, running training loss: 0.8790]\u001b[A\n",
            "Training:  89%|████████▊ | 1569/1772 [09:32<01:09,  2.92it/s, running training loss: 0.7530]\u001b[A\n",
            "Training:  89%|████████▊ | 1570/1772 [09:32<01:24,  2.39it/s, running training loss: 0.7530]\u001b[A\n",
            "Training:  89%|████████▊ | 1570/1772 [09:32<01:24,  2.39it/s, running training loss: 0.9251]\u001b[A\n",
            "Training:  89%|████████▊ | 1571/1772 [09:32<01:24,  2.39it/s, running training loss: 0.9251]\u001b[A\n",
            "Training:  89%|████████▊ | 1571/1772 [09:33<01:24,  2.39it/s, running training loss: 0.8203]\u001b[A\n",
            "Training:  89%|████████▊ | 1572/1772 [09:33<01:30,  2.20it/s, running training loss: 0.8203]\u001b[A\n",
            "Training:  89%|████████▊ | 1572/1772 [09:33<01:30,  2.20it/s, running training loss: 0.6473]\u001b[A\n",
            "Training:  89%|████████▉ | 1573/1772 [09:33<01:20,  2.48it/s, running training loss: 0.6473]\u001b[A\n",
            "Training:  89%|████████▉ | 1573/1772 [09:34<01:20,  2.48it/s, running training loss: 0.8566]\u001b[A\n",
            "Training:  89%|████████▉ | 1574/1772 [09:34<01:11,  2.77it/s, running training loss: 0.8566]\u001b[A\n",
            "Training:  89%|████████▉ | 1574/1772 [09:34<01:11,  2.77it/s, running training loss: 0.8829]\u001b[A\n",
            "Training:  89%|████████▉ | 1575/1772 [09:34<01:07,  2.90it/s, running training loss: 0.8829]\u001b[A\n",
            "Training:  89%|████████▉ | 1575/1772 [09:34<01:07,  2.90it/s, running training loss: 0.7197]\u001b[A\n",
            "Training:  89%|████████▉ | 1576/1772 [09:34<01:09,  2.82it/s, running training loss: 0.7197]\u001b[A\n",
            "Training:  89%|████████▉ | 1576/1772 [09:35<01:09,  2.82it/s, running training loss: 0.7336]\u001b[A\n",
            "Training:  89%|████████▉ | 1577/1772 [09:35<01:08,  2.86it/s, running training loss: 0.7336]\u001b[A\n",
            "Training:  89%|████████▉ | 1577/1772 [09:35<01:08,  2.86it/s, running training loss: 0.7318]\u001b[A\n",
            "Training:  89%|████████▉ | 1578/1772 [09:35<01:03,  3.07it/s, running training loss: 0.7318]\u001b[A\n",
            "Training:  89%|████████▉ | 1578/1772 [09:35<01:03,  3.07it/s, running training loss: 0.9419]\u001b[A\n",
            "Training:  89%|████████▉ | 1579/1772 [09:35<01:02,  3.08it/s, running training loss: 0.9419]\u001b[A\n",
            "Training:  89%|████████▉ | 1579/1772 [09:36<01:02,  3.08it/s, running training loss: 0.7776]\u001b[A\n",
            "Training:  89%|████████▉ | 1580/1772 [09:36<01:08,  2.80it/s, running training loss: 0.7776]\u001b[A\n",
            "Training:  89%|████████▉ | 1580/1772 [09:36<01:08,  2.80it/s, running training loss: 1.0090]\u001b[A\n",
            "Training:  89%|████████▉ | 1581/1772 [09:36<01:13,  2.61it/s, running training loss: 1.0090]\u001b[A\n",
            "Training:  89%|████████▉ | 1581/1772 [09:36<01:13,  2.61it/s, running training loss: 0.5164]\u001b[A\n",
            "Training:  89%|████████▉ | 1582/1772 [09:36<01:13,  2.59it/s, running training loss: 0.5164]\u001b[A\n",
            "Training:  89%|████████▉ | 1582/1772 [09:37<01:13,  2.59it/s, running training loss: 0.8640]\u001b[A\n",
            "Training:  89%|████████▉ | 1583/1772 [09:37<01:08,  2.77it/s, running training loss: 0.8640]\u001b[A\n",
            "Training:  89%|████████▉ | 1583/1772 [09:37<01:08,  2.77it/s, running training loss: 1.0031]\u001b[A\n",
            "Training:  89%|████████▉ | 1584/1772 [09:37<01:11,  2.63it/s, running training loss: 1.0031]\u001b[A\n",
            "Training:  89%|████████▉ | 1584/1772 [09:38<01:11,  2.63it/s, running training loss: 0.9095]\u001b[A\n",
            "Training:  89%|████████▉ | 1585/1772 [09:38<01:13,  2.56it/s, running training loss: 0.9095]\u001b[A\n",
            "Training:  89%|████████▉ | 1585/1772 [09:38<01:13,  2.56it/s, running training loss: 0.8370]\u001b[A\n",
            "Training:  90%|████████▉ | 1586/1772 [09:38<01:07,  2.77it/s, running training loss: 0.8370]\u001b[A\n",
            "Training:  90%|████████▉ | 1586/1772 [09:38<01:07,  2.77it/s, running training loss: 1.1203]\u001b[A\n",
            "Training:  90%|████████▉ | 1587/1772 [09:38<01:03,  2.93it/s, running training loss: 1.1203]\u001b[A\n",
            "Training:  90%|████████▉ | 1587/1772 [09:38<01:03,  2.93it/s, running training loss: 1.3889]\u001b[A\n",
            "Training:  90%|████████▉ | 1588/1772 [09:38<01:00,  3.05it/s, running training loss: 1.3889]\u001b[A\n",
            "Training:  90%|████████▉ | 1588/1772 [09:39<01:00,  3.05it/s, running training loss: 1.1124]\u001b[A\n",
            "Training:  90%|████████▉ | 1589/1772 [09:39<01:08,  2.67it/s, running training loss: 1.1124]\u001b[A\n",
            "Training:  90%|████████▉ | 1589/1772 [09:39<01:08,  2.67it/s, running training loss: 0.7190]\u001b[A\n",
            "Training:  90%|████████▉ | 1590/1772 [09:39<01:04,  2.81it/s, running training loss: 0.7190]\u001b[A\n",
            "Training:  90%|████████▉ | 1590/1772 [09:40<01:04,  2.81it/s, running training loss: 0.9656]\u001b[A\n",
            "Training:  90%|████████▉ | 1591/1772 [09:40<01:06,  2.72it/s, running training loss: 0.9656]\u001b[A\n",
            "Training:  90%|████████▉ | 1591/1772 [09:40<01:06,  2.72it/s, running training loss: 1.0413]\u001b[A\n",
            "Training:  90%|████████▉ | 1592/1772 [09:40<01:07,  2.67it/s, running training loss: 1.0413]\u001b[A\n",
            "Training:  90%|████████▉ | 1592/1772 [09:40<01:07,  2.67it/s, running training loss: 0.9640]\u001b[A\n",
            "Training:  90%|████████▉ | 1593/1772 [09:40<01:07,  2.66it/s, running training loss: 0.9640]\u001b[A\n",
            "Training:  90%|████████▉ | 1593/1772 [09:41<01:07,  2.66it/s, running training loss: 0.9512]\u001b[A\n",
            "Training:  90%|████████▉ | 1594/1772 [09:41<01:06,  2.69it/s, running training loss: 0.9512]\u001b[A\n",
            "Training:  90%|████████▉ | 1594/1772 [09:41<01:06,  2.69it/s, running training loss: 0.9647]\u001b[A\n",
            "Training:  90%|█████████ | 1595/1772 [09:41<01:03,  2.79it/s, running training loss: 0.9647]\u001b[A\n",
            "Training:  90%|█████████ | 1595/1772 [09:42<01:03,  2.79it/s, running training loss: 0.9459]\u001b[A\n",
            "Training:  90%|█████████ | 1596/1772 [09:42<01:08,  2.56it/s, running training loss: 0.9459]\u001b[A\n",
            "Training:  90%|█████████ | 1596/1772 [09:42<01:08,  2.56it/s, running training loss: 0.3922]\u001b[A\n",
            "Training:  90%|█████████ | 1597/1772 [09:42<01:05,  2.68it/s, running training loss: 0.3922]\u001b[A\n",
            "Training:  90%|█████████ | 1597/1772 [09:42<01:05,  2.68it/s, running training loss: 0.8004]\u001b[A\n",
            "Training:  90%|█████████ | 1598/1772 [09:42<01:01,  2.81it/s, running training loss: 0.8004]\u001b[A\n",
            "Training:  90%|█████████ | 1598/1772 [09:43<01:01,  2.81it/s, running training loss: 1.3060]\u001b[A\n",
            "Training:  90%|█████████ | 1599/1772 [09:43<01:11,  2.43it/s, running training loss: 1.3060]\u001b[A\n",
            "Training:  90%|█████████ | 1599/1772 [09:43<01:11,  2.43it/s, running training loss: 0.9874]\u001b[A\n",
            "\n",
            "Evaluation:   0%|          | 0/270 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   0%|          | 1/270 [00:00<01:17,  3.49it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   1%|          | 3/270 [00:00<00:32,  8.34it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   2%|▏         | 5/270 [00:00<00:22, 11.65it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   3%|▎         | 7/270 [00:00<00:18, 13.97it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   3%|▎         | 9/270 [00:00<00:17, 15.33it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   4%|▍         | 12/270 [00:00<00:14, 18.26it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   5%|▌         | 14/270 [00:00<00:14, 18.25it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   6%|▌         | 16/270 [00:01<00:13, 18.29it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   7%|▋         | 18/270 [00:01<00:14, 17.61it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   7%|▋         | 20/270 [00:01<00:14, 17.09it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   9%|▊         | 23/270 [00:01<00:12, 19.26it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   9%|▉         | 25/270 [00:01<00:12, 19.08it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  10%|█         | 28/270 [00:01<00:12, 19.02it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  11%|█         | 30/270 [00:01<00:13, 18.32it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  12%|█▏        | 32/270 [00:01<00:12, 18.58it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  13%|█▎        | 35/270 [00:02<00:12, 18.92it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  14%|█▍        | 38/270 [00:02<00:11, 20.48it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  15%|█▌        | 41/270 [00:02<00:11, 19.90it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  16%|█▋        | 44/270 [00:02<00:12, 18.72it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  17%|█▋        | 46/270 [00:02<00:12, 18.43it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  18%|█▊        | 49/270 [00:02<00:11, 19.17it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  19%|█▉        | 51/270 [00:02<00:11, 18.73it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  20%|█▉        | 53/270 [00:03<00:11, 18.76it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  21%|██        | 56/270 [00:03<00:11, 19.00it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  21%|██▏       | 58/270 [00:03<00:11, 18.58it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  22%|██▏       | 60/270 [00:03<00:11, 18.38it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  23%|██▎       | 62/270 [00:03<00:11, 17.95it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  24%|██▎       | 64/270 [00:03<00:11, 17.90it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  25%|██▍       | 67/270 [00:03<00:10, 18.98it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  26%|██▌       | 70/270 [00:03<00:09, 20.46it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  27%|██▋       | 73/270 [00:04<00:09, 20.14it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  28%|██▊       | 76/270 [00:04<00:09, 20.87it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  29%|██▉       | 79/270 [00:04<00:09, 20.08it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  30%|███       | 82/270 [00:04<00:09, 19.20it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  31%|███       | 84/270 [00:04<00:09, 19.14it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  32%|███▏      | 87/270 [00:04<00:09, 19.35it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  33%|███▎      | 89/270 [00:04<00:09, 18.29it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  34%|███▎      | 91/270 [00:05<00:09, 18.46it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  35%|███▍      | 94/270 [00:05<00:09, 19.52it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  36%|███▌      | 97/270 [00:05<00:08, 20.37it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  37%|███▋      | 100/270 [00:05<00:08, 20.17it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  38%|███▊      | 103/270 [00:05<00:08, 20.57it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  39%|███▉      | 106/270 [00:05<00:08, 20.00it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  40%|████      | 109/270 [00:05<00:08, 19.90it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  41%|████      | 111/270 [00:06<00:07, 19.88it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  42%|████▏     | 114/270 [00:06<00:07, 21.01it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  43%|████▎     | 117/270 [00:06<00:07, 19.53it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  44%|████▍     | 119/270 [00:06<00:07, 19.41it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  45%|████▌     | 122/270 [00:06<00:07, 20.13it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  46%|████▋     | 125/270 [00:06<00:07, 19.87it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  47%|████▋     | 127/270 [00:06<00:07, 18.75it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  48%|████▊     | 129/270 [00:06<00:07, 18.07it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  49%|████▉     | 132/270 [00:07<00:07, 18.64it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  50%|████▉     | 134/270 [00:07<00:07, 18.75it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  51%|█████     | 137/270 [00:07<00:06, 19.69it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  52%|█████▏    | 140/270 [00:07<00:06, 19.77it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  53%|█████▎    | 142/270 [00:07<00:06, 18.67it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  54%|█████▎    | 145/270 [00:07<00:06, 19.35it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  54%|█████▍    | 147/270 [00:07<00:06, 18.93it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  55%|█████▌    | 149/270 [00:07<00:06, 19.12it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  56%|█████▋    | 152/270 [00:08<00:06, 18.90it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  57%|█████▋    | 154/270 [00:08<00:06, 18.88it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  58%|█████▊    | 156/270 [00:08<00:06, 18.51it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  59%|█████▉    | 159/270 [00:08<00:05, 19.54it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  60%|█████▉    | 161/270 [00:08<00:05, 18.89it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  60%|██████    | 163/270 [00:08<00:05, 18.66it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  61%|██████    | 165/270 [00:08<00:05, 18.19it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  62%|██████▏   | 168/270 [00:08<00:05, 19.10it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  63%|██████▎   | 170/270 [00:09<00:05, 18.64it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  64%|██████▎   | 172/270 [00:09<00:05, 18.83it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  64%|██████▍   | 174/270 [00:09<00:05, 18.11it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  65%|██████▌   | 176/270 [00:09<00:05, 17.78it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  66%|██████▌   | 178/270 [00:09<00:05, 17.95it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  67%|██████▋   | 180/270 [00:09<00:05, 17.16it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  67%|██████▋   | 182/270 [00:09<00:05, 17.37it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  68%|██████▊   | 184/270 [00:09<00:04, 17.65it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  69%|██████▉   | 187/270 [00:10<00:04, 18.46it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  70%|███████   | 189/270 [00:10<00:04, 18.62it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  71%|███████   | 192/270 [00:10<00:04, 19.37it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  72%|███████▏  | 194/270 [00:10<00:03, 19.05it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  73%|███████▎  | 196/270 [00:10<00:03, 18.53it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  73%|███████▎  | 198/270 [00:10<00:03, 18.38it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  74%|███████▍  | 200/270 [00:10<00:03, 17.69it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  75%|███████▍  | 202/270 [00:10<00:03, 17.31it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  76%|███████▌  | 205/270 [00:11<00:03, 19.70it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  77%|███████▋  | 207/270 [00:11<00:03, 19.04it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  77%|███████▋  | 209/270 [00:11<00:03, 17.99it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  78%|███████▊  | 211/270 [00:11<00:03, 18.16it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  79%|███████▉  | 213/270 [00:11<00:03, 17.78it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  80%|████████  | 216/270 [00:11<00:02, 18.63it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  81%|████████  | 219/270 [00:11<00:02, 19.20it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  82%|████████▏ | 222/270 [00:11<00:02, 20.43it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  83%|████████▎ | 225/270 [00:12<00:02, 21.30it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  84%|████████▍ | 228/270 [00:12<00:02, 19.96it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  86%|████████▌ | 231/270 [00:12<00:02, 18.85it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  87%|████████▋ | 234/270 [00:12<00:01, 19.70it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  88%|████████▊ | 237/270 [00:12<00:01, 20.63it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  89%|████████▉ | 240/270 [00:12<00:01, 19.41it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  90%|████████▉ | 242/270 [00:12<00:01, 19.33it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  90%|█████████ | 244/270 [00:13<00:01, 19.21it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  91%|█████████ | 246/270 [00:13<00:01, 18.20it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  92%|█████████▏| 248/270 [00:13<00:01, 17.24it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  93%|█████████▎| 250/270 [00:13<00:01, 17.11it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  93%|█████████▎| 252/270 [00:13<00:01, 17.05it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  94%|█████████▍| 254/270 [00:13<00:00, 17.01it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  95%|█████████▍| 256/270 [00:13<00:00, 16.52it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  96%|█████████▌| 259/270 [00:13<00:00, 18.65it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  97%|█████████▋| 262/270 [00:14<00:00, 19.41it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  98%|█████████▊| 264/270 [00:14<00:00, 18.65it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  99%|█████████▊| 266/270 [00:14<00:00, 18.46it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  99%|█████████▉| 268/270 [00:14<00:00, 18.36it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation: 100%|██████████| 270/270 [00:14<00:00, 18.40it/s]\n",
            "\n",
            "Training:  90%|█████████ | 1600/1772 [09:58<13:47,  4.81s/it, running training loss: 0.9874]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            ">>> training loss: 0.977977, valid loss: 0.628312, valid f1: 0.000000, valid acc: 0.689991\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  90%|█████████ | 1600/1772 [09:58<13:47,  4.81s/it, running training loss: 0.8287]\u001b[A\n",
            "Training:  90%|█████████ | 1601/1772 [09:58<09:48,  3.44s/it, running training loss: 0.8287]\u001b[A\n",
            "Training:  90%|█████████ | 1601/1772 [09:58<09:48,  3.44s/it, running training loss: 0.6605]\u001b[A\n",
            "Training:  90%|█████████ | 1602/1772 [09:58<07:07,  2.51s/it, running training loss: 0.6605]\u001b[A\n",
            "Training:  90%|█████████ | 1602/1772 [09:59<07:07,  2.51s/it, running training loss: 1.0199]\u001b[A\n",
            "Training:  90%|█████████ | 1603/1772 [09:59<05:14,  1.86s/it, running training loss: 1.0199]\u001b[A\n",
            "Training:  90%|█████████ | 1603/1772 [09:59<05:14,  1.86s/it, running training loss: 0.8462]\u001b[A\n",
            "Training:  91%|█████████ | 1604/1772 [09:59<03:58,  1.42s/it, running training loss: 0.8462]\u001b[A\n",
            "Training:  91%|█████████ | 1604/1772 [09:59<03:58,  1.42s/it, running training loss: 0.6827]\u001b[A\n",
            "Training:  91%|█████████ | 1605/1772 [09:59<02:59,  1.07s/it, running training loss: 0.6827]\u001b[A\n",
            "Training:  91%|█████████ | 1605/1772 [10:00<02:59,  1.07s/it, running training loss: 0.8726]\u001b[A\n",
            "Training:  91%|█████████ | 1606/1772 [10:00<02:19,  1.19it/s, running training loss: 0.8726]\u001b[A\n",
            "Training:  91%|█████████ | 1606/1772 [10:00<02:19,  1.19it/s, running training loss: 1.0898]\u001b[A\n",
            "Training:  91%|█████████ | 1607/1772 [10:00<01:52,  1.46it/s, running training loss: 1.0898]\u001b[A\n",
            "Training:  91%|█████████ | 1607/1772 [10:00<01:52,  1.46it/s, running training loss: 1.1389]\u001b[A\n",
            "Training:  91%|█████████ | 1608/1772 [10:00<01:35,  1.72it/s, running training loss: 1.1389]\u001b[A\n",
            "Training:  91%|█████████ | 1608/1772 [10:01<01:35,  1.72it/s, running training loss: 1.1230]\u001b[A\n",
            "Training:  91%|█████████ | 1609/1772 [10:01<01:18,  2.07it/s, running training loss: 1.1230]\u001b[A\n",
            "Training:  91%|█████████ | 1609/1772 [10:01<01:18,  2.07it/s, running training loss: 0.9688]\u001b[A\n",
            "Training:  91%|█████████ | 1610/1772 [10:01<01:09,  2.33it/s, running training loss: 0.9688]\u001b[A\n",
            "Training:  91%|█████████ | 1610/1772 [10:01<01:09,  2.33it/s, running training loss: 0.8752]\u001b[A\n",
            "Training:  91%|█████████ | 1611/1772 [10:01<01:03,  2.53it/s, running training loss: 0.8752]\u001b[A\n",
            "Training:  91%|█████████ | 1611/1772 [10:02<01:03,  2.53it/s, running training loss: 0.8313]\u001b[A\n",
            "Training:  91%|█████████ | 1612/1772 [10:02<01:00,  2.63it/s, running training loss: 0.8313]\u001b[A\n",
            "Training:  91%|█████████ | 1612/1772 [10:02<01:00,  2.63it/s, running training loss: 1.0947]\u001b[A\n",
            "Training:  91%|█████████ | 1613/1772 [10:02<01:06,  2.38it/s, running training loss: 1.0947]\u001b[A\n",
            "Training:  91%|█████████ | 1613/1772 [10:02<01:06,  2.38it/s, running training loss: 0.6501]\u001b[A\n",
            "Training:  91%|█████████ | 1614/1772 [10:02<00:59,  2.64it/s, running training loss: 0.6501]\u001b[A\n",
            "Training:  91%|█████████ | 1614/1772 [10:03<00:59,  2.64it/s, running training loss: 0.9985]\u001b[A\n",
            "Training:  91%|█████████ | 1615/1772 [10:03<00:55,  2.85it/s, running training loss: 0.9985]\u001b[A\n",
            "Training:  91%|█████████ | 1615/1772 [10:03<00:55,  2.85it/s, running training loss: 1.0719]\u001b[A\n",
            "Training:  91%|█████████ | 1616/1772 [10:03<00:51,  3.01it/s, running training loss: 1.0719]\u001b[A\n",
            "Training:  91%|█████████ | 1616/1772 [10:03<00:51,  3.01it/s, running training loss: 1.0373]\u001b[A\n",
            "Training:  91%|█████████▏| 1617/1772 [10:03<00:50,  3.06it/s, running training loss: 1.0373]\u001b[A\n",
            "Training:  91%|█████████▏| 1617/1772 [10:04<00:50,  3.06it/s, running training loss: 0.6254]\u001b[A\n",
            "Training:  91%|█████████▏| 1618/1772 [10:04<00:49,  3.08it/s, running training loss: 0.6254]\u001b[A\n",
            "Training:  91%|█████████▏| 1618/1772 [10:04<00:49,  3.08it/s, running training loss: 0.8652]\u001b[A\n",
            "Training:  91%|█████████▏| 1619/1772 [10:04<00:48,  3.14it/s, running training loss: 0.8652]\u001b[A\n",
            "Training:  91%|█████████▏| 1619/1772 [10:04<00:48,  3.14it/s, running training loss: 0.5381]\u001b[A\n",
            "Training:  91%|█████████▏| 1620/1772 [10:04<00:58,  2.60it/s, running training loss: 0.5381]\u001b[A\n",
            "Training:  91%|█████████▏| 1620/1772 [10:05<00:58,  2.60it/s, running training loss: 0.8226]\u001b[A\n",
            "Training:  91%|█████████▏| 1621/1772 [10:05<00:54,  2.78it/s, running training loss: 0.8226]\u001b[A\n",
            "Training:  91%|█████████▏| 1621/1772 [10:05<00:54,  2.78it/s, running training loss: 0.7962]\u001b[A\n",
            "Training:  92%|█████████▏| 1622/1772 [10:05<00:52,  2.88it/s, running training loss: 0.7962]\u001b[A\n",
            "Training:  92%|█████████▏| 1622/1772 [10:05<00:52,  2.88it/s, running training loss: 0.5462]\u001b[A\n",
            "Training:  92%|█████████▏| 1623/1772 [10:05<00:51,  2.90it/s, running training loss: 0.5462]\u001b[A\n",
            "Training:  92%|█████████▏| 1623/1772 [10:06<00:51,  2.90it/s, running training loss: 0.5879]\u001b[A\n",
            "Training:  92%|█████████▏| 1624/1772 [10:06<00:50,  2.96it/s, running training loss: 0.5879]\u001b[A\n",
            "Training:  92%|█████████▏| 1624/1772 [10:06<00:50,  2.96it/s, running training loss: 0.6045]\u001b[A\n",
            "Training:  92%|█████████▏| 1625/1772 [10:06<00:52,  2.82it/s, running training loss: 0.6045]\u001b[A\n",
            "Training:  92%|█████████▏| 1625/1772 [10:06<00:52,  2.82it/s, running training loss: 0.8339]\u001b[A\n",
            "Training:  92%|█████████▏| 1626/1772 [10:06<00:50,  2.90it/s, running training loss: 0.8339]\u001b[A\n",
            "Training:  92%|█████████▏| 1626/1772 [10:07<00:50,  2.90it/s, running training loss: 1.0558]\u001b[A\n",
            "Training:  92%|█████████▏| 1627/1772 [10:07<00:48,  2.98it/s, running training loss: 1.0558]\u001b[A\n",
            "Training:  92%|█████████▏| 1627/1772 [10:07<00:48,  2.98it/s, running training loss: 0.9396]\u001b[A\n",
            "Training:  92%|█████████▏| 1628/1772 [10:07<00:48,  3.00it/s, running training loss: 0.9396]\u001b[A\n",
            "Training:  92%|█████████▏| 1628/1772 [10:08<00:48,  3.00it/s, running training loss: 0.9479]\u001b[A\n",
            "Training:  92%|█████████▏| 1629/1772 [10:08<00:55,  2.56it/s, running training loss: 0.9479]\u001b[A\n",
            "Training:  92%|█████████▏| 1629/1772 [10:08<00:55,  2.56it/s, running training loss: 1.1294]\u001b[A\n",
            "Training:  92%|█████████▏| 1630/1772 [10:08<00:52,  2.71it/s, running training loss: 1.1294]\u001b[A\n",
            "Training:  92%|█████████▏| 1630/1772 [10:08<00:52,  2.71it/s, running training loss: 0.9686]\u001b[A\n",
            "Training:  92%|█████████▏| 1631/1772 [10:08<00:52,  2.67it/s, running training loss: 0.9686]\u001b[A\n",
            "Training:  92%|█████████▏| 1631/1772 [10:09<00:52,  2.67it/s, running training loss: 1.1545]\u001b[A\n",
            "Training:  92%|█████████▏| 1632/1772 [10:09<00:51,  2.74it/s, running training loss: 1.1545]\u001b[A\n",
            "Training:  92%|█████████▏| 1632/1772 [10:09<00:51,  2.74it/s, running training loss: 0.6694]\u001b[A\n",
            "Training:  92%|█████████▏| 1633/1772 [10:09<00:48,  2.85it/s, running training loss: 0.6694]\u001b[A\n",
            "Training:  92%|█████████▏| 1633/1772 [10:09<00:48,  2.85it/s, running training loss: 0.5753]\u001b[A\n",
            "Training:  92%|█████████▏| 1634/1772 [10:09<00:47,  2.91it/s, running training loss: 0.5753]\u001b[A\n",
            "Training:  92%|█████████▏| 1634/1772 [10:10<00:47,  2.91it/s, running training loss: 0.6924]\u001b[A\n",
            "Training:  92%|█████████▏| 1635/1772 [10:10<00:50,  2.71it/s, running training loss: 0.6924]\u001b[A\n",
            "Training:  92%|█████████▏| 1635/1772 [10:10<00:50,  2.71it/s, running training loss: 0.5749]\u001b[A\n",
            "Training:  92%|█████████▏| 1636/1772 [10:10<00:49,  2.77it/s, running training loss: 0.5749]\u001b[A\n",
            "Training:  92%|█████████▏| 1636/1772 [10:11<00:49,  2.77it/s, running training loss: 0.5426]\u001b[A\n",
            "Training:  92%|█████████▏| 1637/1772 [10:11<00:50,  2.69it/s, running training loss: 0.5426]\u001b[A\n",
            "Training:  92%|█████████▏| 1637/1772 [10:11<00:50,  2.69it/s, running training loss: 1.0014]\u001b[A\n",
            "Training:  92%|█████████▏| 1638/1772 [10:11<00:45,  2.93it/s, running training loss: 1.0014]\u001b[A\n",
            "Training:  92%|█████████▏| 1638/1772 [10:11<00:45,  2.93it/s, running training loss: 0.6061]\u001b[A\n",
            "Training:  92%|█████████▏| 1639/1772 [10:11<00:43,  3.05it/s, running training loss: 0.6061]\u001b[A\n",
            "Training:  92%|█████████▏| 1639/1772 [10:11<00:43,  3.05it/s, running training loss: 1.0078]\u001b[A\n",
            "Training:  93%|█████████▎| 1640/1772 [10:11<00:45,  2.87it/s, running training loss: 1.0078]\u001b[A\n",
            "Training:  93%|█████████▎| 1640/1772 [10:12<00:45,  2.87it/s, running training loss: 1.0809]\u001b[A\n",
            "Training:  93%|█████████▎| 1641/1772 [10:12<00:43,  3.01it/s, running training loss: 1.0809]\u001b[A\n",
            "Training:  93%|█████████▎| 1641/1772 [10:12<00:43,  3.01it/s, running training loss: 1.1550]\u001b[A\n",
            "Training:  93%|█████████▎| 1642/1772 [10:12<00:42,  3.04it/s, running training loss: 1.1550]\u001b[A\n",
            "Training:  93%|█████████▎| 1642/1772 [10:13<00:42,  3.04it/s, running training loss: 0.9666]\u001b[A\n",
            "Training:  93%|█████████▎| 1643/1772 [10:13<00:49,  2.60it/s, running training loss: 0.9666]\u001b[A\n",
            "Training:  93%|█████████▎| 1643/1772 [10:13<00:49,  2.60it/s, running training loss: 1.2733]\u001b[A\n",
            "Training:  93%|█████████▎| 1644/1772 [10:13<00:44,  2.88it/s, running training loss: 1.2733]\u001b[A\n",
            "Training:  93%|█████████▎| 1644/1772 [10:13<00:44,  2.88it/s, running training loss: 0.6856]\u001b[A\n",
            "Training:  93%|█████████▎| 1645/1772 [10:13<00:48,  2.60it/s, running training loss: 0.6856]\u001b[A\n",
            "Training:  93%|█████████▎| 1645/1772 [10:14<00:48,  2.60it/s, running training loss: 0.9290]\u001b[A\n",
            "Training:  93%|█████████▎| 1646/1772 [10:14<00:51,  2.46it/s, running training loss: 0.9290]\u001b[A\n",
            "Training:  93%|█████████▎| 1646/1772 [10:14<00:51,  2.46it/s, running training loss: 0.9173]\u001b[A\n",
            "Training:  93%|█████████▎| 1647/1772 [10:14<00:50,  2.47it/s, running training loss: 0.9173]\u001b[A\n",
            "Training:  93%|█████████▎| 1647/1772 [10:15<00:50,  2.47it/s, running training loss: 0.9095]\u001b[A\n",
            "Training:  93%|█████████▎| 1648/1772 [10:15<00:48,  2.54it/s, running training loss: 0.9095]\u001b[A\n",
            "Training:  93%|█████████▎| 1648/1772 [10:15<00:48,  2.54it/s, running training loss: 0.5814]\u001b[A\n",
            "Training:  93%|█████████▎| 1649/1772 [10:15<00:47,  2.60it/s, running training loss: 0.5814]\u001b[A\n",
            "Training:  93%|█████████▎| 1649/1772 [10:15<00:47,  2.60it/s, running training loss: 0.7057]\u001b[A\n",
            "Training:  93%|█████████▎| 1650/1772 [10:15<00:45,  2.66it/s, running training loss: 0.7057]\u001b[A\n",
            "Training:  93%|█████████▎| 1650/1772 [10:16<00:45,  2.66it/s, running training loss: 0.9647]\u001b[A\n",
            "Training:  93%|█████████▎| 1651/1772 [10:16<00:45,  2.65it/s, running training loss: 0.9647]\u001b[A\n",
            "Training:  93%|█████████▎| 1651/1772 [10:16<00:45,  2.65it/s, running training loss: 0.8578]\u001b[A\n",
            "Training:  93%|█████████▎| 1652/1772 [10:16<00:44,  2.69it/s, running training loss: 0.8578]\u001b[A\n",
            "Training:  93%|█████████▎| 1652/1772 [10:16<00:44,  2.69it/s, running training loss: 0.8009]\u001b[A\n",
            "Training:  93%|█████████▎| 1653/1772 [10:16<00:43,  2.76it/s, running training loss: 0.8009]\u001b[A\n",
            "Training:  93%|█████████▎| 1653/1772 [10:17<00:43,  2.76it/s, running training loss: 0.6360]\u001b[A\n",
            "Training:  93%|█████████▎| 1654/1772 [10:17<00:43,  2.73it/s, running training loss: 0.6360]\u001b[A\n",
            "Training:  93%|█████████▎| 1654/1772 [10:17<00:43,  2.73it/s, running training loss: 0.5182]\u001b[A\n",
            "Training:  93%|█████████▎| 1655/1772 [10:17<00:40,  2.88it/s, running training loss: 0.5182]\u001b[A\n",
            "Training:  93%|█████████▎| 1655/1772 [10:17<00:40,  2.88it/s, running training loss: 0.7298]\u001b[A\n",
            "Training:  93%|█████████▎| 1656/1772 [10:17<00:37,  3.06it/s, running training loss: 0.7298]\u001b[A\n",
            "Training:  93%|█████████▎| 1656/1772 [10:18<00:37,  3.06it/s, running training loss: 0.6854]\u001b[A\n",
            "Training:  94%|█████████▎| 1657/1772 [10:18<00:35,  3.24it/s, running training loss: 0.6854]\u001b[A\n",
            "Training:  94%|█████████▎| 1657/1772 [10:18<00:35,  3.24it/s, running training loss: 0.8528]\u001b[A\n",
            "Training:  94%|█████████▎| 1658/1772 [10:18<00:38,  2.97it/s, running training loss: 0.8528]\u001b[A\n",
            "Training:  94%|█████████▎| 1658/1772 [10:18<00:38,  2.97it/s, running training loss: 0.7717]\u001b[A\n",
            "Training:  94%|█████████▎| 1659/1772 [10:18<00:34,  3.30it/s, running training loss: 0.7717]\u001b[A\n",
            "Training:  94%|█████████▎| 1659/1772 [10:18<00:34,  3.30it/s, running training loss: 0.7202]\u001b[A\n",
            "Training:  94%|█████████▎| 1660/1772 [10:18<00:33,  3.39it/s, running training loss: 0.7202]\u001b[A\n",
            "Training:  94%|█████████▎| 1660/1772 [10:19<00:33,  3.39it/s, running training loss: 1.6909]\u001b[A\n",
            "Training:  94%|█████████▎| 1661/1772 [10:19<00:35,  3.09it/s, running training loss: 1.6909]\u001b[A\n",
            "Training:  94%|█████████▎| 1661/1772 [10:19<00:35,  3.09it/s, running training loss: 0.8830]\u001b[A\n",
            "Training:  94%|█████████▍| 1662/1772 [10:19<00:36,  3.02it/s, running training loss: 0.8830]\u001b[A\n",
            "Training:  94%|█████████▍| 1662/1772 [10:20<00:36,  3.02it/s, running training loss: 1.1551]\u001b[A\n",
            "Training:  94%|█████████▍| 1663/1772 [10:20<00:35,  3.07it/s, running training loss: 1.1551]\u001b[A\n",
            "Training:  94%|█████████▍| 1663/1772 [10:20<00:35,  3.07it/s, running training loss: 1.3779]\u001b[A\n",
            "Training:  94%|█████████▍| 1664/1772 [10:20<00:38,  2.82it/s, running training loss: 1.3779]\u001b[A\n",
            "Training:  94%|█████████▍| 1664/1772 [10:20<00:38,  2.82it/s, running training loss: 0.5892]\u001b[A\n",
            "Training:  94%|█████████▍| 1665/1772 [10:20<00:38,  2.79it/s, running training loss: 0.5892]\u001b[A\n",
            "Training:  94%|█████████▍| 1665/1772 [10:21<00:38,  2.79it/s, running training loss: 0.8902]\u001b[A\n",
            "Training:  94%|█████████▍| 1666/1772 [10:21<00:35,  3.00it/s, running training loss: 0.8902]\u001b[A\n",
            "Training:  94%|█████████▍| 1666/1772 [10:21<00:35,  3.00it/s, running training loss: 1.4722]\u001b[A\n",
            "Training:  94%|█████████▍| 1667/1772 [10:21<00:36,  2.89it/s, running training loss: 1.4722]\u001b[A\n",
            "Training:  94%|█████████▍| 1667/1772 [10:21<00:36,  2.89it/s, running training loss: 0.9787]\u001b[A\n",
            "Training:  94%|█████████▍| 1668/1772 [10:21<00:41,  2.52it/s, running training loss: 0.9787]\u001b[A\n",
            "Training:  94%|█████████▍| 1668/1772 [10:22<00:41,  2.52it/s, running training loss: 0.8036]\u001b[A\n",
            "Training:  94%|█████████▍| 1669/1772 [10:22<00:40,  2.56it/s, running training loss: 0.8036]\u001b[A\n",
            "Training:  94%|█████████▍| 1669/1772 [10:22<00:40,  2.56it/s, running training loss: 0.7082]\u001b[A\n",
            "Training:  94%|█████████▍| 1670/1772 [10:22<00:35,  2.84it/s, running training loss: 0.7082]\u001b[A\n",
            "Training:  94%|█████████▍| 1670/1772 [10:22<00:35,  2.84it/s, running training loss: 0.7841]\u001b[A\n",
            "Training:  94%|█████████▍| 1671/1772 [10:23<00:36,  2.79it/s, running training loss: 0.7841]\u001b[A\n",
            "Training:  94%|█████████▍| 1671/1772 [10:23<00:36,  2.79it/s, running training loss: 0.7211]\u001b[A\n",
            "Training:  94%|█████████▍| 1672/1772 [10:23<00:33,  2.95it/s, running training loss: 0.7211]\u001b[A\n",
            "Training:  94%|█████████▍| 1672/1772 [10:23<00:33,  2.95it/s, running training loss: 0.9125]\u001b[A\n",
            "Training:  94%|█████████▍| 1673/1772 [10:23<00:31,  3.11it/s, running training loss: 0.9125]\u001b[A\n",
            "Training:  94%|█████████▍| 1673/1772 [10:24<00:31,  3.11it/s, running training loss: 0.9210]\u001b[A\n",
            "Training:  94%|█████████▍| 1674/1772 [10:24<00:34,  2.81it/s, running training loss: 0.9210]\u001b[A\n",
            "Training:  94%|█████████▍| 1674/1772 [10:24<00:34,  2.81it/s, running training loss: 0.6775]\u001b[A\n",
            "Training:  95%|█████████▍| 1675/1772 [10:24<00:33,  2.90it/s, running training loss: 0.6775]\u001b[A\n",
            "Training:  95%|█████████▍| 1675/1772 [10:24<00:33,  2.90it/s, running training loss: 0.8178]\u001b[A\n",
            "Training:  95%|█████████▍| 1676/1772 [10:24<00:31,  3.03it/s, running training loss: 0.8178]\u001b[A\n",
            "Training:  95%|█████████▍| 1676/1772 [10:24<00:31,  3.03it/s, running training loss: 0.5132]\u001b[A\n",
            "Training:  95%|█████████▍| 1677/1772 [10:24<00:30,  3.07it/s, running training loss: 0.5132]\u001b[A\n",
            "Training:  95%|█████████▍| 1677/1772 [10:25<00:30,  3.07it/s, running training loss: 0.7240]\u001b[A\n",
            "Training:  95%|█████████▍| 1678/1772 [10:25<00:32,  2.87it/s, running training loss: 0.7240]\u001b[A\n",
            "Training:  95%|█████████▍| 1678/1772 [10:25<00:32,  2.87it/s, running training loss: 0.7063]\u001b[A\n",
            "Training:  95%|█████████▍| 1679/1772 [10:25<00:32,  2.87it/s, running training loss: 0.7063]\u001b[A\n",
            "Training:  95%|█████████▍| 1679/1772 [10:26<00:32,  2.87it/s, running training loss: 0.6884]\u001b[A\n",
            "Training:  95%|█████████▍| 1680/1772 [10:26<00:31,  2.90it/s, running training loss: 0.6884]\u001b[A\n",
            "Training:  95%|█████████▍| 1680/1772 [10:26<00:31,  2.90it/s, running training loss: 0.6388]\u001b[A\n",
            "Training:  95%|█████████▍| 1681/1772 [10:26<00:37,  2.42it/s, running training loss: 0.6388]\u001b[A\n",
            "Training:  95%|█████████▍| 1681/1772 [10:26<00:37,  2.42it/s, running training loss: 0.7322]\u001b[A\n",
            "Training:  95%|█████████▍| 1682/1772 [10:26<00:36,  2.47it/s, running training loss: 0.7322]\u001b[A\n",
            "Training:  95%|█████████▍| 1682/1772 [10:27<00:36,  2.47it/s, running training loss: 0.4668]\u001b[A\n",
            "Training:  95%|█████████▍| 1683/1772 [10:27<00:36,  2.41it/s, running training loss: 0.4668]\u001b[A\n",
            "Training:  95%|█████████▍| 1683/1772 [10:27<00:36,  2.41it/s, running training loss: 1.0113]\u001b[A\n",
            "Training:  95%|█████████▌| 1684/1772 [10:27<00:34,  2.54it/s, running training loss: 1.0113]\u001b[A\n",
            "Training:  95%|█████████▌| 1684/1772 [10:28<00:34,  2.54it/s, running training loss: 0.7823]\u001b[A\n",
            "Training:  95%|█████████▌| 1685/1772 [10:28<00:34,  2.52it/s, running training loss: 0.7823]\u001b[A\n",
            "Training:  95%|█████████▌| 1685/1772 [10:28<00:34,  2.52it/s, running training loss: 1.0982]\u001b[A\n",
            "Training:  95%|█████████▌| 1686/1772 [10:28<00:34,  2.47it/s, running training loss: 1.0982]\u001b[A\n",
            "Training:  95%|█████████▌| 1686/1772 [10:28<00:34,  2.47it/s, running training loss: 0.9803]\u001b[A\n",
            "Training:  95%|█████████▌| 1687/1772 [10:28<00:32,  2.62it/s, running training loss: 0.9803]\u001b[A\n",
            "Training:  95%|█████████▌| 1687/1772 [10:29<00:32,  2.62it/s, running training loss: 1.0161]\u001b[A\n",
            "Training:  95%|█████████▌| 1688/1772 [10:29<00:29,  2.84it/s, running training loss: 1.0161]\u001b[A\n",
            "Training:  95%|█████████▌| 1688/1772 [10:29<00:29,  2.84it/s, running training loss: 1.3302]\u001b[A\n",
            "Training:  95%|█████████▌| 1689/1772 [10:29<00:27,  3.03it/s, running training loss: 1.3302]\u001b[A\n",
            "Training:  95%|█████████▌| 1689/1772 [10:29<00:27,  3.03it/s, running training loss: 1.1907]\u001b[A\n",
            "Training:  95%|█████████▌| 1690/1772 [10:29<00:27,  2.94it/s, running training loss: 1.1907]\u001b[A\n",
            "Training:  95%|█████████▌| 1690/1772 [10:30<00:27,  2.94it/s, running training loss: 0.9006]\u001b[A\n",
            "Training:  95%|█████████▌| 1691/1772 [10:30<00:29,  2.75it/s, running training loss: 0.9006]\u001b[A\n",
            "Training:  95%|█████████▌| 1691/1772 [10:30<00:29,  2.75it/s, running training loss: 0.8103]\u001b[A\n",
            "Training:  95%|█████████▌| 1692/1772 [10:30<00:27,  2.86it/s, running training loss: 0.8103]\u001b[A\n",
            "Training:  95%|█████████▌| 1692/1772 [10:30<00:27,  2.86it/s, running training loss: 1.0562]\u001b[A\n",
            "Training:  96%|█████████▌| 1693/1772 [10:30<00:28,  2.78it/s, running training loss: 1.0562]\u001b[A\n",
            "Training:  96%|█████████▌| 1693/1772 [10:31<00:28,  2.78it/s, running training loss: 0.7744]\u001b[A\n",
            "Training:  96%|█████████▌| 1694/1772 [10:31<00:29,  2.66it/s, running training loss: 0.7744]\u001b[A\n",
            "Training:  96%|█████████▌| 1694/1772 [10:31<00:29,  2.66it/s, running training loss: 0.8743]\u001b[A\n",
            "Training:  96%|█████████▌| 1695/1772 [10:31<00:29,  2.64it/s, running training loss: 0.8743]\u001b[A\n",
            "Training:  96%|█████████▌| 1695/1772 [10:31<00:29,  2.64it/s, running training loss: 0.7045]\u001b[A\n",
            "Training:  96%|█████████▌| 1696/1772 [10:32<00:25,  2.97it/s, running training loss: 0.7045]\u001b[A\n",
            "Training:  96%|█████████▌| 1696/1772 [10:32<00:25,  2.97it/s, running training loss: 0.8675]\u001b[A\n",
            "Training:  96%|█████████▌| 1697/1772 [10:32<00:25,  2.92it/s, running training loss: 0.8675]\u001b[A\n",
            "Training:  96%|█████████▌| 1697/1772 [10:32<00:25,  2.92it/s, running training loss: 0.5317]\u001b[A\n",
            "Training:  96%|█████████▌| 1698/1772 [10:32<00:25,  2.89it/s, running training loss: 0.5317]\u001b[A\n",
            "Training:  96%|█████████▌| 1698/1772 [10:33<00:25,  2.89it/s, running training loss: 0.9536]\u001b[A\n",
            "Training:  96%|█████████▌| 1699/1772 [10:33<00:24,  2.94it/s, running training loss: 0.9536]\u001b[A\n",
            "Training:  96%|█████████▌| 1699/1772 [10:33<00:24,  2.94it/s, running training loss: 0.6794]\u001b[A\n",
            "Training:  96%|█████████▌| 1700/1772 [10:33<00:25,  2.80it/s, running training loss: 0.6794]\u001b[A\n",
            "Training:  96%|█████████▌| 1700/1772 [10:33<00:25,  2.80it/s, running training loss: 0.4988]\u001b[A\n",
            "Training:  96%|█████████▌| 1701/1772 [10:33<00:29,  2.39it/s, running training loss: 0.4988]\u001b[A\n",
            "Training:  96%|█████████▌| 1701/1772 [10:34<00:29,  2.39it/s, running training loss: 0.4791]\u001b[A\n",
            "Training:  96%|█████████▌| 1702/1772 [10:34<00:28,  2.45it/s, running training loss: 0.4791]\u001b[A\n",
            "Training:  96%|█████████▌| 1702/1772 [10:34<00:28,  2.45it/s, running training loss: 0.7494]\u001b[A\n",
            "Training:  96%|█████████▌| 1703/1772 [10:34<00:25,  2.66it/s, running training loss: 0.7494]\u001b[A\n",
            "Training:  96%|█████████▌| 1703/1772 [10:35<00:25,  2.66it/s, running training loss: 0.7957]\u001b[A\n",
            "Training:  96%|█████████▌| 1704/1772 [10:35<00:24,  2.76it/s, running training loss: 0.7957]\u001b[A\n",
            "Training:  96%|█████████▌| 1704/1772 [10:35<00:24,  2.76it/s, running training loss: 0.8554]\u001b[A\n",
            "Training:  96%|█████████▌| 1705/1772 [10:35<00:26,  2.51it/s, running training loss: 0.8554]\u001b[A\n",
            "Training:  96%|█████████▌| 1705/1772 [10:35<00:26,  2.51it/s, running training loss: 0.7135]\u001b[A\n",
            "Training:  96%|█████████▋| 1706/1772 [10:35<00:26,  2.46it/s, running training loss: 0.7135]\u001b[A\n",
            "Training:  96%|█████████▋| 1706/1772 [10:36<00:26,  2.46it/s, running training loss: 1.2857]\u001b[A\n",
            "Training:  96%|█████████▋| 1707/1772 [10:36<00:24,  2.61it/s, running training loss: 1.2857]\u001b[A\n",
            "Training:  96%|█████████▋| 1707/1772 [10:36<00:24,  2.61it/s, running training loss: 0.7879]\u001b[A\n",
            "Training:  96%|█████████▋| 1708/1772 [10:36<00:22,  2.86it/s, running training loss: 0.7879]\u001b[A\n",
            "Training:  96%|█████████▋| 1708/1772 [10:36<00:22,  2.86it/s, running training loss: 0.5218]\u001b[A\n",
            "Training:  96%|█████████▋| 1709/1772 [10:36<00:21,  2.92it/s, running training loss: 0.5218]\u001b[A\n",
            "Training:  96%|█████████▋| 1709/1772 [10:37<00:21,  2.92it/s, running training loss: 0.6898]\u001b[A\n",
            "Training:  97%|█████████▋| 1710/1772 [10:37<00:21,  2.85it/s, running training loss: 0.6898]\u001b[A\n",
            "Training:  97%|█████████▋| 1710/1772 [10:37<00:21,  2.85it/s, running training loss: 0.7143]\u001b[A\n",
            "Training:  97%|█████████▋| 1711/1772 [10:37<00:22,  2.68it/s, running training loss: 0.7143]\u001b[A\n",
            "Training:  97%|█████████▋| 1711/1772 [10:38<00:22,  2.68it/s, running training loss: 0.6984]\u001b[A\n",
            "Training:  97%|█████████▋| 1712/1772 [10:38<00:22,  2.69it/s, running training loss: 0.6984]\u001b[A\n",
            "Training:  97%|█████████▋| 1712/1772 [10:38<00:22,  2.69it/s, running training loss: 0.8197]\u001b[A\n",
            "Training:  97%|█████████▋| 1713/1772 [10:38<00:21,  2.78it/s, running training loss: 0.8197]\u001b[A\n",
            "Training:  97%|█████████▋| 1713/1772 [10:38<00:21,  2.78it/s, running training loss: 0.8598]\u001b[A\n",
            "Training:  97%|█████████▋| 1714/1772 [10:38<00:20,  2.89it/s, running training loss: 0.8598]\u001b[A\n",
            "Training:  97%|█████████▋| 1714/1772 [10:38<00:20,  2.89it/s, running training loss: 0.9522]\u001b[A\n",
            "Training:  97%|█████████▋| 1715/1772 [10:38<00:18,  3.02it/s, running training loss: 0.9522]\u001b[A\n",
            "Training:  97%|█████████▋| 1715/1772 [10:39<00:18,  3.02it/s, running training loss: 0.8092]\u001b[A\n",
            "Training:  97%|█████████▋| 1716/1772 [10:39<00:18,  2.97it/s, running training loss: 0.8092]\u001b[A\n",
            "Training:  97%|█████████▋| 1716/1772 [10:39<00:18,  2.97it/s, running training loss: 0.9736]\u001b[A\n",
            "Training:  97%|█████████▋| 1717/1772 [10:39<00:17,  3.18it/s, running training loss: 0.9736]\u001b[A\n",
            "Training:  97%|█████████▋| 1717/1772 [10:39<00:17,  3.18it/s, running training loss: 0.9075]\u001b[A\n",
            "Training:  97%|█████████▋| 1718/1772 [10:39<00:18,  2.94it/s, running training loss: 0.9075]\u001b[A\n",
            "Training:  97%|█████████▋| 1718/1772 [10:40<00:18,  2.94it/s, running training loss: 0.5773]\u001b[A\n",
            "Training:  97%|█████████▋| 1719/1772 [10:40<00:18,  2.81it/s, running training loss: 0.5773]\u001b[A\n",
            "Training:  97%|█████████▋| 1719/1772 [10:40<00:18,  2.81it/s, running training loss: 0.6329]\u001b[A\n",
            "Training:  97%|█████████▋| 1720/1772 [10:40<00:18,  2.86it/s, running training loss: 0.6329]\u001b[A\n",
            "Training:  97%|█████████▋| 1720/1772 [10:41<00:18,  2.86it/s, running training loss: 1.1841]\u001b[A\n",
            "Training:  97%|█████████▋| 1721/1772 [10:41<00:17,  2.91it/s, running training loss: 1.1841]\u001b[A\n",
            "Training:  97%|█████████▋| 1721/1772 [10:41<00:17,  2.91it/s, running training loss: 0.3607]\u001b[A\n",
            "Training:  97%|█████████▋| 1722/1772 [10:41<00:16,  3.09it/s, running training loss: 0.3607]\u001b[A\n",
            "Training:  97%|█████████▋| 1722/1772 [10:41<00:16,  3.09it/s, running training loss: 0.6206]\u001b[A\n",
            "Training:  97%|█████████▋| 1723/1772 [10:41<00:17,  2.72it/s, running training loss: 0.6206]\u001b[A\n",
            "Training:  97%|█████████▋| 1723/1772 [10:42<00:17,  2.72it/s, running training loss: 0.8477]\u001b[A\n",
            "Training:  97%|█████████▋| 1724/1772 [10:42<00:16,  2.94it/s, running training loss: 0.8477]\u001b[A\n",
            "Training:  97%|█████████▋| 1724/1772 [10:42<00:16,  2.94it/s, running training loss: 0.9338]\u001b[A\n",
            "Training:  97%|█████████▋| 1725/1772 [10:42<00:15,  3.10it/s, running training loss: 0.9338]\u001b[A\n",
            "Training:  97%|█████████▋| 1725/1772 [10:42<00:15,  3.10it/s, running training loss: 0.7255]\u001b[A\n",
            "Training:  97%|█████████▋| 1726/1772 [10:42<00:14,  3.25it/s, running training loss: 0.7255]\u001b[A\n",
            "Training:  97%|█████████▋| 1726/1772 [10:42<00:14,  3.25it/s, running training loss: 0.8525]\u001b[A\n",
            "Training:  97%|█████████▋| 1727/1772 [10:42<00:13,  3.38it/s, running training loss: 0.8525]\u001b[A\n",
            "Training:  97%|█████████▋| 1727/1772 [10:43<00:13,  3.38it/s, running training loss: 0.8087]\u001b[A\n",
            "Training:  98%|█████████▊| 1728/1772 [10:43<00:15,  2.85it/s, running training loss: 0.8087]\u001b[A\n",
            "Training:  98%|█████████▊| 1728/1772 [10:43<00:15,  2.85it/s, running training loss: 0.4735]\u001b[A\n",
            "Training:  98%|█████████▊| 1729/1772 [10:43<00:15,  2.77it/s, running training loss: 0.4735]\u001b[A\n",
            "Training:  98%|█████████▊| 1729/1772 [10:44<00:15,  2.77it/s, running training loss: 0.3796]\u001b[A\n",
            "Training:  98%|█████████▊| 1730/1772 [10:44<00:14,  2.89it/s, running training loss: 0.3796]\u001b[A\n",
            "Training:  98%|█████████▊| 1730/1772 [10:44<00:14,  2.89it/s, running training loss: 0.8283]\u001b[A\n",
            "Training:  98%|█████████▊| 1731/1772 [10:44<00:13,  2.95it/s, running training loss: 0.8283]\u001b[A\n",
            "Training:  98%|█████████▊| 1731/1772 [10:44<00:13,  2.95it/s, running training loss: 0.8462]\u001b[A\n",
            "Training:  98%|█████████▊| 1732/1772 [10:44<00:13,  3.05it/s, running training loss: 0.8462]\u001b[A\n",
            "Training:  98%|█████████▊| 1732/1772 [10:44<00:13,  3.05it/s, running training loss: 1.0193]\u001b[A\n",
            "Training:  98%|█████████▊| 1733/1772 [10:44<00:12,  3.09it/s, running training loss: 1.0193]\u001b[A\n",
            "Training:  98%|█████████▊| 1733/1772 [10:45<00:12,  3.09it/s, running training loss: 1.0004]\u001b[A\n",
            "Training:  98%|█████████▊| 1734/1772 [10:45<00:13,  2.77it/s, running training loss: 1.0004]\u001b[A\n",
            "Training:  98%|█████████▊| 1734/1772 [10:45<00:13,  2.77it/s, running training loss: 0.9209]\u001b[A\n",
            "Training:  98%|█████████▊| 1735/1772 [10:45<00:12,  2.98it/s, running training loss: 0.9209]\u001b[A\n",
            "Training:  98%|█████████▊| 1735/1772 [10:46<00:12,  2.98it/s, running training loss: 0.6472]\u001b[A\n",
            "Training:  98%|█████████▊| 1736/1772 [10:46<00:12,  3.00it/s, running training loss: 0.6472]\u001b[A\n",
            "Training:  98%|█████████▊| 1736/1772 [10:46<00:12,  3.00it/s, running training loss: 0.7257]\u001b[A\n",
            "Training:  98%|█████████▊| 1737/1772 [10:46<00:11,  2.92it/s, running training loss: 0.7257]\u001b[A\n",
            "Training:  98%|█████████▊| 1737/1772 [10:46<00:11,  2.92it/s, running training loss: 0.5236]\u001b[A\n",
            "Training:  98%|█████████▊| 1738/1772 [10:46<00:10,  3.14it/s, running training loss: 0.5236]\u001b[A\n",
            "Training:  98%|█████████▊| 1738/1772 [10:46<00:10,  3.14it/s, running training loss: 0.6097]\u001b[A\n",
            "Training:  98%|█████████▊| 1739/1772 [10:46<00:10,  3.16it/s, running training loss: 0.6097]\u001b[A\n",
            "Training:  98%|█████████▊| 1739/1772 [10:47<00:10,  3.16it/s, running training loss: 0.8461]\u001b[A\n",
            "Training:  98%|█████████▊| 1740/1772 [10:47<00:11,  2.79it/s, running training loss: 0.8461]\u001b[A\n",
            "Training:  98%|█████████▊| 1740/1772 [10:47<00:11,  2.79it/s, running training loss: 0.8405]\u001b[A\n",
            "Training:  98%|█████████▊| 1741/1772 [10:47<00:11,  2.69it/s, running training loss: 0.8405]\u001b[A\n",
            "Training:  98%|█████████▊| 1741/1772 [10:48<00:11,  2.69it/s, running training loss: 0.9584]\u001b[A\n",
            "Training:  98%|█████████▊| 1742/1772 [10:48<00:10,  2.86it/s, running training loss: 0.9584]\u001b[A\n",
            "Training:  98%|█████████▊| 1742/1772 [10:48<00:10,  2.86it/s, running training loss: 0.7235]\u001b[A\n",
            "Training:  98%|█████████▊| 1743/1772 [10:48<00:10,  2.73it/s, running training loss: 0.7235]\u001b[A\n",
            "Training:  98%|█████████▊| 1743/1772 [10:48<00:10,  2.73it/s, running training loss: 0.5047]\u001b[A\n",
            "Training:  98%|█████████▊| 1744/1772 [10:48<00:09,  2.90it/s, running training loss: 0.5047]\u001b[A\n",
            "Training:  98%|█████████▊| 1744/1772 [10:49<00:09,  2.90it/s, running training loss: 1.1457]\u001b[A\n",
            "Training:  98%|█████████▊| 1745/1772 [10:49<00:09,  2.91it/s, running training loss: 1.1457]\u001b[A\n",
            "Training:  98%|█████████▊| 1745/1772 [10:49<00:09,  2.91it/s, running training loss: 1.0727]\u001b[A\n",
            "Training:  99%|█████████▊| 1746/1772 [10:49<00:09,  2.86it/s, running training loss: 1.0727]\u001b[A\n",
            "Training:  99%|█████████▊| 1746/1772 [10:49<00:09,  2.86it/s, running training loss: 0.4998]\u001b[A\n",
            "Training:  99%|█████████▊| 1747/1772 [10:49<00:08,  2.88it/s, running training loss: 0.4998]\u001b[A\n",
            "Training:  99%|█████████▊| 1747/1772 [10:50<00:08,  2.88it/s, running training loss: 1.0627]\u001b[A\n",
            "Training:  99%|█████████▊| 1748/1772 [10:50<00:08,  2.80it/s, running training loss: 1.0627]\u001b[A\n",
            "Training:  99%|█████████▊| 1748/1772 [10:50<00:08,  2.80it/s, running training loss: 0.7530]\u001b[A\n",
            "Training:  99%|█████████▊| 1749/1772 [10:50<00:08,  2.56it/s, running training loss: 0.7530]\u001b[A\n",
            "Training:  99%|█████████▊| 1749/1772 [10:51<00:08,  2.56it/s, running training loss: 0.5829]\u001b[A\n",
            "Training:  99%|█████████▉| 1750/1772 [10:51<00:08,  2.66it/s, running training loss: 0.5829]\u001b[A\n",
            "Training:  99%|█████████▉| 1750/1772 [10:51<00:08,  2.66it/s, running training loss: 1.0990]\u001b[A\n",
            "Training:  99%|█████████▉| 1751/1772 [10:51<00:07,  2.78it/s, running training loss: 1.0990]\u001b[A\n",
            "Training:  99%|█████████▉| 1751/1772 [10:51<00:07,  2.78it/s, running training loss: 0.6219]\u001b[A\n",
            "Training:  99%|█████████▉| 1752/1772 [10:51<00:06,  2.94it/s, running training loss: 0.6219]\u001b[A\n",
            "Training:  99%|█████████▉| 1752/1772 [10:52<00:06,  2.94it/s, running training loss: 1.0954]\u001b[A\n",
            "Training:  99%|█████████▉| 1753/1772 [10:52<00:06,  2.96it/s, running training loss: 1.0954]\u001b[A\n",
            "Training:  99%|█████████▉| 1753/1772 [10:52<00:06,  2.96it/s, running training loss: 0.8192]\u001b[A\n",
            "Training:  99%|█████████▉| 1754/1772 [10:52<00:05,  3.04it/s, running training loss: 0.8192]\u001b[A\n",
            "Training:  99%|█████████▉| 1754/1772 [10:52<00:05,  3.04it/s, running training loss: 0.7237]\u001b[A\n",
            "Training:  99%|█████████▉| 1755/1772 [10:52<00:05,  3.16it/s, running training loss: 0.7237]\u001b[A\n",
            "Training:  99%|█████████▉| 1755/1772 [10:52<00:05,  3.16it/s, running training loss: 1.1920]\u001b[A\n",
            "Training:  99%|█████████▉| 1756/1772 [10:52<00:05,  3.07it/s, running training loss: 1.1920]\u001b[A\n",
            "Training:  99%|█████████▉| 1756/1772 [10:53<00:05,  3.07it/s, running training loss: 0.8037]\u001b[A\n",
            "Training:  99%|█████████▉| 1757/1772 [10:53<00:05,  2.91it/s, running training loss: 0.8037]\u001b[A\n",
            "Training:  99%|█████████▉| 1757/1772 [10:53<00:05,  2.91it/s, running training loss: 0.7386]\u001b[A\n",
            "Training:  99%|█████████▉| 1758/1772 [10:53<00:04,  2.99it/s, running training loss: 0.7386]\u001b[A\n",
            "Training:  99%|█████████▉| 1758/1772 [10:53<00:04,  2.99it/s, running training loss: 0.8316]\u001b[A\n",
            "Training:  99%|█████████▉| 1759/1772 [10:53<00:04,  2.98it/s, running training loss: 0.8316]\u001b[A\n",
            "Training:  99%|█████████▉| 1759/1772 [10:54<00:04,  2.98it/s, running training loss: 0.8165]\u001b[A\n",
            "Training:  99%|█████████▉| 1760/1772 [10:54<00:03,  3.07it/s, running training loss: 0.8165]\u001b[A\n",
            "Training:  99%|█████████▉| 1760/1772 [10:54<00:03,  3.07it/s, running training loss: 0.7237]\u001b[A\n",
            "Training:  99%|█████████▉| 1761/1772 [10:54<00:03,  3.12it/s, running training loss: 0.7237]\u001b[A\n",
            "Training:  99%|█████████▉| 1761/1772 [10:54<00:03,  3.12it/s, running training loss: 0.9024]\u001b[A\n",
            "Training:  99%|█████████▉| 1762/1772 [10:54<00:03,  3.13it/s, running training loss: 0.9024]\u001b[A\n",
            "Training:  99%|█████████▉| 1762/1772 [10:55<00:03,  3.13it/s, running training loss: 0.4086]\u001b[A\n",
            "Training:  99%|█████████▉| 1763/1772 [10:55<00:03,  2.48it/s, running training loss: 0.4086]\u001b[A\n",
            "Training:  99%|█████████▉| 1763/1772 [10:56<00:03,  2.48it/s, running training loss: 0.7863]\u001b[A\n",
            "Training: 100%|█████████▉| 1764/1772 [10:56<00:03,  2.16it/s, running training loss: 0.7863]\u001b[A\n",
            "Training: 100%|█████████▉| 1764/1772 [10:56<00:03,  2.16it/s, running training loss: 0.7268]\u001b[A\n",
            "Training: 100%|█████████▉| 1765/1772 [10:56<00:02,  2.41it/s, running training loss: 0.7268]\u001b[A\n",
            "Training: 100%|█████████▉| 1765/1772 [10:56<00:02,  2.41it/s, running training loss: 0.9378]\u001b[A\n",
            "Training: 100%|█████████▉| 1766/1772 [10:56<00:02,  2.61it/s, running training loss: 0.9378]\u001b[A\n",
            "Training: 100%|█████████▉| 1766/1772 [10:56<00:02,  2.61it/s, running training loss: 0.4044]\u001b[A\n",
            "Training: 100%|█████████▉| 1767/1772 [10:56<00:01,  2.91it/s, running training loss: 0.4044]\u001b[A\n",
            "Training: 100%|█████████▉| 1767/1772 [10:57<00:01,  2.91it/s, running training loss: 0.5869]\u001b[A\n",
            "Training: 100%|█████████▉| 1768/1772 [10:57<00:01,  2.62it/s, running training loss: 0.5869]\u001b[A\n",
            "Training: 100%|█████████▉| 1768/1772 [10:57<00:01,  2.62it/s, running training loss: 0.8206]\u001b[A\n",
            "Training: 100%|█████████▉| 1769/1772 [10:57<00:01,  2.74it/s, running training loss: 0.8206]\u001b[A\n",
            "Training: 100%|█████████▉| 1769/1772 [10:58<00:01,  2.74it/s, running training loss: 0.9550]\u001b[A\n",
            "Training: 100%|█████████▉| 1770/1772 [10:58<00:00,  2.86it/s, running training loss: 0.9550]\u001b[A\n",
            "Training: 100%|█████████▉| 1770/1772 [10:58<00:00,  2.86it/s, running training loss: 0.8280]\u001b[A\n",
            "Training: 100%|█████████▉| 1771/1772 [10:58<00:00,  2.64it/s, running training loss: 0.8280]\u001b[A\n",
            "Training: 100%|█████████▉| 1771/1772 [10:58<00:00,  2.64it/s, running training loss: 0.7764]\u001b[A\n",
            "Training: 100%|██████████| 1772/1772 [10:59<00:00,  2.69it/s, running training loss: 0.7764]\n",
            "100%|██████████| 1/1 [10:59<00:00, 659.36s/it]\n"
          ]
        }
      ],
      "source": [
        "model, best_model_path = train(config, train_dataloader, dev_dataloader, unsup_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "0m6m5j70nF1V"
      },
      "outputs": [],
      "source": [
        "from zipfile import ZipFile\n",
        "def predict(config, model, test_dataloader):\n",
        "    test_iterator = tqdm(test_dataloader, desc='Predicting', total=len(test_dataloader))\n",
        "    test_preds = []\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in test_iterator:\n",
        "            batch_cuda = {item: value.to(config['device']) for item, value in list(batch.items())}\n",
        "            logits = model(**batch_cuda)[0]\n",
        "            probs = torch.softmax(logits, dim=-1)\n",
        "            test_preds.append(probs[:, 1].detach().cpu())\n",
        "    \n",
        "\n",
        "    test_preds = torch.cat(test_preds)\n",
        "    test_preds = torch.stack(test_preds.split(2), dim=0).mean(dim=1).numpy()\n",
        "    submission_path = os.path.join(config['output_path'], 'submission.tsv')\n",
        "    test_df = pd.DataFrame(data={'prediction': test_preds})\n",
        "    test_df.to_csv(submission_path, index=False, header=False, encoding='utf8', sep='\\t')\n",
        "    with ZipFile(os.path.join(config['output_path'], 'submission.zip'), 'w') as myzip:\n",
        "        myzip.write(submission_path, 'submission.tsv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0xujBsunHMN",
        "outputId": "6ab3847b-bed0-46dd-fef8-7494ae855a22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Predicting: 100%|██████████| 483/483 [00:21<00:00, 22.13it/s]\n"
          ]
        }
      ],
      "source": [
        "predict(config, model, test_dataloader)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "06_self_Text_Data_Augmentation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}