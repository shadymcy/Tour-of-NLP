{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "06_self_Text_Data_Augmentation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwtCjsf4sTwU",
        "outputId": "8a764e9a-45e9-47aa-a2d6-3955de9ae28a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu May 12 06:14:32 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   50C    P8    31W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import sys\n",
        "drive.mount('/content/drive')\n",
        "#设置路径\n",
        "sys.path.append('/content/drive/MyDrive/Colab Notebooks')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6XY-7WNswSL",
        "outputId": "969ecc7e-0994-43e5-b2ae-faaa206b0351"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -U synonyms"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqvtiNDuuAxi",
        "outputId": "c8cea99c-3eae-48b9-a884-cde75da57977"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting synonyms\n",
            "  Downloading synonyms-3.16.0.tar.gz (10.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.7 MB 5.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from synonyms) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.13.1 in /usr/local/lib/python3.7/dist-packages (from synonyms) (1.21.6)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from synonyms) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from synonyms) (1.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.1->synonyms) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.1->synonyms) (1.1.0)\n",
            "Building wheels for collected packages: synonyms\n",
            "  Building wheel for synonyms (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for synonyms: filename=synonyms-3.16.0-py3-none-any.whl size=10832785 sha256=a2de9364714af04ff23c5671741efd45a155445f73bad39574af3931de8d5d2d\n",
            "  Stored in directory: /root/.cache/pip/wheels/e4/cd/43/b4548753509a94471fc946967a07116252d49aeeb689db8f7c\n",
            "Successfully built synonyms\n",
            "Installing collected packages: synonyms\n",
            "Successfully installed synonyms-3.16.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import synonyms"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h10xpanIu7nh",
        "outputId": "76eb6c08-07fa-4c73-880d-ec0eb5724185"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[jieba] default dict file path ../data/vocab.txt\n",
            "[jieba] default dict file path ../data/vocab.txt\n",
            "[jieba] load default dict ../data/vocab.txt ...\n",
            "[jieba] load default dict ../data/vocab.txt ...\n",
            ">> Synonyms load wordseg dict [/usr/local/lib/python3.7/dist-packages/synonyms/data/vocab.txt] ... \n",
            ">> Synonyms on loading stopwords [/usr/local/lib/python3.7/dist-packages/synonyms/data/stopwords.txt] ...\n",
            "[Synonyms] on loading vectors [/usr/local/lib/python3.7/dist-packages/synonyms/data/words.vector.gz] ...\n",
            "\n",
            "[Synonyms] downloading data from https://github.com/chatopera/Synonyms/releases/download/3.15.0/words.vector.gz to /usr/local/lib/python3.7/dist-packages/synonyms/data/words.vector.gz ... \n",
            " this only happens if SYNONYMS_WORD2VEC_BIN_URL_ZH_CN is not present and Synonyms initialization for the first time. \n",
            " It would take minutes that depends on network.\n",
            "\n",
            "[Synonyms] downloaded.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "synonyms.nearby('篮球')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9mOaqDkfvPU8",
        "outputId": "b32d5f45-3c46-40b6-b376-ab78af555768"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['篮球', '橄榄球', '排球', '棒球', '美式足球', '冰球', '拳击', '网球', '高尔夫球', '高球'],\n",
              " [1.0,\n",
              "  0.81482756,\n",
              "  0.78554475,\n",
              "  0.7845952,\n",
              "  0.7815255,\n",
              "  0.7550466,\n",
              "  0.7411452,\n",
              "  0.7350726,\n",
              "  0.72586256,\n",
              "  0.7199612])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EDA(Easy Data Augmentation)\n",
        "![UDA1](https://img-blog.csdnimg.cn/c5ffcca4482c4c42beb6f1215e37657c.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTI4NzA2MA==,size_16,color_FFFFFF,t_70)\n",
        "### EDA：用于提高文本分类任务性能的简单数据增强技术。 EDA 由四个简单但功能强大的操作组成：同义词替换、随机插入、随机交换和随机删除。\n",
        "### 之前的工作已经提出了一些 NLP 中数据增强的技术，回译通过将句子翻译成法语然后再翻译成英语来生成新数据。"
      ],
      "metadata": {
        "id": "JE5-bWj3NWHP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 对于训练集中的给定句子，随机选择并执行以下操作之一：\n",
        "* 同义词替换（SR）：从句子中随机选择 n 个不是停用词的词。 用随机选择的同义词之一替换这些单词中的每一个。\n",
        "* 随机插入 (RI)：在句子中随机找到一个词，并找出其同义词，且该同义词不是停用词。 将该同义词插入句子中的随机位置。 这样做n次。\n",
        "* 随机交换（RS）：随机选择句子中的两个单词并交换它们的位置。 这样做n次。\n",
        "* 随机删除（RD）：以概率 p 随机删除句子中的每个单词。"
      ],
      "metadata": {
        "id": "wnQO5mqsO2BQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 停用词 stop word\n",
        "\n",
        "停用词是指在信息检索中，为节省存储空间和提高搜索效率，在处理自然语言数据（或文本）之前或之后会自动过滤掉某些字或词，这些字或词即被称为Stop Words（停用词）\n",
        "```\n",
        "str = \"00000003210Runoob01230000000\"; \n",
        "print str.strip( '0' );  # 去除首尾字符 0\n",
        "\n",
        "str2 = \"   Runoob      \";   # 去除首尾空格\n",
        "print str2.strip();\n",
        "\n",
        "3210Runoob0123\n",
        "Runoob\n",
        "```\n"
      ],
      "metadata": {
        "id": "f3M9EIDDO3Bf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# strip() 方法用于移除字符串头尾指定的字符（默认为空格或换行符）或字符序列。\n",
        "stop_words = {word.strip() for word in open('/content/drive/MyDrive/Colab Notebooks/baidu_stopwords.txt', 'r', encoding='utf8').readlines()}"
      ],
      "metadata": {
        "id": "LXVB0xAdPdzO"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 同义词替换（SR）：从句子中随机选择 n 个不是停用词的词。 用随机选择的同义词之一替换这些单词中的每一个。\n",
        "import random\n",
        "def get_synonyms(word):\n",
        "  # (['mama'],['0.9'])\n",
        "  #取出元组第0个元素（['mama']），并去重\n",
        "  sys = set(synonyms.nearby(word)[0])\n",
        "  #将word从同义词列表中去除\n",
        "  if word in sys:\n",
        "    sys.remove(word)\n",
        "  return list(sys)\n",
        "  # 如果输入\"给力\" 可能没有同义词（同义词只有他自己） 则返回  ([],[])\n",
        "\n",
        "\n",
        "def synonym_replacement(words, n):\n",
        "  new_words = words.copy()\n",
        "  # 遍历句子中的每个词，并且这个词不是停用词\n",
        "  # set()去重， 以列表形式返回\n",
        "  random_word_list = list(set([word for word in words if word not in stop_words]))\n",
        "  # 打乱\n",
        "  random.shuffle(random_word_list)\n",
        "  num_replaced = 0\n",
        "  for random_word in random_word_list:\n",
        "    # 得到近义词列表\n",
        "    synonyms = get_synonyms(random_word)\n",
        "    if len(synonyms) >= 1:\n",
        "      # 随机取出一个同义词\n",
        "      synonym = random.choice(list(synonyms))\n",
        "      # 用synonym替换原词\n",
        "      new_words = [synonym if word == random_word else word for word in new_words]\n",
        "      num_replaced += 1\n",
        "    if num_replaced >= n:\n",
        "      break\n",
        "  # new_words 已经是个列表了 下一块代码举例\n",
        "  sentence = ' '.join(new_words)\n",
        "  new_words = sentence.split(' ')\n",
        "  return new_words"
      ],
      "metadata": {
        "id": "jUQPnSQXQGEP"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 存在一种情况  \n",
        "*有近义词：**actor** -> **film star** 一个单词的近义词是两个单词*\n",
        "\n",
        "sentence = ['in', 'actor']\n",
        "\n",
        "*默认new_words = ['in', 'film star']*\n",
        "\n",
        "*希望有如下表示：*\n",
        "new_words = ['in', 'film', 'star']"
      ],
      "metadata": {
        "id": "gbDtk6R6YltF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 随机删除（RD）：以概率 p 随机删除句子中的每个单词。\n",
        "def random_deletion(words, p):\n",
        "  if len(words) == 1:\n",
        "    return words\n",
        "  new_words = []\n",
        "  for word in words:\n",
        "    # 概率\n",
        "    r = random.uniform(0, 1)\n",
        "    # r>p 保留\n",
        "    if r > p:\n",
        "      new_words.append(word)\n",
        "  # 如果都删没了 随机返回一个词\n",
        "  if len(new_words) == 0:\n",
        "    random_int = random.randint(0, len(words) - 1)\n",
        "    return [words[random_int]]\n",
        "  return new_words"
      ],
      "metadata": {
        "id": "5bkLsC96Zn5V"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 随机交换（RS）：随机选择句子中的两个单词并交换它们的位置。 这样做n次。\n",
        "def swap_word(new_words):\n",
        "  random_idx_1 = random.randint(0, len(new_words) - 1)\n",
        "  random_idx_2 = random_idx_1\n",
        "  \n",
        "  count = 0\n",
        "  # 两者相等重新取idx_2\n",
        "  while random_idx_2 == random_idx_1:\n",
        "    random_idx_2 - random.randint(0, len(new_words) - 1)\n",
        "    count += 1\n",
        "    # 取了三次还是相等 立即推\n",
        "    if count > 3:\n",
        "      return new_words\n",
        "\n",
        "  new_words[random_idx_1], new_words[random_idx_2] = new_words[random_idx_2], new_words[random_idx_1] \n",
        "  return new_words\n",
        "\n",
        "def random_swap(words, n):\n",
        "  new_words = words.copy()\n",
        "  for _ in range(n):\n",
        "    new_words = swap_word(new_words)\n",
        "  return new_words"
      ],
      "metadata": {
        "id": "547rlZnwbGfO"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 随机插入 (RI)：在句子中随机找到一个词，并找出其同义词，且该同义词不是停用词。 将该同义词插入句子中的随机位置。 这样做n次。\n",
        "def add_word(new_words):\n",
        "  # 同义词列表\n",
        "  synonyms = []\n",
        "  count = 0\n",
        "  while len(synonyms) < 1:\n",
        "    # 在句子中随机找到一个词\n",
        "    random_word = new_words[random.randint(0, len(new_words) - 1)]\n",
        "    synonyms = get_synonyms(random_word)\n",
        "    count += 1\n",
        "    # 找了10次同义词数量仍小于1，立即推\n",
        "    if count >= 10:\n",
        "      return \n",
        "  #将同义词表中第一个插入\n",
        "  random_synonym = synonyms[0]\n",
        "  # 取出要插入的位置  \n",
        "  random_idx = random.randint(0, len(new_words) - 1)\n",
        "  new_words.insert(random_idx, random_synonym)\n",
        "\n",
        "def random_insert(words, n):\n",
        "  new_words = words.copy()\n",
        "  for i in range(n):\n",
        "    add_word(new_words)\n",
        "  return new_words"
      ],
      "metadata": {
        "id": "3j4gTLdNm0La"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = synonyms.seg('目前华为部分型号的手机产品出现货少的现象')\n",
        "print(words)\n",
        "# 后面的是词性"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okqcsY-ivdK5",
        "outputId": "dfe6f2f1-6857-482b-8cc3-7b57c87de5ab"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(['目前', '华为', '部分', '型号', '的', '手机', '产品', '出现', '货', '少', '的', '现象'], ['t', 'nr', 'n', 'n', 'uj', 'n', 'n', 'v', 'n', 'a', 'uj', 'n'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from random import shuffle\n",
        "# EDA方法\n",
        "# 参数num_aug：增加了几条数据\n",
        "def eda(sentence, alpha_sr= 0.1, alpha_ri = 0.1, alpha_rs = 0.1, p_rd = 0.1, num_aug = 9):\n",
        "  words = synonyms.seg(sentence)[0]\n",
        "  num_words = len(words)\n",
        "  augmented_sentence = []\n",
        "  \n",
        "  # 每种技术增加了多少样本\n",
        "  num_new_per_tech = int(num_aug / 4) + 1\n",
        "  # = 3\n",
        "\n",
        "  # 同义词替换数量\n",
        "  n_sr = max(1, int(alpha_sr * num_words))\n",
        "  # 随机插入数量\n",
        "  n_ri = max(1, int(alpha_ri * num_words))\n",
        "  # 随机交换数量\n",
        "  n_rs = max(1, int(alpha_rs * num_words))\n",
        "\n",
        "  # 同义词替换\n",
        "  for i in range(num_new_per_tech):\n",
        "    a_words = synonym_replacement(words, n_sr)\n",
        "    # a_words 是列表 []\n",
        "    print('a-words(同义词替换):',a_words)\n",
        "    augmented_sentence.append(' '.join(a_words))\n",
        "  # 随机插入\n",
        "  for i in range(num_new_per_tech):\n",
        "    a_words = random_insert(words, n_ri)\n",
        "    augmented_sentence.append(' '.join(a_words))\n",
        "  # 随机交换\n",
        "  for i in range(num_new_per_tech):\n",
        "    a_words = random_swap(words, n_rs)\n",
        "    augmented_sentence.append(' '.join(a_words))\n",
        "  # 随机删除\n",
        "  for i in range(num_new_per_tech):\n",
        "    a_words = random_deletion(words, p_rd)\n",
        "    augmented_sentence.append(' '.join(a_words))\n",
        "\n",
        "  shuffle(augmented_sentence)\n",
        "\n",
        "  if num_aug >= 1:\n",
        "    augmented_sentence = augmented_sentence[:num_aug]\n",
        "  else: # num_aug<1\n",
        "    keep_prob = num_aug / len(augmented_sentence)\n",
        "    # random_delete\n",
        "    augmented_sentence = [s for s in augmented_sentence if random.uniform(0, 1) < keep_prob]\n",
        "\n",
        "  return augmented_sentence\n",
        "\n"
      ],
      "metadata": {
        "id": "Lh7LU9vdqV5a"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eda('9月15日以来，台积电、高通、三星等华为的重要合作伙伴，只要没有美国的相关许可证，都无法供应芯片给华为，而中芯国际等国产芯片企业，也因采用美国技术，而无法供货给华为。目前华为部分型号的手机产品出现货少的现象，若该形势持续下去，华为手机业务将遭受重创。')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFV5Q0IP517R",
        "outputId": "ac3fe67f-03c3-40fc-b6c0-8151e2e62788"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a-words(同义词替换): ['9', '月', '15', '日晚', '以来', '，', '台积电', '、', '高通', '、', '三星', '等', '华为', '的', '重要', '竞争者', '，', '只要', '没有', '古巴', '的', '相关', '许可证', '，', '都', '无法', '供应', '芯片', '给', '华为', '，', '而', '中芯国际', '等', '国产', '芯片', '企业', '，', '也', '因', '引入', '古巴', '半导体技术', '，', '而', '无法', '供货', '给', '华为', '。', '目前', '华为', '部分', '型号', '的', '手机', '家电产品', '出现', '装箱', '少', '的', '现象', '，', '若', '该', '形势', '持续', '下去', '，', '华为', '手机', '业务', '将', '遭受', '重创', '。']\n",
            "a-words(同义词替换): ['9', '月', '15', '同年', '以来', '，', '台积电', '、', '高通', '、', '三星电子', '等', '华为', '的', '重要', '合作伙伴', '，', '只要', '没有', '古巴', '的', '相关', '许可证', '，', '都', '无法', '供应', '芯片', '给', '华为', '，', '而', '中芯国际', '等', '混动', '芯片', '民企', '，', '也', '因', '采用', '古巴', '关键技术', '，', '而', '无法', '供货', '给', '华为', '。', '目前', '华为', '部分', '型号', '的', '手机', '产品', '出现', '货', '少', '的', '现象', '，', '若', '该', '形势', '持续', '下去', '，', '华为', '手机', '业务', '将', '遭受', '挫败', '。']\n",
            "a-words(同义词替换): ['9', '月前', '15', '日', '以来', '，', '台积电', '、', '高通', '、', '三星', '等', '华为', '的', '重要', '合作伙伴', '，', '只要', '没有', '美国', '的', '相关', '许可证', '，', '就', '无法', '市场供应', '芯片', '给', '华为', '，', '而', '中芯国际', '等', '国产', '芯片', '企业', '，', '也', '因', '引入', '美国', '技术', '，', '而', '无法', '供货', '给', '华为', '。', '目前', '华为', '部分', '车种', '的', '手机', '产品', '出现', '货', '少', '的', '现象', '，', '若', '该', '形势', '在短期内', '下去', '，', '华为', '手机', '业务', '将', '遭受', '顽强抵抗', '。']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['9 月 15 同年 以来 ， 台积电 、 高通 、 三星电子 等 华为 的 重要 合作伙伴 ， 只要 没有 古巴 的 相关 许可证 ， 都 无法 供应 芯片 给 华为 ， 而 中芯国际 等 混动 芯片 民企 ， 也 因 采用 古巴 关键技术 ， 而 无法 供货 给 华为 。 目前 华为 部分 型号 的 手机 产品 出现 货 少 的 现象 ， 若 该 形势 持续 下去 ， 华为 手机 业务 将 遭受 挫败 。',\n",
              " '9 月 15 日晚 以来 ， 台积电 、 高通 、 三星 等 华为 的 重要 竞争者 ， 只要 没有 古巴 的 相关 许可证 ， 都 无法 供应 芯片 给 华为 ， 而 中芯国际 等 国产 芯片 企业 ， 也 因 引入 古巴 半导体技术 ， 而 无法 供货 给 华为 。 目前 华为 部分 型号 的 手机 家电产品 出现 装箱 少 的 现象 ， 若 该 形势 持续 下去 ， 华为 手机 业务 将 遭受 重创 。',\n",
              " '9 月 15 日 以来 ， 台积电 、 高通 、 三星 等 华为 的 重要 合作伙伴 鸭蛋 譬如 ， 只要 没有 第五代 美国 的 相关 许可证 ， 都 无法 供应 芯片 给 华为 ， 而 中芯国际 等 国产 芯片 譬如 企业 ， 也 因 显现出 采用 美国 技术 ， 而 无法 加拿大 供货 给 华为 。 目前 华为 部分 型号 的 手机 产品 出现 货 少 的 现象 ， 若 该 形势 持续 下去 突出 ， 华为 手机 业务 将 遭受 重创 。',\n",
              " '9 月 15 日 以来 ， 台积电 、 高通 、 三星 等 华为 的 重要 合作伙伴 ， 只要 没有 美国 的 相关 许可证 ， 都 无法 供应 芯片 给 华为 ， 而 中芯国际 等 国产 芯片 企业 ， 也 因 采用 美国 技术 ， 而 无法 供货 给 华为 。 目前 华为 部分 型号 的 手机 产品 出现 货 少 的 现象 ， 若 该 形势 持续 下去 ， 华为 手机 业务 将 遭受 重创 。',\n",
              " '9 月前 15 日 以来 ， 台积电 、 高通 、 三星 等 华为 的 重要 合作伙伴 ， 只要 没有 美国 的 相关 许可证 ， 就 无法 市场供应 芯片 给 华为 ， 而 中芯国际 等 国产 芯片 企业 ， 也 因 引入 美国 技术 ， 而 无法 供货 给 华为 。 目前 华为 部分 车种 的 手机 产品 出现 货 少 的 现象 ， 若 该 形势 在短期内 下去 ， 华为 手机 业务 将 遭受 顽强抵抗 。',\n",
              " '9 月 15 日 以来 ， 台积电 、 高通 、 三星 等 华为 的 重要 合作伙伴 ， 只要 没有 美国 相关 许可证 ， 都 无法 芯片 华为 ， 而 中芯国际 等 国产 芯片 企业 ， 也 因 采用 美国 技术 ， 而 无法 给 华为 目前 华为 部分 型号 的 手机 产品 出现 货 少 现象 ， 若 该 形势 持续 下去 ， 华为 手机 业务 将 遭受 重创 。',\n",
              " '9 月 15 日 以来 ， 台积电 、 高通 、 三星 等 华为 的 重要 合作伙伴 只要 没有 美国 的 相关 许可证 ， 都 无法 供应 芯片 给 华为 ， 而 中芯国际 等 国产 芯片 企业 ， 也 因 采用 美国 ， 而 无法 供货 给 华为 。 目前 华为 部分 型号 的 手机 产品 出现 货 少 的 现象 ， 若 该 形势 持续 下去 ， 华为 手机 业务 将 遭受 重创 。',\n",
              " '9 月 15 日 以来 ， 台积电 、 高通 、 三星 等 华为 的 重要 合作伙伴 ， 只要 没有 美国 的 相关 许可证 ， 都 无法 供应 芯片 给 华为 ， 无法 而 中芯国际 等 国产 芯片 合格证 企业 ， 也 因 第五代 采用 美国 技术 ， 而 无法 供货 给 年 Canillac 华为 。 目前 华为 部分 型号 的 手机 产品 年 出现 货 少 的 现象 ， 若 该 形势 持续 下去 ， 华为 不会 手机 业务 将 遭受 重创 。',\n",
              " '9 月 15 日 以来 ， 台积电 、 高通 、 三星 等 华为 的 重要 合作伙伴 ， 只要 没有 美国 的 相关 许可证 ， 都 无法 供应 芯片 给 华为 ， 而 中芯国际 等 国产 芯片 企业 ， 也 因 采用 美国 技术 ， 而 无法 供货 给 华为 。 目前 华为 部分 型号 的 手机 产品 出现 货 少 的 现象 ， 若 该 形势 持续 下去 ， 华为 手机 业务 将 遭受 重创 。']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    }
  ]
}