{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "06_self_Text_Data_Augmentation_part2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bDd1SLjpFhY",
        "outputId": "605a020d-ed5f-4bf5-acdb-e33c44de2257"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu May 19 03:41:20 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import sys\n",
        "drive.mount('/content/drive')\n",
        "#设置路径\n",
        "sys.path.append('/content/drive/MyDrive/Colab Notebooks')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2WrbHfHxpjWG",
        "outputId": "8dc55411-21fe-4dad-afd7-a4b85e55a9cc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -U synonyms"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IitZuf_Cplw1",
        "outputId": "1e6ac664-a626-4124-b515-c2cdde27039b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting synonyms\n",
            "  Downloading synonyms-3.16.0.tar.gz (10.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.7 MB 15.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from synonyms) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.13.1 in /usr/local/lib/python3.7/dist-packages (from synonyms) (1.21.6)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from synonyms) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from synonyms) (1.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.1->synonyms) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.1->synonyms) (1.1.0)\n",
            "Building wheels for collected packages: synonyms\n",
            "  Building wheel for synonyms (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for synonyms: filename=synonyms-3.16.0-py3-none-any.whl size=10832785 sha256=1a1745fcb8ed8534cc72528bc078678d6ce32095a917349f33162dc82e20ce42\n",
            "  Stored in directory: /root/.cache/pip/wheels/e4/cd/43/b4548753509a94471fc946967a07116252d49aeeb689db8f7c\n",
            "Successfully built synonyms\n",
            "Installing collected packages: synonyms\n",
            "Successfully installed synonyms-3.16.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install torch==1.6.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frmB8caapm32",
        "outputId": "1dbc5a17-18fc-4b0b-b9cc-fc0a87a8ae02"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==1.6.0\n",
            "  Downloading torch-1.6.0-cp37-cp37m-manylinux1_x86_64.whl (748.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 748.8 MB 18 kB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0) (1.21.6)\n",
            "Installing collected packages: torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.11.0+cu113\n",
            "    Uninstalling torch-1.11.0+cu113:\n",
            "      Successfully uninstalled torch-1.11.0+cu113\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.12.0+cu113 requires torch==1.11.0, but you have torch 1.6.0 which is incompatible.\n",
            "torchtext 0.12.0 requires torch==1.11.0, but you have torch 1.6.0 which is incompatible.\n",
            "torchaudio 0.11.0+cu113 requires torch==1.11.0, but you have torch 1.6.0 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install transformers==4.0.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6SSwE6yppv-",
        "outputId": "9a0dc882-1ed5-419e-a273-4110e0a05889"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers==4.0.1\n",
            "  Downloading transformers-4.0.1-py3-none-any.whl (1.4 MB)\n",
            "\u001b[?25l\r\u001b[K     |▎                               | 10 kB 30.5 MB/s eta 0:00:01\r\u001b[K     |▌                               | 20 kB 35.5 MB/s eta 0:00:01\r\u001b[K     |▊                               | 30 kB 40.4 MB/s eta 0:00:01\r\u001b[K     |█                               | 40 kB 44.6 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 51 kB 21.5 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 61 kB 24.0 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 71 kB 25.3 MB/s eta 0:00:01\r\u001b[K     |██                              | 81 kB 26.3 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 92 kB 28.4 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 102 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 112 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |███                             | 122 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 133 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |███▍                            | 143 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 153 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 163 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 174 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 184 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 194 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 204 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |█████                           | 215 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 225 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 235 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 245 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |██████                          | 256 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 266 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 276 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 286 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |███████                         | 296 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 307 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 317 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 327 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |████████                        | 337 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 348 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 358 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 368 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 378 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 389 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 399 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 409 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 419 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 430 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 440 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 450 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 460 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 471 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 481 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 491 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 501 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 512 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 522 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 532 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 542 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 552 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 563 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 573 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 583 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 593 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 604 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 614 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 624 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 634 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 645 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 655 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 665 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 675 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 686 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 696 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 706 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 716 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 727 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 737 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 747 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 757 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 768 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 778 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 788 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 798 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 808 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 819 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 829 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 839 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 849 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 860 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 870 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 880 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 890 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 901 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 911 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 921 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 931 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 942 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 952 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 962 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 972 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 983 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 993 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.0 MB 29.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.0 MB 29.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 1.0 MB 29.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.0 MB 29.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.0 MB 29.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.1 MB 29.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.1 MB 29.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 1.1 MB 29.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.1 MB 29.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.1 MB 29.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.1 MB 29.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.1 MB 29.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.1 MB 29.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.1 MB 29.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.1 MB 29.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 1.2 MB 29.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 1.2 MB 29.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.2 MB 29.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.2 MB 29.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.2 MB 29.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.2 MB 29.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.2 MB 29.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.2 MB 29.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.2 MB 29.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 1.2 MB 29.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.3 MB 29.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.3 MB 29.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.3 MB 29.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.3 MB 29.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.3 MB 29.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.3 MB 29.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.3 MB 29.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.3 MB 29.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.3 MB 29.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.4 MB 29.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.4 MB 29.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.0.1) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.0.1) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.0.1) (3.7.0)\n",
            "Collecting tokenizers==0.9.4\n",
            "  Downloading tokenizers-0.9.4-cp37-cp37m-manylinux2010_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 51.2 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 48.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.0.1) (4.64.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.0.1) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==4.0.1) (1.21.6)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.0.1) (3.0.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.0.1) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.0.1) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.0.1) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.0.1) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.0.1) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.0.1) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.0.1) (1.1.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=85b4ac140bc7079e27ca4468ca207d374026b5751bca276a50a895b1b722196f\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.53 tokenizers-0.9.4 transformers-4.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import synonyms"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSoEhm8xprxX",
        "outputId": "e130c7e2-e08e-438e-da14-a60b7bdd704a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[jieba] default dict file path ../data/vocab.txt\n",
            "[jieba] default dict file path ../data/vocab.txt\n",
            "[jieba] load default dict ../data/vocab.txt ...\n",
            "[jieba] load default dict ../data/vocab.txt ...\n",
            ">> Synonyms load wordseg dict [/usr/local/lib/python3.7/dist-packages/synonyms/data/vocab.txt] ... \n",
            ">> Synonyms on loading stopwords [/usr/local/lib/python3.7/dist-packages/synonyms/data/stopwords.txt] ...\n",
            "[Synonyms] on loading vectors [/usr/local/lib/python3.7/dist-packages/synonyms/data/words.vector.gz] ...\n",
            "\n",
            "[Synonyms] downloading data from https://github.com/chatopera/Synonyms/releases/download/3.15.0/words.vector.gz to /usr/local/lib/python3.7/dist-packages/synonyms/data/words.vector.gz ... \n",
            " this only happens if SYNONYMS_WORD2VEC_BIN_URL_ZH_CN is not present and Synonyms initialization for the first time. \n",
            " It would take minutes that depends on network.\n",
            "\n",
            "[Synonyms] downloaded.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EDA（Easy Data Augmentation）\n",
        "![EDA3](https://img-blog.csdnimg.cn/50c22b4212714b509ce053ff921d6bdd.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTI4NzA2MA==,size_16,color_FFFFFF,t_70)"
      ],
      "metadata": {
        "id": "RIeS3F2QrMZV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 对于训练集中的给定句子，随机选择并执行以下操作之一：\n",
        "* 同义词替换（SR）：从句子中随机选择 n 个不是停用词的词。 用随机选择的同义词之一替换这些单词中的每一个。\n",
        "* 随机插入 (RI)：在句子中随机找到一个词，并找出其同义词，且该同义词不是停用词。 将该同义词插入句子中的随机位置。 这样做n次。\n",
        "* 随机交换（RS）：随机选择句子中的两个单词并交换它们的位置。 这样做n次。\n",
        "* 随机删除（RD）：以概率 p 随机删除句子中的每个单词。"
      ],
      "metadata": {
        "id": "wuNtIMkDrSoN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 读取停用词表\n",
        "import random\n",
        "import re\n",
        "from random import shuffle\n",
        "# strip() 方法用于移除字符串头尾指定的字符（默认为空格或换行符）或字符序列。\n",
        "stop_words = {word.strip() for word in open('/content/drive/MyDrive/Colab Notebooks/dataset/baidu_stopwords.txt', 'r', encoding='utf8').readlines()}"
      ],
      "metadata": {
        "id": "9BUv5AFRptie"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 同义词替换（SR）：从句子中随机选择 n 个不是停用词的词。 用随机选择的同义词之一替换这些单词中的每一个。\n",
        "\n",
        "# 得到同义词列表\n",
        "def get_synonym(word):\n",
        "  # nearby返回一个元组，位置0返回同义词，位置1返回相似度\n",
        "  sys = set(synonyms.nearby(word)[0])\n",
        "  # 去除原词\n",
        "  if word in sys:\n",
        "    sys.remove(word)\n",
        "  return list(sys)\n",
        "  # 如果输入\"给力\" 可能没有同义词（同义词只有他自己） 则返回  ([],[])\n",
        "\n",
        "# 同义词替换\n",
        "# 传入一个词列表和替换词的数量\n",
        "def synonym_replacement(words, n):\n",
        "\n",
        "  new_words = words.copy()\n",
        "  # 去除停用词，去重，变成列表\n",
        "  random_word_list = list(set([word for word in words if word not in stop_words]))\n",
        "  # 打乱\n",
        "  random.shuffle(random_word_list)\n",
        "\n",
        "  num_replaced = 0\n",
        "  for random_word in random_word_list:\n",
        "    synonym_words = get_synonym(random_word)\n",
        "    if len(synonym_words)>=1:\n",
        "        # 随机选取一个同义词\n",
        "        synonym = random.choice(list(synonym_words))\n",
        "        # 如果word是要替换的词 替换成同义词 ，否则返回原词\n",
        "        new_words = [synonym if word == random_word else word for word in new_words]\n",
        "        # 同义词替换数量+1\n",
        "        num_replaced += 1\n",
        "        \n",
        "    if num_replaced >= n:\n",
        "        break\n",
        "  # 为什么加这两句话？ 看note1\n",
        "  sentence = ' '.join(new_words)\n",
        "  new_words = sentence.split(' ')\n",
        "\n",
        "  return new_words"
      ],
      "metadata": {
        "id": "FoteXbv0swx1"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 使用eda进行数据增强\n",
        "# 同义词替换的比例、 增强的句子数目\n",
        "def eda(sentence, alpha_sr=0.1, num_aug=9):\n",
        "\n",
        "  # 位置0是词组、1是词性\n",
        "  words = synonyms.seg(sentence)[0]\n",
        "  num_words = len(words)\n",
        "  n_sr = max(1, int(alpha_sr * num_words))\n",
        "\n",
        "  augmented_sentences = []\n",
        "\n",
        "  for _ in range(num_aug):\n",
        "    a_words = synonym_replacement(words, n_sr)\n",
        "    augmented_sentences.append(' '.join(a_words))\n",
        "  return augmented_sentences"
      ],
      "metadata": {
        "id": "HdAYQ0i5u69t"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# note1\n",
        "# 存在这样一种情况\n",
        "sentence = ['in', 'war', 'one', 'must', 'be', 'a', 'good', 'actor']\n",
        "word = 'actor'\n",
        "example_synonyms = ['actress', 'film star', 'performer', 'comedian', 'entertainer']\n",
        "new_sentence = ['in', 'war', 'one', 'must', 'be', 'a', 'good', 'film star']\n",
        "# 为了消除空格\n",
        "new_sentence = ['in', 'war', 'one', 'must', 'be', 'a', 'good', 'film', 'star']"
      ],
      "metadata": {
        "id": "5HHl5NL13t5z"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eda('9月15日以来，台积电、高通、三星等华为的重要合作伙伴，只要没有美国的相关许可证，都无法供应芯片给华为，而中芯国际等国产芯片企业，也因采用美国技术，而无法供货给华为。目前华为部分型号的手机产品出现货少的现象，若该形势持续下去，华为手机业务将遭受重创。')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mz-l0Yxj30JT",
        "outputId": "aeeb09df-f6d5-4f35-fd1f-a0b7f748af00"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['9 年末 15 日 以来 ， A43EI235E 、 高通 、 三星 等 华为 的 重要 合作伙伴 ， 只要 没有 美国 的 相关 许可证 ， 都 无法 供应 芯片 给 华为 ， 而 中芯国际 等 国产 芯片 企业 ， 也 因 采用 美国 电子技术 ， 而 无法 产品销售 给 华为 。 目前 华为 部分 改型 的 手机 产品 出现 货 少 的 异常现象 ， 若 该 形势 持续 下去 ， 华为 手机 业务 将 遭受重创 重创 。',\n",
              " '9 月 15 日 以来 ， 台积电 、 高通 、 Samsung 等 华为 的 重要 SAP ， 只要 没有 美国 的 相关 许可证 ， 都 无法 配给 芯片 给 华为 ， 而 中芯国际 等 量产 芯片 企业 ， 也 因 采行 美国 技术 ， 而 无法 供货 给 华为 。 目前 华为 部分 型号 的 手机 产品 出现 货 少 的 怪象 ， 若 该 形势 持续 下去 ， 华为 手机 业务 将 造成 重创 。',\n",
              " '9 月底 15 日 以来 ， 台积电 、 手机芯片 、 Samsung 等 华为 的 重要 合作伙伴 ， 只要 没有 美国 的 相关 许可证 ， 都 无法 配给 芯片 给 华为 ， 而 中芯国际 等 换代 芯片 企业 ， 也 因 采用 美国 技术 ， 而 无法 供货 给 华为 。 目前 华为 部分 型号 的 手机 产品 出现 货 缺 的 现象 ， 若 该 金融形势 持续 下去 ， 华为 手机 业务 将 遭受 重创 。',\n",
              " '9 月 15 日 以来 ， TNUMBERG34iss 、 高通 、 三星 等 华为 的 重要 伙伴 ， 只要 没有 美国 的 相关 许可证 ， 虽然 无法 货源 芯片 给 华为 ， 而 中芯国际 等 第五代 芯片 企业 ， 也 因 采用 美国 技术 ， 而 无法 供货 给 华为 。 目前 华为 部分 制式 的 手机 产品 出现 二手 少 的 现象 ， 若 该 形势 持续 下去 ， 华为 手机 业务 将 遭受 重创 。',\n",
              " '9 月 15 日晨 以来 ， Canillac 、 高通 、 三星 等 华为 的 重要 合作伙伴 ， 只要 没有 美国 的 相关 许可证 ， 都 无法 供应 芯片 给 华为 ， 而 SE9 等 国产 芯片 民营企业 ， 也 因 采用 美国 技术 ， 而 无法 供货 给 华为 。 目前 华为 部分 型号 的 手机 产品 出现 货 多一点 的 现象 ， 若 该 形势 持续 下去 ， 华为 手机 产品销售 将 蒙受 重创 。',\n",
              " '9 年 15 日 以来 ， 台积电 、 高通 、 三星 等 华为 的 重要 合作伙伴 ， 只要 没有 美国 的 相关 许可证 ， 都 无法 供应 器件 给 华为 ， 而 中芯国际 等 国产 器件 企业 ， 也 因 采用 美国 技术 ， 而 无法 供货 给 华为 。 目前 华为 部分 型号 的 笔记本电脑 产品线 出现 货 少 的 弊端 ， 若 该 情势 持续 下去 ， 华为 笔记本电脑 管理业务 将 遭受 重创 。',\n",
              " '9 月 15 日 以来 ， 台积电 、 高通 、 三星 等 华为 的 重要 合作伙伴 ， 只要 没有 美国 的 相关 许可证 ， 确实 无法 供应 芯片 给 华为 ， 而 SE9 等 国产 芯片 企业 ， 也 因 采用 美国 工艺技术 ， 而 无法 供货 给 华为 。 目前 华为 部分 车种 的 手机 产品 出现 接单 少 的 弊端 ， 若 该 形势 持续 下去 ， 华为 手机 银行业务 将 遭受 重创 。',\n",
              " '9 年末 15 日 以来 ， 台积电 、 高通 、 三星 等 华为 的 重要 分销商 ， 只要 没有 美国 的 各类 许可证 ， 都 无法 供应 芯片 给 华为 ， 而 中芯国际 等 国产 芯片 企业 ， 也 因 换用 美国 专利技术 ， 而 无法 供货 给 华为 。 目前 华为 部分 型号 的 手机 产品 出现 货 贵 的 异常现象 ， 若 该 形势 持续 下去 ， 华为 手机 业务 将 遭受 重创 。',\n",
              " '9 月 15 日 以来 ， TNUMBERG34iss 、 高通 、 LG 等 华为 的 重要 合作伙伴 ， 只要 没有 美国 的 相关 许可证 ， 即使 无法 供应 芯片 给 华为 ， 而 中芯国际 等 国产 芯片 企业 ， 也 因 装配 美国 技术 ， 而 无法 分销 给 华为 。 目前 华为 部分 型号 的 手机 产品 出现 货 多一点 的 现象 ， 若 该 形势 急剧 下去 ， 华为 手机 业务 将 遭受 重创 。']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![UDA5](https://img-blog.csdnimg.cn/9d10da70d1d0467e93ef5bb1267ac87f.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTI4NzA2MA==,size_16,color_FFFFFF,t_70)\n",
        "**$ \\tilde{\\theta} $： 参数不变 不进行反向传播**\n",
        "\n",
        "\n",
        "![在这里插入图片描述](https://img-blog.csdnimg.cn/88a3abe95bbd4e369fe4d085533c9c35.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTI4NzA2MA==,size_16,color_FFFFFF,t_70)"
      ],
      "metadata": {
        "id": "vPU8nQ-9Ap3r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bucket_sampler import SortedSampler, BucketBatchSampler\n",
        "from EMA import *"
      ],
      "metadata": {
        "id": "JPf1XYme_WiE"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "config = {\n",
        "        'train_file_path': '/content/drive/MyDrive/Colab Notebooks/dataset/ESIM/train.json',\n",
        "        'dev_file_path': '/content/drive/MyDrive/Colab Notebooks/dataset/ESIM/dev.json',\n",
        "        'test_file_path': '/content/drive/MyDrive/Colab Notebooks/dataset/ESIM/test.json',\n",
        "        'output_path': '.',\n",
        "        'model_path': '/content/drive/MyDrive/Colab Notebooks/dataset/BERT_model',\n",
        "        'batch_size': 16,\n",
        "        'num_epochs': 1,\n",
        "        'max_seq_len': 64,\n",
        "        'learning_rate': 2e-5,\n",
        "        'weight_decay': 0.01,\n",
        "        'use_bucket': True,\n",
        "        'bucket_multiplier': 200,\n",
        "        'unsup_data_ratio': 1.5,\n",
        "        'uda_softmax_temp': 0.4,\n",
        "        'uda_confidence_threshold': 0.8,\n",
        "        'device': 'cuda',\n",
        "        'n_gpus': 0,\n",
        "        'logging_step': 300,\n",
        "        'ema_start_step': 500,\n",
        "        'ema_start': False,\n",
        "        'seed': 2022\n",
        "    }\n",
        "\n",
        "if not torch.cuda.is_available():\n",
        "    config['device'] = 'cpu'\n",
        "else:\n",
        "    config['n_gpus'] = torch.cuda.device_count()\n",
        "    config['batch_size'] *= config['n_gpus']\n",
        "\n",
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    return seed\n",
        "\n",
        "seed_everything(config['seed'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSIh_qnCFxnq",
        "outputId": "b19f9c94-a8fe-4e64-93fa-a6663eae2106"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2022"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(config['model_path'])"
      ],
      "metadata": {
        "id": "Ed8eczWuH7sj"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_bert_inputs(inputs, label, sentence_a, sentence_b, tokenizer):\n",
        "  inputs_dict = tokenizer.encode_plus(sentence_a, sentence_b, add_special_tokens = True, return_token_type_ids =True, return_attention_mask = True)\n",
        "\n",
        "  inputs['input_ids'].append(inputs_dict['input_ids'])\n",
        "  inputs['token_type_ids'].append(inputs_dict['token_type_ids'])\n",
        "  inputs['attention_mask'].append(inputs_dict['attention_mask'])\n",
        "  inputs['labels'].append(label)"
      ],
      "metadata": {
        "id": "aLobuIWSH9Za"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 对偶数据增强\n",
        "\n",
        "**a-b对，变成b-a对, 把两个句子换顺序**\\\n",
        "**我们的无监督数据增强就是用的对偶数据增强**\\\n",
        "**BERT输入 a，b两个句子，现在输入以b,a作为输入，增强样本**"
      ],
      "metadata": {
        "id": "p1OJnYZ3IQsa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "def parse_data(path, data_type='train'):\n",
        "  sentence_a = []\n",
        "  sentence_b = []\n",
        "  labels = []\n",
        "\n",
        "  with open(path, 'r', encoding = 'utf8') as f:\n",
        "    for line in tqdm(f.readlines(), desc=f'Reading {data_type} data'):\n",
        "      line = json.loads(line)\n",
        "      sentence_a.append(line['sentence1'])\n",
        "      sentence_b.append(line['sentence2'])\n",
        "      if data_type != 'test':\n",
        "        labels.append(int(line['label']))\n",
        "      else:\n",
        "        labels.append(0)\n",
        "\n",
        "  df = pd.DataFrame(zip(sentence_a, sentence_b, labels), columns = ['text_a', 'text_b', 'labels'])\n",
        "  return df"
      ],
      "metadata": {
        "id": "q2a4-zAUKFnS"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 无监督BERT输入\n",
        "def build_unsup_bert_inputs(inputs, label, sentence_a, sentence_b, tokenizer):\n",
        "  # 左右\n",
        "  lr_inputs_dict = tokenizer.encode_plus(sentence_a, sentence_b, add_special_tokens = True, return_token_type_ids = True, return_attention_mask = True)\n",
        "  # 右左\n",
        "  rl_inputs_dict = tokenizer.encode_plus(sentence_b, sentence_a, add_special_tokens = True, return_token_type_ids = True, return_attention_mask = True)\n",
        "\n",
        "  # 元组的形式\n",
        "  inputs['input_ids'].append((lr_inputs_dict['input_ids'], rl_inputs_dict['input_ids']))\n",
        "  inputs['token_type_ids'].append((lr_inputs_dict['token_type_ids'], rl_inputs_dict['token_type_ids']))\n",
        "  inputs['attention_mask'].append((lr_inputs_dict['attention_mask'], rl_inputs_dict['attention_mask']))\n",
        "  inputs['labels'].append(label)"
      ],
      "metadata": {
        "id": "ivfX_45aM8fb"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## startswith()方法\n",
        "startswith() 方法用于检查字符串是否是以指定子字符串开头\\\n",
        "如果是则返回 True，否则返回 False。如果参数 beg 和 end 指定值，则在指定范围内检查。\\\n",
        "str.startswith(str, beg=0,end=len(string));\\\n",
        "*参数*\n",
        "```\n",
        "str --检测的字符串。\n",
        "strbeg --可选参数用于设置字符串检测的起始位置。\n",
        "strend --可选参数用于设置字符串检测的结束位置。\n",
        "```"
      ],
      "metadata": {
        "id": "0mKVUaZvs6GF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "def read_data(config, tokenizer):\n",
        "  train_df = parse_data(config['train_file_path'], data_type = 'train')\n",
        "  dev_df = parse_data(config['dev_file_path'], data_type = 'dev')\n",
        "  test_df = parse_data(config['test_file_path'], data_type = 'test')\n",
        "\n",
        "  data_df = {'train': train_df, 'dev': dev_df, 'test': test_df}\n",
        "  processed_data = {}\n",
        "  unsup_data = defaultdict(list)\n",
        "  for data_type, df in data_df.items():\n",
        "    inputs = defaultdict(list)\n",
        "    if data_type == 'train':\n",
        "      reversed_inputs = defaultdict(list)\n",
        "\n",
        "    for i, row in tqdm(df.iterrows(), desc=f'Preprocessing {data_type} data', total = len(df)):\n",
        "      label = 0 if data_type == 'test' else row[2]\n",
        "      sentence_a, sentence_b = row[0], row[1]\n",
        "      build_bert_inputs(inputs, label, sentence_a, sentence_b, tokenizer)\n",
        "\n",
        "      if data_type.startswith('test'):\n",
        "        build_bert_inputs(inputs, label, sentence_b, sentence_a, tokenizer)\n",
        "\n",
        "\n",
        "      build_unsup_bert_inputs(unsup_data, label, sentence_a, sentence_b, tokenizer)\n",
        "\n",
        "    processed_data[data_type] = inputs\n",
        "  processed_data['unsup_data'] = unsup_data\n",
        "  return processed_data\n",
        "\n",
        "# processed_data\n",
        "# {\n",
        "#    'train':,\n",
        "#    'dev':,\n",
        "#    'test':,\n",
        "#    'unsup_data':   # 数据量最大的\n",
        "# }"
      ],
      "metadata": {
        "id": "dwfnsojmrjBm"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = read_data(config, tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NxzjWiL3thie",
        "outputId": "e74cbd18-80e2-48ed-ef2a-bfda5ed90eed"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reading train data: 100%|██████████| 34334/34334 [00:00<00:00, 66611.14it/s]\n",
            "Reading dev data: 100%|██████████| 4316/4316 [00:00<00:00, 291366.75it/s]\n",
            "Reading test data: 100%|██████████| 3861/3861 [00:00<00:00, 229236.85it/s]\n",
            "Preprocessing train data: 100%|██████████| 34334/34334 [00:46<00:00, 744.58it/s]\n",
            "Preprocessing dev data: 100%|██████████| 4316/4316 [00:06<00:00, 644.03it/s]\n",
            "Preprocessing test data: 100%|██████████| 3861/3861 [00:08<00:00, 478.15it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "class AFQMCDataset(Dataset):\n",
        "  def __init__(self, data_dict):\n",
        "    super(AFQMCDataset, self).__init__()\n",
        "    self.data_dict = data_dict\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    data = (self.data_dict['input_ids'][idx],\n",
        "         self.data_dict['token_type_ids'][idx],\n",
        "         self.data_dict['attention_mask'][idx],\n",
        "         self.data_dict['labels'][idx])\n",
        "    return data\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.data_dict['input_ids'])\n"
      ],
      "metadata": {
        "id": "dHu8cHCuVrH6"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Collator:\n",
        "  def __init__(self, max_seq_len, tokenizer):\n",
        "    self.max_seq_len = max_seq_len\n",
        "    self.tokenizer = tokenizer\n",
        "\n",
        "  def pad_and_truncate(self, input_ids_list, token_type_ids_list, attention_mask_list, labels_list, max_seq_len):\n",
        "    input_ids = torch.zeros((len(input_ids_list), max_seq_len), dtype = torch.long)\n",
        "    token_type_ids = torch.zeros_like(input_ids)\n",
        "    attention_mask = torch.zeros_like(input_ids)\n",
        "    for i in range(len(input_ids_list)):\n",
        "      seq_len = len(input_ids_list[i])\n",
        "      if seq_len <= max_seq_len:\n",
        "        input_ids[i, :seq_len] = torch.tensor(input_ids_list[i], dtype = torch.long)\n",
        "        token_type_ids[i, :seq_len] = torch.tensor(token_type_ids_list[i], dtype = torch.long)\n",
        "        attention_mask[i, :seq_len] = torch.tensor(attention_mask_list[i], dtype = torch.long)\n",
        "\n",
        "      else:\n",
        "        input_ids[i] = torch.tensor(input_ids_list[i][:max_seq_len - 1] + [self.tokenizer.sep_token_id], dtype = torch.long)\n",
        "        token_type_ids[i] = torch.tensor(token_type_ids_list[i][:max_seq_len], dtype = torch.long)\n",
        "        attention_mask[i] = torch.tensor(attention_mask_list[i][:max_seq_len], dtype = torch.long)\n",
        "\n",
        "    labels = torch.tensor(labels_list, dtype = torch.long)\n",
        "    return input_ids, token_type_ids, attention_mask, labels\n",
        "\n",
        "  def __call__(self, examples):\n",
        "    input_ids_list, token_type_ids_list, attention_mask_list, labels_list = list(zip(*examples))\n",
        "    cur_max_seq_len = max(len(input_ids) for input_ids in input_ids_list)\n",
        "    max_seq_len = min(cur_max_seq_len, self.max_seq_len)\n",
        "\n",
        "    input_ids, token_type_ids, attention_mask, labels = self.pad_and_truncate(input_ids_list, token_type_ids_list, attention_mask_list, labels_list, max_seq_len)\n",
        "\n",
        "    data_dict = {\n",
        "        'input_ids':input_ids,\n",
        "        'token_type_ids':token_type_ids,\n",
        "        'attention_mask':attention_mask,\n",
        "        'labels':labels\n",
        "    }\n",
        "    return data_dict"
      ],
      "metadata": {
        "id": "jLRFtNPjWBV0"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "collate_fn = Collator(config['max_seq_len'], tokenizer)"
      ],
      "metadata": {
        "id": "qU-ST7YHWnGT"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# UDA 无监督重新构造dataset 和 collator\n",
        "class UnsupAFQMCDataset(Dataset):\n",
        "  def __init__(self, data_dict):\n",
        "    super(UnsupAFQMCDataset, self).__init__()\n",
        "    self.data_dict = data_dict\n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "    input_ids = self.data_dict['input_ids'][idx]\n",
        "    token_type_ids = self.data_dict['token_type_ids'][idx]\n",
        "    attention_mask = self.data_dict['attention_mask'][idx]\n",
        "    labels = self.data_dict['labels'][idx]\n",
        "    # input_ids[0]：lr_inputs_dict['input_ids']    (build_unsup_bert_inputs)\n",
        "    # input_ids[1]：rl_inputs_dict['input_ids']\n",
        "    return (input_ids[0], token_type_ids[0], attention_mask[0],\n",
        "         input_ids[1], token_type_ids[1], attention_mask[1],\n",
        "         labels)\n",
        "    \n",
        "  def __len__(self):\n",
        "    return len(self.data_dict['input_ids'])"
      ],
      "metadata": {
        "id": "PzCTMQpXWp0q"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UnsupCollator(Collator):\n",
        "  def __init__(self, max_seq_len, tokenizer):\n",
        "    super(UnsupCollator, self).__init__(max_seq_len, tokenizer)\n",
        "\n",
        "  def __call__(self, examples):\n",
        "    # 根据UnsupAFQMCDataset的getitem 有七个数据\n",
        "    (ab_input_ids_list, ab_token_type_ids_list, ab_attention_mask_list,\n",
        "     ba_input_ids_list, ba_token_type_ids_list, ba_attention_mask_list,\n",
        "     labels_list) = list(zip(*examples))\n",
        "    cur_max_seq_len = max(len(input_ids) for input_ids in ab_input_ids_list)\n",
        "    max_seq_len = min(cur_max_seq_len, self.max_seq_len)\n",
        "    # 分批整ab, ba（填充与截断）\n",
        "    ab_input_ids, ab_token_type_ids, ab_attention_mask, labels = self.pad_and_truncate(ab_input_ids_list, ab_token_type_ids_list, ab_attention_mask_list, labels_list, max_seq_len)\n",
        "    ba_input_ids, ba_token_type_ids, ba_attention_mask, labels = self.pad_and_truncate(ba_input_ids_list, ba_token_type_ids_list, ba_attention_mask_list, labels_list, max_seq_len)\n",
        "\n",
        "\n",
        "    data_dict = {\n",
        "        'ab_input_ids':ab_input_ids,\n",
        "        'ab_token_type_ids':ab_token_type_ids,\n",
        "        'ab_attention_mask':ab_attention_mask,\n",
        "        'ba_input_ids':ba_input_ids,\n",
        "        'ba_token_type_ids':ba_token_type_ids,\n",
        "        'ba_attention_mask':ba_attention_mask,\n",
        "        'labels':labels\n",
        "    }\n",
        "    return data_dict"
      ],
      "metadata": {
        "id": "THRD_vhSZhPS"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler\n",
        "def build_dataloader(config, data, tokenizer):\n",
        "  train_dataset = AFQMCDataset(data['train'])\n",
        "  dev_dataset = AFQMCDataset(data['dev'])\n",
        "  test_dataset = AFQMCDataset(data['test'])\n",
        "  unsup_dataset = UnsupAFQMCDataset(data['unsup_data'])\n",
        "\n",
        "  collate_fn = Collator(config['max_seq_len'], tokenizer)\n",
        "  unsup_collate_fn = UnsupCollator(config['max_seq_len'], tokenizer)\n",
        "\n",
        "  # 使用桶采样\n",
        "  if config['use_bucket']:\n",
        "    # 监督数据\n",
        "    # 基采样器RandomSampler\n",
        "    train_sampler = RandomSampler(train_dataset)\n",
        "    # drop_last 最后一个batch小于size 丢弃\n",
        "    bucket_sampler = BucketBatchSampler(train_sampler, batch_size = config['batch_size'],\n",
        "                      drop_last = False, sort_key = lambda x: len(train_dataset[x][0]),# 以 input_id 长度作为排序的指标\n",
        "                      bucket_size_multiplier = config['bucket_multiplier'])\n",
        "    train_dataloader = DataLoader(dataset = train_dataset, batch_sampler = bucket_sampler, num_workers = 4, collate_fn = collate_fn)\n",
        "    # 无监督数据 \n",
        "    # grad_data中(图) 有监督、无监督一起训练， 无监督数据量大， batchsize可以设置大一点\n",
        "    unsup_sampler = RandomSampler(unsup_dataset)\n",
        "    unsup_bucket_sampler = BucketBatchSampler(unsup_sampler, batch_size = int(config['batch_size'] * config['unsup_data_ratio']),\n",
        "                      drop_last = False, sort_key = lambda x: len(unsup_dataset[x][0]),# 以 input_id 长度作为排序的指标\n",
        "                      bucket_size_multiplier = config['bucket_multiplier'])\n",
        "    \n",
        "    unsup_dataloader = DataLoader(dataset = unsup_dataset, batch_sampler = unsup_bucket_sampler, num_workers = 4, collate_fn = unsup_collate_fn)\n",
        "  # 不使用桶采样\n",
        "  else:\n",
        "    # 监督数据\n",
        "    train_dataloader = DataLoader(dataset = train_dataset, batch_size = config['batch_size'], shuffle = True, num_workers = 4, collate_fn = collate_fn)\n",
        "    # 无监督数据\n",
        "    unsup_dataloader = DataLoader(dataset = unsup_dataset, batch_size = int(config['batch_size'] * config['unsup_data_ratio']), \n",
        "                    shuffle = True, num_workers = 4, collate_fn = unsup_collate_fn)\n",
        "  # 验证集、测试集dataloader 与桶采样无关 因为shuffle=false  \n",
        "  dev_dataloader = DataLoader(dataset = dev_dataset, batch_size = config['batch_size'], shuffle = False, num_workers = 4, collate_fn = collate_fn)\n",
        "  test_dataloader = DataLoader(dataset = test_dataset, batch_size = config['batch_size'], shuffle = False, num_workers = 4, collate_fn = collate_fn)\n",
        "\n",
        "  return unsup_dataloader, train_dataloader, dev_dataloader, test_dataloader"
      ],
      "metadata": {
        "id": "CFS6iR02a6Ba"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unsup_dataloader, train_dataloader, dev_dataloader, test_dataloader = build_dataloader(config, data, tokenizer)"
      ],
      "metadata": {
        "id": "V7YWrqMYb516"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "def evaluation(config, model, val_dataloader):\n",
        "  model.eval()\n",
        "  preds = []\n",
        "  labels = []\n",
        "  val_loss = 0.\n",
        "  val_iterator = tqdm(val_dataloader, desc = 'Evaluation', total = len(val_dataloader))\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for batch in val_iterator:\n",
        "      labels.append(batch['labels'])\n",
        "      batch_cuda = {item: value.to(config['device']) for item, value in list(batch.items())}\n",
        "      batch_cuda['mode'] = 'val'\n",
        "      loss, logits = model(**batch_cuda)[:2]\n",
        "\n",
        "      if config['n_gpus'] > 1:\n",
        "        loss = loss.mean()\n",
        "\n",
        "      val_loss += loss.item()\n",
        "      preds.append(logits.argmax(dim = -1).detach().cpu())\n",
        "\n",
        "  avg_val_loss = val_loss / len(val_dataloader)\n",
        "  labels = torch.cat(labels, dim = 0).numpy()\n",
        "  preds = torch.cat(preds, dim = 0).numpy()\n",
        "  f1 = f1_score(labels, preds)\n",
        "  acc = accuracy_score(labels, preds)\n",
        "  return avg_val_loss, f1, acc"
      ],
      "metadata": {
        "id": "ljaJQ6mLcIoJ"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForSequenceClassification\n",
        "import torch.nn as nn\n",
        "class BertForAFQMC(BertForSequenceClassification):\n",
        "   # 复写forward\n",
        "   def forward(self, input_ids, token_type_ids, attention_mask, labels = None, mode= 'train'):\n",
        "\n",
        "     outputs = self.bert(input_ids, token_type_ids = token_type_ids, attention_mask = attention_mask, output_hidden_states = True)\n",
        "     # 维度：[batch_size, hidden_size]\n",
        "     pooled_output = outputs[1]\n",
        "     pooled_output = self.dropout(pooled_output)\n",
        "\n",
        "     logits = self.classifier(pooled_output)\n",
        "     # print('BertForAFQMC中logits：',logits)\n",
        "     outputs = (logits, )\n",
        "     # print('BertForAFQMC中outputs：',outputs)\n",
        "\n",
        "     if mode == 'val':\n",
        "       loss_fct = nn.CrossEntropyLoss()\n",
        "       # X.view(-1)中的-1本意是根据另外一个数来自动调整维度\n",
        "       loss = loss_fct(logits, labels.view(-1))\n",
        "\n",
        "       outputs = (loss, ) + outputs\n",
        "     return outputs"
      ],
      "metadata": {
        "id": "CEdDR6ZUcbJ5"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "![addtitional Training1](https://img-blog.csdnimg.cn/5916fe8ae028469bb877d15a1ac566de.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTI4NzA2MA==,size_16,color_FFFFFF,t_70)\n",
        "### 额外训练技巧\n",
        "### Confidence-based masking用于无监督训练数据中\n",
        "基于置信度的MASK，发现MASK当前模型不自信的examples很有帮助。总结来说，无监督数据（grad_data ba_unsup_value）要 选出置信度>$\\beta$的样本（够自信的样本）"
      ],
      "metadata": {
        "id": "QsX20JoEGbR2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![UDA5](https://img-blog.csdnimg.cn/1ddf28077b88449aa84e0391149467e4.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTI4NzA2MA==,size_16,color_FFFFFF,t_70)\n",
        "\n",
        "###  A.1 \n",
        "在半监督学习中，经常会遇到未标记数据量和标记数据量存在巨大差异的情况\\\n",
        "模型通常很快会在标记数据上过拟合，同时在未标记数据欠拟合。\\\n",
        "为了解决这个问题，引入一种技术，训练信号退火（TSA）. 它随着训练的进行逐渐释放。\n",
        "\n",
        "这是一种MASK\\\n",
        "当$\\eta=1$ 代表所有数据都训练了\\\n",
        "当$\\eta=0.5$  代表不是所有数据都训练"
      ],
      "metadata": {
        "id": "MtZibL2DFv8u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 上方Figure 5公式\n",
        "def get_tsa_threshold(total_steps, global_steps):\n",
        "  return np.exp((global_steps / total_steps - 1) * 5) / 2 + 0.5"
      ],
      "metadata": {
        "id": "UQzUtpzhFEom"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "![在这里插入图片描述](https://img-blog.csdnimg.cn/88a3abe95bbd4e369fe4d085533c9c35.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTI4NzA2MA==,size_16,color_FFFFFF,t_70)\n",
        "## 有监督数据和无监督数据怎么拼接：\n",
        "### 无监督的batchsize大，但句子长度不一定大 图为else的情况\n",
        "### 连接时先有监督后无监督，图有误（重要！）\n",
        "**get_data**\n",
        "\n",
        "![在这里插入图片描述](https://img-blog.csdnimg.cn/38a2b12d76094f17819ae918b25f3c71.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTI4NzA2MA==,size_16,color_FFFFFF,t_70)"
      ],
      "metadata": {
        "id": "tMm046pdMZcV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 返回 grad_data：需要计算梯度，需要进行反向传播的数据\n",
        "# 返回 no_grad_data: 不需要计算梯度，不需要进行反向传播的数据\n",
        "def get_data(sup_batch, unsup_batch, config):\n",
        "  # 定义成字典\n",
        "  grad_data = {}\n",
        "  no_grad_data = {}\n",
        "  # sup_batch [bs, seq_len] bs:batchsize\n",
        "  # unsup_batch [bs, seq_len]\n",
        "  # 监督数据的 最长 长度\n",
        "  sup_max_len = sup_batch['input_ids'].size(1)\n",
        "  # 无监督数据 的最长 长度\n",
        "  unsup_max_len = unsup_batch['ba_input_ids'].size(1)\n",
        "  \n",
        "  # 当前数据 的最长 长度(谁短补谁)\n",
        "  cur_max_len = max(sup_max_len, unsup_max_len)\n",
        "  # sup_batch是个字典\n",
        "  for item, sup_value in sup_batch.items():\n",
        "    # 如果键是标签 直接放进来\n",
        "    if item == 'labels':\n",
        "      grad_data[item] = sup_value.to(config['device'])\n",
        "      continue\n",
        "\n",
        "    ba_unsup_value = unsup_batch[f'ba_{item}']\n",
        "    ab_unsup_value = unsup_batch[f'ab_{item}']\n",
        "    \n",
        "    # 谁短补谁，ba_unsup_value短\n",
        "    if sup_max_len == cur_max_len:\n",
        "      padding_value = torch.zeros((ba_unsup_value.size(0), cur_max_len - unsup_max_len), dtype = ba_unsup_value.dtype)\n",
        "      ba_unsup_value = torch.cat([ba_unsup_value, padding_value], dim = -1)\n",
        "    \n",
        "    else:\n",
        "      padding_value = torch.zeros((sup_value.size(0), cur_max_len - sup_max_len), dtype = sup_value.dtype)\n",
        "      sup_value = torch.cat([sup_value, padding_value], dim = -1)\n",
        "    \n",
        "    # 把 sup_batch 和 ba 的 数据放在一起\n",
        "    grad_value = torch.cat([sup_value, ba_unsup_value], dim = 0)\n",
        "    grad_data[item] = grad_value.to(config['device'])\n",
        "    # 对它不用进行操作直接放入字典  \n",
        "    no_grad_data[item] = ab_unsup_value.to(config['device'])\n",
        "\n",
        "  return grad_data, no_grad_data\n"
      ],
      "metadata": {
        "id": "zP1AeM6xGrcd"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sharpen操作\n",
        "import torch.nn as nn\n",
        "logits = torch.randn(2,3)\n",
        "print('logits:',logits)\n",
        "t_softmax = torch.softmax(logits, dim=1)\n",
        "# 一个[]中的数加起来为1\n",
        "print('t_softmax:',t_softmax)\n",
        "# 0.4 为config['uda_softmax_temp']\n",
        "# 让大的更大小的更小，变得更硬标签\n",
        "t_sharpen = torch.softmax(logits/0.4, dim=1)\n",
        "print('t_sharpen:',t_sharpen)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55aDnZv6MAu0",
        "outputId": "18c63b41-72f9-47ed-c99f-f23538f05425"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logits: tensor([[ 0.1915,  0.3306,  0.2306],\n",
            "        [ 0.8936, -0.2044, -0.9081]])\n",
            "t_softmax: tensor([[0.3136, 0.3604, 0.3261],\n",
            "        [0.6673, 0.2226, 0.1101]])\n",
            "t_sharpen: tensor([[0.2842, 0.4024, 0.3134],\n",
            "        [0.9300, 0.0597, 0.0103]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### no_grad_data 经过前向传播，产生ab的逻辑值，做ba逻辑值的标签"
      ],
      "metadata": {
        "id": "SXCEkcK2Nbjk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 无监督数据 (ab) 只需要正向传播\n",
        "# Confidence-based masking\n",
        "def forward_no_grad(no_grad_data, config, model):\n",
        "  with torch.no_grad():\n",
        "    # 取逻辑值\n",
        "    np_grad_logits = model(**no_grad_data)[0]\n",
        "    # ----------- sharpen操作(config['uda_softmax_temp']) -------------#\n",
        "    # 概率值\n",
        "    no_grad_probs = torch.softmax(np_grad_logits / config['uda_softmax_temp'], dim = -1)\n",
        "    # ----------- sharpen -------------#\n",
        "    # 取出最大概率值\n",
        "    # largest_probs [Batchsize] 举例：[0.879, 0.987, 0.234, 0.768, 0.333]\n",
        "    largest_probs, _ = no_grad_probs.max(dim = -1)\n",
        "    # config['uda_confidence_threshold']为0.7  是否大于0.7\n",
        "    unsup_loss_mask = largest_probs.gt(config['uda_confidence_threshold']).float()\n",
        "    # unsup_loss_mask tensor([True, True, False, True, False])\n",
        "\n",
        "    \n",
        "  return unsup_loss_mask, no_grad_probs"
      ],
      "metadata": {
        "id": "mUtSZVeoNcmU"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**与上面的图相差mask**\n",
        "![在这里插入图片描述](https://img-blog.csdnimg.cn/b21349f49ba446b698e6f27823983fc5.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTI4NzA2MA==,size_16,color_FFFFFF,t_70)"
      ],
      "metadata": {
        "id": "Bqjtw3bFSOXk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**在forward_with_grad中reduction='none':**\\\n",
        "CE：交叉熵\n",
        "\n",
        "![ce](https://img-blog.csdnimg.cn/52f18386dbea423f846611c558aa24c7.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTI4NzA2MA==,size_16,color_FFFFFF,t_70)\n",
        "\n",
        "**CE交叉熵  E熵  KLD KL散度**\n",
        "\n",
        "$$CE = -plogq$$   \n",
        "$$E = -plogp$$\n",
        "p-真实分布（已知） q-预测分布\n",
        "$$KLDiv(p||q) = \\sum_{i=1}^{N}p(x_{i})(logp(x_{i})- logq(x_{i}))$$\n",
        "$$ = p(logp-logq) $$\n",
        "$$ = -plogq - (- plogp)$$\n",
        "$$ = CE-E$$\n",
        "\n",
        "**KL散度就是拿交叉熵减去熵，熵又是确定的**\n",
        "\n",
        "\n",
        "*torch接口中，class是类别的索引，是整数\\\n",
        "在无监督中,标签是ab_logits是非整数 因此用KL散度*"
      ],
      "metadata": {
        "id": "_vdI408bSTwD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![cross entropy](https://img-blog.csdnimg.cn/4572c78d76624c49b01b96a1cba42279.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTI4NzA2MA==,size_16,color_FFFFFF,t_70)\n",
        "![KL](https://img-blog.csdnimg.cn/189e4bc953904c199afbc7e6a11e5d9a.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTI4NzA2MA==,size_16,color_FFFFFF,t_70)"
      ],
      "metadata": {
        "id": "MBNNFWuwSl1G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_with_grad(unsup_loss_mask, unsup_probs, config, cur_bs, model, grad_data, total_steps, global_steps):\n",
        "  # 得到\\eta值， 随着训练的进行，阈值逐渐变大，最后是1，把所有监督数据都用上了\n",
        "  tsa_threshold = get_tsa_threshold(total_steps, global_steps)\n",
        "  # 逻辑值包括有监督的和无监督的\n",
        "  logits = model(**grad_data)[0]\n",
        "  # --------- 有监督损失 -------#\n",
        "  # cur_bs 无监督 ba 的 batch_size\n",
        "  # 前面一部分是有监督 train 的 sup_data, 后面是unsup_data\n",
        "  sup_logits, unsup_logits = logits.split([logits.size(0) - cur_bs, cur_bs])\n",
        "  # 得到 sup_labels\n",
        "  sup_labels = grad_data['labels'][:logits.size(0) - cur_bs]\n",
        "  # 计算交叉熵损失 （每个样本）\n",
        "  per_example_loss = nn.CrossEntropyLoss(reduction = 'none')(sup_logits, sup_labels)\n",
        "  # 拿出 正确标签 对应的概率\n",
        "  correct_label_probs = torch.softmax(sup_logits, dim = -1).gather(dim = -1, index = sup_labels.view(-1, 1))\n",
        "  # 监督数据 过于自信不要，留下小于等于 tsa_threshold 的计算损失\n",
        "  sup_loss_mask = correct_label_probs.le(tsa_threshold).squeeze().float()\n",
        "  # 应用mask掩盖有监督数据过度自信的样本损失\n",
        "  per_example_loss *= sup_loss_mask\n",
        "\n",
        "  # 有效监督样本的平均损失\n",
        "  # (参考forward_no_grad)\n",
        "  sup_loss = per_example_loss.sum() / max(sup_loss_mask.sum(), 1) # max(sup_loss_mask.sum(), 1) 有效个数\n",
        "  # --------- 有监督损失 -------#\n",
        "\n",
        "  # --------- 无监督损失 -------#\n",
        "  # log_softmax：为了能输入到KL散度中\n",
        "  unsup_log_probs = torch.log_softmax(unsup_logits, dim = -1)\n",
        "  # input 希望是一个对数概率\n",
        "  # Target 目标为概率值\n",
        "  # ab_logits:unsup_probs\n",
        "  per_example_kl_loss = nn.KLDivLoss(reduction = 'none')(unsup_log_probs, unsup_probs).sum(dim = -1)\n",
        "  # 应用mask掩盖无监督数据中不自信的样本损失\n",
        "  per_example_kl_loss *= unsup_loss_mask\n",
        "  # 计算无监督样本的平均损失\n",
        "  unsup_loss = per_example_kl_loss.sum() / max(unsup_loss_mask.sum(), 1)\n",
        "  # --------- 无监督损失 -------#\n",
        "\n",
        "  # 加权两种损失\n",
        "  loss = sup_loss + unsup_loss\n",
        "  # 多卡取平均\n",
        "  if config['n_gpus'] > 1:\n",
        "    loss = loss.mean()\n",
        "    sup_loss = sup_loss.mean()\n",
        "    unsup_loss = unsup_loss.mean()\n",
        "\n",
        "  return loss, tsa_threshold, unsup_loss, sup_loss"
      ],
      "metadata": {
        "id": "Ben5nJlQNcn5"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AdamW\n",
        "from tqdm import trange\n",
        "import os\n",
        "def train(config, train_dataloader, dev_dataloader, unsup_dataloader=None):\n",
        "  model = BertForAFQMC.from_pretrained(config['model_path'])\n",
        "\n",
        "  optimizer = AdamW(model.parameters(), lr = config['learning_rate'], weight_decay = config['weight_decay'])\n",
        "\n",
        "  model.to(config['device'])\n",
        "  # unsup_dataloader包含 train, dev, test    \n",
        "  # 使用 unsup_dataloader，因为unsup_dataloader比较大\n",
        "  total_steps = len(unsup_dataloader) * config['num_epochs']\n",
        "  epoch_iterator = trange(config['num_epochs'])\n",
        "  global_steps = 0\n",
        "  train_loss = 0.\n",
        "  logging_loss = 0.\n",
        "  best_acc = 0.\n",
        "  UDA_model_path = ''\n",
        "\n",
        "  if config['n_gpus'] > 1:\n",
        "    model =nn.DataParallel(model)\n",
        "\n",
        "  train_iterator = iter(train_dataloader)\n",
        "  for i in epoch_iterator:\n",
        "    unsup_iterator = tqdm(unsup_dataloader, desc = 'Training', total = len(unsup_dataloader))\n",
        "    model.train()\n",
        "    # ----------------------- new ----------------------#\n",
        "    # 遍历无监督的batch\n",
        "    for unsup_batch in unsup_iterator:\n",
        "      cur_bs = unsup_batch['ab_input_ids'].size(0)\n",
        "      try:\n",
        "        # 不断拿监督数据的batch\n",
        "        sup_batch = next(train_iterator)\n",
        "\n",
        "      except StopIteration:\n",
        "        # 监督数据用完了 再重新拿\n",
        "        train_iterator = iter(train_dataloader)\n",
        "        sup_batch = next(train_iterator)\n",
        "      # 返回 grad_data：需要计算梯度，需要进行反向传播的数据\n",
        "      # 返回 no_grad_data: 不需要计算梯度，不需要进行反向传播的数据\n",
        "      grad_data, no_grad_data = get_data(sup_batch, unsup_batch, config)\n",
        "      # 无监督数据 (ab) 只需要正向传播\n",
        "      # mask, ab_logits\n",
        "      unsup_loss_mask, unsup_probs =forward_no_grad(no_grad_data, config, model)\n",
        "      # 得出loss\n",
        "      loss, tsa_threshold, unsup_loss, sup_loss = forward_with_grad(unsup_loss_mask, unsup_probs, config, cur_bs, model, grad_data,\n",
        "                                        total_steps, global_steps)\n",
        "      model.zero_grad()\n",
        "      loss.backward()\n",
        "\n",
        "      nn.utils.clip_grad_norm_(model.parameters(), max_norm = 1.0)\n",
        "      optimizer.step()\n",
        "\n",
        "      if config['ema_start']:\n",
        "        ema.update()\n",
        "\n",
        "      train_loss += loss.item()\n",
        "      global_steps += 1\n",
        "\n",
        "      unsup_iterator.set_postfix_str(f'running training loss: {loss.item(): .5f}')\n",
        "\n",
        "      if global_steps % config['logging_step'] == 0:\n",
        "        if global_steps >= config['ema_start_step'] and not config['ema_start']:\n",
        "          print('\\n>>> EMA starting .....')\n",
        "          config['ema_start'] = True\n",
        "\n",
        "          ema = EMA(model.module if hasattr(model, 'module') else model, decay = 0.99)\n",
        "\n",
        "        print_train_loss = (train_loss - logging_loss) / config['logging_step']\n",
        "        logging_loss = train_loss\n",
        "\n",
        "        if config['ema_start']:\n",
        "          ema.apply_shadow()\n",
        "        val_loss, f1, acc = evaluation(config, model, dev_dataloader)\n",
        "\n",
        "        print_log = f'\\n>>> training loss: {print_train_loss:.6f}, valid loss: {val_loss:.6f},' \n",
        "\n",
        "        if acc > best_acc:\n",
        "          model_save_path = os.path.join(config['output_path'],\n",
        "                          f'checkpoint- {global_steps} - {acc:.6f}')\n",
        "          model_to_save = model.module if hasattr(model, 'module') else model\n",
        "          model_to_save.save_pretrained(model_save_path)\n",
        "          best_acc = acc\n",
        "          UDA_model_path = model_save_path\n",
        "        print_log += f'valid f1: {f1:.6f}, valid acc:{acc:.6f}'\n",
        "\n",
        "        print(print_log)\n",
        "        model.train()\n",
        "\n",
        "        if config['ema_start']:\n",
        "          ema.restore()\n",
        "\n",
        "\n",
        "  return model, UDA_model_path"
      ],
      "metadata": {
        "id": "6YDUNt2Kax9b"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model, UDA_model_path = train(config, train_dataloader, dev_dataloader, unsup_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lD_3C78JgyG4",
        "outputId": "1b1f7eab-ed18-43da-9627-e57af83ed869"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at /content/drive/MyDrive/Colab Notebooks/dataset/BERT_model were not used when initializing BertForAFQMC: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForAFQMC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForAFQMC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForAFQMC were not initialized from the model checkpoint at /content/drive/MyDrive/Colab Notebooks/dataset/BERT_model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "Training:   0%|          | 0/1772 [00:00<?, ?it/s]\u001b[A\n",
            "Training:   0%|          | 0/1772 [00:00<?, ?it/s, running training loss:  1.62965]\u001b[A\n",
            "Training:   0%|          | 1/1772 [00:00<20:12,  1.46it/s, running training loss:  1.62965]\u001b[A\n",
            "Training:   0%|          | 1/1772 [00:00<20:12,  1.46it/s, running training loss:  1.48554]\u001b[A\n",
            "Training:   0%|          | 2/1772 [00:00<13:21,  2.21it/s, running training loss:  1.48554]\u001b[A\n",
            "Training:   0%|          | 2/1772 [00:01<13:21,  2.21it/s, running training loss:  1.19361]\u001b[A\n",
            "Training:   0%|          | 3/1772 [00:01<10:41,  2.76it/s, running training loss:  1.19361]\u001b[A\n",
            "Training:   0%|          | 3/1772 [00:01<10:41,  2.76it/s, running training loss:  1.22273]\u001b[A\n",
            "Training:   0%|          | 4/1772 [00:01<10:16,  2.87it/s, running training loss:  1.22273]\u001b[A\n",
            "Training:   0%|          | 4/1772 [00:01<10:16,  2.87it/s, running training loss:  0.72718]\u001b[A\n",
            "Training:   0%|          | 5/1772 [00:01<10:16,  2.87it/s, running training loss:  0.72718]\u001b[A\n",
            "Training:   0%|          | 5/1772 [00:02<10:16,  2.87it/s, running training loss:  0.95542]\u001b[A\n",
            "Training:   0%|          | 6/1772 [00:02<10:34,  2.78it/s, running training loss:  0.95542]\u001b[A\n",
            "Training:   0%|          | 6/1772 [00:02<10:34,  2.78it/s, running training loss:  0.99495]\u001b[A\n",
            "Training:   0%|          | 7/1772 [00:02<10:55,  2.69it/s, running training loss:  0.99495]\u001b[A\n",
            "Training:   0%|          | 7/1772 [00:02<10:55,  2.69it/s, running training loss:  1.11326]\u001b[A\n",
            "Training:   0%|          | 8/1772 [00:02<09:59,  2.94it/s, running training loss:  1.11326]\u001b[A\n",
            "Training:   0%|          | 8/1772 [00:03<09:59,  2.94it/s, running training loss:  1.00223]\u001b[A\n",
            "Training:   1%|          | 9/1772 [00:03<09:17,  3.16it/s, running training loss:  1.00223]\u001b[A\n",
            "Training:   1%|          | 9/1772 [00:03<09:17,  3.16it/s, running training loss:  1.03168]\u001b[A\n",
            "Training:   1%|          | 10/1772 [00:03<10:30,  2.80it/s, running training loss:  1.03168]\u001b[A\n",
            "Training:   1%|          | 10/1772 [00:03<10:30,  2.80it/s, running training loss:  1.22726]\u001b[A\n",
            "Training:   1%|          | 11/1772 [00:03<10:10,  2.88it/s, running training loss:  1.22726]\u001b[A\n",
            "Training:   1%|          | 11/1772 [00:04<10:10,  2.88it/s, running training loss:  1.00414]\u001b[A\n",
            "Training:   1%|          | 12/1772 [00:04<09:50,  2.98it/s, running training loss:  1.00414]\u001b[A\n",
            "Training:   1%|          | 12/1772 [00:04<09:50,  2.98it/s, running training loss:  1.13889]\u001b[A\n",
            "Training:   1%|          | 13/1772 [00:04<09:36,  3.05it/s, running training loss:  1.13889]\u001b[A\n",
            "Training:   1%|          | 13/1772 [00:04<09:36,  3.05it/s, running training loss:  1.07610]\u001b[A\n",
            "Training:   1%|          | 14/1772 [00:04<09:35,  3.06it/s, running training loss:  1.07610]\u001b[A\n",
            "Training:   1%|          | 14/1772 [00:05<09:35,  3.06it/s, running training loss:  1.02934]\u001b[A\n",
            "Training:   1%|          | 15/1772 [00:05<09:26,  3.10it/s, running training loss:  1.02934]\u001b[A\n",
            "Training:   1%|          | 15/1772 [00:05<09:26,  3.10it/s, running training loss:  1.22123]\u001b[A\n",
            "Training:   1%|          | 16/1772 [00:05<08:39,  3.38it/s, running training loss:  1.22123]\u001b[A\n",
            "Training:   1%|          | 16/1772 [00:05<08:39,  3.38it/s, running training loss:  0.99010]\u001b[A\n",
            "Training:   1%|          | 17/1772 [00:05<08:05,  3.61it/s, running training loss:  0.99010]\u001b[A\n",
            "Training:   1%|          | 17/1772 [00:06<08:05,  3.61it/s, running training loss:  1.14658]\u001b[A\n",
            "Training:   1%|          | 18/1772 [00:06<08:21,  3.50it/s, running training loss:  1.14658]\u001b[A\n",
            "Training:   1%|          | 18/1772 [00:06<08:21,  3.50it/s, running training loss:  1.00922]\u001b[A\n",
            "Training:   1%|          | 19/1772 [00:06<09:09,  3.19it/s, running training loss:  1.00922]\u001b[A\n",
            "Training:   1%|          | 19/1772 [00:06<09:09,  3.19it/s, running training loss:  1.02239]\u001b[A\n",
            "Training:   1%|          | 20/1772 [00:06<10:29,  2.78it/s, running training loss:  1.02239]\u001b[A\n",
            "Training:   1%|          | 20/1772 [00:07<10:29,  2.78it/s, running training loss:  1.16192]\u001b[A\n",
            "Training:   1%|          | 21/1772 [00:07<09:54,  2.95it/s, running training loss:  1.16192]\u001b[A\n",
            "Training:   1%|          | 21/1772 [00:07<09:54,  2.95it/s, running training loss:  1.08928]\u001b[A\n",
            "Training:   1%|          | 22/1772 [00:07<10:27,  2.79it/s, running training loss:  1.08928]\u001b[A\n",
            "Training:   1%|          | 22/1772 [00:07<10:27,  2.79it/s, running training loss:  1.09099]\u001b[A\n",
            "Training:   1%|▏         | 23/1772 [00:07<09:13,  3.16it/s, running training loss:  1.09099]\u001b[A\n",
            "Training:   1%|▏         | 23/1772 [00:08<09:13,  3.16it/s, running training loss:  0.87530]\u001b[A\n",
            "Training:   1%|▏         | 24/1772 [00:08<09:36,  3.03it/s, running training loss:  0.87530]\u001b[A\n",
            "Training:   1%|▏         | 24/1772 [00:08<09:36,  3.03it/s, running training loss:  0.92578]\u001b[A\n",
            "Training:   1%|▏         | 25/1772 [00:08<10:06,  2.88it/s, running training loss:  0.92578]\u001b[A\n",
            "Training:   1%|▏         | 25/1772 [00:08<10:06,  2.88it/s, running training loss:  1.04769]\u001b[A\n",
            "Training:   1%|▏         | 26/1772 [00:08<10:13,  2.85it/s, running training loss:  1.04769]\u001b[A\n",
            "Training:   1%|▏         | 26/1772 [00:09<10:13,  2.85it/s, running training loss:  1.11314]\u001b[A\n",
            "Training:   2%|▏         | 27/1772 [00:09<09:17,  3.13it/s, running training loss:  1.11314]\u001b[A\n",
            "Training:   2%|▏         | 27/1772 [00:09<09:17,  3.13it/s, running training loss:  1.19018]\u001b[A\n",
            "Training:   2%|▏         | 28/1772 [00:09<10:28,  2.77it/s, running training loss:  1.19018]\u001b[A\n",
            "Training:   2%|▏         | 28/1772 [00:09<10:28,  2.77it/s, running training loss:  1.09473]\u001b[A\n",
            "Training:   2%|▏         | 29/1772 [00:09<09:45,  2.98it/s, running training loss:  1.09473]\u001b[A\n",
            "Training:   2%|▏         | 29/1772 [00:10<09:45,  2.98it/s, running training loss:  1.36356]\u001b[A\n",
            "Training:   2%|▏         | 30/1772 [00:10<09:41,  2.99it/s, running training loss:  1.36356]\u001b[A\n",
            "Training:   2%|▏         | 30/1772 [00:10<09:41,  2.99it/s, running training loss:  1.18792]\u001b[A\n",
            "Training:   2%|▏         | 31/1772 [00:10<09:04,  3.20it/s, running training loss:  1.18792]\u001b[A\n",
            "Training:   2%|▏         | 31/1772 [00:10<09:04,  3.20it/s, running training loss:  1.17195]\u001b[A\n",
            "Training:   2%|▏         | 32/1772 [00:10<08:27,  3.43it/s, running training loss:  1.17195]\u001b[A\n",
            "Training:   2%|▏         | 32/1772 [00:11<08:27,  3.43it/s, running training loss:  0.99712]\u001b[A\n",
            "Training:   2%|▏         | 33/1772 [00:11<09:27,  3.06it/s, running training loss:  0.99712]\u001b[A\n",
            "Training:   2%|▏         | 33/1772 [00:11<09:27,  3.06it/s, running training loss:  1.09412]\u001b[A\n",
            "Training:   2%|▏         | 34/1772 [00:11<08:40,  3.34it/s, running training loss:  1.09412]\u001b[A\n",
            "Training:   2%|▏         | 34/1772 [00:11<08:40,  3.34it/s, running training loss:  0.99822]\u001b[A\n",
            "Training:   2%|▏         | 35/1772 [00:11<08:15,  3.50it/s, running training loss:  0.99822]\u001b[A\n",
            "Training:   2%|▏         | 35/1772 [00:11<08:15,  3.50it/s, running training loss:  0.84842]\u001b[A\n",
            "Training:   2%|▏         | 36/1772 [00:11<08:20,  3.47it/s, running training loss:  0.84842]\u001b[A\n",
            "Training:   2%|▏         | 36/1772 [00:12<08:20,  3.47it/s, running training loss:  0.97954]\u001b[A\n",
            "Training:   2%|▏         | 37/1772 [00:12<08:03,  3.59it/s, running training loss:  0.97954]\u001b[A\n",
            "Training:   2%|▏         | 37/1772 [00:12<08:03,  3.59it/s, running training loss:  0.78533]\u001b[A\n",
            "Training:   2%|▏         | 38/1772 [00:12<07:55,  3.65it/s, running training loss:  0.78533]\u001b[A\n",
            "Training:   2%|▏         | 38/1772 [00:12<07:55,  3.65it/s, running training loss:  1.10863]\u001b[A\n",
            "Training:   2%|▏         | 39/1772 [00:12<07:35,  3.81it/s, running training loss:  1.10863]\u001b[A\n",
            "Training:   2%|▏         | 39/1772 [00:12<07:35,  3.81it/s, running training loss:  1.04436]\u001b[A\n",
            "Training:   2%|▏         | 40/1772 [00:12<07:28,  3.86it/s, running training loss:  1.04436]\u001b[A\n",
            "Training:   2%|▏         | 40/1772 [00:13<07:28,  3.86it/s, running training loss:  0.95297]\u001b[A\n",
            "Training:   2%|▏         | 41/1772 [00:13<07:41,  3.75it/s, running training loss:  0.95297]\u001b[A\n",
            "Training:   2%|▏         | 41/1772 [00:13<07:41,  3.75it/s, running training loss:  1.02658]\u001b[A\n",
            "Training:   2%|▏         | 42/1772 [00:13<07:48,  3.69it/s, running training loss:  1.02658]\u001b[A\n",
            "Training:   2%|▏         | 42/1772 [00:13<07:48,  3.69it/s, running training loss:  0.82159]\u001b[A\n",
            "Training:   2%|▏         | 43/1772 [00:13<07:53,  3.65it/s, running training loss:  0.82159]\u001b[A\n",
            "Training:   2%|▏         | 43/1772 [00:14<07:53,  3.65it/s, running training loss:  1.06649]\u001b[A\n",
            "Training:   2%|▏         | 44/1772 [00:14<08:46,  3.28it/s, running training loss:  1.06649]\u001b[A\n",
            "Training:   2%|▏         | 44/1772 [00:14<08:46,  3.28it/s, running training loss:  0.98798]\u001b[A\n",
            "Training:   3%|▎         | 45/1772 [00:14<08:51,  3.25it/s, running training loss:  0.98798]\u001b[A\n",
            "Training:   3%|▎         | 45/1772 [00:14<08:51,  3.25it/s, running training loss:  0.84643]\u001b[A\n",
            "Training:   3%|▎         | 46/1772 [00:14<08:37,  3.33it/s, running training loss:  0.84643]\u001b[A\n",
            "Training:   3%|▎         | 46/1772 [00:14<08:37,  3.33it/s, running training loss:  1.15487]\u001b[A\n",
            "Training:   3%|▎         | 47/1772 [00:14<08:18,  3.46it/s, running training loss:  1.15487]\u001b[A\n",
            "Training:   3%|▎         | 47/1772 [00:15<08:18,  3.46it/s, running training loss:  0.95861]\u001b[A\n",
            "Training:   3%|▎         | 48/1772 [00:15<07:51,  3.65it/s, running training loss:  0.95861]\u001b[A\n",
            "Training:   3%|▎         | 48/1772 [00:15<07:51,  3.65it/s, running training loss:  1.03648]\u001b[A\n",
            "Training:   3%|▎         | 49/1772 [00:15<08:39,  3.31it/s, running training loss:  1.03648]\u001b[A\n",
            "Training:   3%|▎         | 49/1772 [00:15<08:39,  3.31it/s, running training loss:  1.02105]\u001b[A\n",
            "Training:   3%|▎         | 50/1772 [00:15<08:26,  3.40it/s, running training loss:  1.02105]\u001b[A\n",
            "Training:   3%|▎         | 50/1772 [00:16<08:26,  3.40it/s, running training loss:  1.03583]\u001b[A\n",
            "Training:   3%|▎         | 51/1772 [00:16<08:02,  3.57it/s, running training loss:  1.03583]\u001b[A\n",
            "Training:   3%|▎         | 51/1772 [00:16<08:02,  3.57it/s, running training loss:  1.07343]\u001b[A\n",
            "Training:   3%|▎         | 52/1772 [00:16<08:04,  3.55it/s, running training loss:  1.07343]\u001b[A\n",
            "Training:   3%|▎         | 52/1772 [00:16<08:04,  3.55it/s, running training loss:  0.89349]\u001b[A\n",
            "Training:   3%|▎         | 53/1772 [00:16<08:12,  3.49it/s, running training loss:  0.89349]\u001b[A\n",
            "Training:   3%|▎         | 53/1772 [00:16<08:12,  3.49it/s, running training loss:  0.89956]\u001b[A\n",
            "Training:   3%|▎         | 54/1772 [00:16<07:52,  3.64it/s, running training loss:  0.89956]\u001b[A\n",
            "Training:   3%|▎         | 54/1772 [00:17<07:52,  3.64it/s, running training loss:  1.00554]\u001b[A\n",
            "Training:   3%|▎         | 55/1772 [00:17<07:31,  3.80it/s, running training loss:  1.00554]\u001b[A\n",
            "Training:   3%|▎         | 55/1772 [00:17<07:31,  3.80it/s, running training loss:  0.96964]\u001b[A\n",
            "Training:   3%|▎         | 56/1772 [00:17<07:27,  3.84it/s, running training loss:  0.96964]\u001b[A\n",
            "Training:   3%|▎         | 56/1772 [00:17<07:27,  3.84it/s, running training loss:  1.07723]\u001b[A\n",
            "Training:   3%|▎         | 57/1772 [00:17<07:29,  3.82it/s, running training loss:  1.07723]\u001b[A\n",
            "Training:   3%|▎         | 57/1772 [00:17<07:29,  3.82it/s, running training loss:  0.97998]\u001b[A\n",
            "Training:   3%|▎         | 58/1772 [00:17<07:39,  3.73it/s, running training loss:  0.97998]\u001b[A\n",
            "Training:   3%|▎         | 58/1772 [00:18<07:39,  3.73it/s, running training loss:  1.19649]\u001b[A\n",
            "Training:   3%|▎         | 59/1772 [00:18<07:17,  3.92it/s, running training loss:  1.19649]\u001b[A\n",
            "Training:   3%|▎         | 59/1772 [00:18<07:17,  3.92it/s, running training loss:  1.02512]\u001b[A\n",
            "Training:   3%|▎         | 60/1772 [00:18<08:03,  3.54it/s, running training loss:  1.02512]\u001b[A\n",
            "Training:   3%|▎         | 60/1772 [00:18<08:03,  3.54it/s, running training loss:  1.11961]\u001b[A\n",
            "Training:   3%|▎         | 61/1772 [00:18<07:46,  3.67it/s, running training loss:  1.11961]\u001b[A\n",
            "Training:   3%|▎         | 61/1772 [00:19<07:46,  3.67it/s, running training loss:  0.75597]\u001b[A\n",
            "Training:   3%|▎         | 62/1772 [00:19<07:40,  3.71it/s, running training loss:  0.75597]\u001b[A\n",
            "Training:   3%|▎         | 62/1772 [00:19<07:40,  3.71it/s, running training loss:  0.93934]\u001b[A\n",
            "Training:   4%|▎         | 63/1772 [00:19<07:23,  3.85it/s, running training loss:  0.93934]\u001b[A\n",
            "Training:   4%|▎         | 63/1772 [00:19<07:23,  3.85it/s, running training loss:  1.03336]\u001b[A\n",
            "Training:   4%|▎         | 64/1772 [00:19<08:02,  3.54it/s, running training loss:  1.03336]\u001b[A\n",
            "Training:   4%|▎         | 64/1772 [00:19<08:02,  3.54it/s, running training loss:  0.97742]\u001b[A\n",
            "Training:   4%|▎         | 65/1772 [00:19<08:27,  3.36it/s, running training loss:  0.97742]\u001b[A\n",
            "Training:   4%|▎         | 65/1772 [00:20<08:27,  3.36it/s, running training loss:  1.02058]\u001b[A\n",
            "Training:   4%|▎         | 66/1772 [00:20<08:38,  3.29it/s, running training loss:  1.02058]\u001b[A\n",
            "Training:   4%|▎         | 66/1772 [00:20<08:38,  3.29it/s, running training loss:  1.00671]\u001b[A\n",
            "Training:   4%|▍         | 67/1772 [00:20<08:27,  3.36it/s, running training loss:  1.00671]\u001b[A\n",
            "Training:   4%|▍         | 67/1772 [00:20<08:27,  3.36it/s, running training loss:  0.77988]\u001b[A\n",
            "Training:   4%|▍         | 68/1772 [00:20<08:10,  3.47it/s, running training loss:  0.77988]\u001b[A\n",
            "Training:   4%|▍         | 68/1772 [00:21<08:10,  3.47it/s, running training loss:  0.88499]\u001b[A\n",
            "Training:   4%|▍         | 69/1772 [00:21<08:19,  3.41it/s, running training loss:  0.88499]\u001b[A\n",
            "Training:   4%|▍         | 69/1772 [00:21<08:19,  3.41it/s, running training loss:  1.02877]\u001b[A\n",
            "Training:   4%|▍         | 70/1772 [00:21<07:54,  3.59it/s, running training loss:  1.02877]\u001b[A\n",
            "Training:   4%|▍         | 70/1772 [00:21<07:54,  3.59it/s, running training loss:  0.82860]\u001b[A\n",
            "Training:   4%|▍         | 71/1772 [00:21<07:53,  3.59it/s, running training loss:  0.82860]\u001b[A\n",
            "Training:   4%|▍         | 71/1772 [00:21<07:53,  3.59it/s, running training loss:  0.98423]\u001b[A\n",
            "Training:   4%|▍         | 72/1772 [00:21<07:41,  3.68it/s, running training loss:  0.98423]\u001b[A\n",
            "Training:   4%|▍         | 72/1772 [00:22<07:41,  3.68it/s, running training loss:  0.99478]\u001b[A\n",
            "Training:   4%|▍         | 73/1772 [00:22<07:32,  3.76it/s, running training loss:  0.99478]\u001b[A\n",
            "Training:   4%|▍         | 73/1772 [00:22<07:32,  3.76it/s, running training loss:  0.94830]\u001b[A\n",
            "Training:   4%|▍         | 74/1772 [00:22<08:37,  3.28it/s, running training loss:  0.94830]\u001b[A\n",
            "Training:   4%|▍         | 74/1772 [00:23<08:37,  3.28it/s, running training loss:  1.04970]\u001b[A\n",
            "Training:   4%|▍         | 75/1772 [00:23<09:50,  2.87it/s, running training loss:  1.04970]\u001b[A\n",
            "Training:   4%|▍         | 75/1772 [00:23<09:50,  2.87it/s, running training loss:  1.00276]\u001b[A\n",
            "Training:   4%|▍         | 76/1772 [00:23<08:58,  3.15it/s, running training loss:  1.00276]\u001b[A\n",
            "Training:   4%|▍         | 76/1772 [00:23<08:58,  3.15it/s, running training loss:  1.14579]\u001b[A\n",
            "Training:   4%|▍         | 77/1772 [00:23<09:55,  2.85it/s, running training loss:  1.14579]\u001b[A\n",
            "Training:   4%|▍         | 77/1772 [00:23<09:55,  2.85it/s, running training loss:  0.99857]\u001b[A\n",
            "Training:   4%|▍         | 78/1772 [00:23<08:38,  3.27it/s, running training loss:  0.99857]\u001b[A\n",
            "Training:   4%|▍         | 78/1772 [00:24<08:38,  3.27it/s, running training loss:  1.09763]\u001b[A\n",
            "Training:   4%|▍         | 79/1772 [00:24<08:22,  3.37it/s, running training loss:  1.09763]\u001b[A\n",
            "Training:   4%|▍         | 79/1772 [00:24<08:22,  3.37it/s, running training loss:  0.99343]\u001b[A\n",
            "Training:   5%|▍         | 80/1772 [00:24<08:04,  3.50it/s, running training loss:  0.99343]\u001b[A\n",
            "Training:   5%|▍         | 80/1772 [00:24<08:04,  3.50it/s, running training loss:  0.89080]\u001b[A\n",
            "Training:   5%|▍         | 81/1772 [00:24<08:37,  3.27it/s, running training loss:  0.89080]\u001b[A\n",
            "Training:   5%|▍         | 81/1772 [00:25<08:37,  3.27it/s, running training loss:  0.93770]\u001b[A\n",
            "Training:   5%|▍         | 82/1772 [00:25<08:24,  3.35it/s, running training loss:  0.93770]\u001b[A\n",
            "Training:   5%|▍         | 82/1772 [00:25<08:24,  3.35it/s, running training loss:  0.99471]\u001b[A\n",
            "Training:   5%|▍         | 83/1772 [00:25<08:04,  3.49it/s, running training loss:  0.99471]\u001b[A\n",
            "Training:   5%|▍         | 83/1772 [00:25<08:04,  3.49it/s, running training loss:  1.00893]\u001b[A\n",
            "Training:   5%|▍         | 84/1772 [00:25<07:37,  3.69it/s, running training loss:  1.00893]\u001b[A\n",
            "Training:   5%|▍         | 84/1772 [00:25<07:37,  3.69it/s, running training loss:  1.04868]\u001b[A\n",
            "Training:   5%|▍         | 85/1772 [00:25<07:53,  3.56it/s, running training loss:  1.04868]\u001b[A\n",
            "Training:   5%|▍         | 85/1772 [00:26<07:53,  3.56it/s, running training loss:  1.17663]\u001b[A\n",
            "Training:   5%|▍         | 86/1772 [00:26<07:53,  3.56it/s, running training loss:  1.17663]\u001b[A\n",
            "Training:   5%|▍         | 86/1772 [00:26<07:53,  3.56it/s, running training loss:  1.11392]\u001b[A\n",
            "Training:   5%|▍         | 87/1772 [00:26<07:49,  3.59it/s, running training loss:  1.11392]\u001b[A\n",
            "Training:   5%|▍         | 87/1772 [00:26<07:49,  3.59it/s, running training loss:  1.15986]\u001b[A\n",
            "Training:   5%|▍         | 88/1772 [00:26<08:11,  3.42it/s, running training loss:  1.15986]\u001b[A\n",
            "Training:   5%|▍         | 88/1772 [00:26<08:11,  3.42it/s, running training loss:  0.90381]\u001b[A\n",
            "Training:   5%|▌         | 89/1772 [00:27<07:54,  3.55it/s, running training loss:  0.90381]\u001b[A\n",
            "Training:   5%|▌         | 89/1772 [00:27<07:54,  3.55it/s, running training loss:  1.02619]\u001b[A\n",
            "Training:   5%|▌         | 90/1772 [00:27<08:25,  3.33it/s, running training loss:  1.02619]\u001b[A\n",
            "Training:   5%|▌         | 90/1772 [00:27<08:25,  3.33it/s, running training loss:  0.99253]\u001b[A\n",
            "Training:   5%|▌         | 91/1772 [00:27<08:55,  3.14it/s, running training loss:  0.99253]\u001b[A\n",
            "Training:   5%|▌         | 91/1772 [00:28<08:55,  3.14it/s, running training loss:  0.94252]\u001b[A\n",
            "Training:   5%|▌         | 92/1772 [00:28<08:51,  3.16it/s, running training loss:  0.94252]\u001b[A\n",
            "Training:   5%|▌         | 92/1772 [00:28<08:51,  3.16it/s, running training loss:  1.02002]\u001b[A\n",
            "Training:   5%|▌         | 93/1772 [00:28<08:28,  3.30it/s, running training loss:  1.02002]\u001b[A\n",
            "Training:   5%|▌         | 93/1772 [00:28<08:28,  3.30it/s, running training loss:  1.14095]\u001b[A\n",
            "Training:   5%|▌         | 94/1772 [00:28<08:15,  3.39it/s, running training loss:  1.14095]\u001b[A\n",
            "Training:   5%|▌         | 94/1772 [00:28<08:15,  3.39it/s, running training loss:  0.83579]\u001b[A\n",
            "Training:   5%|▌         | 95/1772 [00:28<08:11,  3.41it/s, running training loss:  0.83579]\u001b[A\n",
            "Training:   5%|▌         | 95/1772 [00:29<08:11,  3.41it/s, running training loss:  1.14124]\u001b[A\n",
            "Training:   5%|▌         | 96/1772 [00:29<08:29,  3.29it/s, running training loss:  1.14124]\u001b[A\n",
            "Training:   5%|▌         | 96/1772 [00:29<08:29,  3.29it/s, running training loss:  0.95633]\u001b[A\n",
            "Training:   5%|▌         | 97/1772 [00:29<08:35,  3.25it/s, running training loss:  0.95633]\u001b[A\n",
            "Training:   5%|▌         | 97/1772 [00:29<08:35,  3.25it/s, running training loss:  1.00314]\u001b[A\n",
            "Training:   6%|▌         | 98/1772 [00:29<08:01,  3.48it/s, running training loss:  1.00314]\u001b[A\n",
            "Training:   6%|▌         | 98/1772 [00:30<08:01,  3.48it/s, running training loss:  1.08187]\u001b[A\n",
            "Training:   6%|▌         | 99/1772 [00:30<07:54,  3.53it/s, running training loss:  1.08187]\u001b[A\n",
            "Training:   6%|▌         | 99/1772 [00:30<07:54,  3.53it/s, running training loss:  1.01570]\u001b[A\n",
            "Training:   6%|▌         | 100/1772 [00:30<07:28,  3.73it/s, running training loss:  1.01570]\u001b[A\n",
            "Training:   6%|▌         | 100/1772 [00:30<07:28,  3.73it/s, running training loss:  1.20279]\u001b[A\n",
            "Training:   6%|▌         | 101/1772 [00:30<09:29,  2.93it/s, running training loss:  1.20279]\u001b[A\n",
            "Training:   6%|▌         | 101/1772 [00:31<09:29,  2.93it/s, running training loss:  1.10765]\u001b[A\n",
            "Training:   6%|▌         | 102/1772 [00:31<08:54,  3.13it/s, running training loss:  1.10765]\u001b[A\n",
            "Training:   6%|▌         | 102/1772 [00:31<08:54,  3.13it/s, running training loss:  1.00254]\u001b[A\n",
            "Training:   6%|▌         | 103/1772 [00:31<08:10,  3.40it/s, running training loss:  1.00254]\u001b[A\n",
            "Training:   6%|▌         | 103/1772 [00:31<08:10,  3.40it/s, running training loss:  1.10647]\u001b[A\n",
            "Training:   6%|▌         | 104/1772 [00:31<07:53,  3.52it/s, running training loss:  1.10647]\u001b[A\n",
            "Training:   6%|▌         | 104/1772 [00:31<07:53,  3.52it/s, running training loss:  1.08103]\u001b[A\n",
            "Training:   6%|▌         | 105/1772 [00:31<08:55,  3.12it/s, running training loss:  1.08103]\u001b[A\n",
            "Training:   6%|▌         | 105/1772 [00:32<08:55,  3.12it/s, running training loss:  1.04614]\u001b[A\n",
            "Training:   6%|▌         | 106/1772 [00:32<08:29,  3.27it/s, running training loss:  1.04614]\u001b[A\n",
            "Training:   6%|▌         | 106/1772 [00:32<08:29,  3.27it/s, running training loss:  0.97215]\u001b[A\n",
            "Training:   6%|▌         | 107/1772 [00:32<09:19,  2.98it/s, running training loss:  0.97215]\u001b[A\n",
            "Training:   6%|▌         | 107/1772 [00:32<09:19,  2.98it/s, running training loss:  1.09099]\u001b[A\n",
            "Training:   6%|▌         | 108/1772 [00:32<09:02,  3.07it/s, running training loss:  1.09099]\u001b[A\n",
            "Training:   6%|▌         | 108/1772 [00:33<09:02,  3.07it/s, running training loss:  0.84831]\u001b[A\n",
            "Training:   6%|▌         | 109/1772 [00:33<08:23,  3.30it/s, running training loss:  0.84831]\u001b[A\n",
            "Training:   6%|▌         | 109/1772 [00:33<08:23,  3.30it/s, running training loss:  0.93112]\u001b[A\n",
            "Training:   6%|▌         | 110/1772 [00:33<08:51,  3.12it/s, running training loss:  0.93112]\u001b[A\n",
            "Training:   6%|▌         | 110/1772 [00:33<08:51,  3.12it/s, running training loss:  1.08869]\u001b[A\n",
            "Training:   6%|▋         | 111/1772 [00:33<08:37,  3.21it/s, running training loss:  1.08869]\u001b[A\n",
            "Training:   6%|▋         | 111/1772 [00:34<08:37,  3.21it/s, running training loss:  1.04992]\u001b[A\n",
            "Training:   6%|▋         | 112/1772 [00:34<08:35,  3.22it/s, running training loss:  1.04992]\u001b[A\n",
            "Training:   6%|▋         | 112/1772 [00:34<08:35,  3.22it/s, running training loss:  1.01996]\u001b[A\n",
            "Training:   6%|▋         | 113/1772 [00:34<07:58,  3.46it/s, running training loss:  1.01996]\u001b[A\n",
            "Training:   6%|▋         | 113/1772 [00:34<07:58,  3.46it/s, running training loss:  0.86420]\u001b[A\n",
            "Training:   6%|▋         | 114/1772 [00:34<07:52,  3.51it/s, running training loss:  0.86420]\u001b[A\n",
            "Training:   6%|▋         | 114/1772 [00:34<07:52,  3.51it/s, running training loss:  1.21860]\u001b[A\n",
            "Training:   6%|▋         | 115/1772 [00:34<08:19,  3.31it/s, running training loss:  1.21860]\u001b[A\n",
            "Training:   6%|▋         | 115/1772 [00:35<08:19,  3.31it/s, running training loss:  0.98017]\u001b[A\n",
            "Training:   7%|▋         | 116/1772 [00:35<07:47,  3.54it/s, running training loss:  0.98017]\u001b[A\n",
            "Training:   7%|▋         | 116/1772 [00:35<07:47,  3.54it/s, running training loss:  0.82996]\u001b[A\n",
            "Training:   7%|▋         | 117/1772 [00:35<09:23,  2.94it/s, running training loss:  0.82996]\u001b[A\n",
            "Training:   7%|▋         | 117/1772 [00:35<09:23,  2.94it/s, running training loss:  0.82369]\u001b[A\n",
            "Training:   7%|▋         | 118/1772 [00:35<08:57,  3.08it/s, running training loss:  0.82369]\u001b[A\n",
            "Training:   7%|▋         | 118/1772 [00:36<08:57,  3.08it/s, running training loss:  0.97496]\u001b[A\n",
            "Training:   7%|▋         | 119/1772 [00:36<08:12,  3.36it/s, running training loss:  0.97496]\u001b[A\n",
            "Training:   7%|▋         | 119/1772 [00:36<08:12,  3.36it/s, running training loss:  0.92657]\u001b[A\n",
            "Training:   7%|▋         | 120/1772 [00:36<07:42,  3.57it/s, running training loss:  0.92657]\u001b[A\n",
            "Training:   7%|▋         | 120/1772 [00:36<07:42,  3.57it/s, running training loss:  0.79530]\u001b[A\n",
            "Training:   7%|▋         | 121/1772 [00:36<07:39,  3.59it/s, running training loss:  0.79530]\u001b[A\n",
            "Training:   7%|▋         | 121/1772 [00:37<07:39,  3.59it/s, running training loss:  0.82780]\u001b[A\n",
            "Training:   7%|▋         | 122/1772 [00:37<08:00,  3.44it/s, running training loss:  0.82780]\u001b[A\n",
            "Training:   7%|▋         | 122/1772 [00:37<08:00,  3.44it/s, running training loss:  1.05649]\u001b[A\n",
            "Training:   7%|▋         | 123/1772 [00:37<07:53,  3.48it/s, running training loss:  1.05649]\u001b[A\n",
            "Training:   7%|▋         | 123/1772 [00:37<07:53,  3.48it/s, running training loss:  0.76572]\u001b[A\n",
            "Training:   7%|▋         | 124/1772 [00:37<08:01,  3.42it/s, running training loss:  0.76572]\u001b[A\n",
            "Training:   7%|▋         | 124/1772 [00:38<08:01,  3.42it/s, running training loss:  1.16048]\u001b[A\n",
            "Training:   7%|▋         | 125/1772 [00:38<09:47,  2.80it/s, running training loss:  1.16048]\u001b[A\n",
            "Training:   7%|▋         | 125/1772 [00:38<09:47,  2.80it/s, running training loss:  1.13836]\u001b[A\n",
            "Training:   7%|▋         | 126/1772 [00:38<09:27,  2.90it/s, running training loss:  1.13836]\u001b[A\n",
            "Training:   7%|▋         | 126/1772 [00:38<09:27,  2.90it/s, running training loss:  0.78462]\u001b[A\n",
            "Training:   7%|▋         | 127/1772 [00:38<08:43,  3.15it/s, running training loss:  0.78462]\u001b[A\n",
            "Training:   7%|▋         | 127/1772 [00:38<08:43,  3.15it/s, running training loss:  1.05475]\u001b[A\n",
            "Training:   7%|▋         | 128/1772 [00:38<08:02,  3.41it/s, running training loss:  1.05475]\u001b[A\n",
            "Training:   7%|▋         | 128/1772 [00:39<08:02,  3.41it/s, running training loss:  1.09849]\u001b[A\n",
            "Training:   7%|▋         | 129/1772 [00:39<08:12,  3.34it/s, running training loss:  1.09849]\u001b[A\n",
            "Training:   7%|▋         | 129/1772 [00:39<08:12,  3.34it/s, running training loss:  0.94770]\u001b[A\n",
            "Training:   7%|▋         | 130/1772 [00:39<08:53,  3.08it/s, running training loss:  0.94770]\u001b[A\n",
            "Training:   7%|▋         | 130/1772 [00:39<08:53,  3.08it/s, running training loss:  1.05474]\u001b[A\n",
            "Training:   7%|▋         | 131/1772 [00:39<08:12,  3.33it/s, running training loss:  1.05474]\u001b[A\n",
            "Training:   7%|▋         | 131/1772 [00:40<08:12,  3.33it/s, running training loss:  1.05015]\u001b[A\n",
            "Training:   7%|▋         | 132/1772 [00:40<09:35,  2.85it/s, running training loss:  1.05015]\u001b[A\n",
            "Training:   7%|▋         | 132/1772 [00:40<09:35,  2.85it/s, running training loss:  0.96573]\u001b[A\n",
            "Training:   8%|▊         | 133/1772 [00:40<08:47,  3.11it/s, running training loss:  0.96573]\u001b[A\n",
            "Training:   8%|▊         | 133/1772 [00:40<08:47,  3.11it/s, running training loss:  0.99840]\u001b[A\n",
            "Training:   8%|▊         | 134/1772 [00:40<08:13,  3.32it/s, running training loss:  0.99840]\u001b[A\n",
            "Training:   8%|▊         | 134/1772 [00:41<08:13,  3.32it/s, running training loss:  0.94563]\u001b[A\n",
            "Training:   8%|▊         | 135/1772 [00:41<08:21,  3.27it/s, running training loss:  0.94563]\u001b[A\n",
            "Training:   8%|▊         | 135/1772 [00:41<08:21,  3.27it/s, running training loss:  1.06003]\u001b[A\n",
            "Training:   8%|▊         | 136/1772 [00:41<08:37,  3.16it/s, running training loss:  1.06003]\u001b[A\n",
            "Training:   8%|▊         | 136/1772 [00:41<08:37,  3.16it/s, running training loss:  1.03714]\u001b[A\n",
            "Training:   8%|▊         | 137/1772 [00:41<08:05,  3.37it/s, running training loss:  1.03714]\u001b[A\n",
            "Training:   8%|▊         | 137/1772 [00:42<08:05,  3.37it/s, running training loss:  1.18320]\u001b[A\n",
            "Training:   8%|▊         | 138/1772 [00:42<08:29,  3.21it/s, running training loss:  1.18320]\u001b[A\n",
            "Training:   8%|▊         | 138/1772 [00:42<08:29,  3.21it/s, running training loss:  1.03257]\u001b[A\n",
            "Training:   8%|▊         | 139/1772 [00:42<08:19,  3.27it/s, running training loss:  1.03257]\u001b[A\n",
            "Training:   8%|▊         | 139/1772 [00:42<08:19,  3.27it/s, running training loss:  1.06176]\u001b[A\n",
            "Training:   8%|▊         | 140/1772 [00:42<08:22,  3.25it/s, running training loss:  1.06176]\u001b[A\n",
            "Training:   8%|▊         | 140/1772 [00:43<08:22,  3.25it/s, running training loss:  1.02829]\u001b[A\n",
            "Training:   8%|▊         | 141/1772 [00:43<10:04,  2.70it/s, running training loss:  1.02829]\u001b[A\n",
            "Training:   8%|▊         | 141/1772 [00:43<10:04,  2.70it/s, running training loss:  1.01130]\u001b[A\n",
            "Training:   8%|▊         | 142/1772 [00:43<10:02,  2.71it/s, running training loss:  1.01130]\u001b[A\n",
            "Training:   8%|▊         | 142/1772 [00:43<10:02,  2.71it/s, running training loss:  1.04459]\u001b[A\n",
            "Training:   8%|▊         | 143/1772 [00:43<09:14,  2.94it/s, running training loss:  1.04459]\u001b[A\n",
            "Training:   8%|▊         | 143/1772 [00:44<09:14,  2.94it/s, running training loss:  0.96659]\u001b[A\n",
            "Training:   8%|▊         | 144/1772 [00:44<08:57,  3.03it/s, running training loss:  0.96659]\u001b[A\n",
            "Training:   8%|▊         | 144/1772 [00:44<08:57,  3.03it/s, running training loss:  0.94268]\u001b[A\n",
            "Training:   8%|▊         | 145/1772 [00:44<09:10,  2.95it/s, running training loss:  0.94268]\u001b[A\n",
            "Training:   8%|▊         | 145/1772 [00:44<09:10,  2.95it/s, running training loss:  0.99476]\u001b[A\n",
            "Training:   8%|▊         | 146/1772 [00:44<09:02,  2.99it/s, running training loss:  0.99476]\u001b[A\n",
            "Training:   8%|▊         | 146/1772 [00:45<09:02,  2.99it/s, running training loss:  1.02229]\u001b[A\n",
            "Training:   8%|▊         | 147/1772 [00:45<09:01,  3.00it/s, running training loss:  1.02229]\u001b[A\n",
            "Training:   8%|▊         | 147/1772 [00:45<09:01,  3.00it/s, running training loss:  1.04918]\u001b[A\n",
            "Training:   8%|▊         | 148/1772 [00:45<09:49,  2.75it/s, running training loss:  1.04918]\u001b[A\n",
            "Training:   8%|▊         | 148/1772 [00:45<09:49,  2.75it/s, running training loss:  0.90783]\u001b[A\n",
            "Training:   8%|▊         | 149/1772 [00:45<09:30,  2.85it/s, running training loss:  0.90783]\u001b[A\n",
            "Training:   8%|▊         | 149/1772 [00:46<09:30,  2.85it/s, running training loss:  0.82513]\u001b[A\n",
            "Training:   8%|▊         | 150/1772 [00:46<09:39,  2.80it/s, running training loss:  0.82513]\u001b[A\n",
            "Training:   8%|▊         | 150/1772 [00:46<09:39,  2.80it/s, running training loss:  1.00062]\u001b[A\n",
            "Training:   9%|▊         | 151/1772 [00:46<11:01,  2.45it/s, running training loss:  1.00062]\u001b[A\n",
            "Training:   9%|▊         | 151/1772 [00:47<11:01,  2.45it/s, running training loss:  1.00710]\u001b[A\n",
            "Training:   9%|▊         | 152/1772 [00:47<10:08,  2.66it/s, running training loss:  1.00710]\u001b[A\n",
            "Training:   9%|▊         | 152/1772 [00:47<10:08,  2.66it/s, running training loss:  1.02578]\u001b[A\n",
            "Training:   9%|▊         | 153/1772 [00:47<09:38,  2.80it/s, running training loss:  1.02578]\u001b[A\n",
            "Training:   9%|▊         | 153/1772 [00:47<09:38,  2.80it/s, running training loss:  0.94156]\u001b[A\n",
            "Training:   9%|▊         | 154/1772 [00:47<08:59,  3.00it/s, running training loss:  0.94156]\u001b[A\n",
            "Training:   9%|▊         | 154/1772 [00:47<08:59,  3.00it/s, running training loss:  1.12260]\u001b[A\n",
            "Training:   9%|▊         | 155/1772 [00:47<08:13,  3.28it/s, running training loss:  1.12260]\u001b[A\n",
            "Training:   9%|▊         | 155/1772 [00:48<08:13,  3.28it/s, running training loss:  0.97838]\u001b[A\n",
            "Training:   9%|▉         | 156/1772 [00:48<08:07,  3.31it/s, running training loss:  0.97838]\u001b[A\n",
            "Training:   9%|▉         | 156/1772 [00:48<08:07,  3.31it/s, running training loss:  1.06853]\u001b[A\n",
            "Training:   9%|▉         | 157/1772 [00:48<07:33,  3.56it/s, running training loss:  1.06853]\u001b[A\n",
            "Training:   9%|▉         | 157/1772 [00:48<07:33,  3.56it/s, running training loss:  0.87638]\u001b[A\n",
            "Training:   9%|▉         | 158/1772 [00:48<07:30,  3.58it/s, running training loss:  0.87638]\u001b[A\n",
            "Training:   9%|▉         | 158/1772 [00:49<07:30,  3.58it/s, running training loss:  1.09483]\u001b[A\n",
            "Training:   9%|▉         | 159/1772 [00:49<07:13,  3.72it/s, running training loss:  1.09483]\u001b[A\n",
            "Training:   9%|▉         | 159/1772 [00:49<07:13,  3.72it/s, running training loss:  0.99941]\u001b[A\n",
            "Training:   9%|▉         | 160/1772 [00:49<07:09,  3.75it/s, running training loss:  0.99941]\u001b[A\n",
            "Training:   9%|▉         | 160/1772 [00:49<07:09,  3.75it/s, running training loss:  1.04134]\u001b[A\n",
            "Training:   9%|▉         | 161/1772 [00:49<08:05,  3.32it/s, running training loss:  1.04134]\u001b[A\n",
            "Training:   9%|▉         | 161/1772 [00:49<08:05,  3.32it/s, running training loss:  0.92930]\u001b[A\n",
            "Training:   9%|▉         | 162/1772 [00:50<08:17,  3.23it/s, running training loss:  0.92930]\u001b[A\n",
            "Training:   9%|▉         | 162/1772 [00:50<08:17,  3.23it/s, running training loss:  0.85892]\u001b[A\n",
            "Training:   9%|▉         | 163/1772 [00:50<08:00,  3.35it/s, running training loss:  0.85892]\u001b[A\n",
            "Training:   9%|▉         | 163/1772 [00:50<08:00,  3.35it/s, running training loss:  0.99894]\u001b[A\n",
            "Training:   9%|▉         | 164/1772 [00:50<08:27,  3.17it/s, running training loss:  0.99894]\u001b[A\n",
            "Training:   9%|▉         | 164/1772 [00:50<08:27,  3.17it/s, running training loss:  0.78317]\u001b[A\n",
            "Training:   9%|▉         | 165/1772 [00:50<08:26,  3.17it/s, running training loss:  0.78317]\u001b[A\n",
            "Training:   9%|▉         | 165/1772 [00:51<08:26,  3.17it/s, running training loss:  0.89603]\u001b[A\n",
            "Training:   9%|▉         | 166/1772 [00:51<08:15,  3.24it/s, running training loss:  0.89603]\u001b[A\n",
            "Training:   9%|▉         | 166/1772 [00:51<08:15,  3.24it/s, running training loss:  1.12167]\u001b[A\n",
            "Training:   9%|▉         | 167/1772 [00:51<07:43,  3.46it/s, running training loss:  1.12167]\u001b[A\n",
            "Training:   9%|▉         | 167/1772 [00:51<07:43,  3.46it/s, running training loss:  0.92815]\u001b[A\n",
            "Training:   9%|▉         | 168/1772 [00:51<07:40,  3.48it/s, running training loss:  0.92815]\u001b[A\n",
            "Training:   9%|▉         | 168/1772 [00:52<07:40,  3.48it/s, running training loss:  0.98170]\u001b[A\n",
            "Training:  10%|▉         | 169/1772 [00:52<08:07,  3.29it/s, running training loss:  0.98170]\u001b[A\n",
            "Training:  10%|▉         | 169/1772 [00:52<08:07,  3.29it/s, running training loss:  1.07304]\u001b[A\n",
            "Training:  10%|▉         | 170/1772 [00:52<07:57,  3.36it/s, running training loss:  1.07304]\u001b[A\n",
            "Training:  10%|▉         | 170/1772 [00:52<07:57,  3.36it/s, running training loss:  1.01297]\u001b[A\n",
            "Training:  10%|▉         | 171/1772 [00:52<08:48,  3.03it/s, running training loss:  1.01297]\u001b[A\n",
            "Training:  10%|▉         | 171/1772 [00:53<08:48,  3.03it/s, running training loss:  1.06885]\u001b[A\n",
            "Training:  10%|▉         | 172/1772 [00:53<08:18,  3.21it/s, running training loss:  1.06885]\u001b[A\n",
            "Training:  10%|▉         | 172/1772 [00:53<08:18,  3.21it/s, running training loss:  1.18602]\u001b[A\n",
            "Training:  10%|▉         | 173/1772 [00:53<07:57,  3.35it/s, running training loss:  1.18602]\u001b[A\n",
            "Training:  10%|▉         | 173/1772 [00:53<07:57,  3.35it/s, running training loss:  1.09877]\u001b[A\n",
            "Training:  10%|▉         | 174/1772 [00:53<09:12,  2.89it/s, running training loss:  1.09877]\u001b[A\n",
            "Training:  10%|▉         | 174/1772 [00:54<09:12,  2.89it/s, running training loss:  1.14550]\u001b[A\n",
            "Training:  10%|▉         | 175/1772 [00:54<08:43,  3.05it/s, running training loss:  1.14550]\u001b[A\n",
            "Training:  10%|▉         | 175/1772 [00:54<08:43,  3.05it/s, running training loss:  1.06660]\u001b[A\n",
            "Training:  10%|▉         | 176/1772 [00:54<08:36,  3.09it/s, running training loss:  1.06660]\u001b[A\n",
            "Training:  10%|▉         | 176/1772 [00:54<08:36,  3.09it/s, running training loss:  1.08220]\u001b[A\n",
            "Training:  10%|▉         | 177/1772 [00:54<08:22,  3.17it/s, running training loss:  1.08220]\u001b[A\n",
            "Training:  10%|▉         | 177/1772 [00:54<08:22,  3.17it/s, running training loss:  1.16307]\u001b[A\n",
            "Training:  10%|█         | 178/1772 [00:54<08:18,  3.20it/s, running training loss:  1.16307]\u001b[A\n",
            "Training:  10%|█         | 178/1772 [00:55<08:18,  3.20it/s, running training loss:  0.88795]\u001b[A\n",
            "Training:  10%|█         | 179/1772 [00:55<08:47,  3.02it/s, running training loss:  0.88795]\u001b[A\n",
            "Training:  10%|█         | 179/1772 [00:55<08:47,  3.02it/s, running training loss:  1.18444]\u001b[A\n",
            "Training:  10%|█         | 180/1772 [00:55<08:06,  3.27it/s, running training loss:  1.18444]\u001b[A\n",
            "Training:  10%|█         | 180/1772 [00:55<08:06,  3.27it/s, running training loss:  1.02644]\u001b[A\n",
            "Training:  10%|█         | 181/1772 [00:55<07:50,  3.38it/s, running training loss:  1.02644]\u001b[A\n",
            "Training:  10%|█         | 181/1772 [00:56<07:50,  3.38it/s, running training loss:  0.75828]\u001b[A\n",
            "Training:  10%|█         | 182/1772 [00:56<08:30,  3.11it/s, running training loss:  0.75828]\u001b[A\n",
            "Training:  10%|█         | 182/1772 [00:56<08:30,  3.11it/s, running training loss:  0.99725]\u001b[A\n",
            "Training:  10%|█         | 183/1772 [00:56<08:13,  3.22it/s, running training loss:  0.99725]\u001b[A\n",
            "Training:  10%|█         | 183/1772 [00:56<08:13,  3.22it/s, running training loss:  0.96362]\u001b[A\n",
            "Training:  10%|█         | 184/1772 [00:56<08:17,  3.19it/s, running training loss:  0.96362]\u001b[A\n",
            "Training:  10%|█         | 184/1772 [00:57<08:17,  3.19it/s, running training loss:  1.05877]\u001b[A\n",
            "Training:  10%|█         | 185/1772 [00:57<07:48,  3.39it/s, running training loss:  1.05877]\u001b[A\n",
            "Training:  10%|█         | 185/1772 [00:57<07:48,  3.39it/s, running training loss:  1.08522]\u001b[A\n",
            "Training:  10%|█         | 186/1772 [00:57<07:33,  3.50it/s, running training loss:  1.08522]\u001b[A\n",
            "Training:  10%|█         | 186/1772 [00:57<07:33,  3.50it/s, running training loss:  0.74669]\u001b[A\n",
            "Training:  11%|█         | 187/1772 [00:57<09:02,  2.92it/s, running training loss:  0.74669]\u001b[A\n",
            "Training:  11%|█         | 187/1772 [00:58<09:02,  2.92it/s, running training loss:  0.81753]\u001b[A\n",
            "Training:  11%|█         | 188/1772 [00:58<08:41,  3.04it/s, running training loss:  0.81753]\u001b[A\n",
            "Training:  11%|█         | 188/1772 [00:58<08:41,  3.04it/s, running training loss:  0.99514]\u001b[A\n",
            "Training:  11%|█         | 189/1772 [00:58<08:48,  2.99it/s, running training loss:  0.99514]\u001b[A\n",
            "Training:  11%|█         | 189/1772 [00:58<08:48,  2.99it/s, running training loss:  0.96029]\u001b[A\n",
            "Training:  11%|█         | 190/1772 [00:58<08:31,  3.09it/s, running training loss:  0.96029]\u001b[A\n",
            "Training:  11%|█         | 190/1772 [00:59<08:31,  3.09it/s, running training loss:  0.90761]\u001b[A\n",
            "Training:  11%|█         | 191/1772 [00:59<08:26,  3.12it/s, running training loss:  0.90761]\u001b[A\n",
            "Training:  11%|█         | 191/1772 [00:59<08:26,  3.12it/s, running training loss:  0.97582]\u001b[A\n",
            "Training:  11%|█         | 192/1772 [00:59<09:11,  2.86it/s, running training loss:  0.97582]\u001b[A\n",
            "Training:  11%|█         | 192/1772 [00:59<09:11,  2.86it/s, running training loss:  0.97354]\u001b[A\n",
            "Training:  11%|█         | 193/1772 [00:59<09:05,  2.89it/s, running training loss:  0.97354]\u001b[A\n",
            "Training:  11%|█         | 193/1772 [01:00<09:05,  2.89it/s, running training loss:  1.21801]\u001b[A\n",
            "Training:  11%|█         | 194/1772 [01:00<08:19,  3.16it/s, running training loss:  1.21801]\u001b[A\n",
            "Training:  11%|█         | 194/1772 [01:00<08:19,  3.16it/s, running training loss:  0.87011]\u001b[A\n",
            "Training:  11%|█         | 195/1772 [01:00<07:49,  3.36it/s, running training loss:  0.87011]\u001b[A\n",
            "Training:  11%|█         | 195/1772 [01:00<07:49,  3.36it/s, running training loss:  0.97736]\u001b[A\n",
            "Training:  11%|█         | 196/1772 [01:00<08:58,  2.93it/s, running training loss:  0.97736]\u001b[A\n",
            "Training:  11%|█         | 196/1772 [01:01<08:58,  2.93it/s, running training loss:  0.83886]\u001b[A\n",
            "Training:  11%|█         | 197/1772 [01:01<08:16,  3.17it/s, running training loss:  0.83886]\u001b[A\n",
            "Training:  11%|█         | 197/1772 [01:01<08:16,  3.17it/s, running training loss:  1.27173]\u001b[A\n",
            "Training:  11%|█         | 198/1772 [01:01<07:54,  3.32it/s, running training loss:  1.27173]\u001b[A\n",
            "Training:  11%|█         | 198/1772 [01:01<07:54,  3.32it/s, running training loss:  0.72940]\u001b[A\n",
            "Training:  11%|█         | 199/1772 [01:01<07:51,  3.33it/s, running training loss:  0.72940]\u001b[A\n",
            "Training:  11%|█         | 199/1772 [01:01<07:51,  3.33it/s, running training loss:  0.80575]\u001b[A\n",
            "Training:  11%|█▏        | 200/1772 [01:02<08:20,  3.14it/s, running training loss:  0.80575]\u001b[A\n",
            "Training:  11%|█▏        | 200/1772 [01:02<08:20,  3.14it/s, running training loss:  0.97067]\u001b[A\n",
            "Training:  11%|█▏        | 201/1772 [01:02<08:03,  3.25it/s, running training loss:  0.97067]\u001b[A\n",
            "Training:  11%|█▏        | 201/1772 [01:02<08:03,  3.25it/s, running training loss:  0.92191]\u001b[A\n",
            "Training:  11%|█▏        | 202/1772 [01:02<08:07,  3.22it/s, running training loss:  0.92191]\u001b[A\n",
            "Training:  11%|█▏        | 202/1772 [01:02<08:07,  3.22it/s, running training loss:  1.03370]\u001b[A\n",
            "Training:  11%|█▏        | 203/1772 [01:02<08:02,  3.25it/s, running training loss:  1.03370]\u001b[A\n",
            "Training:  11%|█▏        | 203/1772 [01:03<08:02,  3.25it/s, running training loss:  1.01594]\u001b[A\n",
            "Training:  12%|█▏        | 204/1772 [01:03<07:30,  3.48it/s, running training loss:  1.01594]\u001b[A\n",
            "Training:  12%|█▏        | 204/1772 [01:03<07:30,  3.48it/s, running training loss:  1.13331]\u001b[A\n",
            "Training:  12%|█▏        | 205/1772 [01:03<08:08,  3.21it/s, running training loss:  1.13331]\u001b[A\n",
            "Training:  12%|█▏        | 205/1772 [01:03<08:08,  3.21it/s, running training loss:  0.93054]\u001b[A\n",
            "Training:  12%|█▏        | 206/1772 [01:03<07:54,  3.30it/s, running training loss:  0.93054]\u001b[A\n",
            "Training:  12%|█▏        | 206/1772 [01:04<07:54,  3.30it/s, running training loss:  1.03908]\u001b[A\n",
            "Training:  12%|█▏        | 207/1772 [01:04<07:56,  3.28it/s, running training loss:  1.03908]\u001b[A\n",
            "Training:  12%|█▏        | 207/1772 [01:04<07:56,  3.28it/s, running training loss:  0.98224]\u001b[A\n",
            "Training:  12%|█▏        | 208/1772 [01:04<07:35,  3.44it/s, running training loss:  0.98224]\u001b[A\n",
            "Training:  12%|█▏        | 208/1772 [01:04<07:35,  3.44it/s, running training loss:  1.11023]\u001b[A\n",
            "Training:  12%|█▏        | 209/1772 [01:04<08:37,  3.02it/s, running training loss:  1.11023]\u001b[A\n",
            "Training:  12%|█▏        | 209/1772 [01:05<08:37,  3.02it/s, running training loss:  1.06794]\u001b[A\n",
            "Training:  12%|█▏        | 210/1772 [01:05<09:31,  2.73it/s, running training loss:  1.06794]\u001b[A\n",
            "Training:  12%|█▏        | 210/1772 [01:05<09:31,  2.73it/s, running training loss:  1.07139]\u001b[A\n",
            "Training:  12%|█▏        | 211/1772 [01:05<08:46,  2.96it/s, running training loss:  1.07139]\u001b[A\n",
            "Training:  12%|█▏        | 211/1772 [01:05<08:46,  2.96it/s, running training loss:  1.11218]\u001b[A\n",
            "Training:  12%|█▏        | 212/1772 [01:05<08:23,  3.10it/s, running training loss:  1.11218]\u001b[A\n",
            "Training:  12%|█▏        | 212/1772 [01:06<08:23,  3.10it/s, running training loss:  1.15958]\u001b[A\n",
            "Training:  12%|█▏        | 213/1772 [01:06<07:46,  3.34it/s, running training loss:  1.15958]\u001b[A\n",
            "Training:  12%|█▏        | 213/1772 [01:06<07:46,  3.34it/s, running training loss:  1.00561]\u001b[A\n",
            "Training:  12%|█▏        | 214/1772 [01:06<07:37,  3.41it/s, running training loss:  1.00561]\u001b[A\n",
            "Training:  12%|█▏        | 214/1772 [01:06<07:37,  3.41it/s, running training loss:  0.80496]\u001b[A\n",
            "Training:  12%|█▏        | 215/1772 [01:06<07:24,  3.50it/s, running training loss:  0.80496]\u001b[A\n",
            "Training:  12%|█▏        | 215/1772 [01:06<07:24,  3.50it/s, running training loss:  1.06849]\u001b[A\n",
            "Training:  12%|█▏        | 216/1772 [01:06<08:03,  3.22it/s, running training loss:  1.06849]\u001b[A\n",
            "Training:  12%|█▏        | 216/1772 [01:07<08:03,  3.22it/s, running training loss:  1.01377]\u001b[A\n",
            "Training:  12%|█▏        | 217/1772 [01:07<07:58,  3.25it/s, running training loss:  1.01377]\u001b[A\n",
            "Training:  12%|█▏        | 217/1772 [01:07<07:58,  3.25it/s, running training loss:  1.00938]\u001b[A\n",
            "Training:  12%|█▏        | 218/1772 [01:07<07:46,  3.33it/s, running training loss:  1.00938]\u001b[A\n",
            "Training:  12%|█▏        | 218/1772 [01:07<07:46,  3.33it/s, running training loss:  0.90775]\u001b[A\n",
            "Training:  12%|█▏        | 219/1772 [01:07<07:21,  3.52it/s, running training loss:  0.90775]\u001b[A\n",
            "Training:  12%|█▏        | 219/1772 [01:08<07:21,  3.52it/s, running training loss:  0.82667]\u001b[A\n",
            "Training:  12%|█▏        | 220/1772 [01:08<07:24,  3.49it/s, running training loss:  0.82667]\u001b[A\n",
            "Training:  12%|█▏        | 220/1772 [01:08<07:24,  3.49it/s, running training loss:  0.82272]\u001b[A\n",
            "Training:  12%|█▏        | 221/1772 [01:08<07:28,  3.46it/s, running training loss:  0.82272]\u001b[A\n",
            "Training:  12%|█▏        | 221/1772 [01:08<07:28,  3.46it/s, running training loss:  0.99920]\u001b[A\n",
            "Training:  13%|█▎        | 222/1772 [01:08<08:01,  3.22it/s, running training loss:  0.99920]\u001b[A\n",
            "Training:  13%|█▎        | 222/1772 [01:08<08:01,  3.22it/s, running training loss:  0.94308]\u001b[A\n",
            "Training:  13%|█▎        | 223/1772 [01:08<07:27,  3.46it/s, running training loss:  0.94308]\u001b[A\n",
            "Training:  13%|█▎        | 223/1772 [01:09<07:27,  3.46it/s, running training loss:  0.80196]\u001b[A\n",
            "Training:  13%|█▎        | 224/1772 [01:09<08:48,  2.93it/s, running training loss:  0.80196]\u001b[A\n",
            "Training:  13%|█▎        | 224/1772 [01:09<08:48,  2.93it/s, running training loss:  0.94235]\u001b[A\n",
            "Training:  13%|█▎        | 225/1772 [01:09<08:21,  3.09it/s, running training loss:  0.94235]\u001b[A\n",
            "Training:  13%|█▎        | 225/1772 [01:10<08:21,  3.09it/s, running training loss:  1.01150]\u001b[A\n",
            "Training:  13%|█▎        | 226/1772 [01:10<08:11,  3.14it/s, running training loss:  1.01150]\u001b[A\n",
            "Training:  13%|█▎        | 226/1772 [01:10<08:11,  3.14it/s, running training loss:  1.00412]\u001b[A\n",
            "Training:  13%|█▎        | 227/1772 [01:10<07:59,  3.22it/s, running training loss:  1.00412]\u001b[A\n",
            "Training:  13%|█▎        | 227/1772 [01:10<07:59,  3.22it/s, running training loss:  0.75341]\u001b[A\n",
            "Training:  13%|█▎        | 228/1772 [01:10<07:45,  3.32it/s, running training loss:  0.75341]\u001b[A\n",
            "Training:  13%|█▎        | 228/1772 [01:10<07:45,  3.32it/s, running training loss:  0.81546]\u001b[A\n",
            "Training:  13%|█▎        | 229/1772 [01:11<08:33,  3.00it/s, running training loss:  0.81546]\u001b[A\n",
            "Training:  13%|█▎        | 229/1772 [01:11<08:33,  3.00it/s, running training loss:  0.96925]\u001b[A\n",
            "Training:  13%|█▎        | 230/1772 [01:11<08:50,  2.91it/s, running training loss:  0.96925]\u001b[A\n",
            "Training:  13%|█▎        | 230/1772 [01:11<08:50,  2.91it/s, running training loss:  0.77139]\u001b[A\n",
            "Training:  13%|█▎        | 231/1772 [01:11<08:42,  2.95it/s, running training loss:  0.77139]\u001b[A\n",
            "Training:  13%|█▎        | 231/1772 [01:12<08:42,  2.95it/s, running training loss:  0.95878]\u001b[A\n",
            "Training:  13%|█▎        | 232/1772 [01:12<08:52,  2.89it/s, running training loss:  0.95878]\u001b[A\n",
            "Training:  13%|█▎        | 232/1772 [01:12<08:52,  2.89it/s, running training loss:  0.96889]\u001b[A\n",
            "Training:  13%|█▎        | 233/1772 [01:12<08:27,  3.03it/s, running training loss:  0.96889]\u001b[A\n",
            "Training:  13%|█▎        | 233/1772 [01:12<08:27,  3.03it/s, running training loss:  0.79273]\u001b[A\n",
            "Training:  13%|█▎        | 234/1772 [01:12<09:13,  2.78it/s, running training loss:  0.79273]\u001b[A\n",
            "Training:  13%|█▎        | 234/1772 [01:13<09:13,  2.78it/s, running training loss:  0.91427]\u001b[A\n",
            "Training:  13%|█▎        | 235/1772 [01:13<08:47,  2.92it/s, running training loss:  0.91427]\u001b[A\n",
            "Training:  13%|█▎        | 235/1772 [01:13<08:47,  2.92it/s, running training loss:  1.06555]\u001b[A\n",
            "Training:  13%|█▎        | 236/1772 [01:13<08:48,  2.91it/s, running training loss:  1.06555]\u001b[A\n",
            "Training:  13%|█▎        | 236/1772 [01:13<08:48,  2.91it/s, running training loss:  0.97317]\u001b[A\n",
            "Training:  13%|█▎        | 237/1772 [01:13<08:30,  3.01it/s, running training loss:  0.97317]\u001b[A\n",
            "Training:  13%|█▎        | 237/1772 [01:13<08:30,  3.01it/s, running training loss:  1.03580]\u001b[A\n",
            "Training:  13%|█▎        | 238/1772 [01:13<07:54,  3.23it/s, running training loss:  1.03580]\u001b[A\n",
            "Training:  13%|█▎        | 238/1772 [01:14<07:54,  3.23it/s, running training loss:  1.06811]\u001b[A\n",
            "Training:  13%|█▎        | 239/1772 [01:14<07:31,  3.39it/s, running training loss:  1.06811]\u001b[A\n",
            "Training:  13%|█▎        | 239/1772 [01:14<07:31,  3.39it/s, running training loss:  0.99784]\u001b[A\n",
            "Training:  14%|█▎        | 240/1772 [01:14<09:09,  2.79it/s, running training loss:  0.99784]\u001b[A\n",
            "Training:  14%|█▎        | 240/1772 [01:15<09:09,  2.79it/s, running training loss:  0.97617]\u001b[A\n",
            "Training:  14%|█▎        | 241/1772 [01:15<08:31,  2.99it/s, running training loss:  0.97617]\u001b[A\n",
            "Training:  14%|█▎        | 241/1772 [01:15<08:31,  2.99it/s, running training loss:  1.09433]\u001b[A\n",
            "Training:  14%|█▎        | 242/1772 [01:15<08:58,  2.84it/s, running training loss:  1.09433]\u001b[A\n",
            "Training:  14%|█▎        | 242/1772 [01:15<08:58,  2.84it/s, running training loss:  0.97900]\u001b[A\n",
            "Training:  14%|█▎        | 243/1772 [01:15<08:39,  2.95it/s, running training loss:  0.97900]\u001b[A\n",
            "Training:  14%|█▎        | 243/1772 [01:16<08:39,  2.95it/s, running training loss:  0.98223]\u001b[A\n",
            "Training:  14%|█▍        | 244/1772 [01:16<08:35,  2.97it/s, running training loss:  0.98223]\u001b[A\n",
            "Training:  14%|█▍        | 244/1772 [01:16<08:35,  2.97it/s, running training loss:  1.15868]\u001b[A\n",
            "Training:  14%|█▍        | 245/1772 [01:16<09:03,  2.81it/s, running training loss:  1.15868]\u001b[A\n",
            "Training:  14%|█▍        | 245/1772 [01:16<09:03,  2.81it/s, running training loss:  0.80540]\u001b[A\n",
            "Training:  14%|█▍        | 246/1772 [01:16<09:05,  2.80it/s, running training loss:  0.80540]\u001b[A\n",
            "Training:  14%|█▍        | 246/1772 [01:17<09:05,  2.80it/s, running training loss:  0.75306]\u001b[A\n",
            "Training:  14%|█▍        | 247/1772 [01:17<09:10,  2.77it/s, running training loss:  0.75306]\u001b[A\n",
            "Training:  14%|█▍        | 247/1772 [01:17<09:10,  2.77it/s, running training loss:  0.98297]\u001b[A\n",
            "Training:  14%|█▍        | 248/1772 [01:17<08:38,  2.94it/s, running training loss:  0.98297]\u001b[A\n",
            "Training:  14%|█▍        | 248/1772 [01:17<08:38,  2.94it/s, running training loss:  0.97714]\u001b[A\n",
            "Training:  14%|█▍        | 249/1772 [01:17<08:25,  3.01it/s, running training loss:  0.97714]\u001b[A\n",
            "Training:  14%|█▍        | 249/1772 [01:18<08:25,  3.01it/s, running training loss:  0.96041]\u001b[A\n",
            "Training:  14%|█▍        | 250/1772 [01:18<08:25,  3.01it/s, running training loss:  0.96041]\u001b[A\n",
            "Training:  14%|█▍        | 250/1772 [01:18<08:25,  3.01it/s, running training loss:  0.99682]\u001b[A\n",
            "Training:  14%|█▍        | 251/1772 [01:18<08:24,  3.02it/s, running training loss:  0.99682]\u001b[A\n",
            "Training:  14%|█▍        | 251/1772 [01:18<08:24,  3.02it/s, running training loss:  1.00598]\u001b[A\n",
            "Training:  14%|█▍        | 252/1772 [01:18<09:07,  2.78it/s, running training loss:  1.00598]\u001b[A\n",
            "Training:  14%|█▍        | 252/1772 [01:19<09:07,  2.78it/s, running training loss:  0.92620]\u001b[A\n",
            "Training:  14%|█▍        | 253/1772 [01:19<09:24,  2.69it/s, running training loss:  0.92620]\u001b[A\n",
            "Training:  14%|█▍        | 253/1772 [01:19<09:24,  2.69it/s, running training loss:  0.91234]\u001b[A\n",
            "Training:  14%|█▍        | 254/1772 [01:19<09:47,  2.59it/s, running training loss:  0.91234]\u001b[A\n",
            "Training:  14%|█▍        | 254/1772 [01:20<09:47,  2.59it/s, running training loss:  1.02555]\u001b[A\n",
            "Training:  14%|█▍        | 255/1772 [01:20<10:31,  2.40it/s, running training loss:  1.02555]\u001b[A\n",
            "Training:  14%|█▍        | 255/1772 [01:20<10:31,  2.40it/s, running training loss:  0.88168]\u001b[A\n",
            "Training:  14%|█▍        | 256/1772 [01:20<10:11,  2.48it/s, running training loss:  0.88168]\u001b[A\n",
            "Training:  14%|█▍        | 256/1772 [01:20<10:11,  2.48it/s, running training loss:  0.91187]\u001b[A\n",
            "Training:  15%|█▍        | 257/1772 [01:20<09:23,  2.69it/s, running training loss:  0.91187]\u001b[A\n",
            "Training:  15%|█▍        | 257/1772 [01:21<09:23,  2.69it/s, running training loss:  0.92532]\u001b[A\n",
            "Training:  15%|█▍        | 258/1772 [01:21<08:35,  2.94it/s, running training loss:  0.92532]\u001b[A\n",
            "Training:  15%|█▍        | 258/1772 [01:21<08:35,  2.94it/s, running training loss:  0.90518]\u001b[A\n",
            "Training:  15%|█▍        | 259/1772 [01:21<08:37,  2.93it/s, running training loss:  0.90518]\u001b[A\n",
            "Training:  15%|█▍        | 259/1772 [01:21<08:37,  2.93it/s, running training loss:  0.96305]\u001b[A\n",
            "Training:  15%|█▍        | 260/1772 [01:21<08:48,  2.86it/s, running training loss:  0.96305]\u001b[A\n",
            "Training:  15%|█▍        | 260/1772 [01:22<08:48,  2.86it/s, running training loss:  0.97969]\u001b[A\n",
            "Training:  15%|█▍        | 261/1772 [01:22<08:49,  2.85it/s, running training loss:  0.97969]\u001b[A\n",
            "Training:  15%|█▍        | 261/1772 [01:22<08:49,  2.85it/s, running training loss:  1.18642]\u001b[A\n",
            "Training:  15%|█▍        | 262/1772 [01:22<08:35,  2.93it/s, running training loss:  1.18642]\u001b[A\n",
            "Training:  15%|█▍        | 262/1772 [01:22<08:35,  2.93it/s, running training loss:  1.00804]\u001b[A\n",
            "Training:  15%|█▍        | 263/1772 [01:22<08:01,  3.13it/s, running training loss:  1.00804]\u001b[A\n",
            "Training:  15%|█▍        | 263/1772 [01:23<08:01,  3.13it/s, running training loss:  1.20501]\u001b[A\n",
            "Training:  15%|█▍        | 264/1772 [01:23<08:09,  3.08it/s, running training loss:  1.20501]\u001b[A\n",
            "Training:  15%|█▍        | 264/1772 [01:23<08:09,  3.08it/s, running training loss:  1.08834]\u001b[A\n",
            "Training:  15%|█▍        | 265/1772 [01:23<07:35,  3.31it/s, running training loss:  1.08834]\u001b[A\n",
            "Training:  15%|█▍        | 265/1772 [01:23<07:35,  3.31it/s, running training loss:  1.08183]\u001b[A\n",
            "Training:  15%|█▌        | 266/1772 [01:23<07:25,  3.38it/s, running training loss:  1.08183]\u001b[A\n",
            "Training:  15%|█▌        | 266/1772 [01:24<07:25,  3.38it/s, running training loss:  1.02599]\u001b[A\n",
            "Training:  15%|█▌        | 267/1772 [01:24<07:55,  3.16it/s, running training loss:  1.02599]\u001b[A\n",
            "Training:  15%|█▌        | 267/1772 [01:24<07:55,  3.16it/s, running training loss:  0.97214]\u001b[A\n",
            "Training:  15%|█▌        | 268/1772 [01:24<08:06,  3.09it/s, running training loss:  0.97214]\u001b[A\n",
            "Training:  15%|█▌        | 268/1772 [01:24<08:06,  3.09it/s, running training loss:  0.93103]\u001b[A\n",
            "Training:  15%|█▌        | 269/1772 [01:24<08:08,  3.08it/s, running training loss:  0.93103]\u001b[A\n",
            "Training:  15%|█▌        | 269/1772 [01:24<08:08,  3.08it/s, running training loss:  1.06632]\u001b[A\n",
            "Training:  15%|█▌        | 270/1772 [01:24<07:54,  3.16it/s, running training loss:  1.06632]\u001b[A\n",
            "Training:  15%|█▌        | 270/1772 [01:25<07:54,  3.16it/s, running training loss:  1.14982]\u001b[A\n",
            "Training:  15%|█▌        | 271/1772 [01:25<07:46,  3.22it/s, running training loss:  1.14982]\u001b[A\n",
            "Training:  15%|█▌        | 271/1772 [01:25<07:46,  3.22it/s, running training loss:  0.97880]\u001b[A\n",
            "Training:  15%|█▌        | 272/1772 [01:25<08:46,  2.85it/s, running training loss:  0.97880]\u001b[A\n",
            "Training:  15%|█▌        | 272/1772 [01:26<08:46,  2.85it/s, running training loss:  1.07880]\u001b[A\n",
            "Training:  15%|█▌        | 273/1772 [01:26<08:48,  2.84it/s, running training loss:  1.07880]\u001b[A\n",
            "Training:  15%|█▌        | 273/1772 [01:26<08:48,  2.84it/s, running training loss:  1.00972]\u001b[A\n",
            "Training:  15%|█▌        | 274/1772 [01:26<08:29,  2.94it/s, running training loss:  1.00972]\u001b[A\n",
            "Training:  15%|█▌        | 274/1772 [01:26<08:29,  2.94it/s, running training loss:  1.00306]\u001b[A\n",
            "Training:  16%|█▌        | 275/1772 [01:26<08:01,  3.11it/s, running training loss:  1.00306]\u001b[A\n",
            "Training:  16%|█▌        | 275/1772 [01:26<08:01,  3.11it/s, running training loss:  0.93008]\u001b[A\n",
            "Training:  16%|█▌        | 276/1772 [01:26<07:44,  3.22it/s, running training loss:  0.93008]\u001b[A\n",
            "Training:  16%|█▌        | 276/1772 [01:27<07:44,  3.22it/s, running training loss:  0.94135]\u001b[A\n",
            "Training:  16%|█▌        | 277/1772 [01:27<08:01,  3.10it/s, running training loss:  0.94135]\u001b[A\n",
            "Training:  16%|█▌        | 277/1772 [01:27<08:01,  3.10it/s, running training loss:  1.09837]\u001b[A\n",
            "Training:  16%|█▌        | 278/1772 [01:27<07:48,  3.19it/s, running training loss:  1.09837]\u001b[A\n",
            "Training:  16%|█▌        | 278/1772 [01:27<07:48,  3.19it/s, running training loss:  1.00317]\u001b[A\n",
            "Training:  16%|█▌        | 279/1772 [01:27<07:39,  3.25it/s, running training loss:  1.00317]\u001b[A\n",
            "Training:  16%|█▌        | 279/1772 [01:28<07:39,  3.25it/s, running training loss:  1.07518]\u001b[A\n",
            "Training:  16%|█▌        | 280/1772 [01:28<08:09,  3.05it/s, running training loss:  1.07518]\u001b[A\n",
            "Training:  16%|█▌        | 280/1772 [01:28<08:09,  3.05it/s, running training loss:  0.94566]\u001b[A\n",
            "Training:  16%|█▌        | 281/1772 [01:28<07:43,  3.22it/s, running training loss:  0.94566]\u001b[A\n",
            "Training:  16%|█▌        | 281/1772 [01:28<07:43,  3.22it/s, running training loss:  1.05465]\u001b[A\n",
            "Training:  16%|█▌        | 282/1772 [01:28<07:24,  3.35it/s, running training loss:  1.05465]\u001b[A\n",
            "Training:  16%|█▌        | 282/1772 [01:29<07:24,  3.35it/s, running training loss:  0.82775]\u001b[A\n",
            "Training:  16%|█▌        | 283/1772 [01:29<08:34,  2.89it/s, running training loss:  0.82775]\u001b[A\n",
            "Training:  16%|█▌        | 283/1772 [01:29<08:34,  2.89it/s, running training loss:  0.94001]\u001b[A\n",
            "Training:  16%|█▌        | 284/1772 [01:29<07:51,  3.16it/s, running training loss:  0.94001]\u001b[A\n",
            "Training:  16%|█▌        | 284/1772 [01:29<07:51,  3.16it/s, running training loss:  0.96072]\u001b[A\n",
            "Training:  16%|█▌        | 285/1772 [01:29<08:21,  2.97it/s, running training loss:  0.96072]\u001b[A\n",
            "Training:  16%|█▌        | 285/1772 [01:30<08:21,  2.97it/s, running training loss:  1.23063]\u001b[A\n",
            "Training:  16%|█▌        | 286/1772 [01:30<08:18,  2.98it/s, running training loss:  1.23063]\u001b[A\n",
            "Training:  16%|█▌        | 286/1772 [01:30<08:18,  2.98it/s, running training loss:  0.96798]\u001b[A\n",
            "Training:  16%|█▌        | 287/1772 [01:30<08:18,  2.98it/s, running training loss:  0.96798]\u001b[A\n",
            "Training:  16%|█▌        | 287/1772 [01:31<08:18,  2.98it/s, running training loss:  1.30437]\u001b[A\n",
            "Training:  16%|█▋        | 288/1772 [01:31<09:40,  2.56it/s, running training loss:  1.30437]\u001b[A\n",
            "Training:  16%|█▋        | 288/1772 [01:31<09:40,  2.56it/s, running training loss:  1.04047]\u001b[A\n",
            "Training:  16%|█▋        | 289/1772 [01:31<10:50,  2.28it/s, running training loss:  1.04047]\u001b[A\n",
            "Training:  16%|█▋        | 289/1772 [01:31<10:50,  2.28it/s, running training loss:  0.99807]\u001b[A\n",
            "Training:  16%|█▋        | 290/1772 [01:31<09:44,  2.53it/s, running training loss:  0.99807]\u001b[A\n",
            "Training:  16%|█▋        | 290/1772 [01:32<09:44,  2.53it/s, running training loss:  1.00060]\u001b[A\n",
            "Training:  16%|█▋        | 291/1772 [01:32<08:52,  2.78it/s, running training loss:  1.00060]\u001b[A\n",
            "Training:  16%|█▋        | 291/1772 [01:32<08:52,  2.78it/s, running training loss:  1.34999]\u001b[A\n",
            "Training:  16%|█▋        | 292/1772 [01:32<08:40,  2.84it/s, running training loss:  1.34999]\u001b[A\n",
            "Training:  16%|█▋        | 292/1772 [01:32<08:40,  2.84it/s, running training loss:  1.28902]\u001b[A\n",
            "Training:  17%|█▋        | 293/1772 [01:32<08:15,  2.99it/s, running training loss:  1.28902]\u001b[A\n",
            "Training:  17%|█▋        | 293/1772 [01:33<08:15,  2.99it/s, running training loss:  1.02196]\u001b[A\n",
            "Training:  17%|█▋        | 294/1772 [01:33<07:55,  3.11it/s, running training loss:  1.02196]\u001b[A\n",
            "Training:  17%|█▋        | 294/1772 [01:33<07:55,  3.11it/s, running training loss:  0.95987]\u001b[A\n",
            "Training:  17%|█▋        | 295/1772 [01:33<07:41,  3.20it/s, running training loss:  0.95987]\u001b[A\n",
            "Training:  17%|█▋        | 295/1772 [01:33<07:41,  3.20it/s, running training loss:  1.07422]\u001b[A\n",
            "Training:  17%|█▋        | 296/1772 [01:33<07:17,  3.37it/s, running training loss:  1.07422]\u001b[A\n",
            "Training:  17%|█▋        | 296/1772 [01:33<07:17,  3.37it/s, running training loss:  0.89213]\u001b[A\n",
            "Training:  17%|█▋        | 297/1772 [01:33<07:18,  3.37it/s, running training loss:  0.89213]\u001b[A\n",
            "Training:  17%|█▋        | 297/1772 [01:34<07:18,  3.37it/s, running training loss:  1.03797]\u001b[A\n",
            "Training:  17%|█▋        | 298/1772 [01:34<07:51,  3.13it/s, running training loss:  1.03797]\u001b[A\n",
            "Training:  17%|█▋        | 298/1772 [01:34<07:51,  3.13it/s, running training loss:  1.34888]\u001b[A\n",
            "Training:  17%|█▋        | 299/1772 [01:34<08:58,  2.74it/s, running training loss:  1.34888]\u001b[A\n",
            "Training:  17%|█▋        | 299/1772 [01:35<08:58,  2.74it/s, running training loss:  1.00515]\u001b[A\n",
            "\n",
            "Evaluation:   0%|          | 0/270 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   0%|          | 1/270 [00:00<01:30,  2.98it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   1%|          | 3/270 [00:00<00:34,  7.68it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   2%|▏         | 5/270 [00:00<00:24, 10.73it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   3%|▎         | 7/270 [00:00<00:20, 13.08it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   3%|▎         | 9/270 [00:00<00:18, 14.45it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   4%|▍         | 12/270 [00:00<00:14, 17.38it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   5%|▌         | 14/270 [00:01<00:14, 17.51it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   6%|▌         | 16/270 [00:01<00:15, 16.00it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   7%|▋         | 18/270 [00:01<00:16, 15.26it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   7%|▋         | 20/270 [00:01<00:16, 15.43it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   9%|▊         | 23/270 [00:01<00:13, 18.01it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  10%|▉         | 26/270 [00:01<00:12, 19.16it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  10%|█         | 28/270 [00:01<00:12, 18.91it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  11%|█         | 30/270 [00:01<00:13, 18.25it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  12%|█▏        | 32/270 [00:02<00:13, 18.31it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  13%|█▎        | 35/270 [00:02<00:12, 18.50it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  14%|█▍        | 38/270 [00:02<00:11, 19.93it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  15%|█▍        | 40/270 [00:02<00:11, 19.52it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  16%|█▌        | 42/270 [00:02<00:11, 19.09it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  16%|█▋        | 44/270 [00:02<00:12, 18.51it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  17%|█▋        | 46/270 [00:02<00:12, 18.30it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  18%|█▊        | 49/270 [00:02<00:11, 19.03it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  19%|█▉        | 51/270 [00:03<00:11, 18.39it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  20%|█▉        | 53/270 [00:03<00:11, 18.75it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  21%|██        | 56/270 [00:03<00:11, 19.04it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  21%|██▏       | 58/270 [00:03<00:11, 18.79it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  22%|██▏       | 60/270 [00:03<00:11, 18.47it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  23%|██▎       | 62/270 [00:03<00:11, 18.16it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  24%|██▎       | 64/270 [00:03<00:11, 18.09it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  25%|██▍       | 67/270 [00:03<00:10, 19.19it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  26%|██▌       | 70/270 [00:04<00:09, 20.68it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  27%|██▋       | 73/270 [00:04<00:09, 20.45it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  28%|██▊       | 76/270 [00:04<00:09, 21.30it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  29%|██▉       | 79/270 [00:04<00:09, 20.55it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  30%|███       | 82/270 [00:04<00:09, 19.50it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  31%|███       | 84/270 [00:04<00:09, 19.50it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  32%|███▏      | 87/270 [00:04<00:09, 19.56it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  33%|███▎      | 89/270 [00:05<00:09, 18.57it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  34%|███▎      | 91/270 [00:05<00:09, 18.59it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  35%|███▍      | 94/270 [00:05<00:08, 19.67it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  36%|███▌      | 97/270 [00:05<00:08, 20.29it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  37%|███▋      | 100/270 [00:05<00:08, 20.11it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  38%|███▊      | 103/270 [00:05<00:07, 20.90it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  39%|███▉      | 106/270 [00:05<00:08, 20.05it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  40%|████      | 109/270 [00:05<00:08, 19.95it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  41%|████▏     | 112/270 [00:06<00:07, 20.21it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  43%|████▎     | 115/270 [00:06<00:07, 20.64it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  44%|████▎     | 118/270 [00:06<00:07, 20.74it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  45%|████▍     | 121/270 [00:06<00:07, 20.61it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  46%|████▌     | 124/270 [00:06<00:06, 21.45it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  47%|████▋     | 127/270 [00:06<00:07, 19.66it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  48%|████▊     | 130/270 [00:07<00:07, 19.23it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  49%|████▉     | 132/270 [00:07<00:07, 18.92it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  50%|████▉     | 134/270 [00:07<00:07, 18.82it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  51%|█████     | 137/270 [00:07<00:06, 19.90it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  52%|█████▏    | 140/270 [00:07<00:06, 19.91it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  53%|█████▎    | 142/270 [00:07<00:06, 18.86it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  54%|█████▎    | 145/270 [00:07<00:06, 19.44it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  54%|█████▍    | 147/270 [00:07<00:06, 19.19it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  56%|█████▌    | 150/270 [00:08<00:05, 20.02it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  56%|█████▋    | 152/270 [00:08<00:06, 18.80it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  57%|█████▋    | 154/270 [00:08<00:06, 18.81it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  58%|█████▊    | 156/270 [00:08<00:06, 18.69it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  59%|█████▉    | 159/270 [00:08<00:05, 19.65it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  60%|█████▉    | 161/270 [00:08<00:05, 19.37it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  60%|██████    | 163/270 [00:08<00:05, 19.05it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  61%|██████    | 165/270 [00:08<00:05, 18.63it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  62%|██████▏   | 168/270 [00:09<00:05, 19.62it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  63%|██████▎   | 170/270 [00:09<00:05, 18.93it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  64%|██████▎   | 172/270 [00:09<00:05, 18.81it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  64%|██████▍   | 174/270 [00:09<00:05, 17.97it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  65%|██████▌   | 176/270 [00:09<00:05, 17.41it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  66%|██████▌   | 178/270 [00:09<00:05, 17.86it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  67%|██████▋   | 180/270 [00:09<00:05, 17.25it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  67%|██████▋   | 182/270 [00:09<00:05, 17.39it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  68%|██████▊   | 184/270 [00:09<00:04, 17.92it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  69%|██████▉   | 186/270 [00:10<00:04, 18.27it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  70%|██████▉   | 188/270 [00:10<00:04, 17.80it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  71%|███████   | 191/270 [00:10<00:03, 19.78it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  71%|███████▏  | 193/270 [00:10<00:03, 19.34it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  72%|███████▏  | 195/270 [00:10<00:04, 18.14it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  73%|███████▎  | 197/270 [00:10<00:03, 18.57it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  74%|███████▎  | 199/270 [00:10<00:04, 17.71it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  74%|███████▍  | 201/270 [00:10<00:03, 17.61it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  75%|███████▌  | 203/270 [00:10<00:03, 17.88it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  76%|███████▋  | 206/270 [00:11<00:03, 19.52it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  77%|███████▋  | 208/270 [00:11<00:03, 18.66it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  78%|███████▊  | 210/270 [00:11<00:03, 18.29it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  79%|███████▊  | 212/270 [00:11<00:03, 18.21it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  80%|███████▉  | 215/270 [00:11<00:02, 19.64it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  80%|████████  | 217/270 [00:11<00:02, 19.25it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  81%|████████▏ | 220/270 [00:11<00:02, 19.97it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  83%|████████▎ | 223/270 [00:11<00:02, 21.27it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  84%|████████▎ | 226/270 [00:12<00:01, 22.06it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  85%|████████▍ | 229/270 [00:12<00:02, 19.47it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  86%|████████▌ | 232/270 [00:12<00:01, 19.57it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  87%|████████▋ | 235/270 [00:12<00:01, 20.51it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  88%|████████▊ | 238/270 [00:12<00:01, 20.96it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  89%|████████▉ | 241/270 [00:12<00:01, 19.15it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  90%|█████████ | 244/270 [00:13<00:01, 19.63it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  91%|█████████▏| 247/270 [00:13<00:01, 18.46it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  92%|█████████▏| 249/270 [00:13<00:01, 17.95it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  93%|█████████▎| 251/270 [00:13<00:01, 17.53it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  94%|█████████▎| 253/270 [00:13<00:00, 17.38it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  94%|█████████▍| 255/270 [00:13<00:00, 17.35it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  95%|█████████▌| 257/270 [00:13<00:00, 17.44it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  96%|█████████▋| 260/270 [00:13<00:00, 19.27it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  97%|█████████▋| 262/270 [00:14<00:00, 19.03it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  98%|█████████▊| 264/270 [00:14<00:00, 18.25it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  99%|█████████▊| 266/270 [00:14<00:00, 18.20it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  99%|█████████▉| 268/270 [00:14<00:00, 18.32it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation: 100%|██████████| 270/270 [00:14<00:00, 18.41it/s]\n",
            "\n",
            "Training:  17%|█▋        | 300/1772 [01:51<2:08:29,  5.24s/it, running training loss:  1.00515]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            ">>> training loss: 1.009871, valid loss: 0.664214,valid f1: 0.322940, valid acc:0.577386\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  17%|█▋        | 300/1772 [01:51<2:08:29,  5.24s/it, running training loss:  1.05738]\u001b[A\n",
            "Training:  17%|█▋        | 301/1772 [01:51<1:32:43,  3.78s/it, running training loss:  1.05738]\u001b[A\n",
            "Training:  17%|█▋        | 301/1772 [01:52<1:32:43,  3.78s/it, running training loss:  1.10357]\u001b[A\n",
            "Training:  17%|█▋        | 302/1772 [01:52<1:07:16,  2.75s/it, running training loss:  1.10357]\u001b[A\n",
            "Training:  17%|█▋        | 302/1772 [01:52<1:07:16,  2.75s/it, running training loss:  0.89989]\u001b[A\n",
            "Training:  17%|█▋        | 303/1772 [01:52<49:16,  2.01s/it, running training loss:  0.89989]  \u001b[A\n",
            "Training:  17%|█▋        | 303/1772 [01:52<49:16,  2.01s/it, running training loss:  1.25424]\u001b[A\n",
            "Training:  17%|█▋        | 304/1772 [01:52<36:56,  1.51s/it, running training loss:  1.25424]\u001b[A\n",
            "Training:  17%|█▋        | 304/1772 [01:53<36:56,  1.51s/it, running training loss:  0.92054]\u001b[A\n",
            "Training:  17%|█▋        | 305/1772 [01:53<28:03,  1.15s/it, running training loss:  0.92054]\u001b[A\n",
            "Training:  17%|█▋        | 305/1772 [01:53<28:03,  1.15s/it, running training loss:  0.91144]\u001b[A\n",
            "Training:  17%|█▋        | 306/1772 [01:53<21:32,  1.13it/s, running training loss:  0.91144]\u001b[A\n",
            "Training:  17%|█▋        | 306/1772 [01:53<21:32,  1.13it/s, running training loss:  0.96834]\u001b[A\n",
            "Training:  17%|█▋        | 307/1772 [01:53<16:47,  1.45it/s, running training loss:  0.96834]\u001b[A\n",
            "Training:  17%|█▋        | 307/1772 [01:54<16:47,  1.45it/s, running training loss:  1.03434]\u001b[A\n",
            "Training:  17%|█▋        | 308/1772 [01:54<15:40,  1.56it/s, running training loss:  1.03434]\u001b[A\n",
            "Training:  17%|█▋        | 308/1772 [01:54<15:40,  1.56it/s, running training loss:  0.96561]\u001b[A\n",
            "Training:  17%|█▋        | 309/1772 [01:54<13:55,  1.75it/s, running training loss:  0.96561]\u001b[A\n",
            "Training:  17%|█▋        | 309/1772 [01:54<13:55,  1.75it/s, running training loss:  1.03471]\u001b[A\n",
            "Training:  17%|█▋        | 310/1772 [01:54<12:20,  1.97it/s, running training loss:  1.03471]\u001b[A\n",
            "Training:  17%|█▋        | 310/1772 [01:55<12:20,  1.97it/s, running training loss:  1.04317]\u001b[A\n",
            "Training:  18%|█▊        | 311/1772 [01:55<10:47,  2.26it/s, running training loss:  1.04317]\u001b[A\n",
            "Training:  18%|█▊        | 311/1772 [01:55<10:47,  2.26it/s, running training loss:  0.93367]\u001b[A\n",
            "Training:  18%|█▊        | 312/1772 [01:55<11:35,  2.10it/s, running training loss:  0.93367]\u001b[A\n",
            "Training:  18%|█▊        | 312/1772 [01:56<11:35,  2.10it/s, running training loss:  1.01602]\u001b[A\n",
            "Training:  18%|█▊        | 313/1772 [01:56<10:17,  2.36it/s, running training loss:  1.01602]\u001b[A\n",
            "Training:  18%|█▊        | 313/1772 [01:56<10:17,  2.36it/s, running training loss:  1.07038]\u001b[A\n",
            "Training:  18%|█▊        | 314/1772 [01:56<09:18,  2.61it/s, running training loss:  1.07038]\u001b[A\n",
            "Training:  18%|█▊        | 314/1772 [01:56<09:18,  2.61it/s, running training loss:  1.01043]\u001b[A\n",
            "Training:  18%|█▊        | 315/1772 [01:56<08:42,  2.79it/s, running training loss:  1.01043]\u001b[A\n",
            "Training:  18%|█▊        | 315/1772 [01:56<08:42,  2.79it/s, running training loss:  1.02406]\u001b[A\n",
            "Training:  18%|█▊        | 316/1772 [01:56<08:04,  3.01it/s, running training loss:  1.02406]\u001b[A\n",
            "Training:  18%|█▊        | 316/1772 [01:57<08:04,  3.01it/s, running training loss:  0.89724]\u001b[A\n",
            "Training:  18%|█▊        | 317/1772 [01:57<08:08,  2.98it/s, running training loss:  0.89724]\u001b[A\n",
            "Training:  18%|█▊        | 317/1772 [01:57<08:08,  2.98it/s, running training loss:  0.83756]\u001b[A\n",
            "Training:  18%|█▊        | 318/1772 [01:57<07:41,  3.15it/s, running training loss:  0.83756]\u001b[A\n",
            "Training:  18%|█▊        | 318/1772 [01:57<07:41,  3.15it/s, running training loss:  1.04274]\u001b[A\n",
            "Training:  18%|█▊        | 319/1772 [01:57<07:21,  3.29it/s, running training loss:  1.04274]\u001b[A\n",
            "Training:  18%|█▊        | 319/1772 [01:58<07:21,  3.29it/s, running training loss:  0.97743]\u001b[A\n",
            "Training:  18%|█▊        | 320/1772 [01:58<07:28,  3.24it/s, running training loss:  0.97743]\u001b[A\n",
            "Training:  18%|█▊        | 320/1772 [01:58<07:28,  3.24it/s, running training loss:  1.00862]\u001b[A\n",
            "Training:  18%|█▊        | 321/1772 [01:58<07:18,  3.31it/s, running training loss:  1.00862]\u001b[A\n",
            "Training:  18%|█▊        | 321/1772 [01:58<07:18,  3.31it/s, running training loss:  1.16240]\u001b[A\n",
            "Training:  18%|█▊        | 322/1772 [01:58<07:22,  3.28it/s, running training loss:  1.16240]\u001b[A\n",
            "Training:  18%|█▊        | 322/1772 [01:59<07:22,  3.28it/s, running training loss:  0.99978]\u001b[A\n",
            "Training:  18%|█▊        | 323/1772 [01:59<07:45,  3.11it/s, running training loss:  0.99978]\u001b[A\n",
            "Training:  18%|█▊        | 323/1772 [01:59<07:45,  3.11it/s, running training loss:  0.98635]\u001b[A\n",
            "Training:  18%|█▊        | 324/1772 [01:59<07:33,  3.19it/s, running training loss:  0.98635]\u001b[A\n",
            "Training:  18%|█▊        | 324/1772 [01:59<07:33,  3.19it/s, running training loss:  1.08930]\u001b[A\n",
            "Training:  18%|█▊        | 325/1772 [01:59<07:30,  3.22it/s, running training loss:  1.08930]\u001b[A\n",
            "Training:  18%|█▊        | 325/1772 [02:00<07:30,  3.22it/s, running training loss:  0.88177]\u001b[A\n",
            "Training:  18%|█▊        | 326/1772 [02:00<08:03,  2.99it/s, running training loss:  0.88177]\u001b[A\n",
            "Training:  18%|█▊        | 326/1772 [02:00<08:03,  2.99it/s, running training loss:  0.90204]\u001b[A\n",
            "Training:  18%|█▊        | 327/1772 [02:00<09:09,  2.63it/s, running training loss:  0.90204]\u001b[A\n",
            "Training:  18%|█▊        | 327/1772 [02:00<09:09,  2.63it/s, running training loss:  1.02244]\u001b[A\n",
            "Training:  19%|█▊        | 328/1772 [02:00<08:22,  2.88it/s, running training loss:  1.02244]\u001b[A\n",
            "Training:  19%|█▊        | 328/1772 [02:01<08:22,  2.88it/s, running training loss:  0.98135]\u001b[A\n",
            "Training:  19%|█▊        | 329/1772 [02:01<07:40,  3.13it/s, running training loss:  0.98135]\u001b[A\n",
            "Training:  19%|█▊        | 329/1772 [02:01<07:40,  3.13it/s, running training loss:  1.04398]\u001b[A\n",
            "Training:  19%|█▊        | 330/1772 [02:01<07:26,  3.23it/s, running training loss:  1.04398]\u001b[A\n",
            "Training:  19%|█▊        | 330/1772 [02:01<07:26,  3.23it/s, running training loss:  1.00734]\u001b[A\n",
            "Training:  19%|█▊        | 331/1772 [02:01<07:03,  3.41it/s, running training loss:  1.00734]\u001b[A\n",
            "Training:  19%|█▊        | 331/1772 [02:01<07:03,  3.41it/s, running training loss:  1.14386]\u001b[A\n",
            "Training:  19%|█▊        | 332/1772 [02:01<07:29,  3.21it/s, running training loss:  1.14386]\u001b[A\n",
            "Training:  19%|█▊        | 332/1772 [02:02<07:29,  3.21it/s, running training loss:  0.93459]\u001b[A\n",
            "Training:  19%|█▉        | 333/1772 [02:02<07:13,  3.32it/s, running training loss:  0.93459]\u001b[A\n",
            "Training:  19%|█▉        | 333/1772 [02:02<07:13,  3.32it/s, running training loss:  0.94796]\u001b[A\n",
            "Training:  19%|█▉        | 334/1772 [02:02<06:58,  3.43it/s, running training loss:  0.94796]\u001b[A\n",
            "Training:  19%|█▉        | 334/1772 [02:02<06:58,  3.43it/s, running training loss:  0.92095]\u001b[A\n",
            "Training:  19%|█▉        | 335/1772 [02:02<07:29,  3.20it/s, running training loss:  0.92095]\u001b[A\n",
            "Training:  19%|█▉        | 335/1772 [02:03<07:29,  3.20it/s, running training loss:  1.00260]\u001b[A\n",
            "Training:  19%|█▉        | 336/1772 [02:03<07:30,  3.19it/s, running training loss:  1.00260]\u001b[A\n",
            "Training:  19%|█▉        | 336/1772 [02:03<07:30,  3.19it/s, running training loss:  0.97240]\u001b[A\n",
            "Training:  19%|█▉        | 337/1772 [02:03<07:13,  3.31it/s, running training loss:  0.97240]\u001b[A\n",
            "Training:  19%|█▉        | 337/1772 [02:03<07:13,  3.31it/s, running training loss:  1.00907]\u001b[A\n",
            "Training:  19%|█▉        | 338/1772 [02:03<07:28,  3.19it/s, running training loss:  1.00907]\u001b[A\n",
            "Training:  19%|█▉        | 338/1772 [02:04<07:28,  3.19it/s, running training loss:  1.13051]\u001b[A\n",
            "Training:  19%|█▉        | 339/1772 [02:04<07:01,  3.40it/s, running training loss:  1.13051]\u001b[A\n",
            "Training:  19%|█▉        | 339/1772 [02:04<07:01,  3.40it/s, running training loss:  0.81548]\u001b[A\n",
            "Training:  19%|█▉        | 340/1772 [02:04<08:16,  2.88it/s, running training loss:  0.81548]\u001b[A\n",
            "Training:  19%|█▉        | 340/1772 [02:04<08:16,  2.88it/s, running training loss:  0.88660]\u001b[A\n",
            "Training:  19%|█▉        | 341/1772 [02:04<08:36,  2.77it/s, running training loss:  0.88660]\u001b[A\n",
            "Training:  19%|█▉        | 341/1772 [02:05<08:36,  2.77it/s, running training loss:  1.10871]\u001b[A\n",
            "Training:  19%|█▉        | 342/1772 [02:05<08:07,  2.93it/s, running training loss:  1.10871]\u001b[A\n",
            "Training:  19%|█▉        | 342/1772 [02:05<08:07,  2.93it/s, running training loss:  1.17835]\u001b[A\n",
            "Training:  19%|█▉        | 343/1772 [02:05<07:23,  3.22it/s, running training loss:  1.17835]\u001b[A\n",
            "Training:  19%|█▉        | 343/1772 [02:05<07:23,  3.22it/s, running training loss:  1.10867]\u001b[A\n",
            "Training:  19%|█▉        | 344/1772 [02:05<07:08,  3.33it/s, running training loss:  1.10867]\u001b[A\n",
            "Training:  19%|█▉        | 344/1772 [02:06<07:08,  3.33it/s, running training loss:  0.97601]\u001b[A\n",
            "Training:  19%|█▉        | 345/1772 [02:06<07:22,  3.23it/s, running training loss:  0.97601]\u001b[A\n",
            "Training:  19%|█▉        | 345/1772 [02:06<07:22,  3.23it/s, running training loss:  0.88097]\u001b[A\n",
            "Training:  20%|█▉        | 346/1772 [02:06<08:55,  2.66it/s, running training loss:  0.88097]\u001b[A\n",
            "Training:  20%|█▉        | 346/1772 [02:06<08:55,  2.66it/s, running training loss:  1.14714]\u001b[A\n",
            "Training:  20%|█▉        | 347/1772 [02:06<07:55,  2.99it/s, running training loss:  1.14714]\u001b[A\n",
            "Training:  20%|█▉        | 347/1772 [02:07<07:55,  2.99it/s, running training loss:  1.09822]\u001b[A\n",
            "Training:  20%|█▉        | 348/1772 [02:07<07:17,  3.26it/s, running training loss:  1.09822]\u001b[A\n",
            "Training:  20%|█▉        | 348/1772 [02:07<07:17,  3.26it/s, running training loss:  1.19217]\u001b[A\n",
            "Training:  20%|█▉        | 349/1772 [02:07<07:24,  3.20it/s, running training loss:  1.19217]\u001b[A\n",
            "Training:  20%|█▉        | 349/1772 [02:07<07:24,  3.20it/s, running training loss:  0.95621]\u001b[A\n",
            "Training:  20%|█▉        | 350/1772 [02:07<07:10,  3.30it/s, running training loss:  0.95621]\u001b[A\n",
            "Training:  20%|█▉        | 350/1772 [02:07<07:10,  3.30it/s, running training loss:  1.05120]\u001b[A\n",
            "Training:  20%|█▉        | 351/1772 [02:07<07:00,  3.38it/s, running training loss:  1.05120]\u001b[A\n",
            "Training:  20%|█▉        | 351/1772 [02:08<07:00,  3.38it/s, running training loss:  1.07271]\u001b[A\n",
            "Training:  20%|█▉        | 352/1772 [02:08<07:11,  3.29it/s, running training loss:  1.07271]\u001b[A\n",
            "Training:  20%|█▉        | 352/1772 [02:08<07:11,  3.29it/s, running training loss:  0.98561]\u001b[A\n",
            "Training:  20%|█▉        | 353/1772 [02:08<06:51,  3.45it/s, running training loss:  0.98561]\u001b[A\n",
            "Training:  20%|█▉        | 353/1772 [02:08<06:51,  3.45it/s, running training loss:  0.92929]\u001b[A\n",
            "Training:  20%|█▉        | 354/1772 [02:08<06:46,  3.49it/s, running training loss:  0.92929]\u001b[A\n",
            "Training:  20%|█▉        | 354/1772 [02:09<06:46,  3.49it/s, running training loss:  1.22460]\u001b[A\n",
            "Training:  20%|██        | 355/1772 [02:09<06:42,  3.52it/s, running training loss:  1.22460]\u001b[A\n",
            "Training:  20%|██        | 355/1772 [02:09<06:42,  3.52it/s, running training loss:  0.82419]\u001b[A\n",
            "Training:  20%|██        | 356/1772 [02:09<06:33,  3.60it/s, running training loss:  0.82419]\u001b[A\n",
            "Training:  20%|██        | 356/1772 [02:09<06:33,  3.60it/s, running training loss:  0.90034]\u001b[A\n",
            "Training:  20%|██        | 357/1772 [02:09<06:47,  3.48it/s, running training loss:  0.90034]\u001b[A\n",
            "Training:  20%|██        | 357/1772 [02:09<06:47,  3.48it/s, running training loss:  1.00545]\u001b[A\n",
            "Training:  20%|██        | 358/1772 [02:09<06:29,  3.63it/s, running training loss:  1.00545]\u001b[A\n",
            "Training:  20%|██        | 358/1772 [02:10<06:29,  3.63it/s, running training loss:  1.03067]\u001b[A\n",
            "Training:  20%|██        | 359/1772 [02:10<06:24,  3.67it/s, running training loss:  1.03067]\u001b[A\n",
            "Training:  20%|██        | 359/1772 [02:10<06:24,  3.67it/s, running training loss:  1.19165]\u001b[A\n",
            "Training:  20%|██        | 360/1772 [02:10<06:39,  3.54it/s, running training loss:  1.19165]\u001b[A\n",
            "Training:  20%|██        | 360/1772 [02:10<06:39,  3.54it/s, running training loss:  1.12450]\u001b[A\n",
            "Training:  20%|██        | 361/1772 [02:10<06:25,  3.66it/s, running training loss:  1.12450]\u001b[A\n",
            "Training:  20%|██        | 361/1772 [02:11<06:25,  3.66it/s, running training loss:  1.00030]\u001b[A\n",
            "Training:  20%|██        | 362/1772 [02:11<06:37,  3.55it/s, running training loss:  1.00030]\u001b[A\n",
            "Training:  20%|██        | 362/1772 [02:11<06:37,  3.55it/s, running training loss:  1.15950]\u001b[A\n",
            "Training:  20%|██        | 363/1772 [02:11<07:21,  3.19it/s, running training loss:  1.15950]\u001b[A\n",
            "Training:  20%|██        | 363/1772 [02:11<07:21,  3.19it/s, running training loss:  0.87459]\u001b[A\n",
            "Training:  21%|██        | 364/1772 [02:11<07:10,  3.27it/s, running training loss:  0.87459]\u001b[A\n",
            "Training:  21%|██        | 364/1772 [02:12<07:10,  3.27it/s, running training loss:  0.98312]\u001b[A\n",
            "Training:  21%|██        | 365/1772 [02:12<07:22,  3.18it/s, running training loss:  0.98312]\u001b[A\n",
            "Training:  21%|██        | 365/1772 [02:12<07:22,  3.18it/s, running training loss:  0.98889]\u001b[A\n",
            "Training:  21%|██        | 366/1772 [02:12<07:55,  2.96it/s, running training loss:  0.98889]\u001b[A\n",
            "Training:  21%|██        | 366/1772 [02:12<07:55,  2.96it/s, running training loss:  0.76568]\u001b[A\n",
            "Training:  21%|██        | 367/1772 [02:12<08:13,  2.84it/s, running training loss:  0.76568]\u001b[A\n",
            "Training:  21%|██        | 367/1772 [02:13<08:13,  2.84it/s, running training loss:  1.00464]\u001b[A\n",
            "Training:  21%|██        | 368/1772 [02:13<08:24,  2.78it/s, running training loss:  1.00464]\u001b[A\n",
            "Training:  21%|██        | 368/1772 [02:13<08:24,  2.78it/s, running training loss:  0.97761]\u001b[A\n",
            "Training:  21%|██        | 369/1772 [02:13<08:13,  2.84it/s, running training loss:  0.97761]\u001b[A\n",
            "Training:  21%|██        | 369/1772 [02:13<08:13,  2.84it/s, running training loss:  0.91286]\u001b[A\n",
            "Training:  21%|██        | 370/1772 [02:13<07:47,  3.00it/s, running training loss:  0.91286]\u001b[A\n",
            "Training:  21%|██        | 370/1772 [02:14<07:47,  3.00it/s, running training loss:  0.94546]\u001b[A\n",
            "Training:  21%|██        | 371/1772 [02:14<07:35,  3.07it/s, running training loss:  0.94546]\u001b[A\n",
            "Training:  21%|██        | 371/1772 [02:14<07:35,  3.07it/s, running training loss:  1.01479]\u001b[A\n",
            "Training:  21%|██        | 372/1772 [02:14<07:03,  3.31it/s, running training loss:  1.01479]\u001b[A\n",
            "Training:  21%|██        | 372/1772 [02:14<07:03,  3.31it/s, running training loss:  1.09231]\u001b[A\n",
            "Training:  21%|██        | 373/1772 [02:14<07:37,  3.06it/s, running training loss:  1.09231]\u001b[A\n",
            "Training:  21%|██        | 373/1772 [02:15<07:37,  3.06it/s, running training loss:  0.91743]\u001b[A\n",
            "Training:  21%|██        | 374/1772 [02:15<07:19,  3.18it/s, running training loss:  0.91743]\u001b[A\n",
            "Training:  21%|██        | 374/1772 [02:15<07:19,  3.18it/s, running training loss:  0.97156]\u001b[A\n",
            "Training:  21%|██        | 375/1772 [02:15<07:06,  3.28it/s, running training loss:  0.97156]\u001b[A\n",
            "Training:  21%|██        | 375/1772 [02:15<07:06,  3.28it/s, running training loss:  1.02411]\u001b[A\n",
            "Training:  21%|██        | 376/1772 [02:15<06:59,  3.33it/s, running training loss:  1.02411]\u001b[A\n",
            "Training:  21%|██        | 376/1772 [02:15<06:59,  3.33it/s, running training loss:  0.91353]\u001b[A\n",
            "Training:  21%|██▏       | 377/1772 [02:15<07:30,  3.09it/s, running training loss:  0.91353]\u001b[A\n",
            "Training:  21%|██▏       | 377/1772 [02:16<07:30,  3.09it/s, running training loss:  1.04608]\u001b[A\n",
            "Training:  21%|██▏       | 378/1772 [02:16<09:03,  2.56it/s, running training loss:  1.04608]\u001b[A\n",
            "Training:  21%|██▏       | 378/1772 [02:16<09:03,  2.56it/s, running training loss:  1.15866]\u001b[A\n",
            "Training:  21%|██▏       | 379/1772 [02:16<08:48,  2.64it/s, running training loss:  1.15866]\u001b[A\n",
            "Training:  21%|██▏       | 379/1772 [02:17<08:48,  2.64it/s, running training loss:  0.93407]\u001b[A\n",
            "Training:  21%|██▏       | 380/1772 [02:17<07:54,  2.94it/s, running training loss:  0.93407]\u001b[A\n",
            "Training:  21%|██▏       | 380/1772 [02:17<07:54,  2.94it/s, running training loss:  1.03279]\u001b[A\n",
            "Training:  22%|██▏       | 381/1772 [02:17<07:17,  3.18it/s, running training loss:  1.03279]\u001b[A\n",
            "Training:  22%|██▏       | 381/1772 [02:17<07:17,  3.18it/s, running training loss:  0.99962]\u001b[A\n",
            "Training:  22%|██▏       | 382/1772 [02:17<07:53,  2.94it/s, running training loss:  0.99962]\u001b[A\n",
            "Training:  22%|██▏       | 382/1772 [02:18<07:53,  2.94it/s, running training loss:  1.07809]\u001b[A\n",
            "Training:  22%|██▏       | 383/1772 [02:18<07:40,  3.01it/s, running training loss:  1.07809]\u001b[A\n",
            "Training:  22%|██▏       | 383/1772 [02:18<07:40,  3.01it/s, running training loss:  0.90708]\u001b[A\n",
            "Training:  22%|██▏       | 384/1772 [02:18<07:11,  3.22it/s, running training loss:  0.90708]\u001b[A\n",
            "Training:  22%|██▏       | 384/1772 [02:18<07:11,  3.22it/s, running training loss:  0.94044]\u001b[A\n",
            "Training:  22%|██▏       | 385/1772 [02:18<07:23,  3.13it/s, running training loss:  0.94044]\u001b[A\n",
            "Training:  22%|██▏       | 385/1772 [02:19<07:23,  3.13it/s, running training loss:  0.95256]\u001b[A\n",
            "Training:  22%|██▏       | 386/1772 [02:19<07:17,  3.17it/s, running training loss:  0.95256]\u001b[A\n",
            "Training:  22%|██▏       | 386/1772 [02:19<07:17,  3.17it/s, running training loss:  1.08039]\u001b[A\n",
            "Training:  22%|██▏       | 387/1772 [02:19<06:58,  3.31it/s, running training loss:  1.08039]\u001b[A\n",
            "Training:  22%|██▏       | 387/1772 [02:19<06:58,  3.31it/s, running training loss:  1.17471]\u001b[A\n",
            "Training:  22%|██▏       | 388/1772 [02:19<06:54,  3.34it/s, running training loss:  1.17471]\u001b[A\n",
            "Training:  22%|██▏       | 388/1772 [02:19<06:54,  3.34it/s, running training loss:  1.03961]\u001b[A\n",
            "Training:  22%|██▏       | 389/1772 [02:19<06:40,  3.45it/s, running training loss:  1.03961]\u001b[A\n",
            "Training:  22%|██▏       | 389/1772 [02:20<06:40,  3.45it/s, running training loss:  0.98348]\u001b[A\n",
            "Training:  22%|██▏       | 390/1772 [02:20<06:28,  3.56it/s, running training loss:  0.98348]\u001b[A\n",
            "Training:  22%|██▏       | 390/1772 [02:20<06:28,  3.56it/s, running training loss:  0.95561]\u001b[A\n",
            "Training:  22%|██▏       | 391/1772 [02:20<06:17,  3.66it/s, running training loss:  0.95561]\u001b[A\n",
            "Training:  22%|██▏       | 391/1772 [02:20<06:17,  3.66it/s, running training loss:  1.04057]\u001b[A\n",
            "Training:  22%|██▏       | 392/1772 [02:20<07:32,  3.05it/s, running training loss:  1.04057]\u001b[A\n",
            "Training:  22%|██▏       | 392/1772 [02:21<07:32,  3.05it/s, running training loss:  0.89549]\u001b[A\n",
            "Training:  22%|██▏       | 393/1772 [02:21<07:46,  2.96it/s, running training loss:  0.89549]\u001b[A\n",
            "Training:  22%|██▏       | 393/1772 [02:21<07:46,  2.96it/s, running training loss:  0.84723]\u001b[A\n",
            "Training:  22%|██▏       | 394/1772 [02:21<07:27,  3.08it/s, running training loss:  0.84723]\u001b[A\n",
            "Training:  22%|██▏       | 394/1772 [02:21<07:27,  3.08it/s, running training loss:  0.95149]\u001b[A\n",
            "Training:  22%|██▏       | 395/1772 [02:21<07:36,  3.01it/s, running training loss:  0.95149]\u001b[A\n",
            "Training:  22%|██▏       | 395/1772 [02:22<07:36,  3.01it/s, running training loss:  0.95917]\u001b[A\n",
            "Training:  22%|██▏       | 396/1772 [02:22<08:07,  2.82it/s, running training loss:  0.95917]\u001b[A\n",
            "Training:  22%|██▏       | 396/1772 [02:22<08:07,  2.82it/s, running training loss:  1.00228]\u001b[A\n",
            "Training:  22%|██▏       | 397/1772 [02:22<08:56,  2.56it/s, running training loss:  1.00228]\u001b[A\n",
            "Training:  22%|██▏       | 397/1772 [02:22<08:56,  2.56it/s, running training loss:  0.99416]\u001b[A\n",
            "Training:  22%|██▏       | 398/1772 [02:22<08:11,  2.79it/s, running training loss:  0.99416]\u001b[A\n",
            "Training:  22%|██▏       | 398/1772 [02:23<08:11,  2.79it/s, running training loss:  1.10383]\u001b[A\n",
            "Training:  23%|██▎       | 399/1772 [02:23<07:33,  3.03it/s, running training loss:  1.10383]\u001b[A\n",
            "Training:  23%|██▎       | 399/1772 [02:23<07:33,  3.03it/s, running training loss:  1.06312]\u001b[A\n",
            "Training:  23%|██▎       | 400/1772 [02:23<06:59,  3.27it/s, running training loss:  1.06312]\u001b[A\n",
            "Training:  23%|██▎       | 400/1772 [02:23<06:59,  3.27it/s, running training loss:  0.98134]\u001b[A\n",
            "Training:  23%|██▎       | 401/1772 [02:23<06:59,  3.27it/s, running training loss:  0.98134]\u001b[A\n",
            "Training:  23%|██▎       | 401/1772 [02:24<06:59,  3.27it/s, running training loss:  0.99376]\u001b[A\n",
            "Training:  23%|██▎       | 402/1772 [02:24<07:21,  3.10it/s, running training loss:  0.99376]\u001b[A\n",
            "Training:  23%|██▎       | 402/1772 [02:24<07:21,  3.10it/s, running training loss:  0.98581]\u001b[A\n",
            "Training:  23%|██▎       | 403/1772 [02:24<07:08,  3.20it/s, running training loss:  0.98581]\u001b[A\n",
            "Training:  23%|██▎       | 403/1772 [02:24<07:08,  3.20it/s, running training loss:  0.97787]\u001b[A\n",
            "Training:  23%|██▎       | 404/1772 [02:24<07:22,  3.09it/s, running training loss:  0.97787]\u001b[A\n",
            "Training:  23%|██▎       | 404/1772 [02:25<07:22,  3.09it/s, running training loss:  0.81778]\u001b[A\n",
            "Training:  23%|██▎       | 405/1772 [02:25<07:35,  3.00it/s, running training loss:  0.81778]\u001b[A\n",
            "Training:  23%|██▎       | 405/1772 [02:25<07:35,  3.00it/s, running training loss:  1.00010]\u001b[A\n",
            "Training:  23%|██▎       | 406/1772 [02:25<07:01,  3.24it/s, running training loss:  1.00010]\u001b[A\n",
            "Training:  23%|██▎       | 406/1772 [02:25<07:01,  3.24it/s, running training loss:  0.80737]\u001b[A\n",
            "Training:  23%|██▎       | 407/1772 [02:25<07:10,  3.17it/s, running training loss:  0.80737]\u001b[A\n",
            "Training:  23%|██▎       | 407/1772 [02:26<07:10,  3.17it/s, running training loss:  0.95463]\u001b[A\n",
            "Training:  23%|██▎       | 408/1772 [02:26<06:53,  3.30it/s, running training loss:  0.95463]\u001b[A\n",
            "Training:  23%|██▎       | 408/1772 [02:26<06:53,  3.30it/s, running training loss:  0.95290]\u001b[A\n",
            "Training:  23%|██▎       | 409/1772 [02:26<06:38,  3.42it/s, running training loss:  0.95290]\u001b[A\n",
            "Training:  23%|██▎       | 409/1772 [02:26<06:38,  3.42it/s, running training loss:  0.97298]\u001b[A\n",
            "Training:  23%|██▎       | 410/1772 [02:26<06:57,  3.26it/s, running training loss:  0.97298]\u001b[A\n",
            "Training:  23%|██▎       | 410/1772 [02:27<06:57,  3.26it/s, running training loss:  1.01447]\u001b[A\n",
            "Training:  23%|██▎       | 411/1772 [02:27<08:19,  2.73it/s, running training loss:  1.01447]\u001b[A\n",
            "Training:  23%|██▎       | 411/1772 [02:27<08:19,  2.73it/s, running training loss:  1.02066]\u001b[A\n",
            "Training:  23%|██▎       | 412/1772 [02:27<09:28,  2.39it/s, running training loss:  1.02066]\u001b[A\n",
            "Training:  23%|██▎       | 412/1772 [02:27<09:28,  2.39it/s, running training loss:  1.00139]\u001b[A\n",
            "Training:  23%|██▎       | 413/1772 [02:27<08:34,  2.64it/s, running training loss:  1.00139]\u001b[A\n",
            "Training:  23%|██▎       | 413/1772 [02:28<08:34,  2.64it/s, running training loss:  0.98230]\u001b[A\n",
            "Training:  23%|██▎       | 414/1772 [02:28<07:47,  2.91it/s, running training loss:  0.98230]\u001b[A\n",
            "Training:  23%|██▎       | 414/1772 [02:28<07:47,  2.91it/s, running training loss:  1.04772]\u001b[A\n",
            "Training:  23%|██▎       | 415/1772 [02:28<07:24,  3.05it/s, running training loss:  1.04772]\u001b[A\n",
            "Training:  23%|██▎       | 415/1772 [02:28<07:24,  3.05it/s, running training loss:  1.04448]\u001b[A\n",
            "Training:  23%|██▎       | 416/1772 [02:28<08:16,  2.73it/s, running training loss:  1.04448]\u001b[A\n",
            "Training:  23%|██▎       | 416/1772 [02:29<08:16,  2.73it/s, running training loss:  1.16004]\u001b[A\n",
            "Training:  24%|██▎       | 417/1772 [02:29<07:37,  2.96it/s, running training loss:  1.16004]\u001b[A\n",
            "Training:  24%|██▎       | 417/1772 [02:29<07:37,  2.96it/s, running training loss:  0.99018]\u001b[A\n",
            "Training:  24%|██▎       | 418/1772 [02:29<08:33,  2.63it/s, running training loss:  0.99018]\u001b[A\n",
            "Training:  24%|██▎       | 418/1772 [02:30<08:33,  2.63it/s, running training loss:  0.91116]\u001b[A\n",
            "Training:  24%|██▎       | 419/1772 [02:30<08:01,  2.81it/s, running training loss:  0.91116]\u001b[A\n",
            "Training:  24%|██▎       | 419/1772 [02:30<08:01,  2.81it/s, running training loss:  0.85207]\u001b[A\n",
            "Training:  24%|██▎       | 420/1772 [02:30<07:20,  3.07it/s, running training loss:  0.85207]\u001b[A\n",
            "Training:  24%|██▎       | 420/1772 [02:30<07:20,  3.07it/s, running training loss:  0.98193]\u001b[A\n",
            "Training:  24%|██▍       | 421/1772 [02:30<06:55,  3.25it/s, running training loss:  0.98193]\u001b[A\n",
            "Training:  24%|██▍       | 421/1772 [02:30<06:55,  3.25it/s, running training loss:  0.99302]\u001b[A\n",
            "Training:  24%|██▍       | 422/1772 [02:30<06:38,  3.39it/s, running training loss:  0.99302]\u001b[A\n",
            "Training:  24%|██▍       | 422/1772 [02:31<06:38,  3.39it/s, running training loss:  1.00441]\u001b[A\n",
            "Training:  24%|██▍       | 423/1772 [02:31<07:25,  3.02it/s, running training loss:  1.00441]\u001b[A\n",
            "Training:  24%|██▍       | 423/1772 [02:31<07:25,  3.02it/s, running training loss:  1.06622]\u001b[A\n",
            "Training:  24%|██▍       | 424/1772 [02:31<08:04,  2.78it/s, running training loss:  1.06622]\u001b[A\n",
            "Training:  24%|██▍       | 424/1772 [02:31<08:04,  2.78it/s, running training loss:  1.13571]\u001b[A\n",
            "Training:  24%|██▍       | 425/1772 [02:31<07:57,  2.82it/s, running training loss:  1.13571]\u001b[A\n",
            "Training:  24%|██▍       | 425/1772 [02:32<07:57,  2.82it/s, running training loss:  1.06506]\u001b[A\n",
            "Training:  24%|██▍       | 426/1772 [02:32<07:39,  2.93it/s, running training loss:  1.06506]\u001b[A\n",
            "Training:  24%|██▍       | 426/1772 [02:32<07:39,  2.93it/s, running training loss:  1.02561]\u001b[A\n",
            "Training:  24%|██▍       | 427/1772 [02:32<07:36,  2.95it/s, running training loss:  1.02561]\u001b[A\n",
            "Training:  24%|██▍       | 427/1772 [02:32<07:36,  2.95it/s, running training loss:  1.05491]\u001b[A\n",
            "Training:  24%|██▍       | 428/1772 [02:32<06:52,  3.26it/s, running training loss:  1.05491]\u001b[A\n",
            "Training:  24%|██▍       | 428/1772 [02:33<06:52,  3.26it/s, running training loss:  1.02214]\u001b[A\n",
            "Training:  24%|██▍       | 429/1772 [02:33<06:30,  3.44it/s, running training loss:  1.02214]\u001b[A\n",
            "Training:  24%|██▍       | 429/1772 [02:33<06:30,  3.44it/s, running training loss:  1.08554]\u001b[A\n",
            "Training:  24%|██▍       | 430/1772 [02:33<06:44,  3.32it/s, running training loss:  1.08554]\u001b[A\n",
            "Training:  24%|██▍       | 430/1772 [02:33<06:44,  3.32it/s, running training loss:  0.96728]\u001b[A\n",
            "Training:  24%|██▍       | 431/1772 [02:33<07:04,  3.16it/s, running training loss:  0.96728]\u001b[A\n",
            "Training:  24%|██▍       | 431/1772 [02:34<07:04,  3.16it/s, running training loss:  0.94156]\u001b[A\n",
            "Training:  24%|██▍       | 432/1772 [02:34<06:54,  3.23it/s, running training loss:  0.94156]\u001b[A\n",
            "Training:  24%|██▍       | 432/1772 [02:34<06:54,  3.23it/s, running training loss:  0.94959]\u001b[A\n",
            "Training:  24%|██▍       | 433/1772 [02:34<06:59,  3.19it/s, running training loss:  0.94959]\u001b[A\n",
            "Training:  24%|██▍       | 433/1772 [02:34<06:59,  3.19it/s, running training loss:  0.97653]\u001b[A\n",
            "Training:  24%|██▍       | 434/1772 [02:34<07:28,  2.99it/s, running training loss:  0.97653]\u001b[A\n",
            "Training:  24%|██▍       | 434/1772 [02:35<07:28,  2.99it/s, running training loss:  1.01193]\u001b[A\n",
            "Training:  25%|██▍       | 435/1772 [02:35<08:20,  2.67it/s, running training loss:  1.01193]\u001b[A\n",
            "Training:  25%|██▍       | 435/1772 [02:35<08:20,  2.67it/s, running training loss:  1.00932]\u001b[A\n",
            "Training:  25%|██▍       | 436/1772 [02:35<07:29,  2.97it/s, running training loss:  1.00932]\u001b[A\n",
            "Training:  25%|██▍       | 436/1772 [02:35<07:29,  2.97it/s, running training loss:  0.97127]\u001b[A\n",
            "Training:  25%|██▍       | 437/1772 [02:35<08:29,  2.62it/s, running training loss:  0.97127]\u001b[A\n",
            "Training:  25%|██▍       | 437/1772 [02:36<08:29,  2.62it/s, running training loss:  0.96816]\u001b[A\n",
            "Training:  25%|██▍       | 438/1772 [02:36<08:36,  2.58it/s, running training loss:  0.96816]\u001b[A\n",
            "Training:  25%|██▍       | 438/1772 [02:36<08:36,  2.58it/s, running training loss:  0.99344]\u001b[A\n",
            "Training:  25%|██▍       | 439/1772 [02:36<08:03,  2.76it/s, running training loss:  0.99344]\u001b[A\n",
            "Training:  25%|██▍       | 439/1772 [02:36<08:03,  2.76it/s, running training loss:  1.01279]\u001b[A\n",
            "Training:  25%|██▍       | 440/1772 [02:36<07:36,  2.92it/s, running training loss:  1.01279]\u001b[A\n",
            "Training:  25%|██▍       | 440/1772 [02:37<07:36,  2.92it/s, running training loss:  0.91537]\u001b[A\n",
            "Training:  25%|██▍       | 441/1772 [02:37<06:59,  3.17it/s, running training loss:  0.91537]\u001b[A\n",
            "Training:  25%|██▍       | 441/1772 [02:37<06:59,  3.17it/s, running training loss:  0.95531]\u001b[A\n",
            "Training:  25%|██▍       | 442/1772 [02:37<07:06,  3.12it/s, running training loss:  0.95531]\u001b[A\n",
            "Training:  25%|██▍       | 442/1772 [02:37<07:06,  3.12it/s, running training loss:  1.01528]\u001b[A\n",
            "Training:  25%|██▌       | 443/1772 [02:37<06:54,  3.20it/s, running training loss:  1.01528]\u001b[A\n",
            "Training:  25%|██▌       | 443/1772 [02:38<06:54,  3.20it/s, running training loss:  1.19415]\u001b[A\n",
            "Training:  25%|██▌       | 444/1772 [02:38<08:22,  2.64it/s, running training loss:  1.19415]\u001b[A\n",
            "Training:  25%|██▌       | 444/1772 [02:38<08:22,  2.64it/s, running training loss:  1.12139]\u001b[A\n",
            "Training:  25%|██▌       | 445/1772 [02:38<08:09,  2.71it/s, running training loss:  1.12139]\u001b[A\n",
            "Training:  25%|██▌       | 445/1772 [02:39<08:09,  2.71it/s, running training loss:  1.17827]\u001b[A\n",
            "Training:  25%|██▌       | 446/1772 [02:39<08:03,  2.74it/s, running training loss:  1.17827]\u001b[A\n",
            "Training:  25%|██▌       | 446/1772 [02:39<08:03,  2.74it/s, running training loss:  1.15749]\u001b[A\n",
            "Training:  25%|██▌       | 447/1772 [02:39<07:39,  2.88it/s, running training loss:  1.15749]\u001b[A\n",
            "Training:  25%|██▌       | 447/1772 [02:39<07:39,  2.88it/s, running training loss:  1.02846]\u001b[A\n",
            "Training:  25%|██▌       | 448/1772 [02:39<08:11,  2.69it/s, running training loss:  1.02846]\u001b[A\n",
            "Training:  25%|██▌       | 448/1772 [02:40<08:11,  2.69it/s, running training loss:  0.96297]\u001b[A\n",
            "Training:  25%|██▌       | 449/1772 [02:40<07:32,  2.93it/s, running training loss:  0.96297]\u001b[A\n",
            "Training:  25%|██▌       | 449/1772 [02:40<07:32,  2.93it/s, running training loss:  1.27884]\u001b[A\n",
            "Training:  25%|██▌       | 450/1772 [02:40<07:08,  3.09it/s, running training loss:  1.27884]\u001b[A\n",
            "Training:  25%|██▌       | 450/1772 [02:40<07:08,  3.09it/s, running training loss:  0.93560]\u001b[A\n",
            "Training:  25%|██▌       | 451/1772 [02:40<08:30,  2.59it/s, running training loss:  0.93560]\u001b[A\n",
            "Training:  25%|██▌       | 451/1772 [02:41<08:30,  2.59it/s, running training loss:  0.90270]\u001b[A\n",
            "Training:  26%|██▌       | 452/1772 [02:41<08:11,  2.68it/s, running training loss:  0.90270]\u001b[A\n",
            "Training:  26%|██▌       | 452/1772 [02:41<08:11,  2.68it/s, running training loss:  0.87222]\u001b[A\n",
            "Training:  26%|██▌       | 453/1772 [02:41<07:39,  2.87it/s, running training loss:  0.87222]\u001b[A\n",
            "Training:  26%|██▌       | 453/1772 [02:41<07:39,  2.87it/s, running training loss:  1.09185]\u001b[A\n",
            "Training:  26%|██▌       | 454/1772 [02:41<06:55,  3.17it/s, running training loss:  1.09185]\u001b[A\n",
            "Training:  26%|██▌       | 454/1772 [02:42<06:55,  3.17it/s, running training loss:  1.07733]\u001b[A\n",
            "Training:  26%|██▌       | 455/1772 [02:42<07:10,  3.06it/s, running training loss:  1.07733]\u001b[A\n",
            "Training:  26%|██▌       | 455/1772 [02:42<07:10,  3.06it/s, running training loss:  0.77330]\u001b[A\n",
            "Training:  26%|██▌       | 456/1772 [02:42<07:09,  3.06it/s, running training loss:  0.77330]\u001b[A\n",
            "Training:  26%|██▌       | 456/1772 [02:42<07:09,  3.06it/s, running training loss:  1.14634]\u001b[A\n",
            "Training:  26%|██▌       | 457/1772 [02:42<06:52,  3.19it/s, running training loss:  1.14634]\u001b[A\n",
            "Training:  26%|██▌       | 457/1772 [02:42<06:52,  3.19it/s, running training loss:  0.94407]\u001b[A\n",
            "Training:  26%|██▌       | 458/1772 [02:42<06:21,  3.45it/s, running training loss:  0.94407]\u001b[A\n",
            "Training:  26%|██▌       | 458/1772 [02:43<06:21,  3.45it/s, running training loss:  0.98564]\u001b[A\n",
            "Training:  26%|██▌       | 459/1772 [02:43<06:17,  3.48it/s, running training loss:  0.98564]\u001b[A\n",
            "Training:  26%|██▌       | 459/1772 [02:43<06:17,  3.48it/s, running training loss:  0.83260]\u001b[A\n",
            "Training:  26%|██▌       | 460/1772 [02:43<06:47,  3.22it/s, running training loss:  0.83260]\u001b[A\n",
            "Training:  26%|██▌       | 460/1772 [02:43<06:47,  3.22it/s, running training loss:  1.00552]\u001b[A\n",
            "Training:  26%|██▌       | 461/1772 [02:43<06:39,  3.28it/s, running training loss:  1.00552]\u001b[A\n",
            "Training:  26%|██▌       | 461/1772 [02:44<06:39,  3.28it/s, running training loss:  0.96861]\u001b[A\n",
            "Training:  26%|██▌       | 462/1772 [02:44<06:45,  3.23it/s, running training loss:  0.96861]\u001b[A\n",
            "Training:  26%|██▌       | 462/1772 [02:44<06:45,  3.23it/s, running training loss:  0.86929]\u001b[A\n",
            "Training:  26%|██▌       | 463/1772 [02:44<06:25,  3.40it/s, running training loss:  0.86929]\u001b[A\n",
            "Training:  26%|██▌       | 463/1772 [02:44<06:25,  3.40it/s, running training loss:  0.90634]\u001b[A\n",
            "Training:  26%|██▌       | 464/1772 [02:44<07:35,  2.87it/s, running training loss:  0.90634]\u001b[A\n",
            "Training:  26%|██▌       | 464/1772 [02:45<07:35,  2.87it/s, running training loss:  1.28156]\u001b[A\n",
            "Training:  26%|██▌       | 465/1772 [02:45<06:50,  3.18it/s, running training loss:  1.28156]\u001b[A\n",
            "Training:  26%|██▌       | 465/1772 [02:45<06:50,  3.18it/s, running training loss:  0.94393]\u001b[A\n",
            "Training:  26%|██▋       | 466/1772 [02:45<06:55,  3.15it/s, running training loss:  0.94393]\u001b[A\n",
            "Training:  26%|██▋       | 466/1772 [02:45<06:55,  3.15it/s, running training loss:  1.14481]\u001b[A\n",
            "Training:  26%|██▋       | 467/1772 [02:45<06:46,  3.21it/s, running training loss:  1.14481]\u001b[A\n",
            "Training:  26%|██▋       | 467/1772 [02:46<06:46,  3.21it/s, running training loss:  0.98784]\u001b[A\n",
            "Training:  26%|██▋       | 468/1772 [02:46<06:48,  3.19it/s, running training loss:  0.98784]\u001b[A\n",
            "Training:  26%|██▋       | 468/1772 [02:46<06:48,  3.19it/s, running training loss:  0.98139]\u001b[A\n",
            "Training:  26%|██▋       | 469/1772 [02:46<07:09,  3.03it/s, running training loss:  0.98139]\u001b[A\n",
            "Training:  26%|██▋       | 469/1772 [02:46<07:09,  3.03it/s, running training loss:  1.01213]\u001b[A\n",
            "Training:  27%|██▋       | 470/1772 [02:46<06:40,  3.25it/s, running training loss:  1.01213]\u001b[A\n",
            "Training:  27%|██▋       | 470/1772 [02:47<06:40,  3.25it/s, running training loss:  0.89811]\u001b[A\n",
            "Training:  27%|██▋       | 471/1772 [02:47<07:10,  3.02it/s, running training loss:  0.89811]\u001b[A\n",
            "Training:  27%|██▋       | 471/1772 [02:47<07:10,  3.02it/s, running training loss:  0.93033]\u001b[A\n",
            "Training:  27%|██▋       | 472/1772 [02:47<06:46,  3.20it/s, running training loss:  0.93033]\u001b[A\n",
            "Training:  27%|██▋       | 472/1772 [02:47<06:46,  3.20it/s, running training loss:  0.97782]\u001b[A\n",
            "Training:  27%|██▋       | 473/1772 [02:47<06:25,  3.37it/s, running training loss:  0.97782]\u001b[A\n",
            "Training:  27%|██▋       | 473/1772 [02:47<06:25,  3.37it/s, running training loss:  0.88439]\u001b[A\n",
            "Training:  27%|██▋       | 474/1772 [02:47<06:21,  3.40it/s, running training loss:  0.88439]\u001b[A\n",
            "Training:  27%|██▋       | 474/1772 [02:48<06:21,  3.40it/s, running training loss:  1.17870]\u001b[A\n",
            "Training:  27%|██▋       | 475/1772 [02:48<06:33,  3.30it/s, running training loss:  1.17870]\u001b[A\n",
            "Training:  27%|██▋       | 475/1772 [02:48<06:33,  3.30it/s, running training loss:  0.98228]\u001b[A\n",
            "Training:  27%|██▋       | 476/1772 [02:48<07:01,  3.07it/s, running training loss:  0.98228]\u001b[A\n",
            "Training:  27%|██▋       | 476/1772 [02:48<07:01,  3.07it/s, running training loss:  1.06799]\u001b[A\n",
            "Training:  27%|██▋       | 477/1772 [02:48<06:49,  3.16it/s, running training loss:  1.06799]\u001b[A\n",
            "Training:  27%|██▋       | 477/1772 [02:49<06:49,  3.16it/s, running training loss:  0.93776]\u001b[A\n",
            "Training:  27%|██▋       | 478/1772 [02:49<06:29,  3.32it/s, running training loss:  0.93776]\u001b[A\n",
            "Training:  27%|██▋       | 478/1772 [02:49<06:29,  3.32it/s, running training loss:  1.13438]\u001b[A\n",
            "Training:  27%|██▋       | 479/1772 [02:49<06:45,  3.19it/s, running training loss:  1.13438]\u001b[A\n",
            "Training:  27%|██▋       | 479/1772 [02:49<06:45,  3.19it/s, running training loss:  1.01815]\u001b[A\n",
            "Training:  27%|██▋       | 480/1772 [02:49<06:58,  3.09it/s, running training loss:  1.01815]\u001b[A\n",
            "Training:  27%|██▋       | 480/1772 [02:50<06:58,  3.09it/s, running training loss:  0.87082]\u001b[A\n",
            "Training:  27%|██▋       | 481/1772 [02:50<06:41,  3.21it/s, running training loss:  0.87082]\u001b[A\n",
            "Training:  27%|██▋       | 481/1772 [02:50<06:41,  3.21it/s, running training loss:  0.97551]\u001b[A\n",
            "Training:  27%|██▋       | 482/1772 [02:50<06:56,  3.10it/s, running training loss:  0.97551]\u001b[A\n",
            "Training:  27%|██▋       | 482/1772 [02:50<06:56,  3.10it/s, running training loss:  1.05776]\u001b[A\n",
            "Training:  27%|██▋       | 483/1772 [02:50<07:01,  3.06it/s, running training loss:  1.05776]\u001b[A\n",
            "Training:  27%|██▋       | 483/1772 [02:51<07:01,  3.06it/s, running training loss:  0.98539]\u001b[A\n",
            "Training:  27%|██▋       | 484/1772 [02:51<06:44,  3.18it/s, running training loss:  0.98539]\u001b[A\n",
            "Training:  27%|██▋       | 484/1772 [02:51<06:44,  3.18it/s, running training loss:  0.90679]\u001b[A\n",
            "Training:  27%|██▋       | 485/1772 [02:51<06:36,  3.25it/s, running training loss:  0.90679]\u001b[A\n",
            "Training:  27%|██▋       | 485/1772 [02:51<06:36,  3.25it/s, running training loss:  1.03863]\u001b[A\n",
            "Training:  27%|██▋       | 486/1772 [02:51<06:31,  3.28it/s, running training loss:  1.03863]\u001b[A\n",
            "Training:  27%|██▋       | 486/1772 [02:52<06:31,  3.28it/s, running training loss:  0.86496]\u001b[A\n",
            "Training:  27%|██▋       | 487/1772 [02:52<06:36,  3.24it/s, running training loss:  0.86496]\u001b[A\n",
            "Training:  27%|██▋       | 487/1772 [02:52<06:36,  3.24it/s, running training loss:  0.91935]\u001b[A\n",
            "Training:  28%|██▊       | 488/1772 [02:52<06:59,  3.06it/s, running training loss:  0.91935]\u001b[A\n",
            "Training:  28%|██▊       | 488/1772 [02:52<06:59,  3.06it/s, running training loss:  0.91645]\u001b[A\n",
            "Training:  28%|██▊       | 489/1772 [02:52<06:41,  3.19it/s, running training loss:  0.91645]\u001b[A\n",
            "Training:  28%|██▊       | 489/1772 [02:53<06:41,  3.19it/s, running training loss:  1.06161]\u001b[A\n",
            "Training:  28%|██▊       | 490/1772 [02:53<06:27,  3.31it/s, running training loss:  1.06161]\u001b[A\n",
            "Training:  28%|██▊       | 490/1772 [02:53<06:27,  3.31it/s, running training loss:  1.14770]\u001b[A\n",
            "Training:  28%|██▊       | 491/1772 [02:53<07:21,  2.90it/s, running training loss:  1.14770]\u001b[A\n",
            "Training:  28%|██▊       | 491/1772 [02:53<07:21,  2.90it/s, running training loss:  1.17669]\u001b[A\n",
            "Training:  28%|██▊       | 492/1772 [02:53<06:44,  3.16it/s, running training loss:  1.17669]\u001b[A\n",
            "Training:  28%|██▊       | 492/1772 [02:54<06:44,  3.16it/s, running training loss:  1.05068]\u001b[A\n",
            "Training:  28%|██▊       | 493/1772 [02:54<07:27,  2.86it/s, running training loss:  1.05068]\u001b[A\n",
            "Training:  28%|██▊       | 493/1772 [02:54<07:27,  2.86it/s, running training loss:  1.39057]\u001b[A\n",
            "Training:  28%|██▊       | 494/1772 [02:54<07:04,  3.01it/s, running training loss:  1.39057]\u001b[A\n",
            "Training:  28%|██▊       | 494/1772 [02:54<07:04,  3.01it/s, running training loss:  1.08062]\u001b[A\n",
            "Training:  28%|██▊       | 495/1772 [02:54<06:26,  3.31it/s, running training loss:  1.08062]\u001b[A\n",
            "Training:  28%|██▊       | 495/1772 [02:54<06:26,  3.31it/s, running training loss:  1.15394]\u001b[A\n",
            "Training:  28%|██▊       | 496/1772 [02:54<06:14,  3.41it/s, running training loss:  1.15394]\u001b[A\n",
            "Training:  28%|██▊       | 496/1772 [02:55<06:14,  3.41it/s, running training loss:  1.12262]\u001b[A\n",
            "Training:  28%|██▊       | 497/1772 [02:55<06:14,  3.40it/s, running training loss:  1.12262]\u001b[A\n",
            "Training:  28%|██▊       | 497/1772 [02:55<06:14,  3.40it/s, running training loss:  0.95211]\u001b[A\n",
            "Training:  28%|██▊       | 498/1772 [02:55<06:27,  3.29it/s, running training loss:  0.95211]\u001b[A\n",
            "Training:  28%|██▊       | 498/1772 [02:55<06:27,  3.29it/s, running training loss:  1.19217]\u001b[A\n",
            "Training:  28%|██▊       | 499/1772 [02:55<06:44,  3.15it/s, running training loss:  1.19217]\u001b[A\n",
            "Training:  28%|██▊       | 499/1772 [02:56<06:44,  3.15it/s, running training loss:  0.92848]\u001b[A\n",
            "Training:  28%|██▊       | 500/1772 [02:56<06:48,  3.11it/s, running training loss:  0.92848]\u001b[A\n",
            "Training:  28%|██▊       | 500/1772 [02:56<06:48,  3.11it/s, running training loss:  0.97461]\u001b[A\n",
            "Training:  28%|██▊       | 501/1772 [02:56<06:41,  3.17it/s, running training loss:  0.97461]\u001b[A\n",
            "Training:  28%|██▊       | 501/1772 [02:56<06:41,  3.17it/s, running training loss:  1.44110]\u001b[A\n",
            "Training:  28%|██▊       | 502/1772 [02:56<06:16,  3.38it/s, running training loss:  1.44110]\u001b[A\n",
            "Training:  28%|██▊       | 502/1772 [02:57<06:16,  3.38it/s, running training loss:  1.11036]\u001b[A\n",
            "Training:  28%|██▊       | 503/1772 [02:57<06:31,  3.24it/s, running training loss:  1.11036]\u001b[A\n",
            "Training:  28%|██▊       | 503/1772 [02:57<06:31,  3.24it/s, running training loss:  0.99546]\u001b[A\n",
            "Training:  28%|██▊       | 504/1772 [02:57<06:40,  3.16it/s, running training loss:  0.99546]\u001b[A\n",
            "Training:  28%|██▊       | 504/1772 [02:57<06:40,  3.16it/s, running training loss:  0.88813]\u001b[A\n",
            "Training:  28%|██▊       | 505/1772 [02:57<06:37,  3.19it/s, running training loss:  0.88813]\u001b[A\n",
            "Training:  28%|██▊       | 505/1772 [02:58<06:37,  3.19it/s, running training loss:  0.92533]\u001b[A\n",
            "Training:  29%|██▊       | 506/1772 [02:58<06:43,  3.13it/s, running training loss:  0.92533]\u001b[A\n",
            "Training:  29%|██▊       | 506/1772 [02:58<06:43,  3.13it/s, running training loss:  1.12843]\u001b[A\n",
            "Training:  29%|██▊       | 507/1772 [02:58<06:57,  3.03it/s, running training loss:  1.12843]\u001b[A\n",
            "Training:  29%|██▊       | 507/1772 [02:58<06:57,  3.03it/s, running training loss:  1.11617]\u001b[A\n",
            "Training:  29%|██▊       | 508/1772 [02:58<07:00,  3.01it/s, running training loss:  1.11617]\u001b[A\n",
            "Training:  29%|██▊       | 508/1772 [02:59<07:00,  3.01it/s, running training loss:  1.00712]\u001b[A\n",
            "Training:  29%|██▊       | 509/1772 [02:59<07:23,  2.85it/s, running training loss:  1.00712]\u001b[A\n",
            "Training:  29%|██▊       | 509/1772 [02:59<07:23,  2.85it/s, running training loss:  0.95569]\u001b[A\n",
            "Training:  29%|██▉       | 510/1772 [02:59<07:41,  2.73it/s, running training loss:  0.95569]\u001b[A\n",
            "Training:  29%|██▉       | 510/1772 [02:59<07:41,  2.73it/s, running training loss:  1.05010]\u001b[A\n",
            "Training:  29%|██▉       | 511/1772 [02:59<07:07,  2.95it/s, running training loss:  1.05010]\u001b[A\n",
            "Training:  29%|██▉       | 511/1772 [03:00<07:07,  2.95it/s, running training loss:  0.94862]\u001b[A\n",
            "Training:  29%|██▉       | 512/1772 [03:00<06:56,  3.03it/s, running training loss:  0.94862]\u001b[A\n",
            "Training:  29%|██▉       | 512/1772 [03:00<06:56,  3.03it/s, running training loss:  1.08589]\u001b[A\n",
            "Training:  29%|██▉       | 513/1772 [03:00<06:44,  3.11it/s, running training loss:  1.08589]\u001b[A\n",
            "Training:  29%|██▉       | 513/1772 [03:00<06:44,  3.11it/s, running training loss:  1.18725]\u001b[A\n",
            "Training:  29%|██▉       | 514/1772 [03:00<06:27,  3.25it/s, running training loss:  1.18725]\u001b[A\n",
            "Training:  29%|██▉       | 514/1772 [03:01<06:27,  3.25it/s, running training loss:  1.13336]\u001b[A\n",
            "Training:  29%|██▉       | 515/1772 [03:01<07:01,  2.98it/s, running training loss:  1.13336]\u001b[A\n",
            "Training:  29%|██▉       | 515/1772 [03:01<07:01,  2.98it/s, running training loss:  0.83304]\u001b[A\n",
            "Training:  29%|██▉       | 516/1772 [03:01<07:55,  2.64it/s, running training loss:  0.83304]\u001b[A\n",
            "Training:  29%|██▉       | 516/1772 [03:02<07:55,  2.64it/s, running training loss:  0.80410]\u001b[A\n",
            "Training:  29%|██▉       | 517/1772 [03:02<08:10,  2.56it/s, running training loss:  0.80410]\u001b[A\n",
            "Training:  29%|██▉       | 517/1772 [03:02<08:10,  2.56it/s, running training loss:  0.92778]\u001b[A\n",
            "Training:  29%|██▉       | 518/1772 [03:02<07:16,  2.87it/s, running training loss:  0.92778]\u001b[A\n",
            "Training:  29%|██▉       | 518/1772 [03:02<07:16,  2.87it/s, running training loss:  1.20673]\u001b[A\n",
            "Training:  29%|██▉       | 519/1772 [03:02<06:55,  3.01it/s, running training loss:  1.20673]\u001b[A\n",
            "Training:  29%|██▉       | 519/1772 [03:02<06:55,  3.01it/s, running training loss:  0.93174]\u001b[A\n",
            "Training:  29%|██▉       | 520/1772 [03:03<07:19,  2.85it/s, running training loss:  0.93174]\u001b[A\n",
            "Training:  29%|██▉       | 520/1772 [03:03<07:19,  2.85it/s, running training loss:  1.28047]\u001b[A\n",
            "Training:  29%|██▉       | 521/1772 [03:03<06:56,  3.00it/s, running training loss:  1.28047]\u001b[A\n",
            "Training:  29%|██▉       | 521/1772 [03:03<06:56,  3.00it/s, running training loss:  1.28067]\u001b[A\n",
            "Training:  29%|██▉       | 522/1772 [03:03<06:27,  3.22it/s, running training loss:  1.28067]\u001b[A\n",
            "Training:  29%|██▉       | 522/1772 [03:04<06:27,  3.22it/s, running training loss:  1.17530]\u001b[A\n",
            "Training:  30%|██▉       | 523/1772 [03:04<07:42,  2.70it/s, running training loss:  1.17530]\u001b[A\n",
            "Training:  30%|██▉       | 523/1772 [03:04<07:42,  2.70it/s, running training loss:  1.17229]\u001b[A\n",
            "Training:  30%|██▉       | 524/1772 [03:04<08:01,  2.59it/s, running training loss:  1.17229]\u001b[A\n",
            "Training:  30%|██▉       | 524/1772 [03:05<08:01,  2.59it/s, running training loss:  1.20206]\u001b[A\n",
            "Training:  30%|██▉       | 525/1772 [03:05<08:57,  2.32it/s, running training loss:  1.20206]\u001b[A\n",
            "Training:  30%|██▉       | 525/1772 [03:05<08:57,  2.32it/s, running training loss:  1.15751]\u001b[A\n",
            "Training:  30%|██▉       | 526/1772 [03:05<08:08,  2.55it/s, running training loss:  1.15751]\u001b[A\n",
            "Training:  30%|██▉       | 526/1772 [03:05<08:08,  2.55it/s, running training loss:  1.08320]\u001b[A\n",
            "Training:  30%|██▉       | 527/1772 [03:05<07:31,  2.76it/s, running training loss:  1.08320]\u001b[A\n",
            "Training:  30%|██▉       | 527/1772 [03:05<07:31,  2.76it/s, running training loss:  0.96259]\u001b[A\n",
            "Training:  30%|██▉       | 528/1772 [03:05<07:36,  2.72it/s, running training loss:  0.96259]\u001b[A\n",
            "Training:  30%|██▉       | 528/1772 [03:06<07:36,  2.72it/s, running training loss:  0.98489]\u001b[A\n",
            "Training:  30%|██▉       | 529/1772 [03:06<07:22,  2.81it/s, running training loss:  0.98489]\u001b[A\n",
            "Training:  30%|██▉       | 529/1772 [03:06<07:22,  2.81it/s, running training loss:  1.02501]\u001b[A\n",
            "Training:  30%|██▉       | 530/1772 [03:06<07:05,  2.92it/s, running training loss:  1.02501]\u001b[A\n",
            "Training:  30%|██▉       | 530/1772 [03:06<07:05,  2.92it/s, running training loss:  1.03674]\u001b[A\n",
            "Training:  30%|██▉       | 531/1772 [03:06<06:20,  3.26it/s, running training loss:  1.03674]\u001b[A\n",
            "Training:  30%|██▉       | 531/1772 [03:07<06:20,  3.26it/s, running training loss:  1.03576]\u001b[A\n",
            "Training:  30%|███       | 532/1772 [03:07<06:44,  3.06it/s, running training loss:  1.03576]\u001b[A\n",
            "Training:  30%|███       | 532/1772 [03:07<06:44,  3.06it/s, running training loss:  1.11762]\u001b[A\n",
            "Training:  30%|███       | 533/1772 [03:07<07:06,  2.91it/s, running training loss:  1.11762]\u001b[A\n",
            "Training:  30%|███       | 533/1772 [03:08<07:06,  2.91it/s, running training loss:  1.11048]\u001b[A\n",
            "Training:  30%|███       | 534/1772 [03:08<08:00,  2.58it/s, running training loss:  1.11048]\u001b[A\n",
            "Training:  30%|███       | 534/1772 [03:08<08:00,  2.58it/s, running training loss:  0.92039]\u001b[A\n",
            "Training:  30%|███       | 535/1772 [03:08<08:04,  2.55it/s, running training loss:  0.92039]\u001b[A\n",
            "Training:  30%|███       | 535/1772 [03:08<08:04,  2.55it/s, running training loss:  0.88990]\u001b[A\n",
            "Training:  30%|███       | 536/1772 [03:08<07:08,  2.88it/s, running training loss:  0.88990]\u001b[A\n",
            "Training:  30%|███       | 536/1772 [03:09<07:08,  2.88it/s, running training loss:  1.08732]\u001b[A\n",
            "Training:  30%|███       | 537/1772 [03:09<06:45,  3.05it/s, running training loss:  1.08732]\u001b[A\n",
            "Training:  30%|███       | 537/1772 [03:09<06:45,  3.05it/s, running training loss:  1.20942]\u001b[A\n",
            "Training:  30%|███       | 538/1772 [03:09<06:18,  3.26it/s, running training loss:  1.20942]\u001b[A\n",
            "Training:  30%|███       | 538/1772 [03:09<06:18,  3.26it/s, running training loss:  1.13421]\u001b[A\n",
            "Training:  30%|███       | 539/1772 [03:09<06:11,  3.32it/s, running training loss:  1.13421]\u001b[A\n",
            "Training:  30%|███       | 539/1772 [03:09<06:11,  3.32it/s, running training loss:  1.02175]\u001b[A\n",
            "Training:  30%|███       | 540/1772 [03:09<06:01,  3.41it/s, running training loss:  1.02175]\u001b[A\n",
            "Training:  30%|███       | 540/1772 [03:10<06:01,  3.41it/s, running training loss:  1.03453]\u001b[A\n",
            "Training:  31%|███       | 541/1772 [03:10<06:07,  3.35it/s, running training loss:  1.03453]\u001b[A\n",
            "Training:  31%|███       | 541/1772 [03:10<06:07,  3.35it/s, running training loss:  0.97073]\u001b[A\n",
            "Training:  31%|███       | 542/1772 [03:10<06:23,  3.21it/s, running training loss:  0.97073]\u001b[A\n",
            "Training:  31%|███       | 542/1772 [03:10<06:23,  3.21it/s, running training loss:  1.10365]\u001b[A\n",
            "Training:  31%|███       | 543/1772 [03:10<06:39,  3.07it/s, running training loss:  1.10365]\u001b[A\n",
            "Training:  31%|███       | 543/1772 [03:11<06:39,  3.07it/s, running training loss:  0.87585]\u001b[A\n",
            "Training:  31%|███       | 544/1772 [03:11<07:05,  2.89it/s, running training loss:  0.87585]\u001b[A\n",
            "Training:  31%|███       | 544/1772 [03:11<07:05,  2.89it/s, running training loss:  1.01160]\u001b[A\n",
            "Training:  31%|███       | 545/1772 [03:11<06:51,  2.98it/s, running training loss:  1.01160]\u001b[A\n",
            "Training:  31%|███       | 545/1772 [03:11<06:51,  2.98it/s, running training loss:  1.04701]\u001b[A\n",
            "Training:  31%|███       | 546/1772 [03:11<06:32,  3.13it/s, running training loss:  1.04701]\u001b[A\n",
            "Training:  31%|███       | 546/1772 [03:12<06:32,  3.13it/s, running training loss:  0.89263]\u001b[A\n",
            "Training:  31%|███       | 547/1772 [03:12<06:19,  3.23it/s, running training loss:  0.89263]\u001b[A\n",
            "Training:  31%|███       | 547/1772 [03:12<06:19,  3.23it/s, running training loss:  1.08682]\u001b[A\n",
            "Training:  31%|███       | 548/1772 [03:12<05:55,  3.44it/s, running training loss:  1.08682]\u001b[A\n",
            "Training:  31%|███       | 548/1772 [03:12<05:55,  3.44it/s, running training loss:  0.90492]\u001b[A\n",
            "Training:  31%|███       | 549/1772 [03:12<05:26,  3.74it/s, running training loss:  0.90492]\u001b[A\n",
            "Training:  31%|███       | 549/1772 [03:12<05:26,  3.74it/s, running training loss:  1.04149]\u001b[A\n",
            "Training:  31%|███       | 550/1772 [03:12<05:35,  3.64it/s, running training loss:  1.04149]\u001b[A\n",
            "Training:  31%|███       | 550/1772 [03:13<05:35,  3.64it/s, running training loss:  1.08490]\u001b[A\n",
            "Training:  31%|███       | 551/1772 [03:13<05:30,  3.69it/s, running training loss:  1.08490]\u001b[A\n",
            "Training:  31%|███       | 551/1772 [03:13<05:30,  3.69it/s, running training loss:  0.98168]\u001b[A\n",
            "Training:  31%|███       | 552/1772 [03:13<05:29,  3.70it/s, running training loss:  0.98168]\u001b[A\n",
            "Training:  31%|███       | 552/1772 [03:13<05:29,  3.70it/s, running training loss:  1.11602]\u001b[A\n",
            "Training:  31%|███       | 553/1772 [03:13<05:29,  3.70it/s, running training loss:  1.11602]\u001b[A\n",
            "Training:  31%|███       | 553/1772 [03:13<05:29,  3.70it/s, running training loss:  1.03355]\u001b[A\n",
            "Training:  31%|███▏      | 554/1772 [03:13<05:35,  3.63it/s, running training loss:  1.03355]\u001b[A\n",
            "Training:  31%|███▏      | 554/1772 [03:14<05:35,  3.63it/s, running training loss:  0.95407]\u001b[A\n",
            "Training:  31%|███▏      | 555/1772 [03:14<05:26,  3.73it/s, running training loss:  0.95407]\u001b[A\n",
            "Training:  31%|███▏      | 555/1772 [03:14<05:26,  3.73it/s, running training loss:  1.09421]\u001b[A\n",
            "Training:  31%|███▏      | 556/1772 [03:14<05:48,  3.49it/s, running training loss:  1.09421]\u001b[A\n",
            "Training:  31%|███▏      | 556/1772 [03:14<05:48,  3.49it/s, running training loss:  1.00140]\u001b[A\n",
            "Training:  31%|███▏      | 557/1772 [03:14<05:25,  3.73it/s, running training loss:  1.00140]\u001b[A\n",
            "Training:  31%|███▏      | 557/1772 [03:15<05:25,  3.73it/s, running training loss:  1.03413]\u001b[A\n",
            "Training:  31%|███▏      | 558/1772 [03:15<05:42,  3.55it/s, running training loss:  1.03413]\u001b[A\n",
            "Training:  31%|███▏      | 558/1772 [03:15<05:42,  3.55it/s, running training loss:  0.98525]\u001b[A\n",
            "Training:  32%|███▏      | 559/1772 [03:15<05:22,  3.77it/s, running training loss:  0.98525]\u001b[A\n",
            "Training:  32%|███▏      | 559/1772 [03:15<05:22,  3.77it/s, running training loss:  1.00408]\u001b[A\n",
            "Training:  32%|███▏      | 560/1772 [03:15<05:20,  3.78it/s, running training loss:  1.00408]\u001b[A\n",
            "Training:  32%|███▏      | 560/1772 [03:15<05:20,  3.78it/s, running training loss:  0.80680]\u001b[A\n",
            "Training:  32%|███▏      | 561/1772 [03:15<05:34,  3.62it/s, running training loss:  0.80680]\u001b[A\n",
            "Training:  32%|███▏      | 561/1772 [03:16<05:34,  3.62it/s, running training loss:  0.92901]\u001b[A\n",
            "Training:  32%|███▏      | 562/1772 [03:16<05:39,  3.56it/s, running training loss:  0.92901]\u001b[A\n",
            "Training:  32%|███▏      | 562/1772 [03:16<05:39,  3.56it/s, running training loss:  0.99956]\u001b[A\n",
            "Training:  32%|███▏      | 563/1772 [03:16<05:32,  3.64it/s, running training loss:  0.99956]\u001b[A\n",
            "Training:  32%|███▏      | 563/1772 [03:16<05:32,  3.64it/s, running training loss:  0.97365]\u001b[A\n",
            "Training:  32%|███▏      | 564/1772 [03:16<06:44,  2.99it/s, running training loss:  0.97365]\u001b[A\n",
            "Training:  32%|███▏      | 564/1772 [03:17<06:44,  2.99it/s, running training loss:  0.78094]\u001b[A\n",
            "Training:  32%|███▏      | 565/1772 [03:17<07:01,  2.86it/s, running training loss:  0.78094]\u001b[A\n",
            "Training:  32%|███▏      | 565/1772 [03:17<07:01,  2.86it/s, running training loss:  0.94759]\u001b[A\n",
            "Training:  32%|███▏      | 566/1772 [03:17<06:38,  3.03it/s, running training loss:  0.94759]\u001b[A\n",
            "Training:  32%|███▏      | 566/1772 [03:17<06:38,  3.03it/s, running training loss:  0.97670]\u001b[A\n",
            "Training:  32%|███▏      | 567/1772 [03:17<06:26,  3.12it/s, running training loss:  0.97670]\u001b[A\n",
            "Training:  32%|███▏      | 567/1772 [03:18<06:26,  3.12it/s, running training loss:  0.96503]\u001b[A\n",
            "Training:  32%|███▏      | 568/1772 [03:18<06:02,  3.32it/s, running training loss:  0.96503]\u001b[A\n",
            "Training:  32%|███▏      | 568/1772 [03:18<06:02,  3.32it/s, running training loss:  0.97225]\u001b[A\n",
            "Training:  32%|███▏      | 569/1772 [03:18<05:51,  3.43it/s, running training loss:  0.97225]\u001b[A\n",
            "Training:  32%|███▏      | 569/1772 [03:18<05:51,  3.43it/s, running training loss:  1.02092]\u001b[A\n",
            "Training:  32%|███▏      | 570/1772 [03:18<06:00,  3.34it/s, running training loss:  1.02092]\u001b[A\n",
            "Training:  32%|███▏      | 570/1772 [03:19<06:00,  3.34it/s, running training loss:  0.83342]\u001b[A\n",
            "Training:  32%|███▏      | 571/1772 [03:19<06:07,  3.26it/s, running training loss:  0.83342]\u001b[A\n",
            "Training:  32%|███▏      | 571/1772 [03:19<06:07,  3.26it/s, running training loss:  0.78447]\u001b[A\n",
            "Training:  32%|███▏      | 572/1772 [03:19<06:26,  3.10it/s, running training loss:  0.78447]\u001b[A\n",
            "Training:  32%|███▏      | 572/1772 [03:19<06:26,  3.10it/s, running training loss:  0.95433]\u001b[A\n",
            "Training:  32%|███▏      | 573/1772 [03:19<05:58,  3.34it/s, running training loss:  0.95433]\u001b[A\n",
            "Training:  32%|███▏      | 573/1772 [03:20<05:58,  3.34it/s, running training loss:  0.78578]\u001b[A\n",
            "Training:  32%|███▏      | 574/1772 [03:20<06:21,  3.14it/s, running training loss:  0.78578]\u001b[A\n",
            "Training:  32%|███▏      | 574/1772 [03:20<06:21,  3.14it/s, running training loss:  0.81845]\u001b[A\n",
            "Training:  32%|███▏      | 575/1772 [03:20<06:14,  3.20it/s, running training loss:  0.81845]\u001b[A\n",
            "Training:  32%|███▏      | 575/1772 [03:20<06:14,  3.20it/s, running training loss:  0.90998]\u001b[A\n",
            "Training:  33%|███▎      | 576/1772 [03:20<06:04,  3.29it/s, running training loss:  0.90998]\u001b[A\n",
            "Training:  33%|███▎      | 576/1772 [03:20<06:04,  3.29it/s, running training loss:  0.78682]\u001b[A\n",
            "Training:  33%|███▎      | 577/1772 [03:20<06:02,  3.30it/s, running training loss:  0.78682]\u001b[A\n",
            "Training:  33%|███▎      | 577/1772 [03:21<06:02,  3.30it/s, running training loss:  1.06135]\u001b[A\n",
            "Training:  33%|███▎      | 578/1772 [03:21<05:39,  3.51it/s, running training loss:  1.06135]\u001b[A\n",
            "Training:  33%|███▎      | 578/1772 [03:21<05:39,  3.51it/s, running training loss:  0.91418]\u001b[A\n",
            "Training:  33%|███▎      | 579/1772 [03:21<05:45,  3.46it/s, running training loss:  0.91418]\u001b[A\n",
            "Training:  33%|███▎      | 579/1772 [03:21<05:45,  3.46it/s, running training loss:  0.99099]\u001b[A\n",
            "Training:  33%|███▎      | 580/1772 [03:21<05:42,  3.48it/s, running training loss:  0.99099]\u001b[A\n",
            "Training:  33%|███▎      | 580/1772 [03:21<05:42,  3.48it/s, running training loss:  1.03098]\u001b[A\n",
            "Training:  33%|███▎      | 581/1772 [03:21<05:35,  3.55it/s, running training loss:  1.03098]\u001b[A\n",
            "Training:  33%|███▎      | 581/1772 [03:22<05:35,  3.55it/s, running training loss:  1.07469]\u001b[A\n",
            "Training:  33%|███▎      | 582/1772 [03:22<05:33,  3.57it/s, running training loss:  1.07469]\u001b[A\n",
            "Training:  33%|███▎      | 582/1772 [03:22<05:33,  3.57it/s, running training loss:  0.98364]\u001b[A\n",
            "Training:  33%|███▎      | 583/1772 [03:22<05:55,  3.35it/s, running training loss:  0.98364]\u001b[A\n",
            "Training:  33%|███▎      | 583/1772 [03:22<05:55,  3.35it/s, running training loss:  1.12300]\u001b[A\n",
            "Training:  33%|███▎      | 584/1772 [03:22<06:17,  3.15it/s, running training loss:  1.12300]\u001b[A\n",
            "Training:  33%|███▎      | 584/1772 [03:23<06:17,  3.15it/s, running training loss:  1.08951]\u001b[A\n",
            "Training:  33%|███▎      | 585/1772 [03:23<06:34,  3.01it/s, running training loss:  1.08951]\u001b[A\n",
            "Training:  33%|███▎      | 585/1772 [03:23<06:34,  3.01it/s, running training loss:  1.11292]\u001b[A\n",
            "Training:  33%|███▎      | 586/1772 [03:23<06:41,  2.95it/s, running training loss:  1.11292]\u001b[A\n",
            "Training:  33%|███▎      | 586/1772 [03:24<06:41,  2.95it/s, running training loss:  1.03948]\u001b[A\n",
            "Training:  33%|███▎      | 587/1772 [03:24<06:42,  2.94it/s, running training loss:  1.03948]\u001b[A\n",
            "Training:  33%|███▎      | 587/1772 [03:24<06:42,  2.94it/s, running training loss:  0.91609]\u001b[A\n",
            "Training:  33%|███▎      | 588/1772 [03:24<06:22,  3.09it/s, running training loss:  0.91609]\u001b[A\n",
            "Training:  33%|███▎      | 588/1772 [03:24<06:22,  3.09it/s, running training loss:  0.94812]\u001b[A\n",
            "Training:  33%|███▎      | 589/1772 [03:24<06:23,  3.08it/s, running training loss:  0.94812]\u001b[A\n",
            "Training:  33%|███▎      | 589/1772 [03:24<06:23,  3.08it/s, running training loss:  1.12137]\u001b[A\n",
            "Training:  33%|███▎      | 590/1772 [03:24<06:17,  3.13it/s, running training loss:  1.12137]\u001b[A\n",
            "Training:  33%|███▎      | 590/1772 [03:25<06:17,  3.13it/s, running training loss:  0.98786]\u001b[A\n",
            "Training:  33%|███▎      | 591/1772 [03:25<05:47,  3.40it/s, running training loss:  0.98786]\u001b[A\n",
            "Training:  33%|███▎      | 591/1772 [03:25<05:47,  3.40it/s, running training loss:  0.93133]\u001b[A\n",
            "Training:  33%|███▎      | 592/1772 [03:25<06:41,  2.94it/s, running training loss:  0.93133]\u001b[A\n",
            "Training:  33%|███▎      | 592/1772 [03:25<06:41,  2.94it/s, running training loss:  1.14512]\u001b[A\n",
            "Training:  33%|███▎      | 593/1772 [03:25<06:22,  3.08it/s, running training loss:  1.14512]\u001b[A\n",
            "Training:  33%|███▎      | 593/1772 [03:26<06:22,  3.08it/s, running training loss:  0.93013]\u001b[A\n",
            "Training:  34%|███▎      | 594/1772 [03:26<06:17,  3.12it/s, running training loss:  0.93013]\u001b[A\n",
            "Training:  34%|███▎      | 594/1772 [03:26<06:17,  3.12it/s, running training loss:  1.03684]\u001b[A\n",
            "Training:  34%|███▎      | 595/1772 [03:26<06:25,  3.05it/s, running training loss:  1.03684]\u001b[A\n",
            "Training:  34%|███▎      | 595/1772 [03:27<06:25,  3.05it/s, running training loss:  0.93625]\u001b[A\n",
            "Training:  34%|███▎      | 596/1772 [03:27<07:13,  2.71it/s, running training loss:  0.93625]\u001b[A\n",
            "Training:  34%|███▎      | 596/1772 [03:27<07:13,  2.71it/s, running training loss:  0.96255]\u001b[A\n",
            "Training:  34%|███▎      | 597/1772 [03:27<06:58,  2.81it/s, running training loss:  0.96255]\u001b[A\n",
            "Training:  34%|███▎      | 597/1772 [03:27<06:58,  2.81it/s, running training loss:  1.17275]\u001b[A\n",
            "Training:  34%|███▎      | 598/1772 [03:27<06:36,  2.96it/s, running training loss:  1.17275]\u001b[A\n",
            "Training:  34%|███▎      | 598/1772 [03:28<06:36,  2.96it/s, running training loss:  1.07807]\u001b[A\n",
            "Training:  34%|███▍      | 599/1772 [03:28<07:07,  2.74it/s, running training loss:  1.07807]\u001b[A\n",
            "Training:  34%|███▍      | 599/1772 [03:28<07:07,  2.74it/s, running training loss:  1.20020]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            ">>> EMA starting .....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Evaluation:   0%|          | 0/270 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   0%|          | 1/270 [00:00<01:34,  2.85it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   1%|          | 3/270 [00:00<00:36,  7.34it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   2%|▏         | 5/270 [00:00<00:24, 10.68it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   3%|▎         | 7/270 [00:00<00:19, 13.26it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   3%|▎         | 9/270 [00:00<00:17, 14.74it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   4%|▍         | 12/270 [00:00<00:14, 17.64it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   5%|▌         | 14/270 [00:01<00:14, 17.67it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   6%|▌         | 16/270 [00:01<00:14, 17.89it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   7%|▋         | 18/270 [00:01<00:14, 17.89it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   7%|▋         | 20/270 [00:01<00:14, 17.62it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   9%|▊         | 23/270 [00:01<00:12, 19.77it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   9%|▉         | 25/270 [00:01<00:12, 19.82it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  10%|█         | 28/270 [00:01<00:12, 20.10it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  11%|█▏        | 31/270 [00:01<00:12, 19.01it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  12%|█▏        | 33/270 [00:02<00:12, 19.13it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  13%|█▎        | 35/270 [00:02<00:12, 19.34it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  14%|█▍        | 38/270 [00:02<00:11, 20.87it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  15%|█▌        | 41/270 [00:02<00:11, 20.28it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  16%|█▋        | 44/270 [00:02<00:11, 19.32it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  17%|█▋        | 46/270 [00:02<00:11, 19.28it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  18%|█▊        | 49/270 [00:02<00:11, 19.89it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  19%|█▉        | 51/270 [00:02<00:11, 19.18it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  20%|█▉        | 53/270 [00:03<00:11, 19.00it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  21%|██        | 56/270 [00:03<00:11, 19.41it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  21%|██▏       | 58/270 [00:03<00:10, 19.33it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  22%|██▏       | 60/270 [00:03<00:11, 18.91it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  23%|██▎       | 62/270 [00:03<00:11, 18.69it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  24%|██▎       | 64/270 [00:03<00:11, 18.68it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  25%|██▍       | 67/270 [00:03<00:10, 19.74it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  26%|██▌       | 70/270 [00:03<00:09, 20.89it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  27%|██▋       | 73/270 [00:04<00:09, 20.36it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  28%|██▊       | 76/270 [00:04<00:09, 21.12it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  29%|██▉       | 79/270 [00:04<00:09, 20.73it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  30%|███       | 82/270 [00:04<00:09, 19.67it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  31%|███▏      | 85/270 [00:04<00:09, 19.94it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  33%|███▎      | 88/270 [00:04<00:09, 19.90it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  33%|███▎      | 90/270 [00:04<00:09, 19.26it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  34%|███▍      | 92/270 [00:05<00:09, 19.07it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  35%|███▌      | 95/270 [00:05<00:08, 19.90it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  36%|███▋      | 98/270 [00:05<00:08, 20.44it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  37%|███▋      | 101/270 [00:05<00:08, 20.49it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  39%|███▊      | 104/270 [00:05<00:08, 20.55it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  40%|███▉      | 107/270 [00:05<00:07, 20.91it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  41%|████      | 110/270 [00:05<00:07, 20.73it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  42%|████▏     | 113/270 [00:06<00:07, 20.83it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  43%|████▎     | 116/270 [00:06<00:07, 20.67it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  44%|████▍     | 119/270 [00:06<00:07, 20.22it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  45%|████▌     | 122/270 [00:06<00:07, 20.82it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  46%|████▋     | 125/270 [00:06<00:07, 20.71it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  47%|████▋     | 128/270 [00:06<00:07, 19.34it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  49%|████▊     | 131/270 [00:06<00:07, 19.76it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  49%|████▉     | 133/270 [00:07<00:07, 19.53it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  50%|█████     | 135/270 [00:07<00:06, 19.56it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  51%|█████     | 138/270 [00:07<00:06, 20.48it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  52%|█████▏    | 141/270 [00:07<00:06, 20.04it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  53%|█████▎    | 144/270 [00:07<00:06, 20.03it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  54%|█████▍    | 147/270 [00:07<00:06, 19.38it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  56%|█████▌    | 150/270 [00:07<00:05, 20.21it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  57%|█████▋    | 153/270 [00:08<00:06, 19.01it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  57%|█████▋    | 155/270 [00:08<00:06, 19.03it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  58%|█████▊    | 157/270 [00:08<00:05, 19.10it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  59%|█████▉    | 160/270 [00:08<00:05, 19.43it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  60%|██████    | 162/270 [00:08<00:05, 19.53it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  61%|██████    | 164/270 [00:08<00:05, 19.20it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  61%|██████▏   | 166/270 [00:08<00:05, 19.20it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  62%|██████▏   | 168/270 [00:08<00:05, 19.39it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  63%|██████▎   | 170/270 [00:08<00:05, 18.91it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  64%|██████▎   | 172/270 [00:09<00:05, 18.88it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  64%|██████▍   | 174/270 [00:09<00:05, 18.14it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  65%|██████▌   | 176/270 [00:09<00:05, 17.91it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  66%|██████▌   | 178/270 [00:09<00:05, 18.18it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  67%|██████▋   | 180/270 [00:09<00:05, 17.54it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  67%|██████▋   | 182/270 [00:09<00:04, 17.82it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  68%|██████▊   | 184/270 [00:09<00:04, 18.06it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  69%|██████▉   | 186/270 [00:09<00:04, 18.46it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  70%|██████▉   | 188/270 [00:09<00:04, 18.05it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  71%|███████   | 191/270 [00:10<00:03, 19.90it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  71%|███████▏  | 193/270 [00:10<00:03, 19.49it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  72%|███████▏  | 195/270 [00:10<00:04, 18.46it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  73%|███████▎  | 198/270 [00:10<00:03, 18.70it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  74%|███████▍  | 200/270 [00:10<00:03, 18.08it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  75%|███████▍  | 202/270 [00:10<00:03, 17.49it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  76%|███████▌  | 205/270 [00:10<00:03, 19.88it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  77%|███████▋  | 207/270 [00:10<00:03, 19.53it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  77%|███████▋  | 209/270 [00:11<00:03, 18.50it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  78%|███████▊  | 211/270 [00:11<00:03, 18.86it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  79%|███████▉  | 213/270 [00:11<00:03, 18.80it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  80%|████████  | 216/270 [00:11<00:02, 19.20it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  81%|████████  | 219/270 [00:11<00:02, 20.05it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  82%|████████▏ | 222/270 [00:11<00:02, 21.18it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  83%|████████▎ | 225/270 [00:11<00:02, 21.91it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  84%|████████▍ | 228/270 [00:11<00:02, 20.67it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  86%|████████▌ | 231/270 [00:12<00:01, 19.62it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  87%|████████▋ | 234/270 [00:12<00:01, 20.54it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  88%|████████▊ | 237/270 [00:12<00:01, 21.35it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  89%|████████▉ | 240/270 [00:12<00:01, 20.34it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  90%|█████████ | 243/270 [00:12<00:01, 20.64it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  91%|█████████ | 246/270 [00:12<00:01, 19.27it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  92%|█████████▏| 248/270 [00:12<00:01, 18.43it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  93%|█████████▎| 250/270 [00:13<00:01, 18.15it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  93%|█████████▎| 252/270 [00:13<00:01, 17.79it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  94%|█████████▍| 254/270 [00:13<00:00, 17.54it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  95%|█████████▍| 256/270 [00:13<00:00, 16.93it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  96%|█████████▌| 259/270 [00:13<00:00, 18.80it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  97%|█████████▋| 262/270 [00:13<00:00, 19.16it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  98%|█████████▊| 264/270 [00:13<00:00, 18.46it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  99%|█████████▊| 266/270 [00:13<00:00, 18.17it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  99%|█████████▉| 268/270 [00:14<00:00, 18.25it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation: 100%|██████████| 270/270 [00:14<00:00, 18.76it/s]\n",
            "\n",
            "Training:  34%|███▍      | 600/1772 [03:44<1:39:46,  5.11s/it, running training loss:  1.20020]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            ">>> training loss: 1.011115, valid loss: 0.635280,valid f1: 0.027596, valid acc:0.689759\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  34%|███▍      | 600/1772 [03:44<1:39:46,  5.11s/it, running training loss:  0.89997]\u001b[A\n",
            "Training:  34%|███▍      | 601/1772 [03:44<1:11:40,  3.67s/it, running training loss:  0.89997]\u001b[A\n",
            "Training:  34%|███▍      | 601/1772 [03:44<1:11:40,  3.67s/it, running training loss:  1.09242]\u001b[A\n",
            "Training:  34%|███▍      | 602/1772 [03:44<52:18,  2.68s/it, running training loss:  1.09242]  \u001b[A\n",
            "Training:  34%|███▍      | 602/1772 [03:45<52:18,  2.68s/it, running training loss:  1.00831]\u001b[A\n",
            "Training:  34%|███▍      | 603/1772 [03:45<38:40,  1.98s/it, running training loss:  1.00831]\u001b[A\n",
            "Training:  34%|███▍      | 603/1772 [03:45<38:40,  1.98s/it, running training loss:  0.86741]\u001b[A\n",
            "Training:  34%|███▍      | 604/1772 [03:45<28:47,  1.48s/it, running training loss:  0.86741]\u001b[A\n",
            "Training:  34%|███▍      | 604/1772 [03:46<28:47,  1.48s/it, running training loss:  0.88855]\u001b[A\n",
            "Training:  34%|███▍      | 605/1772 [03:46<23:18,  1.20s/it, running training loss:  0.88855]\u001b[A\n",
            "Training:  34%|███▍      | 605/1772 [03:46<23:18,  1.20s/it, running training loss:  1.08233]\u001b[A\n",
            "Training:  34%|███▍      | 606/1772 [03:46<18:30,  1.05it/s, running training loss:  1.08233]\u001b[A\n",
            "Training:  34%|███▍      | 606/1772 [03:46<18:30,  1.05it/s, running training loss:  0.94015]\u001b[A\n",
            "Training:  34%|███▍      | 607/1772 [03:46<14:56,  1.30it/s, running training loss:  0.94015]\u001b[A\n",
            "Training:  34%|███▍      | 607/1772 [03:47<14:56,  1.30it/s, running training loss:  0.76075]\u001b[A\n",
            "Training:  34%|███▍      | 608/1772 [03:47<12:41,  1.53it/s, running training loss:  0.76075]\u001b[A\n",
            "Training:  34%|███▍      | 608/1772 [03:47<12:41,  1.53it/s, running training loss:  1.00320]\u001b[A\n",
            "Training:  34%|███▍      | 609/1772 [03:47<10:52,  1.78it/s, running training loss:  1.00320]\u001b[A\n",
            "Training:  34%|███▍      | 609/1772 [03:48<10:52,  1.78it/s, running training loss:  0.95868]\u001b[A\n",
            "Training:  34%|███▍      | 610/1772 [03:48<10:18,  1.88it/s, running training loss:  0.95868]\u001b[A\n",
            "Training:  34%|███▍      | 610/1772 [03:48<10:18,  1.88it/s, running training loss:  1.04115]\u001b[A\n",
            "Training:  34%|███▍      | 611/1772 [03:48<08:56,  2.16it/s, running training loss:  1.04115]\u001b[A\n",
            "Training:  34%|███▍      | 611/1772 [03:48<08:56,  2.16it/s, running training loss:  0.92953]\u001b[A\n",
            "Training:  35%|███▍      | 612/1772 [03:48<08:21,  2.31it/s, running training loss:  0.92953]\u001b[A\n",
            "Training:  35%|███▍      | 612/1772 [03:49<08:21,  2.31it/s, running training loss:  0.98742]\u001b[A\n",
            "Training:  35%|███▍      | 613/1772 [03:49<07:37,  2.53it/s, running training loss:  0.98742]\u001b[A\n",
            "Training:  35%|███▍      | 613/1772 [03:49<07:37,  2.53it/s, running training loss:  1.14568]\u001b[A\n",
            "Training:  35%|███▍      | 614/1772 [03:49<07:10,  2.69it/s, running training loss:  1.14568]\u001b[A\n",
            "Training:  35%|███▍      | 614/1772 [03:49<07:10,  2.69it/s, running training loss:  1.34766]\u001b[A\n",
            "Training:  35%|███▍      | 615/1772 [03:49<07:11,  2.68it/s, running training loss:  1.34766]\u001b[A\n",
            "Training:  35%|███▍      | 615/1772 [03:50<07:11,  2.68it/s, running training loss:  1.10483]\u001b[A\n",
            "Training:  35%|███▍      | 616/1772 [03:50<07:41,  2.51it/s, running training loss:  1.10483]\u001b[A\n",
            "Training:  35%|███▍      | 616/1772 [03:50<07:41,  2.51it/s, running training loss:  1.00466]\u001b[A\n",
            "Training:  35%|███▍      | 617/1772 [03:50<07:00,  2.75it/s, running training loss:  1.00466]\u001b[A\n",
            "Training:  35%|███▍      | 617/1772 [03:50<07:00,  2.75it/s, running training loss:  1.03734]\u001b[A\n",
            "Training:  35%|███▍      | 618/1772 [03:50<07:08,  2.69it/s, running training loss:  1.03734]\u001b[A\n",
            "Training:  35%|███▍      | 618/1772 [03:51<07:08,  2.69it/s, running training loss:  1.00972]\u001b[A\n",
            "Training:  35%|███▍      | 619/1772 [03:51<06:44,  2.85it/s, running training loss:  1.00972]\u001b[A\n",
            "Training:  35%|███▍      | 619/1772 [03:51<06:44,  2.85it/s, running training loss:  1.03044]\u001b[A\n",
            "Training:  35%|███▍      | 620/1772 [03:51<06:34,  2.92it/s, running training loss:  1.03044]\u001b[A\n",
            "Training:  35%|███▍      | 620/1772 [03:51<06:34,  2.92it/s, running training loss:  1.10334]\u001b[A\n",
            "Training:  35%|███▌      | 621/1772 [03:51<06:08,  3.13it/s, running training loss:  1.10334]\u001b[A\n",
            "Training:  35%|███▌      | 621/1772 [03:52<06:08,  3.13it/s, running training loss:  1.09640]\u001b[A\n",
            "Training:  35%|███▌      | 622/1772 [03:52<06:18,  3.04it/s, running training loss:  1.09640]\u001b[A\n",
            "Training:  35%|███▌      | 622/1772 [03:52<06:18,  3.04it/s, running training loss:  1.04762]\u001b[A\n",
            "Training:  35%|███▌      | 623/1772 [03:52<06:29,  2.95it/s, running training loss:  1.04762]\u001b[A\n",
            "Training:  35%|███▌      | 623/1772 [03:52<06:29,  2.95it/s, running training loss:  1.06780]\u001b[A\n",
            "Training:  35%|███▌      | 624/1772 [03:52<06:20,  3.02it/s, running training loss:  1.06780]\u001b[A\n",
            "Training:  35%|███▌      | 624/1772 [03:53<06:20,  3.02it/s, running training loss:  0.98498]\u001b[A\n",
            "Training:  35%|███▌      | 625/1772 [03:53<06:05,  3.14it/s, running training loss:  0.98498]\u001b[A\n",
            "Training:  35%|███▌      | 625/1772 [03:53<06:05,  3.14it/s, running training loss:  0.99560]\u001b[A\n",
            "Training:  35%|███▌      | 626/1772 [03:53<05:44,  3.32it/s, running training loss:  0.99560]\u001b[A\n",
            "Training:  35%|███▌      | 626/1772 [03:53<05:44,  3.32it/s, running training loss:  1.01608]\u001b[A\n",
            "Training:  35%|███▌      | 627/1772 [03:53<05:58,  3.19it/s, running training loss:  1.01608]\u001b[A\n",
            "Training:  35%|███▌      | 627/1772 [03:53<05:58,  3.19it/s, running training loss:  0.94313]\u001b[A\n",
            "Training:  35%|███▌      | 628/1772 [03:53<05:48,  3.28it/s, running training loss:  0.94313]\u001b[A\n",
            "Training:  35%|███▌      | 628/1772 [03:54<05:48,  3.28it/s, running training loss:  1.00240]\u001b[A\n",
            "Training:  35%|███▌      | 629/1772 [03:54<05:38,  3.38it/s, running training loss:  1.00240]\u001b[A\n",
            "Training:  35%|███▌      | 629/1772 [03:54<05:38,  3.38it/s, running training loss:  0.83991]\u001b[A\n",
            "Training:  36%|███▌      | 630/1772 [03:54<05:40,  3.35it/s, running training loss:  0.83991]\u001b[A\n",
            "Training:  36%|███▌      | 630/1772 [03:54<05:40,  3.35it/s, running training loss:  0.98535]\u001b[A\n",
            "Training:  36%|███▌      | 631/1772 [03:54<05:41,  3.34it/s, running training loss:  0.98535]\u001b[A\n",
            "Training:  36%|███▌      | 631/1772 [03:55<05:41,  3.34it/s, running training loss:  0.77697]\u001b[A\n",
            "Training:  36%|███▌      | 632/1772 [03:55<05:35,  3.40it/s, running training loss:  0.77697]\u001b[A\n",
            "Training:  36%|███▌      | 632/1772 [03:55<05:35,  3.40it/s, running training loss:  0.88691]\u001b[A\n",
            "Training:  36%|███▌      | 633/1772 [03:55<05:37,  3.37it/s, running training loss:  0.88691]\u001b[A\n",
            "Training:  36%|███▌      | 633/1772 [03:55<05:37,  3.37it/s, running training loss:  0.96737]\u001b[A\n",
            "Training:  36%|███▌      | 634/1772 [03:55<06:38,  2.86it/s, running training loss:  0.96737]\u001b[A\n",
            "Training:  36%|███▌      | 634/1772 [03:56<06:38,  2.86it/s, running training loss:  0.95854]\u001b[A\n",
            "Training:  36%|███▌      | 635/1772 [03:56<06:56,  2.73it/s, running training loss:  0.95854]\u001b[A\n",
            "Training:  36%|███▌      | 635/1772 [03:56<06:56,  2.73it/s, running training loss:  0.87716]\u001b[A\n",
            "Training:  36%|███▌      | 636/1772 [03:56<07:21,  2.57it/s, running training loss:  0.87716]\u001b[A\n",
            "Training:  36%|███▌      | 636/1772 [03:57<07:21,  2.57it/s, running training loss:  1.08666]\u001b[A\n",
            "Training:  36%|███▌      | 637/1772 [03:57<06:55,  2.73it/s, running training loss:  1.08666]\u001b[A\n",
            "Training:  36%|███▌      | 637/1772 [03:57<06:55,  2.73it/s, running training loss:  1.06847]\u001b[A\n",
            "Training:  36%|███▌      | 638/1772 [03:57<06:40,  2.83it/s, running training loss:  1.06847]\u001b[A\n",
            "Training:  36%|███▌      | 638/1772 [03:57<06:40,  2.83it/s, running training loss:  1.05309]\u001b[A\n",
            "Training:  36%|███▌      | 639/1772 [03:57<06:09,  3.07it/s, running training loss:  1.05309]\u001b[A\n",
            "Training:  36%|███▌      | 639/1772 [03:57<06:09,  3.07it/s, running training loss:  1.09707]\u001b[A\n",
            "Training:  36%|███▌      | 640/1772 [03:57<06:04,  3.11it/s, running training loss:  1.09707]\u001b[A\n",
            "Training:  36%|███▌      | 640/1772 [03:58<06:04,  3.11it/s, running training loss:  1.02261]\u001b[A\n",
            "Training:  36%|███▌      | 641/1772 [03:58<05:49,  3.24it/s, running training loss:  1.02261]\u001b[A\n",
            "Training:  36%|███▌      | 641/1772 [03:58<05:49,  3.24it/s, running training loss:  0.94738]\u001b[A\n",
            "Training:  36%|███▌      | 642/1772 [03:58<05:28,  3.44it/s, running training loss:  0.94738]\u001b[A\n",
            "Training:  36%|███▌      | 642/1772 [03:58<05:28,  3.44it/s, running training loss:  0.85690]\u001b[A\n",
            "Training:  36%|███▋      | 643/1772 [03:58<05:18,  3.55it/s, running training loss:  0.85690]\u001b[A\n",
            "Training:  36%|███▋      | 643/1772 [03:59<05:18,  3.55it/s, running training loss:  1.01830]\u001b[A\n",
            "Training:  36%|███▋      | 644/1772 [03:59<05:14,  3.58it/s, running training loss:  1.01830]\u001b[A\n",
            "Training:  36%|███▋      | 644/1772 [03:59<05:14,  3.58it/s, running training loss:  0.91400]\u001b[A\n",
            "Training:  36%|███▋      | 645/1772 [03:59<06:47,  2.77it/s, running training loss:  0.91400]\u001b[A\n",
            "Training:  36%|███▋      | 645/1772 [03:59<06:47,  2.77it/s, running training loss:  1.07426]\u001b[A\n",
            "Training:  36%|███▋      | 646/1772 [03:59<06:37,  2.83it/s, running training loss:  1.07426]\u001b[A\n",
            "Training:  36%|███▋      | 646/1772 [04:00<06:37,  2.83it/s, running training loss:  0.97319]\u001b[A\n",
            "Training:  37%|███▋      | 647/1772 [04:00<07:23,  2.53it/s, running training loss:  0.97319]\u001b[A\n",
            "Training:  37%|███▋      | 647/1772 [04:00<07:23,  2.53it/s, running training loss:  0.85968]\u001b[A\n",
            "Training:  37%|███▋      | 648/1772 [04:00<07:48,  2.40it/s, running training loss:  0.85968]\u001b[A\n",
            "Training:  37%|███▋      | 648/1772 [04:01<07:48,  2.40it/s, running training loss:  0.92941]\u001b[A\n",
            "Training:  37%|███▋      | 649/1772 [04:01<07:00,  2.67it/s, running training loss:  0.92941]\u001b[A\n",
            "Training:  37%|███▋      | 649/1772 [04:01<07:00,  2.67it/s, running training loss:  0.93847]\u001b[A\n",
            "Training:  37%|███▋      | 650/1772 [04:01<06:26,  2.90it/s, running training loss:  0.93847]\u001b[A\n",
            "Training:  37%|███▋      | 650/1772 [04:01<06:26,  2.90it/s, running training loss:  0.77296]\u001b[A\n",
            "Training:  37%|███▋      | 651/1772 [04:01<07:23,  2.53it/s, running training loss:  0.77296]\u001b[A\n",
            "Training:  37%|███▋      | 651/1772 [04:02<07:23,  2.53it/s, running training loss:  1.02899]\u001b[A\n",
            "Training:  37%|███▋      | 652/1772 [04:02<07:09,  2.61it/s, running training loss:  1.02899]\u001b[A\n",
            "Training:  37%|███▋      | 652/1772 [04:02<07:09,  2.61it/s, running training loss:  1.04055]\u001b[A\n",
            "Training:  37%|███▋      | 653/1772 [04:02<06:47,  2.75it/s, running training loss:  1.04055]\u001b[A\n",
            "Training:  37%|███▋      | 653/1772 [04:03<06:47,  2.75it/s, running training loss:  0.93016]\u001b[A\n",
            "Training:  37%|███▋      | 654/1772 [04:03<07:00,  2.66it/s, running training loss:  0.93016]\u001b[A\n",
            "Training:  37%|███▋      | 654/1772 [04:03<07:00,  2.66it/s, running training loss:  1.06352]\u001b[A\n",
            "Training:  37%|███▋      | 655/1772 [04:03<07:11,  2.59it/s, running training loss:  1.06352]\u001b[A\n",
            "Training:  37%|███▋      | 655/1772 [04:03<07:11,  2.59it/s, running training loss:  1.06779]\u001b[A\n",
            "Training:  37%|███▋      | 656/1772 [04:03<06:36,  2.82it/s, running training loss:  1.06779]\u001b[A\n",
            "Training:  37%|███▋      | 656/1772 [04:03<06:36,  2.82it/s, running training loss:  0.99219]\u001b[A\n",
            "Training:  37%|███▋      | 657/1772 [04:03<06:08,  3.02it/s, running training loss:  0.99219]\u001b[A\n",
            "Training:  37%|███▋      | 657/1772 [04:04<06:08,  3.02it/s, running training loss:  1.09828]\u001b[A\n",
            "Training:  37%|███▋      | 658/1772 [04:04<06:02,  3.07it/s, running training loss:  1.09828]\u001b[A\n",
            "Training:  37%|███▋      | 658/1772 [04:04<06:02,  3.07it/s, running training loss:  1.01181]\u001b[A\n",
            "Training:  37%|███▋      | 659/1772 [04:04<05:59,  3.10it/s, running training loss:  1.01181]\u001b[A\n",
            "Training:  37%|███▋      | 659/1772 [04:04<05:59,  3.10it/s, running training loss:  1.03671]\u001b[A\n",
            "Training:  37%|███▋      | 660/1772 [04:04<05:36,  3.30it/s, running training loss:  1.03671]\u001b[A\n",
            "Training:  37%|███▋      | 660/1772 [04:05<05:36,  3.30it/s, running training loss:  1.11974]\u001b[A\n",
            "Training:  37%|███▋      | 661/1772 [04:05<05:36,  3.30it/s, running training loss:  1.11974]\u001b[A\n",
            "Training:  37%|███▋      | 661/1772 [04:05<05:36,  3.30it/s, running training loss:  0.97818]\u001b[A\n",
            "Training:  37%|███▋      | 662/1772 [04:05<05:37,  3.29it/s, running training loss:  0.97818]\u001b[A\n",
            "Training:  37%|███▋      | 662/1772 [04:06<05:37,  3.29it/s, running training loss:  0.78963]\u001b[A\n",
            "Training:  37%|███▋      | 663/1772 [04:06<06:59,  2.65it/s, running training loss:  0.78963]\u001b[A\n",
            "Training:  37%|███▋      | 663/1772 [04:06<06:59,  2.65it/s, running training loss:  0.91125]\u001b[A\n",
            "Training:  37%|███▋      | 664/1772 [04:06<06:26,  2.86it/s, running training loss:  0.91125]\u001b[A\n",
            "Training:  37%|███▋      | 664/1772 [04:06<06:26,  2.86it/s, running training loss:  0.92608]\u001b[A\n",
            "Training:  38%|███▊      | 665/1772 [04:06<06:27,  2.86it/s, running training loss:  0.92608]\u001b[A\n",
            "Training:  38%|███▊      | 665/1772 [04:06<06:27,  2.86it/s, running training loss:  1.02850]\u001b[A\n",
            "Training:  38%|███▊      | 666/1772 [04:06<05:59,  3.08it/s, running training loss:  1.02850]\u001b[A\n",
            "Training:  38%|███▊      | 666/1772 [04:07<05:59,  3.08it/s, running training loss:  1.02288]\u001b[A\n",
            "Training:  38%|███▊      | 667/1772 [04:07<06:01,  3.06it/s, running training loss:  1.02288]\u001b[A\n",
            "Training:  38%|███▊      | 667/1772 [04:07<06:01,  3.06it/s, running training loss:  0.91550]\u001b[A\n",
            "Training:  38%|███▊      | 668/1772 [04:07<05:48,  3.17it/s, running training loss:  0.91550]\u001b[A\n",
            "Training:  38%|███▊      | 668/1772 [04:07<05:48,  3.17it/s, running training loss:  0.94911]\u001b[A\n",
            "Training:  38%|███▊      | 669/1772 [04:07<05:50,  3.15it/s, running training loss:  0.94911]\u001b[A\n",
            "Training:  38%|███▊      | 669/1772 [04:08<05:50,  3.15it/s, running training loss:  0.90976]\u001b[A\n",
            "Training:  38%|███▊      | 670/1772 [04:08<05:19,  3.45it/s, running training loss:  0.90976]\u001b[A\n",
            "Training:  38%|███▊      | 670/1772 [04:08<05:19,  3.45it/s, running training loss:  0.95395]\u001b[A\n",
            "Training:  38%|███▊      | 671/1772 [04:08<05:52,  3.12it/s, running training loss:  0.95395]\u001b[A\n",
            "Training:  38%|███▊      | 671/1772 [04:08<05:52,  3.12it/s, running training loss:  0.96567]\u001b[A\n",
            "Training:  38%|███▊      | 672/1772 [04:08<05:42,  3.21it/s, running training loss:  0.96567]\u001b[A\n",
            "Training:  38%|███▊      | 672/1772 [04:09<05:42,  3.21it/s, running training loss:  0.99371]\u001b[A\n",
            "Training:  38%|███▊      | 673/1772 [04:09<05:24,  3.38it/s, running training loss:  0.99371]\u001b[A\n",
            "Training:  38%|███▊      | 673/1772 [04:09<05:24,  3.38it/s, running training loss:  1.02717]\u001b[A\n",
            "Training:  38%|███▊      | 674/1772 [04:09<05:22,  3.40it/s, running training loss:  1.02717]\u001b[A\n",
            "Training:  38%|███▊      | 674/1772 [04:09<05:22,  3.40it/s, running training loss:  0.93523]\u001b[A\n",
            "Training:  38%|███▊      | 675/1772 [04:09<06:11,  2.95it/s, running training loss:  0.93523]\u001b[A\n",
            "Training:  38%|███▊      | 675/1772 [04:10<06:11,  2.95it/s, running training loss:  1.01021]\u001b[A\n",
            "Training:  38%|███▊      | 676/1772 [04:10<06:05,  3.00it/s, running training loss:  1.01021]\u001b[A\n",
            "Training:  38%|███▊      | 676/1772 [04:10<06:05,  3.00it/s, running training loss:  1.22330]\u001b[A\n",
            "Training:  38%|███▊      | 677/1772 [04:10<06:02,  3.02it/s, running training loss:  1.22330]\u001b[A\n",
            "Training:  38%|███▊      | 677/1772 [04:10<06:02,  3.02it/s, running training loss:  1.13866]\u001b[A\n",
            "Training:  38%|███▊      | 678/1772 [04:10<07:23,  2.47it/s, running training loss:  1.13866]\u001b[A\n",
            "Training:  38%|███▊      | 678/1772 [04:11<07:23,  2.47it/s, running training loss:  0.99772]\u001b[A\n",
            "Training:  38%|███▊      | 679/1772 [04:11<07:26,  2.45it/s, running training loss:  0.99772]\u001b[A\n",
            "Training:  38%|███▊      | 679/1772 [04:11<07:26,  2.45it/s, running training loss:  1.04241]\u001b[A\n",
            "Training:  38%|███▊      | 680/1772 [04:11<07:04,  2.57it/s, running training loss:  1.04241]\u001b[A\n",
            "Training:  38%|███▊      | 680/1772 [04:12<07:04,  2.57it/s, running training loss:  0.98610]\u001b[A\n",
            "Training:  38%|███▊      | 681/1772 [04:12<06:38,  2.74it/s, running training loss:  0.98610]\u001b[A\n",
            "Training:  38%|███▊      | 681/1772 [04:12<06:38,  2.74it/s, running training loss:  1.07752]\u001b[A\n",
            "Training:  38%|███▊      | 682/1772 [04:12<06:22,  2.85it/s, running training loss:  1.07752]\u001b[A\n",
            "Training:  38%|███▊      | 682/1772 [04:12<06:22,  2.85it/s, running training loss:  0.98474]\u001b[A\n",
            "Training:  39%|███▊      | 683/1772 [04:12<05:52,  3.09it/s, running training loss:  0.98474]\u001b[A\n",
            "Training:  39%|███▊      | 683/1772 [04:12<05:52,  3.09it/s, running training loss:  0.97192]\u001b[A\n",
            "Training:  39%|███▊      | 684/1772 [04:12<05:49,  3.12it/s, running training loss:  0.97192]\u001b[A\n",
            "Training:  39%|███▊      | 684/1772 [04:13<05:49,  3.12it/s, running training loss:  0.92238]\u001b[A\n",
            "Training:  39%|███▊      | 685/1772 [04:13<05:56,  3.05it/s, running training loss:  0.92238]\u001b[A\n",
            "Training:  39%|███▊      | 685/1772 [04:13<05:56,  3.05it/s, running training loss:  0.95085]\u001b[A\n",
            "Training:  39%|███▊      | 686/1772 [04:13<05:49,  3.11it/s, running training loss:  0.95085]\u001b[A\n",
            "Training:  39%|███▊      | 686/1772 [04:13<05:49,  3.11it/s, running training loss:  1.01608]\u001b[A\n",
            "Training:  39%|███▉      | 687/1772 [04:13<05:27,  3.31it/s, running training loss:  1.01608]\u001b[A\n",
            "Training:  39%|███▉      | 687/1772 [04:14<05:27,  3.31it/s, running training loss:  0.97494]\u001b[A\n",
            "Training:  39%|███▉      | 688/1772 [04:14<05:50,  3.09it/s, running training loss:  0.97494]\u001b[A\n",
            "Training:  39%|███▉      | 688/1772 [04:14<05:50,  3.09it/s, running training loss:  0.97275]\u001b[A\n",
            "Training:  39%|███▉      | 689/1772 [04:14<05:46,  3.12it/s, running training loss:  0.97275]\u001b[A\n",
            "Training:  39%|███▉      | 689/1772 [04:14<05:46,  3.12it/s, running training loss:  0.85806]\u001b[A\n",
            "Training:  39%|███▉      | 690/1772 [04:14<05:47,  3.11it/s, running training loss:  0.85806]\u001b[A\n",
            "Training:  39%|███▉      | 690/1772 [04:15<05:47,  3.11it/s, running training loss:  0.93189]\u001b[A\n",
            "Training:  39%|███▉      | 691/1772 [04:15<05:48,  3.10it/s, running training loss:  0.93189]\u001b[A\n",
            "Training:  39%|███▉      | 691/1772 [04:15<05:48,  3.10it/s, running training loss:  1.01916]\u001b[A\n",
            "Training:  39%|███▉      | 692/1772 [04:15<06:13,  2.89it/s, running training loss:  1.01916]\u001b[A\n",
            "Training:  39%|███▉      | 692/1772 [04:15<06:13,  2.89it/s, running training loss:  0.91940]\u001b[A\n",
            "Training:  39%|███▉      | 693/1772 [04:15<06:09,  2.92it/s, running training loss:  0.91940]\u001b[A\n",
            "Training:  39%|███▉      | 693/1772 [04:16<06:09,  2.92it/s, running training loss:  0.91088]\u001b[A\n",
            "Training:  39%|███▉      | 694/1772 [04:16<05:53,  3.05it/s, running training loss:  0.91088]\u001b[A\n",
            "Training:  39%|███▉      | 694/1772 [04:16<05:53,  3.05it/s, running training loss:  0.97538]\u001b[A\n",
            "Training:  39%|███▉      | 695/1772 [04:16<05:48,  3.09it/s, running training loss:  0.97538]\u001b[A\n",
            "Training:  39%|███▉      | 695/1772 [04:16<05:48,  3.09it/s, running training loss:  0.91665]\u001b[A\n",
            "Training:  39%|███▉      | 696/1772 [04:16<05:41,  3.15it/s, running training loss:  0.91665]\u001b[A\n",
            "Training:  39%|███▉      | 696/1772 [04:17<05:41,  3.15it/s, running training loss:  0.84474]\u001b[A\n",
            "Training:  39%|███▉      | 697/1772 [04:17<05:27,  3.28it/s, running training loss:  0.84474]\u001b[A\n",
            "Training:  39%|███▉      | 697/1772 [04:17<05:27,  3.28it/s, running training loss:  1.05957]\u001b[A\n",
            "Training:  39%|███▉      | 698/1772 [04:17<06:19,  2.83it/s, running training loss:  1.05957]\u001b[A\n",
            "Training:  39%|███▉      | 698/1772 [04:18<06:19,  2.83it/s, running training loss:  0.95189]\u001b[A\n",
            "Training:  39%|███▉      | 699/1772 [04:18<06:52,  2.60it/s, running training loss:  0.95189]\u001b[A\n",
            "Training:  39%|███▉      | 699/1772 [04:18<06:52,  2.60it/s, running training loss:  1.01908]\u001b[A\n",
            "Training:  40%|███▉      | 700/1772 [04:18<06:38,  2.69it/s, running training loss:  1.01908]\u001b[A\n",
            "Training:  40%|███▉      | 700/1772 [04:18<06:38,  2.69it/s, running training loss:  1.01065]\u001b[A\n",
            "Training:  40%|███▉      | 701/1772 [04:18<06:14,  2.86it/s, running training loss:  1.01065]\u001b[A\n",
            "Training:  40%|███▉      | 701/1772 [04:18<06:14,  2.86it/s, running training loss:  1.09789]\u001b[A\n",
            "Training:  40%|███▉      | 702/1772 [04:18<05:56,  3.00it/s, running training loss:  1.09789]\u001b[A\n",
            "Training:  40%|███▉      | 702/1772 [04:19<05:56,  3.00it/s, running training loss:  1.07652]\u001b[A\n",
            "Training:  40%|███▉      | 703/1772 [04:19<06:21,  2.80it/s, running training loss:  1.07652]\u001b[A\n",
            "Training:  40%|███▉      | 703/1772 [04:19<06:21,  2.80it/s, running training loss:  0.95182]\u001b[A\n",
            "Training:  40%|███▉      | 704/1772 [04:19<06:19,  2.82it/s, running training loss:  0.95182]\u001b[A\n",
            "Training:  40%|███▉      | 704/1772 [04:20<06:19,  2.82it/s, running training loss:  1.14502]\u001b[A\n",
            "Training:  40%|███▉      | 705/1772 [04:20<05:51,  3.03it/s, running training loss:  1.14502]\u001b[A\n",
            "Training:  40%|███▉      | 705/1772 [04:20<05:51,  3.03it/s, running training loss:  1.02292]\u001b[A\n",
            "Training:  40%|███▉      | 706/1772 [04:20<05:38,  3.15it/s, running training loss:  1.02292]\u001b[A\n",
            "Training:  40%|███▉      | 706/1772 [04:20<05:38,  3.15it/s, running training loss:  0.81209]\u001b[A\n",
            "Training:  40%|███▉      | 707/1772 [04:20<06:04,  2.92it/s, running training loss:  0.81209]\u001b[A\n",
            "Training:  40%|███▉      | 707/1772 [04:20<06:04,  2.92it/s, running training loss:  0.89588]\u001b[A\n",
            "Training:  40%|███▉      | 708/1772 [04:20<05:45,  3.08it/s, running training loss:  0.89588]\u001b[A\n",
            "Training:  40%|███▉      | 708/1772 [04:21<05:45,  3.08it/s, running training loss:  0.81315]\u001b[A\n",
            "Training:  40%|████      | 709/1772 [04:21<06:05,  2.91it/s, running training loss:  0.81315]\u001b[A\n",
            "Training:  40%|████      | 709/1772 [04:21<06:05,  2.91it/s, running training loss:  0.93124]\u001b[A\n",
            "Training:  40%|████      | 710/1772 [04:21<06:13,  2.85it/s, running training loss:  0.93124]\u001b[A\n",
            "Training:  40%|████      | 710/1772 [04:22<06:13,  2.85it/s, running training loss:  0.83514]\u001b[A\n",
            "Training:  40%|████      | 711/1772 [04:22<06:15,  2.83it/s, running training loss:  0.83514]\u001b[A\n",
            "Training:  40%|████      | 711/1772 [04:22<06:15,  2.83it/s, running training loss:  1.02024]\u001b[A\n",
            "Training:  40%|████      | 712/1772 [04:22<06:13,  2.84it/s, running training loss:  1.02024]\u001b[A\n",
            "Training:  40%|████      | 712/1772 [04:22<06:13,  2.84it/s, running training loss:  1.25694]\u001b[A\n",
            "Training:  40%|████      | 713/1772 [04:22<05:54,  2.98it/s, running training loss:  1.25694]\u001b[A\n",
            "Training:  40%|████      | 713/1772 [04:23<05:54,  2.98it/s, running training loss:  1.15131]\u001b[A\n",
            "Training:  40%|████      | 714/1772 [04:23<05:32,  3.18it/s, running training loss:  1.15131]\u001b[A\n",
            "Training:  40%|████      | 714/1772 [04:23<05:32,  3.18it/s, running training loss:  1.05435]\u001b[A\n",
            "Training:  40%|████      | 715/1772 [04:23<05:59,  2.94it/s, running training loss:  1.05435]\u001b[A\n",
            "Training:  40%|████      | 715/1772 [04:23<05:59,  2.94it/s, running training loss:  1.18083]\u001b[A\n",
            "Training:  40%|████      | 716/1772 [04:23<05:51,  3.01it/s, running training loss:  1.18083]\u001b[A\n",
            "Training:  40%|████      | 716/1772 [04:24<05:51,  3.01it/s, running training loss:  1.67339]\u001b[A\n",
            "Training:  40%|████      | 717/1772 [04:24<06:47,  2.59it/s, running training loss:  1.67339]\u001b[A\n",
            "Training:  40%|████      | 717/1772 [04:24<06:47,  2.59it/s, running training loss:  1.04812]\u001b[A\n",
            "Training:  41%|████      | 718/1772 [04:24<06:42,  2.62it/s, running training loss:  1.04812]\u001b[A\n",
            "Training:  41%|████      | 718/1772 [04:24<06:42,  2.62it/s, running training loss:  1.00933]\u001b[A\n",
            "Training:  41%|████      | 719/1772 [04:24<06:34,  2.67it/s, running training loss:  1.00933]\u001b[A\n",
            "Training:  41%|████      | 719/1772 [04:25<06:34,  2.67it/s, running training loss:  1.10710]\u001b[A\n",
            "Training:  41%|████      | 720/1772 [04:25<06:30,  2.69it/s, running training loss:  1.10710]\u001b[A\n",
            "Training:  41%|████      | 720/1772 [04:25<06:30,  2.69it/s, running training loss:  1.26691]\u001b[A\n",
            "Training:  41%|████      | 721/1772 [04:25<06:36,  2.65it/s, running training loss:  1.26691]\u001b[A\n",
            "Training:  41%|████      | 721/1772 [04:26<06:36,  2.65it/s, running training loss:  0.90466]\u001b[A\n",
            "Training:  41%|████      | 722/1772 [04:26<06:14,  2.81it/s, running training loss:  0.90466]\u001b[A\n",
            "Training:  41%|████      | 722/1772 [04:26<06:14,  2.81it/s, running training loss:  0.91100]\u001b[A\n",
            "Training:  41%|████      | 723/1772 [04:26<05:54,  2.96it/s, running training loss:  0.91100]\u001b[A\n",
            "Training:  41%|████      | 723/1772 [04:26<05:54,  2.96it/s, running training loss:  0.87109]\u001b[A\n",
            "Training:  41%|████      | 724/1772 [04:26<05:43,  3.05it/s, running training loss:  0.87109]\u001b[A\n",
            "Training:  41%|████      | 724/1772 [04:27<05:43,  3.05it/s, running training loss:  0.93810]\u001b[A\n",
            "Training:  41%|████      | 725/1772 [04:27<06:39,  2.62it/s, running training loss:  0.93810]\u001b[A\n",
            "Training:  41%|████      | 725/1772 [04:27<06:39,  2.62it/s, running training loss:  0.80920]\u001b[A\n",
            "Training:  41%|████      | 726/1772 [04:27<06:03,  2.88it/s, running training loss:  0.80920]\u001b[A\n",
            "Training:  41%|████      | 726/1772 [04:27<06:03,  2.88it/s, running training loss:  0.99352]\u001b[A\n",
            "Training:  41%|████      | 727/1772 [04:27<05:46,  3.02it/s, running training loss:  0.99352]\u001b[A\n",
            "Training:  41%|████      | 727/1772 [04:28<05:46,  3.02it/s, running training loss:  0.90106]\u001b[A\n",
            "Training:  41%|████      | 728/1772 [04:28<05:54,  2.94it/s, running training loss:  0.90106]\u001b[A\n",
            "Training:  41%|████      | 728/1772 [04:28<05:54,  2.94it/s, running training loss:  1.49252]\u001b[A\n",
            "Training:  41%|████      | 729/1772 [04:28<05:52,  2.96it/s, running training loss:  1.49252]\u001b[A\n",
            "Training:  41%|████      | 729/1772 [04:28<05:52,  2.96it/s, running training loss:  2.18655]\u001b[A\n",
            "Training:  41%|████      | 730/1772 [04:28<06:05,  2.85it/s, running training loss:  2.18655]\u001b[A\n",
            "Training:  41%|████      | 730/1772 [04:29<06:05,  2.85it/s, running training loss:  1.18447]\u001b[A\n",
            "Training:  41%|████▏     | 731/1772 [04:29<06:14,  2.78it/s, running training loss:  1.18447]\u001b[A\n",
            "Training:  41%|████▏     | 731/1772 [04:29<06:14,  2.78it/s, running training loss:  1.26664]\u001b[A\n",
            "Training:  41%|████▏     | 732/1772 [04:29<05:59,  2.89it/s, running training loss:  1.26664]\u001b[A\n",
            "Training:  41%|████▏     | 732/1772 [04:29<05:59,  2.89it/s, running training loss:  1.34100]\u001b[A\n",
            "Training:  41%|████▏     | 733/1772 [04:29<05:36,  3.09it/s, running training loss:  1.34100]\u001b[A\n",
            "Training:  41%|████▏     | 733/1772 [04:30<05:36,  3.09it/s, running training loss:  0.92789]\u001b[A\n",
            "Training:  41%|████▏     | 734/1772 [04:30<05:47,  2.99it/s, running training loss:  0.92789]\u001b[A\n",
            "Training:  41%|████▏     | 734/1772 [04:30<05:47,  2.99it/s, running training loss:  1.47171]\u001b[A\n",
            "Training:  41%|████▏     | 735/1772 [04:30<05:44,  3.01it/s, running training loss:  1.47171]\u001b[A\n",
            "Training:  41%|████▏     | 735/1772 [04:30<05:44,  3.01it/s, running training loss:  1.14742]\u001b[A\n",
            "Training:  42%|████▏     | 736/1772 [04:30<05:41,  3.03it/s, running training loss:  1.14742]\u001b[A\n",
            "Training:  42%|████▏     | 736/1772 [04:31<05:41,  3.03it/s, running training loss:  0.95389]\u001b[A\n",
            "Training:  42%|████▏     | 737/1772 [04:31<05:35,  3.08it/s, running training loss:  0.95389]\u001b[A\n",
            "Training:  42%|████▏     | 737/1772 [04:31<05:35,  3.08it/s, running training loss:  1.24749]\u001b[A\n",
            "Training:  42%|████▏     | 738/1772 [04:31<05:39,  3.04it/s, running training loss:  1.24749]\u001b[A\n",
            "Training:  42%|████▏     | 738/1772 [04:31<05:39,  3.04it/s, running training loss:  0.98669]\u001b[A\n",
            "Training:  42%|████▏     | 739/1772 [04:31<05:37,  3.06it/s, running training loss:  0.98669]\u001b[A\n",
            "Training:  42%|████▏     | 739/1772 [04:31<05:37,  3.06it/s, running training loss:  1.36253]\u001b[A\n",
            "Training:  42%|████▏     | 740/1772 [04:32<05:23,  3.19it/s, running training loss:  1.36253]\u001b[A\n",
            "Training:  42%|████▏     | 740/1772 [04:32<05:23,  3.19it/s, running training loss:  0.98401]\u001b[A\n",
            "Training:  42%|████▏     | 741/1772 [04:32<05:05,  3.37it/s, running training loss:  0.98401]\u001b[A\n",
            "Training:  42%|████▏     | 741/1772 [04:32<05:05,  3.37it/s, running training loss:  0.90684]\u001b[A\n",
            "Training:  42%|████▏     | 742/1772 [04:32<05:07,  3.35it/s, running training loss:  0.90684]\u001b[A\n",
            "Training:  42%|████▏     | 742/1772 [04:32<05:07,  3.35it/s, running training loss:  0.96049]\u001b[A\n",
            "Training:  42%|████▏     | 743/1772 [04:32<05:15,  3.27it/s, running training loss:  0.96049]\u001b[A\n",
            "Training:  42%|████▏     | 743/1772 [04:33<05:15,  3.27it/s, running training loss:  0.92610]\u001b[A\n",
            "Training:  42%|████▏     | 744/1772 [04:33<05:49,  2.94it/s, running training loss:  0.92610]\u001b[A\n",
            "Training:  42%|████▏     | 744/1772 [04:33<05:49,  2.94it/s, running training loss:  1.11783]\u001b[A\n",
            "Training:  42%|████▏     | 745/1772 [04:33<05:27,  3.14it/s, running training loss:  1.11783]\u001b[A\n",
            "Training:  42%|████▏     | 745/1772 [04:33<05:27,  3.14it/s, running training loss:  1.03932]\u001b[A\n",
            "Training:  42%|████▏     | 746/1772 [04:33<05:22,  3.18it/s, running training loss:  1.03932]\u001b[A\n",
            "Training:  42%|████▏     | 746/1772 [04:34<05:22,  3.18it/s, running training loss:  0.96451]\u001b[A\n",
            "Training:  42%|████▏     | 747/1772 [04:34<05:32,  3.09it/s, running training loss:  0.96451]\u001b[A\n",
            "Training:  42%|████▏     | 747/1772 [04:34<05:32,  3.09it/s, running training loss:  1.20114]\u001b[A\n",
            "Training:  42%|████▏     | 748/1772 [04:34<06:32,  2.61it/s, running training loss:  1.20114]\u001b[A\n",
            "Training:  42%|████▏     | 748/1772 [04:35<06:32,  2.61it/s, running training loss:  0.89079]\u001b[A\n",
            "Training:  42%|████▏     | 749/1772 [04:35<06:07,  2.78it/s, running training loss:  0.89079]\u001b[A\n",
            "Training:  42%|████▏     | 749/1772 [04:35<06:07,  2.78it/s, running training loss:  1.19819]\u001b[A\n",
            "Training:  42%|████▏     | 750/1772 [04:35<05:43,  2.98it/s, running training loss:  1.19819]\u001b[A\n",
            "Training:  42%|████▏     | 750/1772 [04:35<05:43,  2.98it/s, running training loss:  1.27209]\u001b[A\n",
            "Training:  42%|████▏     | 751/1772 [04:35<05:46,  2.95it/s, running training loss:  1.27209]\u001b[A\n",
            "Training:  42%|████▏     | 751/1772 [04:35<05:46,  2.95it/s, running training loss:  1.01748]\u001b[A\n",
            "Training:  42%|████▏     | 752/1772 [04:35<05:24,  3.14it/s, running training loss:  1.01748]\u001b[A\n",
            "Training:  42%|████▏     | 752/1772 [04:36<05:24,  3.14it/s, running training loss:  0.85189]\u001b[A\n",
            "Training:  42%|████▏     | 753/1772 [04:36<05:47,  2.93it/s, running training loss:  0.85189]\u001b[A\n",
            "Training:  42%|████▏     | 753/1772 [04:36<05:47,  2.93it/s, running training loss:  0.94502]\u001b[A\n",
            "Training:  43%|████▎     | 754/1772 [04:36<06:01,  2.82it/s, running training loss:  0.94502]\u001b[A\n",
            "Training:  43%|████▎     | 754/1772 [04:37<06:01,  2.82it/s, running training loss:  0.91752]\u001b[A\n",
            "Training:  43%|████▎     | 755/1772 [04:37<06:16,  2.70it/s, running training loss:  0.91752]\u001b[A\n",
            "Training:  43%|████▎     | 755/1772 [04:37<06:16,  2.70it/s, running training loss:  0.98040]\u001b[A\n",
            "Training:  43%|████▎     | 756/1772 [04:37<06:04,  2.79it/s, running training loss:  0.98040]\u001b[A\n",
            "Training:  43%|████▎     | 756/1772 [04:37<06:04,  2.79it/s, running training loss:  1.07918]\u001b[A\n",
            "Training:  43%|████▎     | 757/1772 [04:37<05:46,  2.93it/s, running training loss:  1.07918]\u001b[A\n",
            "Training:  43%|████▎     | 757/1772 [04:38<05:46,  2.93it/s, running training loss:  0.88632]\u001b[A\n",
            "Training:  43%|████▎     | 758/1772 [04:38<05:50,  2.89it/s, running training loss:  0.88632]\u001b[A\n",
            "Training:  43%|████▎     | 758/1772 [04:38<05:50,  2.89it/s, running training loss:  0.96599]\u001b[A\n",
            "Training:  43%|████▎     | 759/1772 [04:38<05:20,  3.16it/s, running training loss:  0.96599]\u001b[A\n",
            "Training:  43%|████▎     | 759/1772 [04:38<05:20,  3.16it/s, running training loss:  0.99547]\u001b[A\n",
            "Training:  43%|████▎     | 760/1772 [04:38<05:13,  3.23it/s, running training loss:  0.99547]\u001b[A\n",
            "Training:  43%|████▎     | 760/1772 [04:38<05:13,  3.23it/s, running training loss:  1.03620]\u001b[A\n",
            "Training:  43%|████▎     | 761/1772 [04:38<05:12,  3.24it/s, running training loss:  1.03620]\u001b[A\n",
            "Training:  43%|████▎     | 761/1772 [04:39<05:12,  3.24it/s, running training loss:  0.96936]\u001b[A\n",
            "Training:  43%|████▎     | 762/1772 [04:39<05:52,  2.87it/s, running training loss:  0.96936]\u001b[A\n",
            "Training:  43%|████▎     | 762/1772 [04:39<05:52,  2.87it/s, running training loss:  1.00746]\u001b[A\n",
            "Training:  43%|████▎     | 763/1772 [04:39<05:36,  2.99it/s, running training loss:  1.00746]\u001b[A\n",
            "Training:  43%|████▎     | 763/1772 [04:40<05:36,  2.99it/s, running training loss:  0.88954]\u001b[A\n",
            "Training:  43%|████▎     | 764/1772 [04:40<05:26,  3.09it/s, running training loss:  0.88954]\u001b[A\n",
            "Training:  43%|████▎     | 764/1772 [04:40<05:26,  3.09it/s, running training loss:  0.93010]\u001b[A\n",
            "Training:  43%|████▎     | 765/1772 [04:40<05:29,  3.05it/s, running training loss:  0.93010]\u001b[A\n",
            "Training:  43%|████▎     | 765/1772 [04:40<05:29,  3.05it/s, running training loss:  1.15665]\u001b[A\n",
            "Training:  43%|████▎     | 766/1772 [04:40<05:43,  2.93it/s, running training loss:  1.15665]\u001b[A\n",
            "Training:  43%|████▎     | 766/1772 [04:41<05:43,  2.93it/s, running training loss:  1.08241]\u001b[A\n",
            "Training:  43%|████▎     | 767/1772 [04:41<06:30,  2.57it/s, running training loss:  1.08241]\u001b[A\n",
            "Training:  43%|████▎     | 767/1772 [04:41<06:30,  2.57it/s, running training loss:  1.26334]\u001b[A\n",
            "Training:  43%|████▎     | 768/1772 [04:41<05:57,  2.81it/s, running training loss:  1.26334]\u001b[A\n",
            "Training:  43%|████▎     | 768/1772 [04:41<05:57,  2.81it/s, running training loss:  1.20410]\u001b[A\n",
            "Training:  43%|████▎     | 769/1772 [04:41<06:04,  2.75it/s, running training loss:  1.20410]\u001b[A\n",
            "Training:  43%|████▎     | 769/1772 [04:42<06:04,  2.75it/s, running training loss:  1.38621]\u001b[A\n",
            "Training:  43%|████▎     | 770/1772 [04:42<05:36,  2.97it/s, running training loss:  1.38621]\u001b[A\n",
            "Training:  43%|████▎     | 770/1772 [04:42<05:36,  2.97it/s, running training loss:  0.92846]\u001b[A\n",
            "Training:  44%|████▎     | 771/1772 [04:42<05:30,  3.03it/s, running training loss:  0.92846]\u001b[A\n",
            "Training:  44%|████▎     | 771/1772 [04:42<05:30,  3.03it/s, running training loss:  0.85655]\u001b[A\n",
            "Training:  44%|████▎     | 772/1772 [04:42<05:56,  2.80it/s, running training loss:  0.85655]\u001b[A\n",
            "Training:  44%|████▎     | 772/1772 [04:43<05:56,  2.80it/s, running training loss:  1.34625]\u001b[A\n",
            "Training:  44%|████▎     | 773/1772 [04:43<05:30,  3.02it/s, running training loss:  1.34625]\u001b[A\n",
            "Training:  44%|████▎     | 773/1772 [04:43<05:30,  3.02it/s, running training loss:  0.87894]\u001b[A\n",
            "Training:  44%|████▎     | 774/1772 [04:43<06:07,  2.72it/s, running training loss:  0.87894]\u001b[A\n",
            "Training:  44%|████▎     | 774/1772 [04:43<06:07,  2.72it/s, running training loss:  1.24709]\u001b[A\n",
            "Training:  44%|████▎     | 775/1772 [04:43<05:58,  2.78it/s, running training loss:  1.24709]\u001b[A\n",
            "Training:  44%|████▎     | 775/1772 [04:44<05:58,  2.78it/s, running training loss:  1.09868]\u001b[A\n",
            "Training:  44%|████▍     | 776/1772 [04:44<06:25,  2.59it/s, running training loss:  1.09868]\u001b[A\n",
            "Training:  44%|████▍     | 776/1772 [04:44<06:25,  2.59it/s, running training loss:  1.02794]\u001b[A\n",
            "Training:  44%|████▍     | 777/1772 [04:44<06:06,  2.71it/s, running training loss:  1.02794]\u001b[A\n",
            "Training:  44%|████▍     | 777/1772 [04:45<06:06,  2.71it/s, running training loss:  1.13295]\u001b[A\n",
            "Training:  44%|████▍     | 778/1772 [04:45<06:44,  2.46it/s, running training loss:  1.13295]\u001b[A\n",
            "Training:  44%|████▍     | 778/1772 [04:45<06:44,  2.46it/s, running training loss:  1.16176]\u001b[A\n",
            "Training:  44%|████▍     | 779/1772 [04:45<06:10,  2.68it/s, running training loss:  1.16176]\u001b[A\n",
            "Training:  44%|████▍     | 779/1772 [04:45<06:10,  2.68it/s, running training loss:  1.16846]\u001b[A\n",
            "Training:  44%|████▍     | 780/1772 [04:45<06:16,  2.63it/s, running training loss:  1.16846]\u001b[A\n",
            "Training:  44%|████▍     | 780/1772 [04:46<06:16,  2.63it/s, running training loss:  1.46616]\u001b[A\n",
            "Training:  44%|████▍     | 781/1772 [04:46<05:57,  2.77it/s, running training loss:  1.46616]\u001b[A\n",
            "Training:  44%|████▍     | 781/1772 [04:46<05:57,  2.77it/s, running training loss:  1.00374]\u001b[A\n",
            "Training:  44%|████▍     | 782/1772 [04:46<05:56,  2.78it/s, running training loss:  1.00374]\u001b[A\n",
            "Training:  44%|████▍     | 782/1772 [04:46<05:56,  2.78it/s, running training loss:  1.11057]\u001b[A\n",
            "Training:  44%|████▍     | 783/1772 [04:46<05:58,  2.76it/s, running training loss:  1.11057]\u001b[A\n",
            "Training:  44%|████▍     | 783/1772 [04:47<05:58,  2.76it/s, running training loss:  1.01843]\u001b[A\n",
            "Training:  44%|████▍     | 784/1772 [04:47<05:46,  2.85it/s, running training loss:  1.01843]\u001b[A\n",
            "Training:  44%|████▍     | 784/1772 [04:47<05:46,  2.85it/s, running training loss:  0.81576]\u001b[A\n",
            "Training:  44%|████▍     | 785/1772 [04:47<05:45,  2.86it/s, running training loss:  0.81576]\u001b[A\n",
            "Training:  44%|████▍     | 785/1772 [04:47<05:45,  2.86it/s, running training loss:  0.92523]\u001b[A\n",
            "Training:  44%|████▍     | 786/1772 [04:47<05:19,  3.09it/s, running training loss:  0.92523]\u001b[A\n",
            "Training:  44%|████▍     | 786/1772 [04:48<05:19,  3.09it/s, running training loss:  0.92648]\u001b[A\n",
            "Training:  44%|████▍     | 787/1772 [04:48<05:00,  3.28it/s, running training loss:  0.92648]\u001b[A\n",
            "Training:  44%|████▍     | 787/1772 [04:48<05:00,  3.28it/s, running training loss:  0.83455]\u001b[A\n",
            "Training:  44%|████▍     | 788/1772 [04:48<05:31,  2.97it/s, running training loss:  0.83455]\u001b[A\n",
            "Training:  44%|████▍     | 788/1772 [04:48<05:31,  2.97it/s, running training loss:  1.01481]\u001b[A\n",
            "Training:  45%|████▍     | 789/1772 [04:48<05:19,  3.08it/s, running training loss:  1.01481]\u001b[A\n",
            "Training:  45%|████▍     | 789/1772 [04:49<05:19,  3.08it/s, running training loss:  0.91295]\u001b[A\n",
            "Training:  45%|████▍     | 790/1772 [04:49<05:58,  2.74it/s, running training loss:  0.91295]\u001b[A\n",
            "Training:  45%|████▍     | 790/1772 [04:49<05:58,  2.74it/s, running training loss:  0.82927]\u001b[A\n",
            "Training:  45%|████▍     | 791/1772 [04:49<05:58,  2.74it/s, running training loss:  0.82927]\u001b[A\n",
            "Training:  45%|████▍     | 791/1772 [04:49<05:58,  2.74it/s, running training loss:  0.88842]\u001b[A\n",
            "Training:  45%|████▍     | 792/1772 [04:49<05:31,  2.95it/s, running training loss:  0.88842]\u001b[A\n",
            "Training:  45%|████▍     | 792/1772 [04:50<05:31,  2.95it/s, running training loss:  0.97185]\u001b[A\n",
            "Training:  45%|████▍     | 793/1772 [04:50<05:33,  2.94it/s, running training loss:  0.97185]\u001b[A\n",
            "Training:  45%|████▍     | 793/1772 [04:50<05:33,  2.94it/s, running training loss:  1.26423]\u001b[A\n",
            "Training:  45%|████▍     | 794/1772 [04:50<05:20,  3.05it/s, running training loss:  1.26423]\u001b[A\n",
            "Training:  45%|████▍     | 794/1772 [04:50<05:20,  3.05it/s, running training loss:  0.91306]\u001b[A\n",
            "Training:  45%|████▍     | 795/1772 [04:50<05:11,  3.13it/s, running training loss:  0.91306]\u001b[A\n",
            "Training:  45%|████▍     | 795/1772 [04:51<05:11,  3.13it/s, running training loss:  0.91524]\u001b[A\n",
            "Training:  45%|████▍     | 796/1772 [04:51<05:15,  3.10it/s, running training loss:  0.91524]\u001b[A\n",
            "Training:  45%|████▍     | 796/1772 [04:51<05:15,  3.10it/s, running training loss:  1.08844]\u001b[A\n",
            "Training:  45%|████▍     | 797/1772 [04:51<05:10,  3.14it/s, running training loss:  1.08844]\u001b[A\n",
            "Training:  45%|████▍     | 797/1772 [04:51<05:10,  3.14it/s, running training loss:  0.94732]\u001b[A\n",
            "Training:  45%|████▌     | 798/1772 [04:51<05:02,  3.22it/s, running training loss:  0.94732]\u001b[A\n",
            "Training:  45%|████▌     | 798/1772 [04:52<05:02,  3.22it/s, running training loss:  1.23099]\u001b[A\n",
            "Training:  45%|████▌     | 799/1772 [04:52<05:55,  2.73it/s, running training loss:  1.23099]\u001b[A\n",
            "Training:  45%|████▌     | 799/1772 [04:52<05:55,  2.73it/s, running training loss:  0.95719]\u001b[A\n",
            "Training:  45%|████▌     | 800/1772 [04:52<05:39,  2.87it/s, running training loss:  0.95719]\u001b[A\n",
            "Training:  45%|████▌     | 800/1772 [04:52<05:39,  2.87it/s, running training loss:  1.37919]\u001b[A\n",
            "Training:  45%|████▌     | 801/1772 [04:52<05:22,  3.01it/s, running training loss:  1.37919]\u001b[A\n",
            "Training:  45%|████▌     | 801/1772 [04:53<05:22,  3.01it/s, running training loss:  1.25300]\u001b[A\n",
            "Training:  45%|████▌     | 802/1772 [04:53<05:32,  2.92it/s, running training loss:  1.25300]\u001b[A\n",
            "Training:  45%|████▌     | 802/1772 [04:53<05:32,  2.92it/s, running training loss:  0.89459]\u001b[A\n",
            "Training:  45%|████▌     | 803/1772 [04:53<05:23,  2.99it/s, running training loss:  0.89459]\u001b[A\n",
            "Training:  45%|████▌     | 803/1772 [04:53<05:23,  2.99it/s, running training loss:  1.28416]\u001b[A\n",
            "Training:  45%|████▌     | 804/1772 [04:53<05:01,  3.21it/s, running training loss:  1.28416]\u001b[A\n",
            "Training:  45%|████▌     | 804/1772 [04:54<05:01,  3.21it/s, running training loss:  1.30260]\u001b[A\n",
            "Training:  45%|████▌     | 805/1772 [04:54<05:01,  3.20it/s, running training loss:  1.30260]\u001b[A\n",
            "Training:  45%|████▌     | 805/1772 [04:54<05:01,  3.20it/s, running training loss:  1.10807]\u001b[A\n",
            "Training:  45%|████▌     | 806/1772 [04:54<05:57,  2.70it/s, running training loss:  1.10807]\u001b[A\n",
            "Training:  45%|████▌     | 806/1772 [04:55<05:57,  2.70it/s, running training loss:  0.92750]\u001b[A\n",
            "Training:  46%|████▌     | 807/1772 [04:55<06:35,  2.44it/s, running training loss:  0.92750]\u001b[A\n",
            "Training:  46%|████▌     | 807/1772 [04:55<06:35,  2.44it/s, running training loss:  1.08438]\u001b[A\n",
            "Training:  46%|████▌     | 808/1772 [04:55<06:02,  2.66it/s, running training loss:  1.08438]\u001b[A\n",
            "Training:  46%|████▌     | 808/1772 [04:55<06:02,  2.66it/s, running training loss:  1.12294]\u001b[A\n",
            "Training:  46%|████▌     | 809/1772 [04:55<05:43,  2.81it/s, running training loss:  1.12294]\u001b[A\n",
            "Training:  46%|████▌     | 809/1772 [04:56<05:43,  2.81it/s, running training loss:  0.96505]\u001b[A\n",
            "Training:  46%|████▌     | 810/1772 [04:56<05:15,  3.05it/s, running training loss:  0.96505]\u001b[A\n",
            "Training:  46%|████▌     | 810/1772 [04:56<05:15,  3.05it/s, running training loss:  1.00798]\u001b[A\n",
            "Training:  46%|████▌     | 811/1772 [04:56<05:52,  2.73it/s, running training loss:  1.00798]\u001b[A\n",
            "Training:  46%|████▌     | 811/1772 [04:56<05:52,  2.73it/s, running training loss:  0.89419]\u001b[A\n",
            "Training:  46%|████▌     | 812/1772 [04:56<05:34,  2.87it/s, running training loss:  0.89419]\u001b[A\n",
            "Training:  46%|████▌     | 812/1772 [04:57<05:34,  2.87it/s, running training loss:  0.95725]\u001b[A\n",
            "Training:  46%|████▌     | 813/1772 [04:57<05:26,  2.94it/s, running training loss:  0.95725]\u001b[A\n",
            "Training:  46%|████▌     | 813/1772 [04:57<05:26,  2.94it/s, running training loss:  1.00670]\u001b[A\n",
            "Training:  46%|████▌     | 814/1772 [04:57<05:19,  3.00it/s, running training loss:  1.00670]\u001b[A\n",
            "Training:  46%|████▌     | 814/1772 [04:57<05:19,  3.00it/s, running training loss:  0.94713]\u001b[A\n",
            "Training:  46%|████▌     | 815/1772 [04:57<05:47,  2.75it/s, running training loss:  0.94713]\u001b[A\n",
            "Training:  46%|████▌     | 815/1772 [04:58<05:47,  2.75it/s, running training loss:  1.05807]\u001b[A\n",
            "Training:  46%|████▌     | 816/1772 [04:58<05:55,  2.69it/s, running training loss:  1.05807]\u001b[A\n",
            "Training:  46%|████▌     | 816/1772 [04:58<05:55,  2.69it/s, running training loss:  0.80884]\u001b[A\n",
            "Training:  46%|████▌     | 817/1772 [04:58<05:43,  2.78it/s, running training loss:  0.80884]\u001b[A\n",
            "Training:  46%|████▌     | 817/1772 [04:58<05:43,  2.78it/s, running training loss:  1.05015]\u001b[A\n",
            "Training:  46%|████▌     | 818/1772 [04:58<05:36,  2.84it/s, running training loss:  1.05015]\u001b[A\n",
            "Training:  46%|████▌     | 818/1772 [04:59<05:36,  2.84it/s, running training loss:  1.04616]\u001b[A\n",
            "Training:  46%|████▌     | 819/1772 [04:59<05:22,  2.96it/s, running training loss:  1.04616]\u001b[A\n",
            "Training:  46%|████▌     | 819/1772 [04:59<05:22,  2.96it/s, running training loss:  0.98094]\u001b[A\n",
            "Training:  46%|████▋     | 820/1772 [04:59<05:14,  3.03it/s, running training loss:  0.98094]\u001b[A\n",
            "Training:  46%|████▋     | 820/1772 [04:59<05:14,  3.03it/s, running training loss:  1.05128]\u001b[A\n",
            "Training:  46%|████▋     | 821/1772 [04:59<04:53,  3.24it/s, running training loss:  1.05128]\u001b[A\n",
            "Training:  46%|████▋     | 821/1772 [05:00<04:53,  3.24it/s, running training loss:  0.86427]\u001b[A\n",
            "Training:  46%|████▋     | 822/1772 [05:00<05:11,  3.05it/s, running training loss:  0.86427]\u001b[A\n",
            "Training:  46%|████▋     | 822/1772 [05:00<05:11,  3.05it/s, running training loss:  1.04891]\u001b[A\n",
            "Training:  46%|████▋     | 823/1772 [05:00<04:55,  3.21it/s, running training loss:  1.04891]\u001b[A\n",
            "Training:  46%|████▋     | 823/1772 [05:00<04:55,  3.21it/s, running training loss:  0.93389]\u001b[A\n",
            "Training:  47%|████▋     | 824/1772 [05:00<05:09,  3.07it/s, running training loss:  0.93389]\u001b[A\n",
            "Training:  47%|████▋     | 824/1772 [05:01<05:09,  3.07it/s, running training loss:  0.87855]\u001b[A\n",
            "Training:  47%|████▋     | 825/1772 [05:01<05:02,  3.13it/s, running training loss:  0.87855]\u001b[A\n",
            "Training:  47%|████▋     | 825/1772 [05:01<05:02,  3.13it/s, running training loss:  0.85465]\u001b[A\n",
            "Training:  47%|████▋     | 826/1772 [05:01<05:27,  2.89it/s, running training loss:  0.85465]\u001b[A\n",
            "Training:  47%|████▋     | 826/1772 [05:01<05:27,  2.89it/s, running training loss:  0.97487]\u001b[A\n",
            "Training:  47%|████▋     | 827/1772 [05:01<05:27,  2.88it/s, running training loss:  0.97487]\u001b[A\n",
            "Training:  47%|████▋     | 827/1772 [05:02<05:27,  2.88it/s, running training loss:  1.07427]\u001b[A\n",
            "Training:  47%|████▋     | 828/1772 [05:02<05:57,  2.64it/s, running training loss:  1.07427]\u001b[A\n",
            "Training:  47%|████▋     | 828/1772 [05:02<05:57,  2.64it/s, running training loss:  1.31364]\u001b[A\n",
            "Training:  47%|████▋     | 829/1772 [05:02<05:55,  2.66it/s, running training loss:  1.31364]\u001b[A\n",
            "Training:  47%|████▋     | 829/1772 [05:03<05:55,  2.66it/s, running training loss:  0.88229]\u001b[A\n",
            "Training:  47%|████▋     | 830/1772 [05:03<05:26,  2.89it/s, running training loss:  0.88229]\u001b[A\n",
            "Training:  47%|████▋     | 830/1772 [05:03<05:26,  2.89it/s, running training loss:  0.89134]\u001b[A\n",
            "Training:  47%|████▋     | 831/1772 [05:03<05:15,  2.98it/s, running training loss:  0.89134]\u001b[A\n",
            "Training:  47%|████▋     | 831/1772 [05:03<05:15,  2.98it/s, running training loss:  1.08756]\u001b[A\n",
            "Training:  47%|████▋     | 832/1772 [05:03<05:16,  2.97it/s, running training loss:  1.08756]\u001b[A\n",
            "Training:  47%|████▋     | 832/1772 [05:04<05:16,  2.97it/s, running training loss:  0.87698]\u001b[A\n",
            "Training:  47%|████▋     | 833/1772 [05:04<05:32,  2.82it/s, running training loss:  0.87698]\u001b[A\n",
            "Training:  47%|████▋     | 833/1772 [05:04<05:32,  2.82it/s, running training loss:  1.47168]\u001b[A\n",
            "Training:  47%|████▋     | 834/1772 [05:04<05:24,  2.89it/s, running training loss:  1.47168]\u001b[A\n",
            "Training:  47%|████▋     | 834/1772 [05:04<05:24,  2.89it/s, running training loss:  1.43211]\u001b[A\n",
            "Training:  47%|████▋     | 835/1772 [05:04<05:14,  2.97it/s, running training loss:  1.43211]\u001b[A\n",
            "Training:  47%|████▋     | 835/1772 [05:05<05:14,  2.97it/s, running training loss:  1.46567]\u001b[A\n",
            "Training:  47%|████▋     | 836/1772 [05:05<05:27,  2.86it/s, running training loss:  1.46567]\u001b[A\n",
            "Training:  47%|████▋     | 836/1772 [05:05<05:27,  2.86it/s, running training loss:  1.68912]\u001b[A\n",
            "Training:  47%|████▋     | 837/1772 [05:05<05:37,  2.77it/s, running training loss:  1.68912]\u001b[A\n",
            "Training:  47%|████▋     | 837/1772 [05:05<05:37,  2.77it/s, running training loss:  1.28488]\u001b[A\n",
            "Training:  47%|████▋     | 838/1772 [05:05<05:24,  2.88it/s, running training loss:  1.28488]\u001b[A\n",
            "Training:  47%|████▋     | 838/1772 [05:06<05:24,  2.88it/s, running training loss:  1.07681]\u001b[A\n",
            "Training:  47%|████▋     | 839/1772 [05:06<05:35,  2.78it/s, running training loss:  1.07681]\u001b[A\n",
            "Training:  47%|████▋     | 839/1772 [05:06<05:35,  2.78it/s, running training loss:  1.06130]\u001b[A\n",
            "Training:  47%|████▋     | 840/1772 [05:06<05:09,  3.01it/s, running training loss:  1.06130]\u001b[A\n",
            "Training:  47%|████▋     | 840/1772 [05:06<05:09,  3.01it/s, running training loss:  1.44220]\u001b[A\n",
            "Training:  47%|████▋     | 841/1772 [05:06<05:11,  2.99it/s, running training loss:  1.44220]\u001b[A\n",
            "Training:  47%|████▋     | 841/1772 [05:07<05:11,  2.99it/s, running training loss:  1.01433]\u001b[A\n",
            "Training:  48%|████▊     | 842/1772 [05:07<05:23,  2.87it/s, running training loss:  1.01433]\u001b[A\n",
            "Training:  48%|████▊     | 842/1772 [05:07<05:23,  2.87it/s, running training loss:  0.99613]\u001b[A\n",
            "Training:  48%|████▊     | 843/1772 [05:07<05:12,  2.97it/s, running training loss:  0.99613]\u001b[A\n",
            "Training:  48%|████▊     | 843/1772 [05:07<05:12,  2.97it/s, running training loss:  1.12114]\u001b[A\n",
            "Training:  48%|████▊     | 844/1772 [05:07<05:15,  2.94it/s, running training loss:  1.12114]\u001b[A\n",
            "Training:  48%|████▊     | 844/1772 [05:08<05:15,  2.94it/s, running training loss:  0.90777]\u001b[A\n",
            "Training:  48%|████▊     | 845/1772 [05:08<05:03,  3.06it/s, running training loss:  0.90777]\u001b[A\n",
            "Training:  48%|████▊     | 845/1772 [05:08<05:03,  3.06it/s, running training loss:  1.10350]\u001b[A\n",
            "Training:  48%|████▊     | 846/1772 [05:08<04:56,  3.12it/s, running training loss:  1.10350]\u001b[A\n",
            "Training:  48%|████▊     | 846/1772 [05:08<04:56,  3.12it/s, running training loss:  1.45668]\u001b[A\n",
            "Training:  48%|████▊     | 847/1772 [05:08<05:04,  3.03it/s, running training loss:  1.45668]\u001b[A\n",
            "Training:  48%|████▊     | 847/1772 [05:09<05:04,  3.03it/s, running training loss:  0.98817]\u001b[A\n",
            "Training:  48%|████▊     | 848/1772 [05:09<05:00,  3.07it/s, running training loss:  0.98817]\u001b[A\n",
            "Training:  48%|████▊     | 848/1772 [05:09<05:00,  3.07it/s, running training loss:  1.05559]\u001b[A\n",
            "Training:  48%|████▊     | 849/1772 [05:09<05:03,  3.04it/s, running training loss:  1.05559]\u001b[A\n",
            "Training:  48%|████▊     | 849/1772 [05:09<05:03,  3.04it/s, running training loss:  1.41240]\u001b[A\n",
            "Training:  48%|████▊     | 850/1772 [05:09<04:53,  3.14it/s, running training loss:  1.41240]\u001b[A\n",
            "Training:  48%|████▊     | 850/1772 [05:10<04:53,  3.14it/s, running training loss:  0.92278]\u001b[A\n",
            "Training:  48%|████▊     | 851/1772 [05:10<05:44,  2.67it/s, running training loss:  0.92278]\u001b[A\n",
            "Training:  48%|████▊     | 851/1772 [05:10<05:44,  2.67it/s, running training loss:  1.27194]\u001b[A\n",
            "Training:  48%|████▊     | 852/1772 [05:10<05:40,  2.70it/s, running training loss:  1.27194]\u001b[A\n",
            "Training:  48%|████▊     | 852/1772 [05:11<05:40,  2.70it/s, running training loss:  1.32201]\u001b[A\n",
            "Training:  48%|████▊     | 853/1772 [05:11<06:12,  2.47it/s, running training loss:  1.32201]\u001b[A\n",
            "Training:  48%|████▊     | 853/1772 [05:11<06:12,  2.47it/s, running training loss:  1.27702]\u001b[A\n",
            "Training:  48%|████▊     | 854/1772 [05:11<05:38,  2.72it/s, running training loss:  1.27702]\u001b[A\n",
            "Training:  48%|████▊     | 854/1772 [05:11<05:38,  2.72it/s, running training loss:  0.85254]\u001b[A\n",
            "Training:  48%|████▊     | 855/1772 [05:11<05:12,  2.93it/s, running training loss:  0.85254]\u001b[A\n",
            "Training:  48%|████▊     | 855/1772 [05:11<05:12,  2.93it/s, running training loss:  1.25719]\u001b[A\n",
            "Training:  48%|████▊     | 856/1772 [05:11<05:01,  3.04it/s, running training loss:  1.25719]\u001b[A\n",
            "Training:  48%|████▊     | 856/1772 [05:12<05:01,  3.04it/s, running training loss:  0.86756]\u001b[A\n",
            "Training:  48%|████▊     | 857/1772 [05:12<05:11,  2.94it/s, running training loss:  0.86756]\u001b[A\n",
            "Training:  48%|████▊     | 857/1772 [05:12<05:11,  2.94it/s, running training loss:  1.14994]\u001b[A\n",
            "Training:  48%|████▊     | 858/1772 [05:12<05:37,  2.71it/s, running training loss:  1.14994]\u001b[A\n",
            "Training:  48%|████▊     | 858/1772 [05:13<05:37,  2.71it/s, running training loss:  1.08573]\u001b[A\n",
            "Training:  48%|████▊     | 859/1772 [05:13<05:26,  2.80it/s, running training loss:  1.08573]\u001b[A\n",
            "Training:  48%|████▊     | 859/1772 [05:13<05:26,  2.80it/s, running training loss:  1.01828]\u001b[A\n",
            "Training:  49%|████▊     | 860/1772 [05:13<05:14,  2.90it/s, running training loss:  1.01828]\u001b[A\n",
            "Training:  49%|████▊     | 860/1772 [05:13<05:14,  2.90it/s, running training loss:  1.04166]\u001b[A\n",
            "Training:  49%|████▊     | 861/1772 [05:13<05:16,  2.87it/s, running training loss:  1.04166]\u001b[A\n",
            "Training:  49%|████▊     | 861/1772 [05:14<05:16,  2.87it/s, running training loss:  1.05537]\u001b[A\n",
            "Training:  49%|████▊     | 862/1772 [05:14<05:49,  2.61it/s, running training loss:  1.05537]\u001b[A\n",
            "Training:  49%|████▊     | 862/1772 [05:14<05:49,  2.61it/s, running training loss:  1.12650]\u001b[A\n",
            "Training:  49%|████▊     | 863/1772 [05:14<05:52,  2.58it/s, running training loss:  1.12650]\u001b[A\n",
            "Training:  49%|████▊     | 863/1772 [05:14<05:52,  2.58it/s, running training loss:  1.06658]\u001b[A\n",
            "Training:  49%|████▉     | 864/1772 [05:14<05:27,  2.77it/s, running training loss:  1.06658]\u001b[A\n",
            "Training:  49%|████▉     | 864/1772 [05:15<05:27,  2.77it/s, running training loss:  0.94491]\u001b[A\n",
            "Training:  49%|████▉     | 865/1772 [05:15<05:09,  2.93it/s, running training loss:  0.94491]\u001b[A\n",
            "Training:  49%|████▉     | 865/1772 [05:15<05:09,  2.93it/s, running training loss:  0.99228]\u001b[A\n",
            "Training:  49%|████▉     | 866/1772 [05:15<04:56,  3.05it/s, running training loss:  0.99228]\u001b[A\n",
            "Training:  49%|████▉     | 866/1772 [05:15<04:56,  3.05it/s, running training loss:  0.99048]\u001b[A\n",
            "Training:  49%|████▉     | 867/1772 [05:15<04:41,  3.21it/s, running training loss:  0.99048]\u001b[A\n",
            "Training:  49%|████▉     | 867/1772 [05:16<04:41,  3.21it/s, running training loss:  0.89067]\u001b[A\n",
            "Training:  49%|████▉     | 868/1772 [05:16<05:17,  2.85it/s, running training loss:  0.89067]\u001b[A\n",
            "Training:  49%|████▉     | 868/1772 [05:16<05:17,  2.85it/s, running training loss:  1.04292]\u001b[A\n",
            "Training:  49%|████▉     | 869/1772 [05:16<05:09,  2.92it/s, running training loss:  1.04292]\u001b[A\n",
            "Training:  49%|████▉     | 869/1772 [05:17<05:09,  2.92it/s, running training loss:  0.98710]\u001b[A\n",
            "Training:  49%|████▉     | 870/1772 [05:17<06:06,  2.46it/s, running training loss:  0.98710]\u001b[A\n",
            "Training:  49%|████▉     | 870/1772 [05:17<06:06,  2.46it/s, running training loss:  0.98462]\u001b[A\n",
            "Training:  49%|████▉     | 871/1772 [05:17<05:26,  2.76it/s, running training loss:  0.98462]\u001b[A\n",
            "Training:  49%|████▉     | 871/1772 [05:17<05:26,  2.76it/s, running training loss:  0.84149]\u001b[A\n",
            "Training:  49%|████▉     | 872/1772 [05:17<05:20,  2.81it/s, running training loss:  0.84149]\u001b[A\n",
            "Training:  49%|████▉     | 872/1772 [05:18<05:20,  2.81it/s, running training loss:  1.04045]\u001b[A\n",
            "Training:  49%|████▉     | 873/1772 [05:18<06:05,  2.46it/s, running training loss:  1.04045]\u001b[A\n",
            "Training:  49%|████▉     | 873/1772 [05:18<06:05,  2.46it/s, running training loss:  1.00717]\u001b[A\n",
            "Training:  49%|████▉     | 874/1772 [05:18<05:36,  2.67it/s, running training loss:  1.00717]\u001b[A\n",
            "Training:  49%|████▉     | 874/1772 [05:18<05:36,  2.67it/s, running training loss:  1.32046]\u001b[A\n",
            "Training:  49%|████▉     | 875/1772 [05:18<05:12,  2.87it/s, running training loss:  1.32046]\u001b[A\n",
            "Training:  49%|████▉     | 875/1772 [05:19<05:12,  2.87it/s, running training loss:  1.21558]\u001b[A\n",
            "Training:  49%|████▉     | 876/1772 [05:19<05:00,  2.98it/s, running training loss:  1.21558]\u001b[A\n",
            "Training:  49%|████▉     | 876/1772 [05:19<05:00,  2.98it/s, running training loss:  1.08246]\u001b[A\n",
            "Training:  49%|████▉     | 877/1772 [05:19<04:50,  3.09it/s, running training loss:  1.08246]\u001b[A\n",
            "Training:  49%|████▉     | 877/1772 [05:19<04:50,  3.09it/s, running training loss:  1.03896]\u001b[A\n",
            "Training:  50%|████▉     | 878/1772 [05:19<05:04,  2.93it/s, running training loss:  1.03896]\u001b[A\n",
            "Training:  50%|████▉     | 878/1772 [05:20<05:04,  2.93it/s, running training loss:  0.98618]\u001b[A\n",
            "Training:  50%|████▉     | 879/1772 [05:20<05:03,  2.94it/s, running training loss:  0.98618]\u001b[A\n",
            "Training:  50%|████▉     | 879/1772 [05:20<05:03,  2.94it/s, running training loss:  0.98121]\u001b[A\n",
            "Training:  50%|████▉     | 880/1772 [05:20<04:58,  2.99it/s, running training loss:  0.98121]\u001b[A\n",
            "Training:  50%|████▉     | 880/1772 [05:20<04:58,  2.99it/s, running training loss:  0.88140]\u001b[A\n",
            "Training:  50%|████▉     | 881/1772 [05:20<04:39,  3.19it/s, running training loss:  0.88140]\u001b[A\n",
            "Training:  50%|████▉     | 881/1772 [05:21<04:39,  3.19it/s, running training loss:  1.03679]\u001b[A\n",
            "Training:  50%|████▉     | 882/1772 [05:21<05:11,  2.86it/s, running training loss:  1.03679]\u001b[A\n",
            "Training:  50%|████▉     | 882/1772 [05:21<05:11,  2.86it/s, running training loss:  1.03260]\u001b[A\n",
            "Training:  50%|████▉     | 883/1772 [05:21<05:01,  2.95it/s, running training loss:  1.03260]\u001b[A\n",
            "Training:  50%|████▉     | 883/1772 [05:21<05:01,  2.95it/s, running training loss:  1.21315]\u001b[A\n",
            "Training:  50%|████▉     | 884/1772 [05:21<05:05,  2.90it/s, running training loss:  1.21315]\u001b[A\n",
            "Training:  50%|████▉     | 884/1772 [05:22<05:05,  2.90it/s, running training loss:  0.88411]\u001b[A\n",
            "Training:  50%|████▉     | 885/1772 [05:22<05:47,  2.55it/s, running training loss:  0.88411]\u001b[A\n",
            "Training:  50%|████▉     | 885/1772 [05:22<05:47,  2.55it/s, running training loss:  1.04967]\u001b[A\n",
            "Training:  50%|█████     | 886/1772 [05:22<05:11,  2.85it/s, running training loss:  1.04967]\u001b[A\n",
            "Training:  50%|█████     | 886/1772 [05:22<05:11,  2.85it/s, running training loss:  1.07261]\u001b[A\n",
            "Training:  50%|█████     | 887/1772 [05:22<04:48,  3.07it/s, running training loss:  1.07261]\u001b[A\n",
            "Training:  50%|█████     | 887/1772 [05:23<04:48,  3.07it/s, running training loss:  1.10175]\u001b[A\n",
            "Training:  50%|█████     | 888/1772 [05:23<04:51,  3.03it/s, running training loss:  1.10175]\u001b[A\n",
            "Training:  50%|█████     | 888/1772 [05:23<04:51,  3.03it/s, running training loss:  1.00786]\u001b[A\n",
            "Training:  50%|█████     | 889/1772 [05:23<04:34,  3.21it/s, running training loss:  1.00786]\u001b[A\n",
            "Training:  50%|█████     | 889/1772 [05:23<04:34,  3.21it/s, running training loss:  1.14096]\u001b[A\n",
            "Training:  50%|█████     | 890/1772 [05:23<04:52,  3.02it/s, running training loss:  1.14096]\u001b[A\n",
            "Training:  50%|█████     | 890/1772 [05:24<04:52,  3.02it/s, running training loss:  0.99772]\u001b[A\n",
            "Training:  50%|█████     | 891/1772 [05:24<05:19,  2.76it/s, running training loss:  0.99772]\u001b[A\n",
            "Training:  50%|█████     | 891/1772 [05:24<05:19,  2.76it/s, running training loss:  0.89503]\u001b[A\n",
            "Training:  50%|█████     | 892/1772 [05:24<04:46,  3.07it/s, running training loss:  0.89503]\u001b[A\n",
            "Training:  50%|█████     | 892/1772 [05:24<04:46,  3.07it/s, running training loss:  0.98419]\u001b[A\n",
            "Training:  50%|█████     | 893/1772 [05:24<04:50,  3.02it/s, running training loss:  0.98419]\u001b[A\n",
            "Training:  50%|█████     | 893/1772 [05:25<04:50,  3.02it/s, running training loss:  0.90253]\u001b[A\n",
            "Training:  50%|█████     | 894/1772 [05:25<04:41,  3.12it/s, running training loss:  0.90253]\u001b[A\n",
            "Training:  50%|█████     | 894/1772 [05:25<04:41,  3.12it/s, running training loss:  0.92903]\u001b[A\n",
            "Training:  51%|█████     | 895/1772 [05:25<04:32,  3.22it/s, running training loss:  0.92903]\u001b[A\n",
            "Training:  51%|█████     | 895/1772 [05:25<04:32,  3.22it/s, running training loss:  0.94363]\u001b[A\n",
            "Training:  51%|█████     | 896/1772 [05:25<04:43,  3.09it/s, running training loss:  0.94363]\u001b[A\n",
            "Training:  51%|█████     | 896/1772 [05:26<04:43,  3.09it/s, running training loss:  1.02026]\u001b[A\n",
            "Training:  51%|█████     | 897/1772 [05:26<05:48,  2.51it/s, running training loss:  1.02026]\u001b[A\n",
            "Training:  51%|█████     | 897/1772 [05:26<05:48,  2.51it/s, running training loss:  1.15347]\u001b[A\n",
            "Training:  51%|█████     | 898/1772 [05:26<05:42,  2.55it/s, running training loss:  1.15347]\u001b[A\n",
            "Training:  51%|█████     | 898/1772 [05:27<05:42,  2.55it/s, running training loss:  1.16639]\u001b[A\n",
            "Training:  51%|█████     | 899/1772 [05:27<05:21,  2.72it/s, running training loss:  1.16639]\u001b[A\n",
            "Training:  51%|█████     | 899/1772 [05:27<05:21,  2.72it/s, running training loss:  1.07549]\u001b[A\n",
            "\n",
            "Evaluation:   0%|          | 0/270 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   0%|          | 1/270 [00:00<01:27,  3.06it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   1%|          | 3/270 [00:00<00:33,  7.95it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   2%|▏         | 5/270 [00:00<00:23, 11.33it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   3%|▎         | 8/270 [00:00<00:17, 14.57it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   4%|▍         | 11/270 [00:00<00:15, 16.95it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   5%|▌         | 14/270 [00:00<00:14, 18.07it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   6%|▌         | 16/270 [00:01<00:14, 17.95it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   7%|▋         | 18/270 [00:01<00:14, 17.60it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   7%|▋         | 20/270 [00:01<00:14, 17.18it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   9%|▊         | 23/270 [00:01<00:12, 19.35it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   9%|▉         | 25/270 [00:01<00:12, 19.43it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  10%|█         | 28/270 [00:01<00:12, 19.80it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  11%|█         | 30/270 [00:01<00:12, 18.89it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  12%|█▏        | 32/270 [00:01<00:12, 19.04it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  13%|█▎        | 35/270 [00:02<00:12, 19.21it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  14%|█▍        | 38/270 [00:02<00:11, 20.53it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  15%|█▌        | 41/270 [00:02<00:11, 20.02it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  16%|█▋        | 44/270 [00:02<00:11, 19.02it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  17%|█▋        | 46/270 [00:02<00:11, 18.70it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  18%|█▊        | 49/270 [00:02<00:11, 19.21it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  19%|█▉        | 51/270 [00:02<00:11, 18.61it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  20%|█▉        | 53/270 [00:03<00:11, 18.65it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  21%|██        | 56/270 [00:03<00:11, 18.76it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  21%|██▏       | 58/270 [00:03<00:11, 18.63it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  22%|██▏       | 60/270 [00:03<00:11, 18.22it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  23%|██▎       | 62/270 [00:03<00:11, 18.04it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  24%|██▎       | 64/270 [00:03<00:11, 18.24it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  25%|██▍       | 67/270 [00:03<00:10, 19.52it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  26%|██▌       | 70/270 [00:03<00:09, 20.60it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  27%|██▋       | 73/270 [00:04<00:09, 20.25it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  28%|██▊       | 76/270 [00:04<00:09, 21.21it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  29%|██▉       | 79/270 [00:04<00:09, 20.94it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  30%|███       | 82/270 [00:04<00:09, 19.65it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  31%|███       | 84/270 [00:04<00:09, 19.57it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  32%|███▏      | 87/270 [00:04<00:09, 19.59it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  33%|███▎      | 89/270 [00:04<00:09, 18.68it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  34%|███▎      | 91/270 [00:04<00:09, 18.65it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  35%|███▍      | 94/270 [00:05<00:08, 19.65it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  36%|███▌      | 97/270 [00:05<00:08, 20.56it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  37%|███▋      | 100/270 [00:05<00:08, 20.39it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  38%|███▊      | 103/270 [00:05<00:07, 21.28it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  39%|███▉      | 106/270 [00:05<00:08, 20.33it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  40%|████      | 109/270 [00:05<00:08, 20.01it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  41%|████▏     | 112/270 [00:06<00:07, 20.09it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  43%|████▎     | 115/270 [00:06<00:07, 20.53it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  44%|████▎     | 118/270 [00:06<00:07, 20.44it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  45%|████▍     | 121/270 [00:06<00:07, 20.10it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  46%|████▌     | 124/270 [00:06<00:06, 20.93it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  47%|████▋     | 127/270 [00:06<00:07, 19.61it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  48%|████▊     | 129/270 [00:06<00:07, 18.92it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  49%|████▉     | 132/270 [00:07<00:07, 19.31it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  50%|█████     | 135/270 [00:07<00:06, 19.81it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  51%|█████     | 138/270 [00:07<00:06, 20.55it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  52%|█████▏    | 141/270 [00:07<00:06, 19.97it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  53%|█████▎    | 144/270 [00:07<00:06, 20.03it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  54%|█████▍    | 147/270 [00:07<00:06, 19.20it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  56%|█████▌    | 150/270 [00:07<00:05, 20.13it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  57%|█████▋    | 153/270 [00:08<00:06, 19.17it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  57%|█████▋    | 155/270 [00:08<00:05, 19.30it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  59%|█████▊    | 158/270 [00:08<00:05, 20.23it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  60%|█████▉    | 161/270 [00:08<00:05, 19.83it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  60%|██████    | 163/270 [00:08<00:05, 19.40it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  61%|██████    | 165/270 [00:08<00:05, 18.66it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  62%|██████▏   | 168/270 [00:08<00:05, 19.71it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  63%|██████▎   | 170/270 [00:08<00:05, 19.12it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  64%|██████▎   | 172/270 [00:09<00:05, 19.03it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  64%|██████▍   | 174/270 [00:09<00:05, 18.35it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  65%|██████▌   | 176/270 [00:09<00:05, 17.96it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  66%|██████▌   | 178/270 [00:09<00:05, 18.19it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  67%|██████▋   | 180/270 [00:09<00:05, 17.18it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  67%|██████▋   | 182/270 [00:09<00:05, 17.54it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  68%|██████▊   | 184/270 [00:09<00:04, 17.84it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  69%|██████▉   | 186/270 [00:09<00:04, 18.27it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  70%|██████▉   | 188/270 [00:09<00:04, 17.92it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  71%|███████   | 191/270 [00:10<00:04, 19.43it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  71%|███████▏  | 193/270 [00:10<00:04, 18.87it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  72%|███████▏  | 195/270 [00:10<00:04, 17.96it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  73%|███████▎  | 197/270 [00:10<00:03, 18.32it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  74%|███████▎  | 199/270 [00:10<00:04, 17.39it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  74%|███████▍  | 201/270 [00:10<00:03, 17.36it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  75%|███████▌  | 203/270 [00:10<00:03, 17.68it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  76%|███████▋  | 206/270 [00:10<00:03, 19.60it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  77%|███████▋  | 208/270 [00:11<00:03, 18.68it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  78%|███████▊  | 210/270 [00:11<00:03, 18.34it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  79%|███████▊  | 212/270 [00:11<00:03, 18.40it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  80%|███████▉  | 215/270 [00:11<00:02, 20.37it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  81%|████████  | 218/270 [00:11<00:02, 20.09it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  82%|████████▏ | 221/270 [00:11<00:02, 20.65it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  83%|████████▎ | 224/270 [00:11<00:02, 21.12it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  84%|████████▍ | 227/270 [00:11<00:02, 20.64it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  85%|████████▌ | 230/270 [00:12<00:02, 19.05it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  86%|████████▌ | 232/270 [00:12<00:01, 19.24it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  87%|████████▋ | 235/270 [00:12<00:01, 20.31it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  88%|████████▊ | 238/270 [00:12<00:01, 20.90it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  89%|████████▉ | 241/270 [00:12<00:01, 19.12it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  90%|█████████ | 244/270 [00:12<00:01, 19.58it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  91%|█████████ | 246/270 [00:12<00:01, 18.46it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  92%|█████████▏| 248/270 [00:13<00:01, 17.55it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  93%|█████████▎| 250/270 [00:13<00:01, 17.50it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  93%|█████████▎| 252/270 [00:13<00:01, 17.23it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  94%|█████████▍| 254/270 [00:13<00:00, 17.03it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  95%|█████████▍| 256/270 [00:13<00:00, 16.60it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  96%|█████████▌| 259/270 [00:13<00:00, 18.53it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  97%|█████████▋| 262/270 [00:13<00:00, 18.75it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  98%|█████████▊| 264/270 [00:14<00:00, 18.19it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  99%|█████████▊| 266/270 [00:14<00:00, 18.00it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  99%|█████████▉| 268/270 [00:14<00:00, 18.11it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation: 100%|██████████| 270/270 [00:14<00:00, 18.59it/s]\n",
            "\n",
            "Training:  51%|█████     | 900/1772 [05:41<1:08:30,  4.71s/it, running training loss:  1.07549]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            ">>> training loss: 1.039274, valid loss: 0.623487,valid f1: 0.086780, valid acc:0.687905\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  51%|█████     | 900/1772 [05:42<1:08:30,  4.71s/it, running training loss:  1.04067]\u001b[A\n",
            "Training:  51%|█████     | 901/1772 [05:42<49:26,  3.41s/it, running training loss:  1.04067]  \u001b[A\n",
            "Training:  51%|█████     | 901/1772 [05:42<49:26,  3.41s/it, running training loss:  0.99373]\u001b[A\n",
            "Training:  51%|█████     | 902/1772 [05:42<36:18,  2.50s/it, running training loss:  0.99373]\u001b[A\n",
            "Training:  51%|█████     | 902/1772 [05:42<36:18,  2.50s/it, running training loss:  0.85973]\u001b[A\n",
            "Training:  51%|█████     | 903/1772 [05:42<26:48,  1.85s/it, running training loss:  0.85973]\u001b[A\n",
            "Training:  51%|█████     | 903/1772 [05:43<26:48,  1.85s/it, running training loss:  0.92123]\u001b[A\n",
            "Training:  51%|█████     | 904/1772 [05:43<20:03,  1.39s/it, running training loss:  0.92123]\u001b[A\n",
            "Training:  51%|█████     | 904/1772 [05:43<20:03,  1.39s/it, running training loss:  0.98222]\u001b[A\n",
            "Training:  51%|█████     | 905/1772 [05:43<15:20,  1.06s/it, running training loss:  0.98222]\u001b[A\n",
            "Training:  51%|█████     | 905/1772 [05:43<15:20,  1.06s/it, running training loss:  1.06893]\u001b[A\n",
            "Training:  51%|█████     | 906/1772 [05:43<11:50,  1.22it/s, running training loss:  1.06893]\u001b[A\n",
            "Training:  51%|█████     | 906/1772 [05:44<11:50,  1.22it/s, running training loss:  1.01421]\u001b[A\n",
            "Training:  51%|█████     | 907/1772 [05:44<10:06,  1.43it/s, running training loss:  1.01421]\u001b[A\n",
            "Training:  51%|█████     | 907/1772 [05:44<10:06,  1.43it/s, running training loss:  1.03294]\u001b[A\n",
            "Training:  51%|█████     | 908/1772 [05:44<08:20,  1.73it/s, running training loss:  1.03294]\u001b[A\n",
            "Training:  51%|█████     | 908/1772 [05:44<08:20,  1.73it/s, running training loss:  1.00078]\u001b[A\n",
            "Training:  51%|█████▏    | 909/1772 [05:44<07:08,  2.01it/s, running training loss:  1.00078]\u001b[A\n",
            "Training:  51%|█████▏    | 909/1772 [05:45<07:08,  2.01it/s, running training loss:  0.87278]\u001b[A\n",
            "Training:  51%|█████▏    | 910/1772 [05:45<06:22,  2.25it/s, running training loss:  0.87278]\u001b[A\n",
            "Training:  51%|█████▏    | 910/1772 [05:45<06:22,  2.25it/s, running training loss:  1.00750]\u001b[A\n",
            "Training:  51%|█████▏    | 911/1772 [05:45<05:52,  2.44it/s, running training loss:  1.00750]\u001b[A\n",
            "Training:  51%|█████▏    | 911/1772 [05:45<05:52,  2.44it/s, running training loss:  0.93547]\u001b[A\n",
            "Training:  51%|█████▏    | 912/1772 [05:45<05:41,  2.52it/s, running training loss:  0.93547]\u001b[A\n",
            "Training:  51%|█████▏    | 912/1772 [05:46<05:41,  2.52it/s, running training loss:  0.96602]\u001b[A\n",
            "Training:  52%|█████▏    | 913/1772 [05:46<05:10,  2.77it/s, running training loss:  0.96602]\u001b[A\n",
            "Training:  52%|█████▏    | 913/1772 [05:46<05:10,  2.77it/s, running training loss:  1.02117]\u001b[A\n",
            "Training:  52%|█████▏    | 914/1772 [05:46<05:10,  2.76it/s, running training loss:  1.02117]\u001b[A\n",
            "Training:  52%|█████▏    | 914/1772 [05:46<05:10,  2.76it/s, running training loss:  1.05313]\u001b[A\n",
            "Training:  52%|█████▏    | 915/1772 [05:46<05:09,  2.77it/s, running training loss:  1.05313]\u001b[A\n",
            "Training:  52%|█████▏    | 915/1772 [05:47<05:09,  2.77it/s, running training loss:  0.97671]\u001b[A\n",
            "Training:  52%|█████▏    | 916/1772 [05:47<06:00,  2.37it/s, running training loss:  0.97671]\u001b[A\n",
            "Training:  52%|█████▏    | 916/1772 [05:47<06:00,  2.37it/s, running training loss:  1.18956]\u001b[A\n",
            "Training:  52%|█████▏    | 917/1772 [05:47<05:30,  2.59it/s, running training loss:  1.18956]\u001b[A\n",
            "Training:  52%|█████▏    | 917/1772 [05:48<05:30,  2.59it/s, running training loss:  1.00214]\u001b[A\n",
            "Training:  52%|█████▏    | 918/1772 [05:48<05:17,  2.69it/s, running training loss:  1.00214]\u001b[A\n",
            "Training:  52%|█████▏    | 918/1772 [05:48<05:17,  2.69it/s, running training loss:  1.01916]\u001b[A\n",
            "Training:  52%|█████▏    | 919/1772 [05:48<04:48,  2.95it/s, running training loss:  1.01916]\u001b[A\n",
            "Training:  52%|█████▏    | 919/1772 [05:48<04:48,  2.95it/s, running training loss:  0.94768]\u001b[A\n",
            "Training:  52%|█████▏    | 920/1772 [05:48<04:40,  3.03it/s, running training loss:  0.94768]\u001b[A\n",
            "Training:  52%|█████▏    | 920/1772 [05:49<04:40,  3.03it/s, running training loss:  0.99391]\u001b[A\n",
            "Training:  52%|█████▏    | 921/1772 [05:49<05:10,  2.74it/s, running training loss:  0.99391]\u001b[A\n",
            "Training:  52%|█████▏    | 921/1772 [05:49<05:10,  2.74it/s, running training loss:  0.92269]\u001b[A\n",
            "Training:  52%|█████▏    | 922/1772 [05:49<05:15,  2.69it/s, running training loss:  0.92269]\u001b[A\n",
            "Training:  52%|█████▏    | 922/1772 [05:49<05:15,  2.69it/s, running training loss:  0.95993]\u001b[A\n",
            "Training:  52%|█████▏    | 923/1772 [05:49<05:27,  2.59it/s, running training loss:  0.95993]\u001b[A\n",
            "Training:  52%|█████▏    | 923/1772 [05:50<05:27,  2.59it/s, running training loss:  0.99003]\u001b[A\n",
            "Training:  52%|█████▏    | 924/1772 [05:50<04:59,  2.83it/s, running training loss:  0.99003]\u001b[A\n",
            "Training:  52%|█████▏    | 924/1772 [05:50<04:59,  2.83it/s, running training loss:  0.90020]\u001b[A\n",
            "Training:  52%|█████▏    | 925/1772 [05:50<05:42,  2.47it/s, running training loss:  0.90020]\u001b[A\n",
            "Training:  52%|█████▏    | 925/1772 [05:51<05:42,  2.47it/s, running training loss:  0.92334]\u001b[A\n",
            "Training:  52%|█████▏    | 926/1772 [05:51<05:31,  2.55it/s, running training loss:  0.92334]\u001b[A\n",
            "Training:  52%|█████▏    | 926/1772 [05:51<05:31,  2.55it/s, running training loss:  0.93544]\u001b[A\n",
            "Training:  52%|█████▏    | 927/1772 [05:51<04:59,  2.83it/s, running training loss:  0.93544]\u001b[A\n",
            "Training:  52%|█████▏    | 927/1772 [05:51<04:59,  2.83it/s, running training loss:  1.09960]\u001b[A\n",
            "Training:  52%|█████▏    | 928/1772 [05:51<04:43,  2.98it/s, running training loss:  1.09960]\u001b[A\n",
            "Training:  52%|█████▏    | 928/1772 [05:52<04:43,  2.98it/s, running training loss:  0.92959]\u001b[A\n",
            "Training:  52%|█████▏    | 929/1772 [05:52<05:07,  2.74it/s, running training loss:  0.92959]\u001b[A\n",
            "Training:  52%|█████▏    | 929/1772 [05:52<05:07,  2.74it/s, running training loss:  1.16343]\u001b[A\n",
            "Training:  52%|█████▏    | 930/1772 [05:52<04:50,  2.89it/s, running training loss:  1.16343]\u001b[A\n",
            "Training:  52%|█████▏    | 930/1772 [05:52<04:50,  2.89it/s, running training loss:  1.28728]\u001b[A\n",
            "Training:  53%|█████▎    | 931/1772 [05:52<04:40,  2.99it/s, running training loss:  1.28728]\u001b[A\n",
            "Training:  53%|█████▎    | 931/1772 [05:52<04:40,  2.99it/s, running training loss:  0.12136]\u001b[A\n",
            "Training:  53%|█████▎    | 932/1772 [05:52<04:36,  3.03it/s, running training loss:  0.12136]\u001b[A\n",
            "Training:  53%|█████▎    | 932/1772 [05:53<04:36,  3.03it/s, running training loss:  1.02558]\u001b[A\n",
            "Training:  53%|█████▎    | 933/1772 [05:53<04:43,  2.96it/s, running training loss:  1.02558]\u001b[A\n",
            "Training:  53%|█████▎    | 933/1772 [05:53<04:43,  2.96it/s, running training loss:  1.17805]\u001b[A\n",
            "Training:  53%|█████▎    | 934/1772 [05:53<04:50,  2.89it/s, running training loss:  1.17805]\u001b[A\n",
            "Training:  53%|█████▎    | 934/1772 [05:54<04:50,  2.89it/s, running training loss:  0.90992]\u001b[A\n",
            "Training:  53%|█████▎    | 935/1772 [05:54<04:53,  2.85it/s, running training loss:  0.90992]\u001b[A\n",
            "Training:  53%|█████▎    | 935/1772 [05:54<04:53,  2.85it/s, running training loss:  1.49967]\u001b[A\n",
            "Training:  53%|█████▎    | 936/1772 [05:54<04:42,  2.96it/s, running training loss:  1.49967]\u001b[A\n",
            "Training:  53%|█████▎    | 936/1772 [05:54<04:42,  2.96it/s, running training loss:  1.01491]\u001b[A\n",
            "Training:  53%|█████▎    | 937/1772 [05:54<04:37,  3.01it/s, running training loss:  1.01491]\u001b[A\n",
            "Training:  53%|█████▎    | 937/1772 [05:55<04:37,  3.01it/s, running training loss:  1.21450]\u001b[A\n",
            "Training:  53%|█████▎    | 938/1772 [05:55<04:40,  2.97it/s, running training loss:  1.21450]\u001b[A\n",
            "Training:  53%|█████▎    | 938/1772 [05:55<04:40,  2.97it/s, running training loss:  1.48807]\u001b[A\n",
            "Training:  53%|█████▎    | 939/1772 [05:55<04:54,  2.83it/s, running training loss:  1.48807]\u001b[A\n",
            "Training:  53%|█████▎    | 939/1772 [05:55<04:54,  2.83it/s, running training loss:  0.80102]\u001b[A\n",
            "Training:  53%|█████▎    | 940/1772 [05:55<04:28,  3.09it/s, running training loss:  0.80102]\u001b[A\n",
            "Training:  53%|█████▎    | 940/1772 [05:55<04:28,  3.09it/s, running training loss:  1.00360]\u001b[A\n",
            "Training:  53%|█████▎    | 941/1772 [05:55<04:23,  3.16it/s, running training loss:  1.00360]\u001b[A\n",
            "Training:  53%|█████▎    | 941/1772 [05:56<04:23,  3.16it/s, running training loss:  1.01796]\u001b[A\n",
            "Training:  53%|█████▎    | 942/1772 [05:56<04:12,  3.29it/s, running training loss:  1.01796]\u001b[A\n",
            "Training:  53%|█████▎    | 942/1772 [05:56<04:12,  3.29it/s, running training loss:  1.05199]\u001b[A\n",
            "Training:  53%|█████▎    | 943/1772 [05:56<04:13,  3.27it/s, running training loss:  1.05199]\u001b[A\n",
            "Training:  53%|█████▎    | 943/1772 [05:56<04:13,  3.27it/s, running training loss:  1.02888]\u001b[A\n",
            "Training:  53%|█████▎    | 944/1772 [05:56<04:18,  3.21it/s, running training loss:  1.02888]\u001b[A\n",
            "Training:  53%|█████▎    | 944/1772 [05:57<04:18,  3.21it/s, running training loss:  0.85585]\u001b[A\n",
            "Training:  53%|█████▎    | 945/1772 [05:57<04:49,  2.85it/s, running training loss:  0.85585]\u001b[A\n",
            "Training:  53%|█████▎    | 945/1772 [05:57<04:49,  2.85it/s, running training loss:  0.95982]\u001b[A\n",
            "Training:  53%|█████▎    | 946/1772 [05:57<04:33,  3.02it/s, running training loss:  0.95982]\u001b[A\n",
            "Training:  53%|█████▎    | 946/1772 [05:57<04:33,  3.02it/s, running training loss:  0.87057]\u001b[A\n",
            "Training:  53%|█████▎    | 947/1772 [05:57<04:43,  2.91it/s, running training loss:  0.87057]\u001b[A\n",
            "Training:  53%|█████▎    | 947/1772 [05:58<04:43,  2.91it/s, running training loss:  1.00020]\u001b[A\n",
            "Training:  53%|█████▎    | 948/1772 [05:58<05:22,  2.56it/s, running training loss:  1.00020]\u001b[A\n",
            "Training:  53%|█████▎    | 948/1772 [05:58<05:22,  2.56it/s, running training loss:  0.92244]\u001b[A\n",
            "Training:  54%|█████▎    | 949/1772 [05:58<04:46,  2.87it/s, running training loss:  0.92244]\u001b[A\n",
            "Training:  54%|█████▎    | 949/1772 [05:59<04:46,  2.87it/s, running training loss:  0.96187]\u001b[A\n",
            "Training:  54%|█████▎    | 950/1772 [05:59<05:03,  2.71it/s, running training loss:  0.96187]\u001b[A\n",
            "Training:  54%|█████▎    | 950/1772 [05:59<05:03,  2.71it/s, running training loss:  1.03514]\u001b[A\n",
            "Training:  54%|█████▎    | 951/1772 [05:59<05:36,  2.44it/s, running training loss:  1.03514]\u001b[A\n",
            "Training:  54%|█████▎    | 951/1772 [06:00<05:36,  2.44it/s, running training loss:  0.96019]\u001b[A\n",
            "Training:  54%|█████▎    | 952/1772 [06:00<05:24,  2.53it/s, running training loss:  0.96019]\u001b[A\n",
            "Training:  54%|█████▎    | 952/1772 [06:00<05:24,  2.53it/s, running training loss:  0.86191]\u001b[A\n",
            "Training:  54%|█████▍    | 953/1772 [06:00<05:16,  2.59it/s, running training loss:  0.86191]\u001b[A\n",
            "Training:  54%|█████▍    | 953/1772 [06:00<05:16,  2.59it/s, running training loss:  0.97789]\u001b[A\n",
            "Training:  54%|█████▍    | 954/1772 [06:00<04:55,  2.77it/s, running training loss:  0.97789]\u001b[A\n",
            "Training:  54%|█████▍    | 954/1772 [06:00<04:55,  2.77it/s, running training loss:  1.00010]\u001b[A\n",
            "Training:  54%|█████▍    | 955/1772 [06:00<04:37,  2.94it/s, running training loss:  1.00010]\u001b[A\n",
            "Training:  54%|█████▍    | 955/1772 [06:01<04:37,  2.94it/s, running training loss:  1.03438]\u001b[A\n",
            "Training:  54%|█████▍    | 956/1772 [06:01<04:52,  2.79it/s, running training loss:  1.03438]\u001b[A\n",
            "Training:  54%|█████▍    | 956/1772 [06:01<04:52,  2.79it/s, running training loss:  1.13682]\u001b[A\n",
            "Training:  54%|█████▍    | 957/1772 [06:01<04:35,  2.96it/s, running training loss:  1.13682]\u001b[A\n",
            "Training:  54%|█████▍    | 957/1772 [06:02<04:35,  2.96it/s, running training loss:  1.17499]\u001b[A\n",
            "Training:  54%|█████▍    | 958/1772 [06:02<04:52,  2.78it/s, running training loss:  1.17499]\u001b[A\n",
            "Training:  54%|█████▍    | 958/1772 [06:02<04:52,  2.78it/s, running training loss:  0.92002]\u001b[A\n",
            "Training:  54%|█████▍    | 959/1772 [06:02<04:30,  3.00it/s, running training loss:  0.92002]\u001b[A\n",
            "Training:  54%|█████▍    | 959/1772 [06:02<04:30,  3.00it/s, running training loss:  0.91784]\u001b[A\n",
            "Training:  54%|█████▍    | 960/1772 [06:02<04:10,  3.24it/s, running training loss:  0.91784]\u001b[A\n",
            "Training:  54%|█████▍    | 960/1772 [06:03<04:10,  3.24it/s, running training loss:  0.80168]\u001b[A\n",
            "Training:  54%|█████▍    | 961/1772 [06:03<04:45,  2.84it/s, running training loss:  0.80168]\u001b[A\n",
            "Training:  54%|█████▍    | 961/1772 [06:03<04:45,  2.84it/s, running training loss:  1.01897]\u001b[A\n",
            "Training:  54%|█████▍    | 962/1772 [06:03<04:44,  2.85it/s, running training loss:  1.01897]\u001b[A\n",
            "Training:  54%|█████▍    | 962/1772 [06:03<04:44,  2.85it/s, running training loss:  1.00521]\u001b[A\n",
            "Training:  54%|█████▍    | 963/1772 [06:03<04:54,  2.74it/s, running training loss:  1.00521]\u001b[A\n",
            "Training:  54%|█████▍    | 963/1772 [06:04<04:54,  2.74it/s, running training loss:  0.98972]\u001b[A\n",
            "Training:  54%|█████▍    | 964/1772 [06:04<04:44,  2.84it/s, running training loss:  0.98972]\u001b[A\n",
            "Training:  54%|█████▍    | 964/1772 [06:04<04:44,  2.84it/s, running training loss:  0.90744]\u001b[A\n",
            "Training:  54%|█████▍    | 965/1772 [06:04<04:30,  2.98it/s, running training loss:  0.90744]\u001b[A\n",
            "Training:  54%|█████▍    | 965/1772 [06:04<04:30,  2.98it/s, running training loss:  0.84826]\u001b[A\n",
            "Training:  55%|█████▍    | 966/1772 [06:04<04:13,  3.17it/s, running training loss:  0.84826]\u001b[A\n",
            "Training:  55%|█████▍    | 966/1772 [06:04<04:13,  3.17it/s, running training loss:  0.89151]\u001b[A\n",
            "Training:  55%|█████▍    | 967/1772 [06:05<04:12,  3.18it/s, running training loss:  0.89151]\u001b[A\n",
            "Training:  55%|█████▍    | 967/1772 [06:05<04:12,  3.18it/s, running training loss:  1.07286]\u001b[A\n",
            "Training:  55%|█████▍    | 968/1772 [06:05<04:22,  3.07it/s, running training loss:  1.07286]\u001b[A\n",
            "Training:  55%|█████▍    | 968/1772 [06:05<04:22,  3.07it/s, running training loss:  1.03601]\u001b[A\n",
            "Training:  55%|█████▍    | 969/1772 [06:05<04:28,  3.00it/s, running training loss:  1.03601]\u001b[A\n",
            "Training:  55%|█████▍    | 969/1772 [06:06<04:28,  3.00it/s, running training loss:  0.94094]\u001b[A\n",
            "Training:  55%|█████▍    | 970/1772 [06:06<04:20,  3.08it/s, running training loss:  0.94094]\u001b[A\n",
            "Training:  55%|█████▍    | 970/1772 [06:06<04:20,  3.08it/s, running training loss:  0.86539]\u001b[A\n",
            "Training:  55%|█████▍    | 971/1772 [06:06<04:09,  3.21it/s, running training loss:  0.86539]\u001b[A\n",
            "Training:  55%|█████▍    | 971/1772 [06:06<04:09,  3.21it/s, running training loss:  0.95987]\u001b[A\n",
            "Training:  55%|█████▍    | 972/1772 [06:06<04:07,  3.23it/s, running training loss:  0.95987]\u001b[A\n",
            "Training:  55%|█████▍    | 972/1772 [06:07<04:07,  3.23it/s, running training loss:  1.04857]\u001b[A\n",
            "Training:  55%|█████▍    | 973/1772 [06:07<04:44,  2.81it/s, running training loss:  1.04857]\u001b[A\n",
            "Training:  55%|█████▍    | 973/1772 [06:07<04:44,  2.81it/s, running training loss:  1.04083]\u001b[A\n",
            "Training:  55%|█████▍    | 974/1772 [06:07<04:37,  2.88it/s, running training loss:  1.04083]\u001b[A\n",
            "Training:  55%|█████▍    | 974/1772 [06:07<04:37,  2.88it/s, running training loss:  0.97360]\u001b[A\n",
            "Training:  55%|█████▌    | 975/1772 [06:07<04:32,  2.93it/s, running training loss:  0.97360]\u001b[A\n",
            "Training:  55%|█████▌    | 975/1772 [06:08<04:32,  2.93it/s, running training loss:  1.12423]\u001b[A\n",
            "Training:  55%|█████▌    | 976/1772 [06:08<04:25,  2.99it/s, running training loss:  1.12423]\u001b[A\n",
            "Training:  55%|█████▌    | 976/1772 [06:08<04:25,  2.99it/s, running training loss:  1.00881]\u001b[A\n",
            "Training:  55%|█████▌    | 977/1772 [06:08<04:10,  3.18it/s, running training loss:  1.00881]\u001b[A\n",
            "Training:  55%|█████▌    | 977/1772 [06:08<04:10,  3.18it/s, running training loss:  1.16505]\u001b[A\n",
            "Training:  55%|█████▌    | 978/1772 [06:08<04:03,  3.26it/s, running training loss:  1.16505]\u001b[A\n",
            "Training:  55%|█████▌    | 978/1772 [06:08<04:03,  3.26it/s, running training loss:  0.98584]\u001b[A\n",
            "Training:  55%|█████▌    | 979/1772 [06:08<04:11,  3.16it/s, running training loss:  0.98584]\u001b[A\n",
            "Training:  55%|█████▌    | 979/1772 [06:09<04:11,  3.16it/s, running training loss:  0.85022]\u001b[A\n",
            "Training:  55%|█████▌    | 980/1772 [06:09<04:16,  3.09it/s, running training loss:  0.85022]\u001b[A\n",
            "Training:  55%|█████▌    | 980/1772 [06:09<04:16,  3.09it/s, running training loss:  0.95182]\u001b[A\n",
            "Training:  55%|█████▌    | 981/1772 [06:09<04:14,  3.11it/s, running training loss:  0.95182]\u001b[A\n",
            "Training:  55%|█████▌    | 981/1772 [06:09<04:14,  3.11it/s, running training loss:  0.85857]\u001b[A\n",
            "Training:  55%|█████▌    | 982/1772 [06:09<04:10,  3.15it/s, running training loss:  0.85857]\u001b[A\n",
            "Training:  55%|█████▌    | 982/1772 [06:10<04:10,  3.15it/s, running training loss:  0.88879]\u001b[A\n",
            "Training:  55%|█████▌    | 983/1772 [06:10<04:00,  3.29it/s, running training loss:  0.88879]\u001b[A\n",
            "Training:  55%|█████▌    | 983/1772 [06:10<04:00,  3.29it/s, running training loss:  0.95469]\u001b[A\n",
            "Training:  56%|█████▌    | 984/1772 [06:10<04:09,  3.16it/s, running training loss:  0.95469]\u001b[A\n",
            "Training:  56%|█████▌    | 984/1772 [06:10<04:09,  3.16it/s, running training loss:  0.95254]\u001b[A\n",
            "Training:  56%|█████▌    | 985/1772 [06:10<04:20,  3.02it/s, running training loss:  0.95254]\u001b[A\n",
            "Training:  56%|█████▌    | 985/1772 [06:11<04:20,  3.02it/s, running training loss:  0.91132]\u001b[A\n",
            "Training:  56%|█████▌    | 986/1772 [06:11<04:12,  3.12it/s, running training loss:  0.91132]\u001b[A\n",
            "Training:  56%|█████▌    | 986/1772 [06:11<04:12,  3.12it/s, running training loss:  0.90240]\u001b[A\n",
            "Training:  56%|█████▌    | 987/1772 [06:11<04:17,  3.04it/s, running training loss:  0.90240]\u001b[A\n",
            "Training:  56%|█████▌    | 987/1772 [06:11<04:17,  3.04it/s, running training loss:  0.98834]\u001b[A\n",
            "Training:  56%|█████▌    | 988/1772 [06:11<04:21,  3.00it/s, running training loss:  0.98834]\u001b[A\n",
            "Training:  56%|█████▌    | 988/1772 [06:12<04:21,  3.00it/s, running training loss:  0.91486]\u001b[A\n",
            "Training:  56%|█████▌    | 989/1772 [06:12<04:13,  3.08it/s, running training loss:  0.91486]\u001b[A\n",
            "Training:  56%|█████▌    | 989/1772 [06:12<04:13,  3.08it/s, running training loss:  0.98395]\u001b[A\n",
            "Training:  56%|█████▌    | 990/1772 [06:12<04:16,  3.05it/s, running training loss:  0.98395]\u001b[A\n",
            "Training:  56%|█████▌    | 990/1772 [06:12<04:16,  3.05it/s, running training loss:  0.93231]\u001b[A\n",
            "Training:  56%|█████▌    | 991/1772 [06:12<04:04,  3.20it/s, running training loss:  0.93231]\u001b[A\n",
            "Training:  56%|█████▌    | 991/1772 [06:13<04:04,  3.20it/s, running training loss:  1.01594]\u001b[A\n",
            "Training:  56%|█████▌    | 992/1772 [06:13<03:59,  3.25it/s, running training loss:  1.01594]\u001b[A\n",
            "Training:  56%|█████▌    | 992/1772 [06:13<03:59,  3.25it/s, running training loss:  0.82349]\u001b[A\n",
            "Training:  56%|█████▌    | 993/1772 [06:13<04:02,  3.22it/s, running training loss:  0.82349]\u001b[A\n",
            "Training:  56%|█████▌    | 993/1772 [06:13<04:02,  3.22it/s, running training loss:  0.96508]\u001b[A\n",
            "Training:  56%|█████▌    | 994/1772 [06:13<03:59,  3.25it/s, running training loss:  0.96508]\u001b[A\n",
            "Training:  56%|█████▌    | 994/1772 [06:14<03:59,  3.25it/s, running training loss:  0.85351]\u001b[A\n",
            "Training:  56%|█████▌    | 995/1772 [06:14<04:25,  2.92it/s, running training loss:  0.85351]\u001b[A\n",
            "Training:  56%|█████▌    | 995/1772 [06:14<04:25,  2.92it/s, running training loss:  1.05585]\u001b[A\n",
            "Training:  56%|█████▌    | 996/1772 [06:14<04:20,  2.98it/s, running training loss:  1.05585]\u001b[A\n",
            "Training:  56%|█████▌    | 996/1772 [06:14<04:20,  2.98it/s, running training loss:  1.24188]\u001b[A\n",
            "Training:  56%|█████▋    | 997/1772 [06:14<04:43,  2.73it/s, running training loss:  1.24188]\u001b[A\n",
            "Training:  56%|█████▋    | 997/1772 [06:15<04:43,  2.73it/s, running training loss:  1.39608]\u001b[A\n",
            "Training:  56%|█████▋    | 998/1772 [06:15<04:35,  2.81it/s, running training loss:  1.39608]\u001b[A\n",
            "Training:  56%|█████▋    | 998/1772 [06:15<04:35,  2.81it/s, running training loss:  1.34223]\u001b[A\n",
            "Training:  56%|█████▋    | 999/1772 [06:15<04:41,  2.74it/s, running training loss:  1.34223]\u001b[A\n",
            "Training:  56%|█████▋    | 999/1772 [06:15<04:41,  2.74it/s, running training loss:  1.30792]\u001b[A\n",
            "Training:  56%|█████▋    | 1000/1772 [06:15<04:21,  2.95it/s, running training loss:  1.30792]\u001b[A\n",
            "Training:  56%|█████▋    | 1000/1772 [06:16<04:21,  2.95it/s, running training loss:  1.11924]\u001b[A\n",
            "Training:  56%|█████▋    | 1001/1772 [06:16<04:27,  2.89it/s, running training loss:  1.11924]\u001b[A\n",
            "Training:  56%|█████▋    | 1001/1772 [06:16<04:27,  2.89it/s, running training loss:  1.07847]\u001b[A\n",
            "Training:  57%|█████▋    | 1002/1772 [06:16<04:28,  2.87it/s, running training loss:  1.07847]\u001b[A\n",
            "Training:  57%|█████▋    | 1002/1772 [06:16<04:28,  2.87it/s, running training loss:  0.88658]\u001b[A\n",
            "Training:  57%|█████▋    | 1003/1772 [06:16<04:27,  2.88it/s, running training loss:  0.88658]\u001b[A\n",
            "Training:  57%|█████▋    | 1003/1772 [06:17<04:27,  2.88it/s, running training loss:  1.05267]\u001b[A\n",
            "Training:  57%|█████▋    | 1004/1772 [06:17<04:21,  2.94it/s, running training loss:  1.05267]\u001b[A\n",
            "Training:  57%|█████▋    | 1004/1772 [06:17<04:21,  2.94it/s, running training loss:  1.26464]\u001b[A\n",
            "Training:  57%|█████▋    | 1005/1772 [06:17<04:23,  2.91it/s, running training loss:  1.26464]\u001b[A\n",
            "Training:  57%|█████▋    | 1005/1772 [06:17<04:23,  2.91it/s, running training loss:  1.05193]\u001b[A\n",
            "Training:  57%|█████▋    | 1006/1772 [06:17<04:25,  2.89it/s, running training loss:  1.05193]\u001b[A\n",
            "Training:  57%|█████▋    | 1006/1772 [06:18<04:25,  2.89it/s, running training loss:  1.22251]\u001b[A\n",
            "Training:  57%|█████▋    | 1007/1772 [06:18<04:17,  2.97it/s, running training loss:  1.22251]\u001b[A\n",
            "Training:  57%|█████▋    | 1007/1772 [06:18<04:17,  2.97it/s, running training loss:  1.30021]\u001b[A\n",
            "Training:  57%|█████▋    | 1008/1772 [06:18<04:02,  3.16it/s, running training loss:  1.30021]\u001b[A\n",
            "Training:  57%|█████▋    | 1008/1772 [06:18<04:02,  3.16it/s, running training loss:  1.22198]\u001b[A\n",
            "Training:  57%|█████▋    | 1009/1772 [06:18<04:20,  2.92it/s, running training loss:  1.22198]\u001b[A\n",
            "Training:  57%|█████▋    | 1009/1772 [06:19<04:20,  2.92it/s, running training loss:  0.87625]\u001b[A\n",
            "Training:  57%|█████▋    | 1010/1772 [06:19<04:13,  3.00it/s, running training loss:  0.87625]\u001b[A\n",
            "Training:  57%|█████▋    | 1010/1772 [06:19<04:13,  3.00it/s, running training loss:  0.93866]\u001b[A\n",
            "Training:  57%|█████▋    | 1011/1772 [06:19<04:04,  3.11it/s, running training loss:  0.93866]\u001b[A\n",
            "Training:  57%|█████▋    | 1011/1772 [06:19<04:04,  3.11it/s, running training loss:  1.05316]\u001b[A\n",
            "Training:  57%|█████▋    | 1012/1772 [06:19<04:00,  3.16it/s, running training loss:  1.05316]\u001b[A\n",
            "Training:  57%|█████▋    | 1012/1772 [06:20<04:00,  3.16it/s, running training loss:  0.95208]\u001b[A\n",
            "Training:  57%|█████▋    | 1013/1772 [06:20<04:08,  3.06it/s, running training loss:  0.95208]\u001b[A\n",
            "Training:  57%|█████▋    | 1013/1772 [06:20<04:08,  3.06it/s, running training loss:  1.00193]\u001b[A\n",
            "Training:  57%|█████▋    | 1014/1772 [06:20<04:11,  3.01it/s, running training loss:  1.00193]\u001b[A\n",
            "Training:  57%|█████▋    | 1014/1772 [06:20<04:11,  3.01it/s, running training loss:  1.01389]\u001b[A\n",
            "Training:  57%|█████▋    | 1015/1772 [06:20<04:03,  3.11it/s, running training loss:  1.01389]\u001b[A\n",
            "Training:  57%|█████▋    | 1015/1772 [06:21<04:03,  3.11it/s, running training loss:  1.13271]\u001b[A\n",
            "Training:  57%|█████▋    | 1016/1772 [06:21<04:01,  3.14it/s, running training loss:  1.13271]\u001b[A\n",
            "Training:  57%|█████▋    | 1016/1772 [06:21<04:01,  3.14it/s, running training loss:  1.14799]\u001b[A\n",
            "Training:  57%|█████▋    | 1017/1772 [06:21<04:06,  3.07it/s, running training loss:  1.14799]\u001b[A\n",
            "Training:  57%|█████▋    | 1017/1772 [06:21<04:06,  3.07it/s, running training loss:  0.94129]\u001b[A\n",
            "Training:  57%|█████▋    | 1018/1772 [06:21<04:04,  3.09it/s, running training loss:  0.94129]\u001b[A\n",
            "Training:  57%|█████▋    | 1018/1772 [06:22<04:04,  3.09it/s, running training loss:  0.88771]\u001b[A\n",
            "Training:  58%|█████▊    | 1019/1772 [06:22<04:06,  3.05it/s, running training loss:  0.88771]\u001b[A\n",
            "Training:  58%|█████▊    | 1019/1772 [06:22<04:06,  3.05it/s, running training loss:  0.85784]\u001b[A\n",
            "Training:  58%|█████▊    | 1020/1772 [06:22<03:55,  3.19it/s, running training loss:  0.85784]\u001b[A\n",
            "Training:  58%|█████▊    | 1020/1772 [06:22<03:55,  3.19it/s, running training loss:  1.02785]\u001b[A\n",
            "Training:  58%|█████▊    | 1021/1772 [06:22<03:54,  3.21it/s, running training loss:  1.02785]\u001b[A\n",
            "Training:  58%|█████▊    | 1021/1772 [06:23<03:54,  3.21it/s, running training loss:  1.05146]\u001b[A\n",
            "Training:  58%|█████▊    | 1022/1772 [06:23<04:04,  3.06it/s, running training loss:  1.05146]\u001b[A\n",
            "Training:  58%|█████▊    | 1022/1772 [06:23<04:04,  3.06it/s, running training loss:  1.05266]\u001b[A\n",
            "Training:  58%|█████▊    | 1023/1772 [06:23<04:00,  3.11it/s, running training loss:  1.05266]\u001b[A\n",
            "Training:  58%|█████▊    | 1023/1772 [06:23<04:00,  3.11it/s, running training loss:  1.04982]\u001b[A\n",
            "Training:  58%|█████▊    | 1024/1772 [06:23<03:54,  3.19it/s, running training loss:  1.04982]\u001b[A\n",
            "Training:  58%|█████▊    | 1024/1772 [06:24<03:54,  3.19it/s, running training loss:  0.92050]\u001b[A\n",
            "Training:  58%|█████▊    | 1025/1772 [06:24<03:52,  3.21it/s, running training loss:  0.92050]\u001b[A\n",
            "Training:  58%|█████▊    | 1025/1772 [06:24<03:52,  3.21it/s, running training loss:  1.03198]\u001b[A\n",
            "Training:  58%|█████▊    | 1026/1772 [06:24<04:12,  2.96it/s, running training loss:  1.03198]\u001b[A\n",
            "Training:  58%|█████▊    | 1026/1772 [06:24<04:12,  2.96it/s, running training loss:  0.88529]\u001b[A\n",
            "Training:  58%|█████▊    | 1027/1772 [06:24<04:02,  3.07it/s, running training loss:  0.88529]\u001b[A\n",
            "Training:  58%|█████▊    | 1027/1772 [06:25<04:02,  3.07it/s, running training loss:  0.93717]\u001b[A\n",
            "Training:  58%|█████▊    | 1028/1772 [06:25<04:36,  2.69it/s, running training loss:  0.93717]\u001b[A\n",
            "Training:  58%|█████▊    | 1028/1772 [06:25<04:36,  2.69it/s, running training loss:  1.01763]\u001b[A\n",
            "Training:  58%|█████▊    | 1029/1772 [06:25<04:12,  2.94it/s, running training loss:  1.01763]\u001b[A\n",
            "Training:  58%|█████▊    | 1029/1772 [06:25<04:12,  2.94it/s, running training loss:  0.99311]\u001b[A\n",
            "Training:  58%|█████▊    | 1030/1772 [06:25<04:13,  2.93it/s, running training loss:  0.99311]\u001b[A\n",
            "Training:  58%|█████▊    | 1030/1772 [06:26<04:13,  2.93it/s, running training loss:  0.88512]\u001b[A\n",
            "Training:  58%|█████▊    | 1031/1772 [06:26<04:03,  3.05it/s, running training loss:  0.88512]\u001b[A\n",
            "Training:  58%|█████▊    | 1031/1772 [06:26<04:03,  3.05it/s, running training loss:  1.00406]\u001b[A\n",
            "Training:  58%|█████▊    | 1032/1772 [06:26<04:08,  2.97it/s, running training loss:  1.00406]\u001b[A\n",
            "Training:  58%|█████▊    | 1032/1772 [06:26<04:08,  2.97it/s, running training loss:  1.07609]\u001b[A\n",
            "Training:  58%|█████▊    | 1033/1772 [06:26<04:05,  3.01it/s, running training loss:  1.07609]\u001b[A\n",
            "Training:  58%|█████▊    | 1033/1772 [06:27<04:05,  3.01it/s, running training loss:  0.81926]\u001b[A\n",
            "Training:  58%|█████▊    | 1034/1772 [06:27<04:06,  3.00it/s, running training loss:  0.81926]\u001b[A\n",
            "Training:  58%|█████▊    | 1034/1772 [06:27<04:06,  3.00it/s, running training loss:  0.94597]\u001b[A\n",
            "Training:  58%|█████▊    | 1035/1772 [06:27<04:28,  2.75it/s, running training loss:  0.94597]\u001b[A\n",
            "Training:  58%|█████▊    | 1035/1772 [06:27<04:28,  2.75it/s, running training loss:  0.94334]\u001b[A\n",
            "Training:  58%|█████▊    | 1036/1772 [06:27<04:14,  2.89it/s, running training loss:  0.94334]\u001b[A\n",
            "Training:  58%|█████▊    | 1036/1772 [06:28<04:14,  2.89it/s, running training loss:  1.00685]\u001b[A\n",
            "Training:  59%|█████▊    | 1037/1772 [06:28<04:23,  2.79it/s, running training loss:  1.00685]\u001b[A\n",
            "Training:  59%|█████▊    | 1037/1772 [06:28<04:23,  2.79it/s, running training loss:  1.07902]\u001b[A\n",
            "Training:  59%|█████▊    | 1038/1772 [06:28<05:09,  2.37it/s, running training loss:  1.07902]\u001b[A\n",
            "Training:  59%|█████▊    | 1038/1772 [06:29<05:09,  2.37it/s, running training loss:  0.97330]\u001b[A\n",
            "Training:  59%|█████▊    | 1039/1772 [06:29<04:39,  2.62it/s, running training loss:  0.97330]\u001b[A\n",
            "Training:  59%|█████▊    | 1039/1772 [06:29<04:39,  2.62it/s, running training loss:  1.07620]\u001b[A\n",
            "Training:  59%|█████▊    | 1040/1772 [06:29<04:05,  2.99it/s, running training loss:  1.07620]\u001b[A\n",
            "Training:  59%|█████▊    | 1040/1772 [06:29<04:05,  2.99it/s, running training loss:  0.98080]\u001b[A\n",
            "Training:  59%|█████▊    | 1041/1772 [06:29<03:53,  3.13it/s, running training loss:  0.98080]\u001b[A\n",
            "Training:  59%|█████▊    | 1041/1772 [06:29<03:53,  3.13it/s, running training loss:  0.98503]\u001b[A\n",
            "Training:  59%|█████▉    | 1042/1772 [06:29<03:56,  3.09it/s, running training loss:  0.98503]\u001b[A\n",
            "Training:  59%|█████▉    | 1042/1772 [06:30<03:56,  3.09it/s, running training loss:  1.10421]\u001b[A\n",
            "Training:  59%|█████▉    | 1043/1772 [06:30<04:08,  2.94it/s, running training loss:  1.10421]\u001b[A\n",
            "Training:  59%|█████▉    | 1043/1772 [06:30<04:08,  2.94it/s, running training loss:  1.26601]\u001b[A\n",
            "Training:  59%|█████▉    | 1044/1772 [06:30<04:02,  3.00it/s, running training loss:  1.26601]\u001b[A\n",
            "Training:  59%|█████▉    | 1044/1772 [06:30<04:02,  3.00it/s, running training loss:  0.93109]\u001b[A\n",
            "Training:  59%|█████▉    | 1045/1772 [06:30<03:58,  3.05it/s, running training loss:  0.93109]\u001b[A\n",
            "Training:  59%|█████▉    | 1045/1772 [06:31<03:58,  3.05it/s, running training loss:  0.96043]\u001b[A\n",
            "Training:  59%|█████▉    | 1046/1772 [06:31<03:55,  3.09it/s, running training loss:  0.96043]\u001b[A\n",
            "Training:  59%|█████▉    | 1046/1772 [06:31<03:55,  3.09it/s, running training loss:  1.16380]\u001b[A\n",
            "Training:  59%|█████▉    | 1047/1772 [06:31<04:30,  2.68it/s, running training loss:  1.16380]\u001b[A\n",
            "Training:  59%|█████▉    | 1047/1772 [06:32<04:30,  2.68it/s, running training loss:  0.95926]\u001b[A\n",
            "Training:  59%|█████▉    | 1048/1772 [06:32<04:30,  2.68it/s, running training loss:  0.95926]\u001b[A\n",
            "Training:  59%|█████▉    | 1048/1772 [06:32<04:30,  2.68it/s, running training loss:  0.86717]\u001b[A\n",
            "Training:  59%|█████▉    | 1049/1772 [06:32<04:06,  2.93it/s, running training loss:  0.86717]\u001b[A\n",
            "Training:  59%|█████▉    | 1049/1772 [06:32<04:06,  2.93it/s, running training loss:  0.82037]\u001b[A\n",
            "Training:  59%|█████▉    | 1050/1772 [06:32<03:56,  3.05it/s, running training loss:  0.82037]\u001b[A\n",
            "Training:  59%|█████▉    | 1050/1772 [06:32<03:56,  3.05it/s, running training loss:  0.86276]\u001b[A\n",
            "Training:  59%|█████▉    | 1051/1772 [06:32<03:44,  3.21it/s, running training loss:  0.86276]\u001b[A\n",
            "Training:  59%|█████▉    | 1051/1772 [06:33<03:44,  3.21it/s, running training loss:  1.08120]\u001b[A\n",
            "Training:  59%|█████▉    | 1052/1772 [06:33<03:48,  3.15it/s, running training loss:  1.08120]\u001b[A\n",
            "Training:  59%|█████▉    | 1052/1772 [06:33<03:48,  3.15it/s, running training loss:  1.06014]\u001b[A\n",
            "Training:  59%|█████▉    | 1053/1772 [06:33<04:09,  2.89it/s, running training loss:  1.06014]\u001b[A\n",
            "Training:  59%|█████▉    | 1053/1772 [06:34<04:09,  2.89it/s, running training loss:  0.97922]\u001b[A\n",
            "Training:  59%|█████▉    | 1054/1772 [06:34<04:10,  2.87it/s, running training loss:  0.97922]\u001b[A\n",
            "Training:  59%|█████▉    | 1054/1772 [06:34<04:10,  2.87it/s, running training loss:  1.18904]\u001b[A\n",
            "Training:  60%|█████▉    | 1055/1772 [06:34<04:39,  2.56it/s, running training loss:  1.18904]\u001b[A\n",
            "Training:  60%|█████▉    | 1055/1772 [06:34<04:39,  2.56it/s, running training loss:  0.95761]\u001b[A\n",
            "Training:  60%|█████▉    | 1056/1772 [06:34<04:13,  2.83it/s, running training loss:  0.95761]\u001b[A\n",
            "Training:  60%|█████▉    | 1056/1772 [06:35<04:13,  2.83it/s, running training loss:  1.71811]\u001b[A\n",
            "Training:  60%|█████▉    | 1057/1772 [06:35<03:55,  3.03it/s, running training loss:  1.71811]\u001b[A\n",
            "Training:  60%|█████▉    | 1057/1772 [06:35<03:55,  3.03it/s, running training loss:  1.24858]\u001b[A\n",
            "Training:  60%|█████▉    | 1058/1772 [06:35<04:13,  2.82it/s, running training loss:  1.24858]\u001b[A\n",
            "Training:  60%|█████▉    | 1058/1772 [06:35<04:13,  2.82it/s, running training loss:  0.87285]\u001b[A\n",
            "Training:  60%|█████▉    | 1059/1772 [06:35<03:53,  3.05it/s, running training loss:  0.87285]\u001b[A\n",
            "Training:  60%|█████▉    | 1059/1772 [06:36<03:53,  3.05it/s, running training loss:  0.76611]\u001b[A\n",
            "Training:  60%|█████▉    | 1060/1772 [06:36<03:52,  3.07it/s, running training loss:  0.76611]\u001b[A\n",
            "Training:  60%|█████▉    | 1060/1772 [06:36<03:52,  3.07it/s, running training loss:  1.14596]\u001b[A\n",
            "Training:  60%|█████▉    | 1061/1772 [06:36<03:46,  3.13it/s, running training loss:  1.14596]\u001b[A\n",
            "Training:  60%|█████▉    | 1061/1772 [06:36<03:46,  3.13it/s, running training loss:  0.91151]\u001b[A\n",
            "Training:  60%|█████▉    | 1062/1772 [06:36<03:39,  3.23it/s, running training loss:  0.91151]\u001b[A\n",
            "Training:  60%|█████▉    | 1062/1772 [06:37<03:39,  3.23it/s, running training loss:  0.92759]\u001b[A\n",
            "Training:  60%|█████▉    | 1063/1772 [06:37<04:03,  2.91it/s, running training loss:  0.92759]\u001b[A\n",
            "Training:  60%|█████▉    | 1063/1772 [06:37<04:03,  2.91it/s, running training loss:  1.02524]\u001b[A\n",
            "Training:  60%|██████    | 1064/1772 [06:37<03:57,  2.98it/s, running training loss:  1.02524]\u001b[A\n",
            "Training:  60%|██████    | 1064/1772 [06:37<03:57,  2.98it/s, running training loss:  0.75544]\u001b[A\n",
            "Training:  60%|██████    | 1065/1772 [06:37<04:04,  2.90it/s, running training loss:  0.75544]\u001b[A\n",
            "Training:  60%|██████    | 1065/1772 [06:38<04:04,  2.90it/s, running training loss:  0.91836]\u001b[A\n",
            "Training:  60%|██████    | 1066/1772 [06:38<03:45,  3.14it/s, running training loss:  0.91836]\u001b[A\n",
            "Training:  60%|██████    | 1066/1772 [06:38<03:45,  3.14it/s, running training loss:  1.30092]\u001b[A\n",
            "Training:  60%|██████    | 1067/1772 [06:38<03:45,  3.12it/s, running training loss:  1.30092]\u001b[A\n",
            "Training:  60%|██████    | 1067/1772 [06:38<03:45,  3.12it/s, running training loss:  0.95984]\u001b[A\n",
            "Training:  60%|██████    | 1068/1772 [06:38<03:51,  3.04it/s, running training loss:  0.95984]\u001b[A\n",
            "Training:  60%|██████    | 1068/1772 [06:39<03:51,  3.04it/s, running training loss:  1.19791]\u001b[A\n",
            "Training:  60%|██████    | 1069/1772 [06:39<04:30,  2.60it/s, running training loss:  1.19791]\u001b[A\n",
            "Training:  60%|██████    | 1069/1772 [06:39<04:30,  2.60it/s, running training loss:  1.87362]\u001b[A\n",
            "Training:  60%|██████    | 1070/1772 [06:39<04:17,  2.73it/s, running training loss:  1.87362]\u001b[A\n",
            "Training:  60%|██████    | 1070/1772 [06:39<04:17,  2.73it/s, running training loss:  1.11027]\u001b[A\n",
            "Training:  60%|██████    | 1071/1772 [06:39<04:12,  2.78it/s, running training loss:  1.11027]\u001b[A\n",
            "Training:  60%|██████    | 1071/1772 [06:40<04:12,  2.78it/s, running training loss:  1.97330]\u001b[A\n",
            "Training:  60%|██████    | 1072/1772 [06:40<04:17,  2.72it/s, running training loss:  1.97330]\u001b[A\n",
            "Training:  60%|██████    | 1072/1772 [06:40<04:17,  2.72it/s, running training loss:  1.73786]\u001b[A\n",
            "Training:  61%|██████    | 1073/1772 [06:40<04:04,  2.86it/s, running training loss:  1.73786]\u001b[A\n",
            "Training:  61%|██████    | 1073/1772 [06:41<04:04,  2.86it/s, running training loss:  1.12259]\u001b[A\n",
            "Training:  61%|██████    | 1074/1772 [06:41<04:16,  2.72it/s, running training loss:  1.12259]\u001b[A\n",
            "Training:  61%|██████    | 1074/1772 [06:41<04:16,  2.72it/s, running training loss:  1.43007]\u001b[A\n",
            "Training:  61%|██████    | 1075/1772 [06:41<03:59,  2.91it/s, running training loss:  1.43007]\u001b[A\n",
            "Training:  61%|██████    | 1075/1772 [06:41<03:59,  2.91it/s, running training loss:  1.41397]\u001b[A\n",
            "Training:  61%|██████    | 1076/1772 [06:41<04:07,  2.81it/s, running training loss:  1.41397]\u001b[A\n",
            "Training:  61%|██████    | 1076/1772 [06:41<04:07,  2.81it/s, running training loss:  1.24710]\u001b[A\n",
            "Training:  61%|██████    | 1077/1772 [06:41<03:47,  3.06it/s, running training loss:  1.24710]\u001b[A\n",
            "Training:  61%|██████    | 1077/1772 [06:42<03:47,  3.06it/s, running training loss:  1.13145]\u001b[A\n",
            "Training:  61%|██████    | 1078/1772 [06:42<03:54,  2.96it/s, running training loss:  1.13145]\u001b[A\n",
            "Training:  61%|██████    | 1078/1772 [06:42<03:54,  2.96it/s, running training loss:  1.10203]\u001b[A\n",
            "Training:  61%|██████    | 1079/1772 [06:42<04:00,  2.88it/s, running training loss:  1.10203]\u001b[A\n",
            "Training:  61%|██████    | 1079/1772 [06:43<04:00,  2.88it/s, running training loss:  1.02567]\u001b[A\n",
            "Training:  61%|██████    | 1080/1772 [06:43<04:06,  2.81it/s, running training loss:  1.02567]\u001b[A\n",
            "Training:  61%|██████    | 1080/1772 [06:43<04:06,  2.81it/s, running training loss:  0.85136]\u001b[A\n",
            "Training:  61%|██████    | 1081/1772 [06:43<04:35,  2.51it/s, running training loss:  0.85136]\u001b[A\n",
            "Training:  61%|██████    | 1081/1772 [06:43<04:35,  2.51it/s, running training loss:  0.83354]\u001b[A\n",
            "Training:  61%|██████    | 1082/1772 [06:43<04:22,  2.63it/s, running training loss:  0.83354]\u001b[A\n",
            "Training:  61%|██████    | 1082/1772 [06:44<04:22,  2.63it/s, running training loss:  0.79515]\u001b[A\n",
            "Training:  61%|██████    | 1083/1772 [06:44<04:09,  2.76it/s, running training loss:  0.79515]\u001b[A\n",
            "Training:  61%|██████    | 1083/1772 [06:44<04:09,  2.76it/s, running training loss:  0.78333]\u001b[A\n",
            "Training:  61%|██████    | 1084/1772 [06:44<04:41,  2.44it/s, running training loss:  0.78333]\u001b[A\n",
            "Training:  61%|██████    | 1084/1772 [06:45<04:41,  2.44it/s, running training loss:  0.86883]\u001b[A\n",
            "Training:  61%|██████    | 1085/1772 [06:45<04:56,  2.32it/s, running training loss:  0.86883]\u001b[A\n",
            "Training:  61%|██████    | 1085/1772 [06:45<04:56,  2.32it/s, running training loss:  0.79442]\u001b[A\n",
            "Training:  61%|██████▏   | 1086/1772 [06:45<04:35,  2.49it/s, running training loss:  0.79442]\u001b[A\n",
            "Training:  61%|██████▏   | 1086/1772 [06:46<04:35,  2.49it/s, running training loss:  0.96266]\u001b[A\n",
            "Training:  61%|██████▏   | 1087/1772 [06:46<04:57,  2.30it/s, running training loss:  0.96266]\u001b[A\n",
            "Training:  61%|██████▏   | 1087/1772 [06:46<04:57,  2.30it/s, running training loss:  0.91382]\u001b[A\n",
            "Training:  61%|██████▏   | 1088/1772 [06:46<04:28,  2.54it/s, running training loss:  0.91382]\u001b[A\n",
            "Training:  61%|██████▏   | 1088/1772 [06:46<04:28,  2.54it/s, running training loss:  1.04352]\u001b[A\n",
            "Training:  61%|██████▏   | 1089/1772 [06:46<04:03,  2.81it/s, running training loss:  1.04352]\u001b[A\n",
            "Training:  61%|██████▏   | 1089/1772 [06:46<04:03,  2.81it/s, running training loss:  0.95672]\u001b[A\n",
            "Training:  62%|██████▏   | 1090/1772 [06:46<03:49,  2.97it/s, running training loss:  0.95672]\u001b[A\n",
            "Training:  62%|██████▏   | 1090/1772 [06:47<03:49,  2.97it/s, running training loss:  1.02611]\u001b[A\n",
            "Training:  62%|██████▏   | 1091/1772 [06:47<03:46,  3.00it/s, running training loss:  1.02611]\u001b[A\n",
            "Training:  62%|██████▏   | 1091/1772 [06:47<03:46,  3.00it/s, running training loss:  0.81720]\u001b[A\n",
            "Training:  62%|██████▏   | 1092/1772 [06:47<03:55,  2.89it/s, running training loss:  0.81720]\u001b[A\n",
            "Training:  62%|██████▏   | 1092/1772 [06:48<03:55,  2.89it/s, running training loss:  1.06417]\u001b[A\n",
            "Training:  62%|██████▏   | 1093/1772 [06:48<04:25,  2.56it/s, running training loss:  1.06417]\u001b[A\n",
            "Training:  62%|██████▏   | 1093/1772 [06:48<04:25,  2.56it/s, running training loss:  0.95480]\u001b[A\n",
            "Training:  62%|██████▏   | 1094/1772 [06:48<04:30,  2.51it/s, running training loss:  0.95480]\u001b[A\n",
            "Training:  62%|██████▏   | 1094/1772 [06:48<04:30,  2.51it/s, running training loss:  0.82403]\u001b[A\n",
            "Training:  62%|██████▏   | 1095/1772 [06:48<04:10,  2.71it/s, running training loss:  0.82403]\u001b[A\n",
            "Training:  62%|██████▏   | 1095/1772 [06:49<04:10,  2.71it/s, running training loss:  0.83010]\u001b[A\n",
            "Training:  62%|██████▏   | 1096/1772 [06:49<04:25,  2.55it/s, running training loss:  0.83010]\u001b[A\n",
            "Training:  62%|██████▏   | 1096/1772 [06:49<04:25,  2.55it/s, running training loss:  0.94347]\u001b[A\n",
            "Training:  62%|██████▏   | 1097/1772 [06:49<04:03,  2.77it/s, running training loss:  0.94347]\u001b[A\n",
            "Training:  62%|██████▏   | 1097/1772 [06:49<04:03,  2.77it/s, running training loss:  1.08813]\u001b[A\n",
            "Training:  62%|██████▏   | 1098/1772 [06:50<04:18,  2.60it/s, running training loss:  1.08813]\u001b[A\n",
            "Training:  62%|██████▏   | 1098/1772 [06:50<04:18,  2.60it/s, running training loss:  0.97058]\u001b[A\n",
            "Training:  62%|██████▏   | 1099/1772 [06:50<04:08,  2.70it/s, running training loss:  0.97058]\u001b[A\n",
            "Training:  62%|██████▏   | 1099/1772 [06:50<04:08,  2.70it/s, running training loss:  0.98810]\u001b[A\n",
            "Training:  62%|██████▏   | 1100/1772 [06:50<04:05,  2.74it/s, running training loss:  0.98810]\u001b[A\n",
            "Training:  62%|██████▏   | 1100/1772 [06:51<04:05,  2.74it/s, running training loss:  1.14473]\u001b[A\n",
            "Training:  62%|██████▏   | 1101/1772 [06:51<04:04,  2.75it/s, running training loss:  1.14473]\u001b[A\n",
            "Training:  62%|██████▏   | 1101/1772 [06:51<04:04,  2.75it/s, running training loss:  0.86618]\u001b[A\n",
            "Training:  62%|██████▏   | 1102/1772 [06:51<04:20,  2.57it/s, running training loss:  0.86618]\u001b[A\n",
            "Training:  62%|██████▏   | 1102/1772 [06:51<04:20,  2.57it/s, running training loss:  0.76449]\u001b[A\n",
            "Training:  62%|██████▏   | 1103/1772 [06:51<04:06,  2.71it/s, running training loss:  0.76449]\u001b[A\n",
            "Training:  62%|██████▏   | 1103/1772 [06:52<04:06,  2.71it/s, running training loss:  0.76595]\u001b[A\n",
            "Training:  62%|██████▏   | 1104/1772 [06:52<03:54,  2.84it/s, running training loss:  0.76595]\u001b[A\n",
            "Training:  62%|██████▏   | 1104/1772 [06:52<03:54,  2.84it/s, running training loss:  1.11061]\u001b[A\n",
            "Training:  62%|██████▏   | 1105/1772 [06:52<04:00,  2.78it/s, running training loss:  1.11061]\u001b[A\n",
            "Training:  62%|██████▏   | 1105/1772 [06:52<04:00,  2.78it/s, running training loss:  1.23962]\u001b[A\n",
            "Training:  62%|██████▏   | 1106/1772 [06:52<03:41,  3.01it/s, running training loss:  1.23962]\u001b[A\n",
            "Training:  62%|██████▏   | 1106/1772 [06:53<03:41,  3.01it/s, running training loss:  0.92428]\u001b[A\n",
            "Training:  62%|██████▏   | 1107/1772 [06:53<03:51,  2.87it/s, running training loss:  0.92428]\u001b[A\n",
            "Training:  62%|██████▏   | 1107/1772 [06:53<03:51,  2.87it/s, running training loss:  0.92530]\u001b[A\n",
            "Training:  63%|██████▎   | 1108/1772 [06:53<03:46,  2.93it/s, running training loss:  0.92530]\u001b[A\n",
            "Training:  63%|██████▎   | 1108/1772 [06:53<03:46,  2.93it/s, running training loss:  1.11021]\u001b[A\n",
            "Training:  63%|██████▎   | 1109/1772 [06:53<03:40,  3.00it/s, running training loss:  1.11021]\u001b[A\n",
            "Training:  63%|██████▎   | 1109/1772 [06:54<03:40,  3.00it/s, running training loss:  0.81624]\u001b[A\n",
            "Training:  63%|██████▎   | 1110/1772 [06:54<04:00,  2.76it/s, running training loss:  0.81624]\u001b[A\n",
            "Training:  63%|██████▎   | 1110/1772 [06:54<04:00,  2.76it/s, running training loss:  1.25344]\u001b[A\n",
            "Training:  63%|██████▎   | 1111/1772 [06:54<03:39,  3.01it/s, running training loss:  1.25344]\u001b[A\n",
            "Training:  63%|██████▎   | 1111/1772 [06:54<03:39,  3.01it/s, running training loss:  1.09066]\u001b[A\n",
            "Training:  63%|██████▎   | 1112/1772 [06:55<04:13,  2.60it/s, running training loss:  1.09066]\u001b[A\n",
            "Training:  63%|██████▎   | 1112/1772 [06:55<04:13,  2.60it/s, running training loss:  1.03514]\u001b[A\n",
            "Training:  63%|██████▎   | 1113/1772 [06:55<04:00,  2.75it/s, running training loss:  1.03514]\u001b[A\n",
            "Training:  63%|██████▎   | 1113/1772 [06:55<04:00,  2.75it/s, running training loss:  0.98006]\u001b[A\n",
            "Training:  63%|██████▎   | 1114/1772 [06:55<03:45,  2.92it/s, running training loss:  0.98006]\u001b[A\n",
            "Training:  63%|██████▎   | 1114/1772 [06:56<03:45,  2.92it/s, running training loss:  1.17688]\u001b[A\n",
            "Training:  63%|██████▎   | 1115/1772 [06:56<03:56,  2.77it/s, running training loss:  1.17688]\u001b[A\n",
            "Training:  63%|██████▎   | 1115/1772 [06:56<03:56,  2.77it/s, running training loss:  1.19004]\u001b[A\n",
            "Training:  63%|██████▎   | 1116/1772 [06:56<03:45,  2.91it/s, running training loss:  1.19004]\u001b[A\n",
            "Training:  63%|██████▎   | 1116/1772 [06:56<03:45,  2.91it/s, running training loss:  1.21415]\u001b[A\n",
            "Training:  63%|██████▎   | 1117/1772 [06:56<03:38,  3.00it/s, running training loss:  1.21415]\u001b[A\n",
            "Training:  63%|██████▎   | 1117/1772 [06:57<03:38,  3.00it/s, running training loss:  1.08816]\u001b[A\n",
            "Training:  63%|██████▎   | 1118/1772 [06:57<03:57,  2.75it/s, running training loss:  1.08816]\u001b[A\n",
            "Training:  63%|██████▎   | 1118/1772 [06:57<03:57,  2.75it/s, running training loss:  0.91981]\u001b[A\n",
            "Training:  63%|██████▎   | 1119/1772 [06:57<03:59,  2.73it/s, running training loss:  0.91981]\u001b[A\n",
            "Training:  63%|██████▎   | 1119/1772 [06:57<03:59,  2.73it/s, running training loss:  1.10730]\u001b[A\n",
            "Training:  63%|██████▎   | 1120/1772 [06:57<04:29,  2.42it/s, running training loss:  1.10730]\u001b[A\n",
            "Training:  63%|██████▎   | 1120/1772 [06:58<04:29,  2.42it/s, running training loss:  1.05833]\u001b[A\n",
            "Training:  63%|██████▎   | 1121/1772 [06:58<04:11,  2.59it/s, running training loss:  1.05833]\u001b[A\n",
            "Training:  63%|██████▎   | 1121/1772 [06:58<04:11,  2.59it/s, running training loss:  1.02775]\u001b[A\n",
            "Training:  63%|██████▎   | 1122/1772 [06:58<03:54,  2.77it/s, running training loss:  1.02775]\u001b[A\n",
            "Training:  63%|██████▎   | 1122/1772 [06:58<03:54,  2.77it/s, running training loss:  0.90373]\u001b[A\n",
            "Training:  63%|██████▎   | 1123/1772 [06:58<03:44,  2.90it/s, running training loss:  0.90373]\u001b[A\n",
            "Training:  63%|██████▎   | 1123/1772 [06:59<03:44,  2.90it/s, running training loss:  0.94004]\u001b[A\n",
            "Training:  63%|██████▎   | 1124/1772 [06:59<03:32,  3.05it/s, running training loss:  0.94004]\u001b[A\n",
            "Training:  63%|██████▎   | 1124/1772 [06:59<03:32,  3.05it/s, running training loss:  1.09326]\u001b[A\n",
            "Training:  63%|██████▎   | 1125/1772 [06:59<03:48,  2.83it/s, running training loss:  1.09326]\u001b[A\n",
            "Training:  63%|██████▎   | 1125/1772 [06:59<03:48,  2.83it/s, running training loss:  0.93242]\u001b[A\n",
            "Training:  64%|██████▎   | 1126/1772 [06:59<03:51,  2.80it/s, running training loss:  0.93242]\u001b[A\n",
            "Training:  64%|██████▎   | 1126/1772 [07:00<03:51,  2.80it/s, running training loss:  1.01867]\u001b[A\n",
            "Training:  64%|██████▎   | 1127/1772 [07:00<03:42,  2.90it/s, running training loss:  1.01867]\u001b[A\n",
            "Training:  64%|██████▎   | 1127/1772 [07:00<03:42,  2.90it/s, running training loss:  0.89332]\u001b[A\n",
            "Training:  64%|██████▎   | 1128/1772 [07:00<03:37,  2.96it/s, running training loss:  0.89332]\u001b[A\n",
            "Training:  64%|██████▎   | 1128/1772 [07:01<03:37,  2.96it/s, running training loss:  0.97493]\u001b[A\n",
            "Training:  64%|██████▎   | 1129/1772 [07:01<03:54,  2.75it/s, running training loss:  0.97493]\u001b[A\n",
            "Training:  64%|██████▎   | 1129/1772 [07:01<03:54,  2.75it/s, running training loss:  1.16400]\u001b[A\n",
            "Training:  64%|██████▍   | 1130/1772 [07:01<03:43,  2.87it/s, running training loss:  1.16400]\u001b[A\n",
            "Training:  64%|██████▍   | 1130/1772 [07:01<03:43,  2.87it/s, running training loss:  0.85830]\u001b[A\n",
            "Training:  64%|██████▍   | 1131/1772 [07:01<03:44,  2.85it/s, running training loss:  0.85830]\u001b[A\n",
            "Training:  64%|██████▍   | 1131/1772 [07:01<03:44,  2.85it/s, running training loss:  0.92200]\u001b[A\n",
            "Training:  64%|██████▍   | 1132/1772 [07:01<03:33,  3.00it/s, running training loss:  0.92200]\u001b[A\n",
            "Training:  64%|██████▍   | 1132/1772 [07:02<03:33,  3.00it/s, running training loss:  0.98903]\u001b[A\n",
            "Training:  64%|██████▍   | 1133/1772 [07:02<03:39,  2.91it/s, running training loss:  0.98903]\u001b[A\n",
            "Training:  64%|██████▍   | 1133/1772 [07:02<03:39,  2.91it/s, running training loss:  1.00561]\u001b[A\n",
            "Training:  64%|██████▍   | 1134/1772 [07:02<03:24,  3.12it/s, running training loss:  1.00561]\u001b[A\n",
            "Training:  64%|██████▍   | 1134/1772 [07:02<03:24,  3.12it/s, running training loss:  1.05488]\u001b[A\n",
            "Training:  64%|██████▍   | 1135/1772 [07:02<03:08,  3.38it/s, running training loss:  1.05488]\u001b[A\n",
            "Training:  64%|██████▍   | 1135/1772 [07:03<03:08,  3.38it/s, running training loss:  0.96278]\u001b[A\n",
            "Training:  64%|██████▍   | 1136/1772 [07:03<03:24,  3.11it/s, running training loss:  0.96278]\u001b[A\n",
            "Training:  64%|██████▍   | 1136/1772 [07:03<03:24,  3.11it/s, running training loss:  0.90671]\u001b[A\n",
            "Training:  64%|██████▍   | 1137/1772 [07:03<03:40,  2.88it/s, running training loss:  0.90671]\u001b[A\n",
            "Training:  64%|██████▍   | 1137/1772 [07:03<03:40,  2.88it/s, running training loss:  1.53850]\u001b[A\n",
            "Training:  64%|██████▍   | 1138/1772 [07:03<03:32,  2.98it/s, running training loss:  1.53850]\u001b[A\n",
            "Training:  64%|██████▍   | 1138/1772 [07:04<03:32,  2.98it/s, running training loss:  1.17372]\u001b[A\n",
            "Training:  64%|██████▍   | 1139/1772 [07:04<03:29,  3.02it/s, running training loss:  1.17372]\u001b[A\n",
            "Training:  64%|██████▍   | 1139/1772 [07:04<03:29,  3.02it/s, running training loss:  1.05426]\u001b[A\n",
            "Training:  64%|██████▍   | 1140/1772 [07:04<03:40,  2.86it/s, running training loss:  1.05426]\u001b[A\n",
            "Training:  64%|██████▍   | 1140/1772 [07:04<03:40,  2.86it/s, running training loss:  1.40661]\u001b[A\n",
            "Training:  64%|██████▍   | 1141/1772 [07:04<03:33,  2.96it/s, running training loss:  1.40661]\u001b[A\n",
            "Training:  64%|██████▍   | 1141/1772 [07:05<03:33,  2.96it/s, running training loss:  1.34923]\u001b[A\n",
            "Training:  64%|██████▍   | 1142/1772 [07:05<03:27,  3.03it/s, running training loss:  1.34923]\u001b[A\n",
            "Training:  64%|██████▍   | 1142/1772 [07:05<03:27,  3.03it/s, running training loss:  1.22504]\u001b[A\n",
            "Training:  65%|██████▍   | 1143/1772 [07:05<03:30,  2.98it/s, running training loss:  1.22504]\u001b[A\n",
            "Training:  65%|██████▍   | 1143/1772 [07:05<03:30,  2.98it/s, running training loss:  0.87308]\u001b[A\n",
            "Training:  65%|██████▍   | 1144/1772 [07:05<03:32,  2.95it/s, running training loss:  0.87308]\u001b[A\n",
            "Training:  65%|██████▍   | 1144/1772 [07:06<03:32,  2.95it/s, running training loss:  0.80632]\u001b[A\n",
            "Training:  65%|██████▍   | 1145/1772 [07:06<03:21,  3.11it/s, running training loss:  0.80632]\u001b[A\n",
            "Training:  65%|██████▍   | 1145/1772 [07:06<03:21,  3.11it/s, running training loss:  1.30102]\u001b[A\n",
            "Training:  65%|██████▍   | 1146/1772 [07:06<03:16,  3.18it/s, running training loss:  1.30102]\u001b[A\n",
            "Training:  65%|██████▍   | 1146/1772 [07:06<03:16,  3.18it/s, running training loss:  1.17379]\u001b[A\n",
            "Training:  65%|██████▍   | 1147/1772 [07:06<03:15,  3.19it/s, running training loss:  1.17379]\u001b[A\n",
            "Training:  65%|██████▍   | 1147/1772 [07:07<03:15,  3.19it/s, running training loss:  0.87442]\u001b[A\n",
            "Training:  65%|██████▍   | 1148/1772 [07:07<03:16,  3.17it/s, running training loss:  0.87442]\u001b[A\n",
            "Training:  65%|██████▍   | 1148/1772 [07:07<03:16,  3.17it/s, running training loss:  0.90878]\u001b[A\n",
            "Training:  65%|██████▍   | 1149/1772 [07:07<03:10,  3.28it/s, running training loss:  0.90878]\u001b[A\n",
            "Training:  65%|██████▍   | 1149/1772 [07:07<03:10,  3.28it/s, running training loss:  1.06787]\u001b[A\n",
            "Training:  65%|██████▍   | 1150/1772 [07:07<03:09,  3.28it/s, running training loss:  1.06787]\u001b[A\n",
            "Training:  65%|██████▍   | 1150/1772 [07:08<03:09,  3.28it/s, running training loss:  0.96299]\u001b[A\n",
            "Training:  65%|██████▍   | 1151/1772 [07:08<03:01,  3.42it/s, running training loss:  0.96299]\u001b[A\n",
            "Training:  65%|██████▍   | 1151/1772 [07:08<03:01,  3.42it/s, running training loss:  1.19280]\u001b[A\n",
            "Training:  65%|██████▌   | 1152/1772 [07:08<03:03,  3.38it/s, running training loss:  1.19280]\u001b[A\n",
            "Training:  65%|██████▌   | 1152/1772 [07:08<03:03,  3.38it/s, running training loss:  0.76536]\u001b[A\n",
            "Training:  65%|██████▌   | 1153/1772 [07:08<03:36,  2.86it/s, running training loss:  0.76536]\u001b[A\n",
            "Training:  65%|██████▌   | 1153/1772 [07:09<03:36,  2.86it/s, running training loss:  1.07042]\u001b[A\n",
            "Training:  65%|██████▌   | 1154/1772 [07:09<03:26,  2.99it/s, running training loss:  1.07042]\u001b[A\n",
            "Training:  65%|██████▌   | 1154/1772 [07:09<03:26,  2.99it/s, running training loss:  1.27825]\u001b[A\n",
            "Training:  65%|██████▌   | 1155/1772 [07:09<03:09,  3.26it/s, running training loss:  1.27825]\u001b[A\n",
            "Training:  65%|██████▌   | 1155/1772 [07:09<03:09,  3.26it/s, running training loss:  1.14687]\u001b[A\n",
            "Training:  65%|██████▌   | 1156/1772 [07:09<02:58,  3.45it/s, running training loss:  1.14687]\u001b[A\n",
            "Training:  65%|██████▌   | 1156/1772 [07:09<02:58,  3.45it/s, running training loss:  1.16843]\u001b[A\n",
            "Training:  65%|██████▌   | 1157/1772 [07:09<02:56,  3.48it/s, running training loss:  1.16843]\u001b[A\n",
            "Training:  65%|██████▌   | 1157/1772 [07:10<02:56,  3.48it/s, running training loss:  0.96591]\u001b[A\n",
            "Training:  65%|██████▌   | 1158/1772 [07:10<03:08,  3.25it/s, running training loss:  0.96591]\u001b[A\n",
            "Training:  65%|██████▌   | 1158/1772 [07:10<03:08,  3.25it/s, running training loss:  0.92439]\u001b[A\n",
            "Training:  65%|██████▌   | 1159/1772 [07:10<03:08,  3.25it/s, running training loss:  0.92439]\u001b[A\n",
            "Training:  65%|██████▌   | 1159/1772 [07:10<03:08,  3.25it/s, running training loss:  1.17228]\u001b[A\n",
            "Training:  65%|██████▌   | 1160/1772 [07:10<03:15,  3.13it/s, running training loss:  1.17228]\u001b[A\n",
            "Training:  65%|██████▌   | 1160/1772 [07:11<03:15,  3.13it/s, running training loss:  0.86263]\u001b[A\n",
            "Training:  66%|██████▌   | 1161/1772 [07:11<03:22,  3.02it/s, running training loss:  0.86263]\u001b[A\n",
            "Training:  66%|██████▌   | 1161/1772 [07:11<03:22,  3.02it/s, running training loss:  1.31882]\u001b[A\n",
            "Training:  66%|██████▌   | 1162/1772 [07:11<03:09,  3.22it/s, running training loss:  1.31882]\u001b[A\n",
            "Training:  66%|██████▌   | 1162/1772 [07:11<03:09,  3.22it/s, running training loss:  1.06517]\u001b[A\n",
            "Training:  66%|██████▌   | 1163/1772 [07:11<03:06,  3.26it/s, running training loss:  1.06517]\u001b[A\n",
            "Training:  66%|██████▌   | 1163/1772 [07:12<03:06,  3.26it/s, running training loss:  1.00412]\u001b[A\n",
            "Training:  66%|██████▌   | 1164/1772 [07:12<03:23,  2.99it/s, running training loss:  1.00412]\u001b[A\n",
            "Training:  66%|██████▌   | 1164/1772 [07:12<03:23,  2.99it/s, running training loss:  1.38991]\u001b[A\n",
            "Training:  66%|██████▌   | 1165/1772 [07:12<03:16,  3.10it/s, running training loss:  1.38991]\u001b[A\n",
            "Training:  66%|██████▌   | 1165/1772 [07:12<03:16,  3.10it/s, running training loss:  1.05868]\u001b[A\n",
            "Training:  66%|██████▌   | 1166/1772 [07:12<03:05,  3.26it/s, running training loss:  1.05868]\u001b[A\n",
            "Training:  66%|██████▌   | 1166/1772 [07:13<03:05,  3.26it/s, running training loss:  0.92456]\u001b[A\n",
            "Training:  66%|██████▌   | 1167/1772 [07:13<03:01,  3.34it/s, running training loss:  0.92456]\u001b[A\n",
            "Training:  66%|██████▌   | 1167/1772 [07:13<03:01,  3.34it/s, running training loss:  0.80613]\u001b[A\n",
            "Training:  66%|██████▌   | 1168/1772 [07:13<03:28,  2.90it/s, running training loss:  0.80613]\u001b[A\n",
            "Training:  66%|██████▌   | 1168/1772 [07:13<03:28,  2.90it/s, running training loss:  1.03569]\u001b[A\n",
            "Training:  66%|██████▌   | 1169/1772 [07:13<03:19,  3.02it/s, running training loss:  1.03569]\u001b[A\n",
            "Training:  66%|██████▌   | 1169/1772 [07:14<03:19,  3.02it/s, running training loss:  0.87451]\u001b[A\n",
            "Training:  66%|██████▌   | 1170/1772 [07:14<03:24,  2.94it/s, running training loss:  0.87451]\u001b[A\n",
            "Training:  66%|██████▌   | 1170/1772 [07:14<03:24,  2.94it/s, running training loss:  0.93263]\u001b[A\n",
            "Training:  66%|██████▌   | 1171/1772 [07:14<03:11,  3.14it/s, running training loss:  0.93263]\u001b[A\n",
            "Training:  66%|██████▌   | 1171/1772 [07:14<03:11,  3.14it/s, running training loss:  1.18977]\u001b[A\n",
            "Training:  66%|██████▌   | 1172/1772 [07:14<03:11,  3.14it/s, running training loss:  1.18977]\u001b[A\n",
            "Training:  66%|██████▌   | 1172/1772 [07:15<03:11,  3.14it/s, running training loss:  1.35677]\u001b[A\n",
            "Training:  66%|██████▌   | 1173/1772 [07:15<03:02,  3.28it/s, running training loss:  1.35677]\u001b[A\n",
            "Training:  66%|██████▌   | 1173/1772 [07:15<03:02,  3.28it/s, running training loss:  1.19139]\u001b[A\n",
            "Training:  66%|██████▋   | 1174/1772 [07:15<02:51,  3.48it/s, running training loss:  1.19139]\u001b[A\n",
            "Training:  66%|██████▋   | 1174/1772 [07:15<02:51,  3.48it/s, running training loss:  1.00833]\u001b[A\n",
            "Training:  66%|██████▋   | 1175/1772 [07:15<02:52,  3.47it/s, running training loss:  1.00833]\u001b[A\n",
            "Training:  66%|██████▋   | 1175/1772 [07:15<02:52,  3.47it/s, running training loss:  1.01425]\u001b[A\n",
            "Training:  66%|██████▋   | 1176/1772 [07:15<02:55,  3.40it/s, running training loss:  1.01425]\u001b[A\n",
            "Training:  66%|██████▋   | 1176/1772 [07:16<02:55,  3.40it/s, running training loss:  0.99943]\u001b[A\n",
            "Training:  66%|██████▋   | 1177/1772 [07:16<03:11,  3.11it/s, running training loss:  0.99943]\u001b[A\n",
            "Training:  66%|██████▋   | 1177/1772 [07:16<03:11,  3.11it/s, running training loss:  0.94884]\u001b[A\n",
            "Training:  66%|██████▋   | 1178/1772 [07:16<03:08,  3.15it/s, running training loss:  0.94884]\u001b[A\n",
            "Training:  66%|██████▋   | 1178/1772 [07:16<03:08,  3.15it/s, running training loss:  0.87856]\u001b[A\n",
            "Training:  67%|██████▋   | 1179/1772 [07:16<03:03,  3.23it/s, running training loss:  0.87856]\u001b[A\n",
            "Training:  67%|██████▋   | 1179/1772 [07:17<03:03,  3.23it/s, running training loss:  0.85559]\u001b[A\n",
            "Training:  67%|██████▋   | 1180/1772 [07:17<03:02,  3.25it/s, running training loss:  0.85559]\u001b[A\n",
            "Training:  67%|██████▋   | 1180/1772 [07:17<03:02,  3.25it/s, running training loss:  0.95201]\u001b[A\n",
            "Training:  67%|██████▋   | 1181/1772 [07:17<03:01,  3.26it/s, running training loss:  0.95201]\u001b[A\n",
            "Training:  67%|██████▋   | 1181/1772 [07:17<03:01,  3.26it/s, running training loss:  0.83496]\u001b[A\n",
            "Training:  67%|██████▋   | 1182/1772 [07:17<03:06,  3.17it/s, running training loss:  0.83496]\u001b[A\n",
            "Training:  67%|██████▋   | 1182/1772 [07:18<03:06,  3.17it/s, running training loss:  1.12840]\u001b[A\n",
            "Training:  67%|██████▋   | 1183/1772 [07:18<03:12,  3.06it/s, running training loss:  1.12840]\u001b[A\n",
            "Training:  67%|██████▋   | 1183/1772 [07:18<03:12,  3.06it/s, running training loss:  1.02383]\u001b[A\n",
            "Training:  67%|██████▋   | 1184/1772 [07:18<03:07,  3.13it/s, running training loss:  1.02383]\u001b[A\n",
            "Training:  67%|██████▋   | 1184/1772 [07:18<03:07,  3.13it/s, running training loss:  1.14264]\u001b[A\n",
            "Training:  67%|██████▋   | 1185/1772 [07:18<03:01,  3.23it/s, running training loss:  1.14264]\u001b[A\n",
            "Training:  67%|██████▋   | 1185/1772 [07:19<03:01,  3.23it/s, running training loss:  1.41201]\u001b[A\n",
            "Training:  67%|██████▋   | 1186/1772 [07:19<02:57,  3.31it/s, running training loss:  1.41201]\u001b[A\n",
            "Training:  67%|██████▋   | 1186/1772 [07:19<02:57,  3.31it/s, running training loss:  1.13137]\u001b[A\n",
            "Training:  67%|██████▋   | 1187/1772 [07:19<03:06,  3.13it/s, running training loss:  1.13137]\u001b[A\n",
            "Training:  67%|██████▋   | 1187/1772 [07:19<03:06,  3.13it/s, running training loss:  1.24897]\u001b[A\n",
            "Training:  67%|██████▋   | 1188/1772 [07:19<02:57,  3.29it/s, running training loss:  1.24897]\u001b[A\n",
            "Training:  67%|██████▋   | 1188/1772 [07:20<02:57,  3.29it/s, running training loss:  1.10128]\u001b[A\n",
            "Training:  67%|██████▋   | 1189/1772 [07:20<03:21,  2.89it/s, running training loss:  1.10128]\u001b[A\n",
            "Training:  67%|██████▋   | 1189/1772 [07:20<03:21,  2.89it/s, running training loss:  0.86143]\u001b[A\n",
            "Training:  67%|██████▋   | 1190/1772 [07:20<03:07,  3.11it/s, running training loss:  0.86143]\u001b[A\n",
            "Training:  67%|██████▋   | 1190/1772 [07:20<03:07,  3.11it/s, running training loss:  1.06850]\u001b[A\n",
            "Training:  67%|██████▋   | 1191/1772 [07:20<03:16,  2.96it/s, running training loss:  1.06850]\u001b[A\n",
            "Training:  67%|██████▋   | 1191/1772 [07:21<03:16,  2.96it/s, running training loss:  0.87579]\u001b[A\n",
            "Training:  67%|██████▋   | 1192/1772 [07:21<03:04,  3.15it/s, running training loss:  0.87579]\u001b[A\n",
            "Training:  67%|██████▋   | 1192/1772 [07:21<03:04,  3.15it/s, running training loss:  0.88659]\u001b[A\n",
            "Training:  67%|██████▋   | 1193/1772 [07:21<03:24,  2.83it/s, running training loss:  0.88659]\u001b[A\n",
            "Training:  67%|██████▋   | 1193/1772 [07:21<03:24,  2.83it/s, running training loss:  0.95113]\u001b[A\n",
            "Training:  67%|██████▋   | 1194/1772 [07:21<03:14,  2.97it/s, running training loss:  0.95113]\u001b[A\n",
            "Training:  67%|██████▋   | 1194/1772 [07:22<03:14,  2.97it/s, running training loss:  0.99309]\u001b[A\n",
            "Training:  67%|██████▋   | 1195/1772 [07:22<03:17,  2.92it/s, running training loss:  0.99309]\u001b[A\n",
            "Training:  67%|██████▋   | 1195/1772 [07:22<03:17,  2.92it/s, running training loss:  0.98093]\u001b[A\n",
            "Training:  67%|██████▋   | 1196/1772 [07:22<03:07,  3.08it/s, running training loss:  0.98093]\u001b[A\n",
            "Training:  67%|██████▋   | 1196/1772 [07:22<03:07,  3.08it/s, running training loss:  0.93829]\u001b[A\n",
            "Training:  68%|██████▊   | 1197/1772 [07:22<03:14,  2.96it/s, running training loss:  0.93829]\u001b[A\n",
            "Training:  68%|██████▊   | 1197/1772 [07:23<03:14,  2.96it/s, running training loss:  0.97199]\u001b[A\n",
            "Training:  68%|██████▊   | 1198/1772 [07:23<03:26,  2.78it/s, running training loss:  0.97199]\u001b[A\n",
            "Training:  68%|██████▊   | 1198/1772 [07:23<03:26,  2.78it/s, running training loss:  1.12267]\u001b[A\n",
            "Training:  68%|██████▊   | 1199/1772 [07:23<04:04,  2.35it/s, running training loss:  1.12267]\u001b[A\n",
            "Training:  68%|██████▊   | 1199/1772 [07:24<04:04,  2.35it/s, running training loss:  1.16509]\u001b[A\n",
            "\n",
            "Evaluation:   0%|          | 0/270 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   0%|          | 1/270 [00:00<01:16,  3.52it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   1%|          | 3/270 [00:00<00:31,  8.53it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   2%|▏         | 5/270 [00:00<00:22, 11.81it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   3%|▎         | 8/270 [00:00<00:17, 14.94it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   4%|▎         | 10/270 [00:00<00:15, 16.28it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   5%|▍         | 13/270 [00:00<00:14, 18.31it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   6%|▌         | 15/270 [00:01<00:13, 18.40it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   6%|▋         | 17/270 [00:01<00:14, 17.35it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   7%|▋         | 20/270 [00:01<00:13, 17.95it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   9%|▊         | 23/270 [00:01<00:12, 19.77it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  10%|▉         | 26/270 [00:01<00:12, 20.21it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  11%|█         | 29/270 [00:01<00:12, 19.46it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  11%|█▏        | 31/270 [00:01<00:12, 18.89it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  13%|█▎        | 34/270 [00:01<00:11, 19.83it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  13%|█▎        | 36/270 [00:02<00:11, 19.64it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  14%|█▍        | 39/270 [00:02<00:11, 20.24it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  16%|█▌        | 42/270 [00:02<00:11, 19.44it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  16%|█▋        | 44/270 [00:02<00:11, 18.96it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  17%|█▋        | 46/270 [00:02<00:11, 18.91it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  18%|█▊        | 49/270 [00:02<00:11, 19.42it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  19%|█▉        | 51/270 [00:02<00:11, 18.95it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  20%|█▉        | 53/270 [00:02<00:11, 18.92it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  21%|██        | 56/270 [00:03<00:11, 19.20it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  21%|██▏       | 58/270 [00:03<00:11, 18.70it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  22%|██▏       | 60/270 [00:03<00:11, 18.59it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  23%|██▎       | 62/270 [00:03<00:11, 18.37it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  24%|██▎       | 64/270 [00:03<00:11, 18.38it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  25%|██▍       | 67/270 [00:03<00:10, 19.48it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  26%|██▌       | 70/270 [00:03<00:09, 20.88it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  27%|██▋       | 73/270 [00:03<00:09, 20.66it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  28%|██▊       | 76/270 [00:04<00:09, 21.49it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  29%|██▉       | 79/270 [00:04<00:09, 21.03it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  30%|███       | 82/270 [00:04<00:09, 19.77it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  31%|███       | 84/270 [00:04<00:09, 19.68it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  32%|███▏      | 87/270 [00:04<00:09, 20.01it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  33%|███▎      | 90/270 [00:04<00:09, 19.42it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  34%|███▍      | 92/270 [00:04<00:09, 19.35it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  35%|███▌      | 95/270 [00:05<00:08, 20.24it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  36%|███▋      | 98/270 [00:05<00:08, 20.83it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  37%|███▋      | 101/270 [00:05<00:08, 21.08it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  39%|███▊      | 104/270 [00:05<00:08, 20.55it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  40%|███▉      | 107/270 [00:05<00:07, 20.95it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  41%|████      | 110/270 [00:05<00:07, 20.65it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  42%|████▏     | 113/270 [00:05<00:07, 20.72it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  43%|████▎     | 116/270 [00:06<00:07, 20.55it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  44%|████▍     | 119/270 [00:06<00:07, 20.33it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  45%|████▌     | 122/270 [00:06<00:07, 21.08it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  46%|████▋     | 125/270 [00:06<00:07, 20.52it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  47%|████▋     | 128/270 [00:06<00:07, 19.28it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  48%|████▊     | 130/270 [00:06<00:07, 19.36it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  49%|████▉     | 132/270 [00:06<00:07, 19.06it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  50%|████▉     | 134/270 [00:07<00:07, 18.87it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  51%|█████     | 137/270 [00:07<00:06, 19.96it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  52%|█████▏    | 140/270 [00:07<00:06, 20.00it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  53%|█████▎    | 142/270 [00:07<00:06, 18.91it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  54%|█████▎    | 145/270 [00:07<00:06, 19.44it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  54%|█████▍    | 147/270 [00:07<00:06, 19.32it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  56%|█████▌    | 150/270 [00:07<00:05, 20.20it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  57%|█████▋    | 153/270 [00:07<00:06, 19.06it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  57%|█████▋    | 155/270 [00:08<00:06, 19.07it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  59%|█████▊    | 158/270 [00:08<00:05, 20.10it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  60%|█████▉    | 161/270 [00:08<00:05, 19.41it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  60%|██████    | 163/270 [00:08<00:05, 19.07it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  61%|██████    | 165/270 [00:08<00:05, 18.62it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  62%|██████▏   | 168/270 [00:08<00:05, 19.51it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  63%|██████▎   | 170/270 [00:08<00:05, 19.17it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  64%|██████▎   | 172/270 [00:08<00:05, 19.27it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  64%|██████▍   | 174/270 [00:09<00:05, 18.33it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  65%|██████▌   | 176/270 [00:09<00:05, 17.71it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  66%|██████▌   | 178/270 [00:09<00:05, 18.00it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  67%|██████▋   | 180/270 [00:09<00:05, 17.49it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  67%|██████▋   | 182/270 [00:09<00:04, 17.79it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  68%|██████▊   | 184/270 [00:09<00:04, 18.04it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  69%|██████▉   | 186/270 [00:09<00:04, 18.26it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  70%|██████▉   | 188/270 [00:09<00:04, 17.85it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  71%|███████   | 191/270 [00:10<00:04, 19.65it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  71%|███████▏  | 193/270 [00:10<00:04, 19.16it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  72%|███████▏  | 195/270 [00:10<00:04, 18.37it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  73%|███████▎  | 197/270 [00:10<00:03, 18.79it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  74%|███████▎  | 199/270 [00:10<00:03, 18.07it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  74%|███████▍  | 201/270 [00:10<00:03, 17.48it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  75%|███████▌  | 203/270 [00:10<00:03, 17.75it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  76%|███████▋  | 206/270 [00:10<00:03, 19.58it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  77%|███████▋  | 208/270 [00:10<00:03, 18.53it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  78%|███████▊  | 210/270 [00:11<00:03, 18.28it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  79%|███████▊  | 212/270 [00:11<00:03, 18.36it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  80%|███████▉  | 215/270 [00:11<00:02, 20.25it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  81%|████████  | 218/270 [00:11<00:02, 20.52it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  82%|████████▏ | 221/270 [00:11<00:02, 20.92it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  83%|████████▎ | 224/270 [00:11<00:02, 21.81it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  84%|████████▍ | 227/270 [00:11<00:01, 21.68it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  85%|████████▌ | 230/270 [00:12<00:02, 19.88it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  86%|████████▋ | 233/270 [00:12<00:01, 20.32it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  87%|████████▋ | 236/270 [00:12<00:01, 20.95it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  89%|████████▊ | 239/270 [00:12<00:01, 21.12it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  90%|████████▉ | 242/270 [00:12<00:01, 20.36it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  91%|█████████ | 245/270 [00:12<00:01, 19.86it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  91%|█████████▏| 247/270 [00:12<00:01, 18.96it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  92%|█████████▏| 249/270 [00:13<00:01, 18.43it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  93%|█████████▎| 251/270 [00:13<00:01, 17.76it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  94%|█████████▎| 253/270 [00:13<00:00, 17.53it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  94%|█████████▍| 255/270 [00:13<00:00, 17.68it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  95%|█████████▌| 257/270 [00:13<00:00, 18.04it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  96%|█████████▋| 260/270 [00:13<00:00, 19.46it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  97%|█████████▋| 262/270 [00:13<00:00, 19.13it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  98%|█████████▊| 264/270 [00:13<00:00, 18.58it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  99%|█████████▊| 266/270 [00:13<00:00, 18.31it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  99%|█████████▉| 268/270 [00:14<00:00, 18.26it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation: 100%|██████████| 270/270 [00:14<00:00, 18.82it/s]\n",
            "\n",
            "Training:  68%|██████▊   | 1200/1772 [07:38<45:32,  4.78s/it, running training loss:  1.16509]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            ">>> training loss: 1.027474, valid loss: 0.623412,valid f1: 0.041488, valid acc:0.689527\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  68%|██████▊   | 1200/1772 [07:38<45:32,  4.78s/it, running training loss:  1.19053]\u001b[A\n",
            "Training:  68%|██████▊   | 1201/1772 [07:39<32:44,  3.44s/it, running training loss:  1.19053]\u001b[A\n",
            "Training:  68%|██████▊   | 1201/1772 [07:39<32:44,  3.44s/it, running training loss:  1.02758]\u001b[A\n",
            "Training:  68%|██████▊   | 1202/1772 [07:39<23:44,  2.50s/it, running training loss:  1.02758]\u001b[A\n",
            "Training:  68%|██████▊   | 1202/1772 [07:39<23:44,  2.50s/it, running training loss:  1.07684]\u001b[A\n",
            "Training:  68%|██████▊   | 1203/1772 [07:39<17:17,  1.82s/it, running training loss:  1.07684]\u001b[A\n",
            "Training:  68%|██████▊   | 1203/1772 [07:39<17:17,  1.82s/it, running training loss:  1.06052]\u001b[A\n",
            "Training:  68%|██████▊   | 1204/1772 [07:39<12:58,  1.37s/it, running training loss:  1.06052]\u001b[A\n",
            "Training:  68%|██████▊   | 1204/1772 [07:40<12:58,  1.37s/it, running training loss:  0.97041]\u001b[A\n",
            "Training:  68%|██████▊   | 1205/1772 [07:40<09:58,  1.06s/it, running training loss:  0.97041]\u001b[A\n",
            "Training:  68%|██████▊   | 1205/1772 [07:40<09:58,  1.06s/it, running training loss:  1.06053]\u001b[A\n",
            "Training:  68%|██████▊   | 1206/1772 [07:40<07:49,  1.21it/s, running training loss:  1.06053]\u001b[A\n",
            "Training:  68%|██████▊   | 1206/1772 [07:40<07:49,  1.21it/s, running training loss:  0.96981]\u001b[A\n",
            "Training:  68%|██████▊   | 1207/1772 [07:40<06:20,  1.49it/s, running training loss:  0.96981]\u001b[A\n",
            "Training:  68%|██████▊   | 1207/1772 [07:41<06:20,  1.49it/s, running training loss:  1.05146]\u001b[A\n",
            "Training:  68%|██████▊   | 1208/1772 [07:41<05:26,  1.73it/s, running training loss:  1.05146]\u001b[A\n",
            "Training:  68%|██████▊   | 1208/1772 [07:41<05:26,  1.73it/s, running training loss:  0.88888]\u001b[A\n",
            "Training:  68%|██████▊   | 1209/1772 [07:41<04:42,  1.99it/s, running training loss:  0.88888]\u001b[A\n",
            "Training:  68%|██████▊   | 1209/1772 [07:41<04:42,  1.99it/s, running training loss:  0.84762]\u001b[A\n",
            "Training:  68%|██████▊   | 1210/1772 [07:41<04:07,  2.27it/s, running training loss:  0.84762]\u001b[A\n",
            "Training:  68%|██████▊   | 1210/1772 [07:42<04:07,  2.27it/s, running training loss:  0.88392]\u001b[A\n",
            "Training:  68%|██████▊   | 1211/1772 [07:42<03:42,  2.53it/s, running training loss:  0.88392]\u001b[A\n",
            "Training:  68%|██████▊   | 1211/1772 [07:42<03:42,  2.53it/s, running training loss:  0.88834]\u001b[A\n",
            "Training:  68%|██████▊   | 1212/1772 [07:42<03:40,  2.54it/s, running training loss:  0.88834]\u001b[A\n",
            "Training:  68%|██████▊   | 1212/1772 [07:42<03:40,  2.54it/s, running training loss:  0.96369]\u001b[A\n",
            "Training:  68%|██████▊   | 1213/1772 [07:42<03:29,  2.67it/s, running training loss:  0.96369]\u001b[A\n",
            "Training:  68%|██████▊   | 1213/1772 [07:43<03:29,  2.67it/s, running training loss:  0.99773]\u001b[A\n",
            "Training:  69%|██████▊   | 1214/1772 [07:43<03:56,  2.36it/s, running training loss:  0.99773]\u001b[A\n",
            "Training:  69%|██████▊   | 1214/1772 [07:43<03:56,  2.36it/s, running training loss:  0.86369]\u001b[A\n",
            "Training:  69%|██████▊   | 1215/1772 [07:43<03:27,  2.68it/s, running training loss:  0.86369]\u001b[A\n",
            "Training:  69%|██████▊   | 1215/1772 [07:43<03:27,  2.68it/s, running training loss:  0.86133]\u001b[A\n",
            "Training:  69%|██████▊   | 1216/1772 [07:43<03:16,  2.83it/s, running training loss:  0.86133]\u001b[A\n",
            "Training:  69%|██████▊   | 1216/1772 [07:44<03:16,  2.83it/s, running training loss:  0.99499]\u001b[A\n",
            "Training:  69%|██████▊   | 1217/1772 [07:44<03:08,  2.94it/s, running training loss:  0.99499]\u001b[A\n",
            "Training:  69%|██████▊   | 1217/1772 [07:44<03:08,  2.94it/s, running training loss:  1.00321]\u001b[A\n",
            "Training:  69%|██████▊   | 1218/1772 [07:44<03:36,  2.55it/s, running training loss:  1.00321]\u001b[A\n",
            "Training:  69%|██████▊   | 1218/1772 [07:45<03:36,  2.55it/s, running training loss:  0.92321]\u001b[A\n",
            "Training:  69%|██████▉   | 1219/1772 [07:45<03:24,  2.71it/s, running training loss:  0.92321]\u001b[A\n",
            "Training:  69%|██████▉   | 1219/1772 [07:45<03:24,  2.71it/s, running training loss:  0.97836]\u001b[A\n",
            "Training:  69%|██████▉   | 1220/1772 [07:45<03:13,  2.86it/s, running training loss:  0.97836]\u001b[A\n",
            "Training:  69%|██████▉   | 1220/1772 [07:45<03:13,  2.86it/s, running training loss:  1.12669]\u001b[A\n",
            "Training:  69%|██████▉   | 1221/1772 [07:45<02:59,  3.08it/s, running training loss:  1.12669]\u001b[A\n",
            "Training:  69%|██████▉   | 1221/1772 [07:45<02:59,  3.08it/s, running training loss:  1.17275]\u001b[A\n",
            "Training:  69%|██████▉   | 1222/1772 [07:45<03:05,  2.96it/s, running training loss:  1.17275]\u001b[A\n",
            "Training:  69%|██████▉   | 1222/1772 [07:46<03:05,  2.96it/s, running training loss:  1.17436]\u001b[A\n",
            "Training:  69%|██████▉   | 1223/1772 [07:46<03:10,  2.89it/s, running training loss:  1.17436]\u001b[A\n",
            "Training:  69%|██████▉   | 1223/1772 [07:46<03:10,  2.89it/s, running training loss:  1.07835]\u001b[A\n",
            "Training:  69%|██████▉   | 1224/1772 [07:46<03:07,  2.93it/s, running training loss:  1.07835]\u001b[A\n",
            "Training:  69%|██████▉   | 1224/1772 [07:46<03:07,  2.93it/s, running training loss:  0.96708]\u001b[A\n",
            "Training:  69%|██████▉   | 1225/1772 [07:46<03:02,  2.99it/s, running training loss:  0.96708]\u001b[A\n",
            "Training:  69%|██████▉   | 1225/1772 [07:47<03:02,  2.99it/s, running training loss:  1.29252]\u001b[A\n",
            "Training:  69%|██████▉   | 1226/1772 [07:47<03:04,  2.95it/s, running training loss:  1.29252]\u001b[A\n",
            "Training:  69%|██████▉   | 1226/1772 [07:47<03:04,  2.95it/s, running training loss:  0.94618]\u001b[A\n",
            "Training:  69%|██████▉   | 1227/1772 [07:47<02:58,  3.06it/s, running training loss:  0.94618]\u001b[A\n",
            "Training:  69%|██████▉   | 1227/1772 [07:48<02:58,  3.06it/s, running training loss:  0.97404]\u001b[A\n",
            "Training:  69%|██████▉   | 1228/1772 [07:48<03:13,  2.82it/s, running training loss:  0.97404]\u001b[A\n",
            "Training:  69%|██████▉   | 1228/1772 [07:48<03:13,  2.82it/s, running training loss:  1.21946]\u001b[A\n",
            "Training:  69%|██████▉   | 1229/1772 [07:48<02:58,  3.05it/s, running training loss:  1.21946]\u001b[A\n",
            "Training:  69%|██████▉   | 1229/1772 [07:48<02:58,  3.05it/s, running training loss:  0.99131]\u001b[A\n",
            "Training:  69%|██████▉   | 1230/1772 [07:48<02:58,  3.03it/s, running training loss:  0.99131]\u001b[A\n",
            "Training:  69%|██████▉   | 1230/1772 [07:49<02:58,  3.03it/s, running training loss:  1.35077]\u001b[A\n",
            "Training:  69%|██████▉   | 1231/1772 [07:49<03:10,  2.84it/s, running training loss:  1.35077]\u001b[A\n",
            "Training:  69%|██████▉   | 1231/1772 [07:49<03:10,  2.84it/s, running training loss:  1.08924]\u001b[A\n",
            "Training:  70%|██████▉   | 1232/1772 [07:49<03:02,  2.96it/s, running training loss:  1.08924]\u001b[A\n",
            "Training:  70%|██████▉   | 1232/1772 [07:49<03:02,  2.96it/s, running training loss:  1.04497]\u001b[A\n",
            "Training:  70%|██████▉   | 1233/1772 [07:49<02:50,  3.16it/s, running training loss:  1.04497]\u001b[A\n",
            "Training:  70%|██████▉   | 1233/1772 [07:49<02:50,  3.16it/s, running training loss:  0.93762]\u001b[A\n",
            "Training:  70%|██████▉   | 1234/1772 [07:49<02:44,  3.27it/s, running training loss:  0.93762]\u001b[A\n",
            "Training:  70%|██████▉   | 1234/1772 [07:50<02:44,  3.27it/s, running training loss:  0.89488]\u001b[A\n",
            "Training:  70%|██████▉   | 1235/1772 [07:50<02:54,  3.07it/s, running training loss:  0.89488]\u001b[A\n",
            "Training:  70%|██████▉   | 1235/1772 [07:50<02:54,  3.07it/s, running training loss:  0.77826]\u001b[A\n",
            "Training:  70%|██████▉   | 1236/1772 [07:50<03:02,  2.93it/s, running training loss:  0.77826]\u001b[A\n",
            "Training:  70%|██████▉   | 1236/1772 [07:50<03:02,  2.93it/s, running training loss:  1.20457]\u001b[A\n",
            "Training:  70%|██████▉   | 1237/1772 [07:50<02:48,  3.17it/s, running training loss:  1.20457]\u001b[A\n",
            "Training:  70%|██████▉   | 1237/1772 [07:51<02:48,  3.17it/s, running training loss:  1.02254]\u001b[A\n",
            "Training:  70%|██████▉   | 1238/1772 [07:51<02:46,  3.21it/s, running training loss:  1.02254]\u001b[A\n",
            "Training:  70%|██████▉   | 1238/1772 [07:51<02:46,  3.21it/s, running training loss:  1.01069]\u001b[A\n",
            "Training:  70%|██████▉   | 1239/1772 [07:51<02:52,  3.10it/s, running training loss:  1.01069]\u001b[A\n",
            "Training:  70%|██████▉   | 1239/1772 [07:51<02:52,  3.10it/s, running training loss:  0.94276]\u001b[A\n",
            "Training:  70%|██████▉   | 1240/1772 [07:51<02:46,  3.19it/s, running training loss:  0.94276]\u001b[A\n",
            "Training:  70%|██████▉   | 1240/1772 [07:52<02:46,  3.19it/s, running training loss:  1.04610]\u001b[A\n",
            "Training:  70%|███████   | 1241/1772 [07:52<02:48,  3.16it/s, running training loss:  1.04610]\u001b[A\n",
            "Training:  70%|███████   | 1241/1772 [07:52<02:48,  3.16it/s, running training loss:  0.90609]\u001b[A\n",
            "Training:  70%|███████   | 1242/1772 [07:52<03:03,  2.90it/s, running training loss:  0.90609]\u001b[A\n",
            "Training:  70%|███████   | 1242/1772 [07:52<03:03,  2.90it/s, running training loss:  1.03987]\u001b[A\n",
            "Training:  70%|███████   | 1243/1772 [07:52<03:03,  2.89it/s, running training loss:  1.03987]\u001b[A\n",
            "Training:  70%|███████   | 1243/1772 [07:53<03:03,  2.89it/s, running training loss:  1.06418]\u001b[A\n",
            "Training:  70%|███████   | 1244/1772 [07:53<03:02,  2.90it/s, running training loss:  1.06418]\u001b[A\n",
            "Training:  70%|███████   | 1244/1772 [07:53<03:02,  2.90it/s, running training loss:  0.93914]\u001b[A\n",
            "Training:  70%|███████   | 1245/1772 [07:53<03:29,  2.52it/s, running training loss:  0.93914]\u001b[A\n",
            "Training:  70%|███████   | 1245/1772 [07:54<03:29,  2.52it/s, running training loss:  0.87298]\u001b[A\n",
            "Training:  70%|███████   | 1246/1772 [07:54<03:15,  2.70it/s, running training loss:  0.87298]\u001b[A\n",
            "Training:  70%|███████   | 1246/1772 [07:54<03:15,  2.70it/s, running training loss:  0.90933]\u001b[A\n",
            "Training:  70%|███████   | 1247/1772 [07:54<03:04,  2.85it/s, running training loss:  0.90933]\u001b[A\n",
            "Training:  70%|███████   | 1247/1772 [07:54<03:04,  2.85it/s, running training loss:  1.05929]\u001b[A\n",
            "Training:  70%|███████   | 1248/1772 [07:54<02:59,  2.92it/s, running training loss:  1.05929]\u001b[A\n",
            "Training:  70%|███████   | 1248/1772 [07:55<02:59,  2.92it/s, running training loss:  1.01692]\u001b[A\n",
            "Training:  70%|███████   | 1249/1772 [07:55<03:00,  2.90it/s, running training loss:  1.01692]\u001b[A\n",
            "Training:  70%|███████   | 1249/1772 [07:55<03:00,  2.90it/s, running training loss:  1.02451]\u001b[A\n",
            "Training:  71%|███████   | 1250/1772 [07:55<02:46,  3.13it/s, running training loss:  1.02451]\u001b[A\n",
            "Training:  71%|███████   | 1250/1772 [07:55<02:46,  3.13it/s, running training loss:  0.95447]\u001b[A\n",
            "Training:  71%|███████   | 1251/1772 [07:55<02:36,  3.33it/s, running training loss:  0.95447]\u001b[A\n",
            "Training:  71%|███████   | 1251/1772 [07:55<02:36,  3.33it/s, running training loss:  0.88833]\u001b[A\n",
            "Training:  71%|███████   | 1252/1772 [07:55<02:49,  3.07it/s, running training loss:  0.88833]\u001b[A\n",
            "Training:  71%|███████   | 1252/1772 [07:56<02:49,  3.07it/s, running training loss:  0.98630]\u001b[A\n",
            "Training:  71%|███████   | 1253/1772 [07:56<03:08,  2.76it/s, running training loss:  0.98630]\u001b[A\n",
            "Training:  71%|███████   | 1253/1772 [07:56<03:08,  2.76it/s, running training loss:  0.77419]\u001b[A\n",
            "Training:  71%|███████   | 1254/1772 [07:56<02:55,  2.95it/s, running training loss:  0.77419]\u001b[A\n",
            "Training:  71%|███████   | 1254/1772 [07:57<02:55,  2.95it/s, running training loss:  1.09960]\u001b[A\n",
            "Training:  71%|███████   | 1255/1772 [07:57<03:15,  2.65it/s, running training loss:  1.09960]\u001b[A\n",
            "Training:  71%|███████   | 1255/1772 [07:57<03:15,  2.65it/s, running training loss:  0.94284]\u001b[A\n",
            "Training:  71%|███████   | 1256/1772 [07:57<02:58,  2.89it/s, running training loss:  0.94284]\u001b[A\n",
            "Training:  71%|███████   | 1256/1772 [07:57<02:58,  2.89it/s, running training loss:  1.07793]\u001b[A\n",
            "Training:  71%|███████   | 1257/1772 [07:57<02:53,  2.97it/s, running training loss:  1.07793]\u001b[A\n",
            "Training:  71%|███████   | 1257/1772 [07:58<02:53,  2.97it/s, running training loss:  0.87762]\u001b[A\n",
            "Training:  71%|███████   | 1258/1772 [07:58<02:51,  3.00it/s, running training loss:  0.87762]\u001b[A\n",
            "Training:  71%|███████   | 1258/1772 [07:58<02:51,  3.00it/s, running training loss:  1.13431]\u001b[A\n",
            "Training:  71%|███████   | 1259/1772 [07:58<02:42,  3.16it/s, running training loss:  1.13431]\u001b[A\n",
            "Training:  71%|███████   | 1259/1772 [07:58<02:42,  3.16it/s, running training loss:  0.94616]\u001b[A\n",
            "Training:  71%|███████   | 1260/1772 [07:58<02:41,  3.18it/s, running training loss:  0.94616]\u001b[A\n",
            "Training:  71%|███████   | 1260/1772 [07:58<02:41,  3.18it/s, running training loss:  0.98681]\u001b[A\n",
            "Training:  71%|███████   | 1261/1772 [07:58<02:32,  3.34it/s, running training loss:  0.98681]\u001b[A\n",
            "Training:  71%|███████   | 1261/1772 [07:59<02:32,  3.34it/s, running training loss:  1.15302]\u001b[A\n",
            "Training:  71%|███████   | 1262/1772 [07:59<02:31,  3.36it/s, running training loss:  1.15302]\u001b[A\n",
            "Training:  71%|███████   | 1262/1772 [07:59<02:31,  3.36it/s, running training loss:  0.89816]\u001b[A\n",
            "Training:  71%|███████▏  | 1263/1772 [07:59<02:30,  3.39it/s, running training loss:  0.89816]\u001b[A\n",
            "Training:  71%|███████▏  | 1263/1772 [07:59<02:30,  3.39it/s, running training loss:  0.97411]\u001b[A\n",
            "Training:  71%|███████▏  | 1264/1772 [07:59<02:51,  2.96it/s, running training loss:  0.97411]\u001b[A\n",
            "Training:  71%|███████▏  | 1264/1772 [08:00<02:51,  2.96it/s, running training loss:  0.93736]\u001b[A\n",
            "Training:  71%|███████▏  | 1265/1772 [08:00<03:14,  2.61it/s, running training loss:  0.93736]\u001b[A\n",
            "Training:  71%|███████▏  | 1265/1772 [08:00<03:14,  2.61it/s, running training loss:  1.06006]\u001b[A\n",
            "Training:  71%|███████▏  | 1266/1772 [08:00<03:02,  2.77it/s, running training loss:  1.06006]\u001b[A\n",
            "Training:  71%|███████▏  | 1266/1772 [08:01<03:02,  2.77it/s, running training loss:  1.04871]\u001b[A\n",
            "Training:  72%|███████▏  | 1267/1772 [08:01<03:00,  2.81it/s, running training loss:  1.04871]\u001b[A\n",
            "Training:  72%|███████▏  | 1267/1772 [08:01<03:00,  2.81it/s, running training loss:  1.10805]\u001b[A\n",
            "Training:  72%|███████▏  | 1268/1772 [08:01<03:31,  2.39it/s, running training loss:  1.10805]\u001b[A\n",
            "Training:  72%|███████▏  | 1268/1772 [08:02<03:31,  2.39it/s, running training loss:  1.22784]\u001b[A\n",
            "Training:  72%|███████▏  | 1269/1772 [08:02<03:18,  2.53it/s, running training loss:  1.22784]\u001b[A\n",
            "Training:  72%|███████▏  | 1269/1772 [08:02<03:18,  2.53it/s, running training loss:  0.93228]\u001b[A\n",
            "Training:  72%|███████▏  | 1270/1772 [08:02<03:00,  2.78it/s, running training loss:  0.93228]\u001b[A\n",
            "Training:  72%|███████▏  | 1270/1772 [08:02<03:00,  2.78it/s, running training loss:  0.81030]\u001b[A\n",
            "Training:  72%|███████▏  | 1271/1772 [08:02<02:44,  3.04it/s, running training loss:  0.81030]\u001b[A\n",
            "Training:  72%|███████▏  | 1271/1772 [08:02<02:44,  3.04it/s, running training loss:  0.93797]\u001b[A\n",
            "Training:  72%|███████▏  | 1272/1772 [08:02<02:51,  2.92it/s, running training loss:  0.93797]\u001b[A\n",
            "Training:  72%|███████▏  | 1272/1772 [08:03<02:51,  2.92it/s, running training loss:  0.99235]\u001b[A\n",
            "Training:  72%|███████▏  | 1273/1772 [08:03<03:00,  2.77it/s, running training loss:  0.99235]\u001b[A\n",
            "Training:  72%|███████▏  | 1273/1772 [08:03<03:00,  2.77it/s, running training loss:  0.97873]\u001b[A\n",
            "Training:  72%|███████▏  | 1274/1772 [08:03<02:43,  3.04it/s, running training loss:  0.97873]\u001b[A\n",
            "Training:  72%|███████▏  | 1274/1772 [08:03<02:43,  3.04it/s, running training loss:  0.93294]\u001b[A\n",
            "Training:  72%|███████▏  | 1275/1772 [08:03<02:40,  3.10it/s, running training loss:  0.93294]\u001b[A\n",
            "Training:  72%|███████▏  | 1275/1772 [08:04<02:40,  3.10it/s, running training loss:  0.92242]\u001b[A\n",
            "Training:  72%|███████▏  | 1276/1772 [08:04<02:43,  3.04it/s, running training loss:  0.92242]\u001b[A\n",
            "Training:  72%|███████▏  | 1276/1772 [08:04<02:43,  3.04it/s, running training loss:  0.93920]\u001b[A\n",
            "Training:  72%|███████▏  | 1277/1772 [08:04<02:43,  3.03it/s, running training loss:  0.93920]\u001b[A\n",
            "Training:  72%|███████▏  | 1277/1772 [08:04<02:43,  3.03it/s, running training loss:  0.86926]\u001b[A\n",
            "Training:  72%|███████▏  | 1278/1772 [08:04<02:44,  3.00it/s, running training loss:  0.86926]\u001b[A\n",
            "Training:  72%|███████▏  | 1278/1772 [08:05<02:44,  3.00it/s, running training loss:  1.02168]\u001b[A\n",
            "Training:  72%|███████▏  | 1279/1772 [08:05<02:46,  2.97it/s, running training loss:  1.02168]\u001b[A\n",
            "Training:  72%|███████▏  | 1279/1772 [08:05<02:46,  2.97it/s, running training loss:  0.90630]\u001b[A\n",
            "Training:  72%|███████▏  | 1280/1772 [08:05<02:50,  2.88it/s, running training loss:  0.90630]\u001b[A\n",
            "Training:  72%|███████▏  | 1280/1772 [08:05<02:50,  2.88it/s, running training loss:  1.01943]\u001b[A\n",
            "Training:  72%|███████▏  | 1281/1772 [08:05<02:47,  2.94it/s, running training loss:  1.01943]\u001b[A\n",
            "Training:  72%|███████▏  | 1281/1772 [08:06<02:47,  2.94it/s, running training loss:  0.91347]\u001b[A\n",
            "Training:  72%|███████▏  | 1282/1772 [08:06<02:35,  3.15it/s, running training loss:  0.91347]\u001b[A\n",
            "Training:  72%|███████▏  | 1282/1772 [08:06<02:35,  3.15it/s, running training loss:  0.82567]\u001b[A\n",
            "Training:  72%|███████▏  | 1283/1772 [08:06<02:22,  3.43it/s, running training loss:  0.82567]\u001b[A\n",
            "Training:  72%|███████▏  | 1283/1772 [08:06<02:22,  3.43it/s, running training loss:  0.92511]\u001b[A\n",
            "Training:  72%|███████▏  | 1284/1772 [08:06<02:30,  3.24it/s, running training loss:  0.92511]\u001b[A\n",
            "Training:  72%|███████▏  | 1284/1772 [08:07<02:30,  3.24it/s, running training loss:  1.02322]\u001b[A\n",
            "Training:  73%|███████▎  | 1285/1772 [08:07<02:33,  3.17it/s, running training loss:  1.02322]\u001b[A\n",
            "Training:  73%|███████▎  | 1285/1772 [08:07<02:33,  3.17it/s, running training loss:  0.79880]\u001b[A\n",
            "Training:  73%|███████▎  | 1286/1772 [08:07<03:03,  2.65it/s, running training loss:  0.79880]\u001b[A\n",
            "Training:  73%|███████▎  | 1286/1772 [08:07<03:03,  2.65it/s, running training loss:  0.88375]\u001b[A\n",
            "Training:  73%|███████▎  | 1287/1772 [08:07<02:51,  2.82it/s, running training loss:  0.88375]\u001b[A\n",
            "Training:  73%|███████▎  | 1287/1772 [08:08<02:51,  2.82it/s, running training loss:  1.03627]\u001b[A\n",
            "Training:  73%|███████▎  | 1288/1772 [08:08<02:45,  2.93it/s, running training loss:  1.03627]\u001b[A\n",
            "Training:  73%|███████▎  | 1288/1772 [08:08<02:45,  2.93it/s, running training loss:  1.03016]\u001b[A\n",
            "Training:  73%|███████▎  | 1289/1772 [08:08<02:48,  2.87it/s, running training loss:  1.03016]\u001b[A\n",
            "Training:  73%|███████▎  | 1289/1772 [08:09<02:48,  2.87it/s, running training loss:  0.73919]\u001b[A\n",
            "Training:  73%|███████▎  | 1290/1772 [08:09<02:54,  2.76it/s, running training loss:  0.73919]\u001b[A\n",
            "Training:  73%|███████▎  | 1290/1772 [08:09<02:54,  2.76it/s, running training loss:  1.10254]\u001b[A\n",
            "Training:  73%|███████▎  | 1291/1772 [08:09<02:46,  2.89it/s, running training loss:  1.10254]\u001b[A\n",
            "Training:  73%|███████▎  | 1291/1772 [08:09<02:46,  2.89it/s, running training loss:  1.31423]\u001b[A\n",
            "Training:  73%|███████▎  | 1292/1772 [08:09<02:33,  3.13it/s, running training loss:  1.31423]\u001b[A\n",
            "Training:  73%|███████▎  | 1292/1772 [08:09<02:33,  3.13it/s, running training loss:  1.57447]\u001b[A\n",
            "Training:  73%|███████▎  | 1293/1772 [08:09<02:23,  3.33it/s, running training loss:  1.57447]\u001b[A\n",
            "Training:  73%|███████▎  | 1293/1772 [08:10<02:23,  3.33it/s, running training loss:  1.46422]\u001b[A\n",
            "Training:  73%|███████▎  | 1294/1772 [08:10<02:23,  3.32it/s, running training loss:  1.46422]\u001b[A\n",
            "Training:  73%|███████▎  | 1294/1772 [08:10<02:23,  3.32it/s, running training loss:  1.33469]\u001b[A\n",
            "Training:  73%|███████▎  | 1295/1772 [08:10<02:35,  3.06it/s, running training loss:  1.33469]\u001b[A\n",
            "Training:  73%|███████▎  | 1295/1772 [08:10<02:35,  3.06it/s, running training loss:  1.44008]\u001b[A\n",
            "Training:  73%|███████▎  | 1296/1772 [08:11<02:55,  2.70it/s, running training loss:  1.44008]\u001b[A\n",
            "Training:  73%|███████▎  | 1296/1772 [08:11<02:55,  2.70it/s, running training loss:  0.88069]\u001b[A\n",
            "Training:  73%|███████▎  | 1297/1772 [08:11<03:05,  2.57it/s, running training loss:  0.88069]\u001b[A\n",
            "Training:  73%|███████▎  | 1297/1772 [08:11<03:05,  2.57it/s, running training loss:  0.96128]\u001b[A\n",
            "Training:  73%|███████▎  | 1298/1772 [08:11<02:46,  2.84it/s, running training loss:  0.96128]\u001b[A\n",
            "Training:  73%|███████▎  | 1298/1772 [08:12<02:46,  2.84it/s, running training loss:  1.23257]\u001b[A\n",
            "Training:  73%|███████▎  | 1299/1772 [08:12<03:01,  2.61it/s, running training loss:  1.23257]\u001b[A\n",
            "Training:  73%|███████▎  | 1299/1772 [08:12<03:01,  2.61it/s, running training loss:  0.91572]\u001b[A\n",
            "Training:  73%|███████▎  | 1300/1772 [08:12<02:49,  2.78it/s, running training loss:  0.91572]\u001b[A\n",
            "Training:  73%|███████▎  | 1300/1772 [08:12<02:49,  2.78it/s, running training loss:  0.87635]\u001b[A\n",
            "Training:  73%|███████▎  | 1301/1772 [08:12<02:45,  2.84it/s, running training loss:  0.87635]\u001b[A\n",
            "Training:  73%|███████▎  | 1301/1772 [08:13<02:45,  2.84it/s, running training loss:  1.05359]\u001b[A\n",
            "Training:  73%|███████▎  | 1302/1772 [08:13<02:58,  2.63it/s, running training loss:  1.05359]\u001b[A\n",
            "Training:  73%|███████▎  | 1302/1772 [08:13<02:58,  2.63it/s, running training loss:  0.92490]\u001b[A\n",
            "Training:  74%|███████▎  | 1303/1772 [08:13<03:14,  2.41it/s, running training loss:  0.92490]\u001b[A\n",
            "Training:  74%|███████▎  | 1303/1772 [08:13<03:14,  2.41it/s, running training loss:  1.23733]\u001b[A\n",
            "Training:  74%|███████▎  | 1304/1772 [08:14<02:53,  2.70it/s, running training loss:  1.23733]\u001b[A\n",
            "Training:  74%|███████▎  | 1304/1772 [08:14<02:53,  2.70it/s, running training loss:  0.93082]\u001b[A\n",
            "Training:  74%|███████▎  | 1305/1772 [08:14<02:56,  2.64it/s, running training loss:  0.93082]\u001b[A\n",
            "Training:  74%|███████▎  | 1305/1772 [08:14<02:56,  2.64it/s, running training loss:  0.95355]\u001b[A\n",
            "Training:  74%|███████▎  | 1306/1772 [08:14<02:47,  2.78it/s, running training loss:  0.95355]\u001b[A\n",
            "Training:  74%|███████▎  | 1306/1772 [08:14<02:47,  2.78it/s, running training loss:  0.99456]\u001b[A\n",
            "Training:  74%|███████▍  | 1307/1772 [08:14<02:35,  3.00it/s, running training loss:  0.99456]\u001b[A\n",
            "Training:  74%|███████▍  | 1307/1772 [08:15<02:35,  3.00it/s, running training loss:  0.91788]\u001b[A\n",
            "Training:  74%|███████▍  | 1308/1772 [08:15<02:32,  3.03it/s, running training loss:  0.91788]\u001b[A\n",
            "Training:  74%|███████▍  | 1308/1772 [08:15<02:32,  3.03it/s, running training loss:  1.15816]\u001b[A\n",
            "Training:  74%|███████▍  | 1309/1772 [08:15<02:22,  3.25it/s, running training loss:  1.15816]\u001b[A\n",
            "Training:  74%|███████▍  | 1309/1772 [08:15<02:22,  3.25it/s, running training loss:  0.79325]\u001b[A\n",
            "Training:  74%|███████▍  | 1310/1772 [08:15<02:22,  3.24it/s, running training loss:  0.79325]\u001b[A\n",
            "Training:  74%|███████▍  | 1310/1772 [08:16<02:22,  3.24it/s, running training loss:  0.82559]\u001b[A\n",
            "Training:  74%|███████▍  | 1311/1772 [08:16<02:28,  3.11it/s, running training loss:  0.82559]\u001b[A\n",
            "Training:  74%|███████▍  | 1311/1772 [08:16<02:28,  3.11it/s, running training loss:  0.97263]\u001b[A\n",
            "Training:  74%|███████▍  | 1312/1772 [08:16<02:26,  3.14it/s, running training loss:  0.97263]\u001b[A\n",
            "Training:  74%|███████▍  | 1312/1772 [08:16<02:26,  3.14it/s, running training loss:  0.84565]\u001b[A\n",
            "Training:  74%|███████▍  | 1313/1772 [08:16<02:21,  3.25it/s, running training loss:  0.84565]\u001b[A\n",
            "Training:  74%|███████▍  | 1313/1772 [08:17<02:21,  3.25it/s, running training loss:  1.04125]\u001b[A\n",
            "Training:  74%|███████▍  | 1314/1772 [08:17<02:27,  3.11it/s, running training loss:  1.04125]\u001b[A\n",
            "Training:  74%|███████▍  | 1314/1772 [08:17<02:27,  3.11it/s, running training loss:  0.95076]\u001b[A\n",
            "Training:  74%|███████▍  | 1315/1772 [08:17<02:54,  2.63it/s, running training loss:  0.95076]\u001b[A\n",
            "Training:  74%|███████▍  | 1315/1772 [08:18<02:54,  2.63it/s, running training loss:  0.82065]\u001b[A\n",
            "Training:  74%|███████▍  | 1316/1772 [08:18<02:53,  2.62it/s, running training loss:  0.82065]\u001b[A\n",
            "Training:  74%|███████▍  | 1316/1772 [08:18<02:53,  2.62it/s, running training loss:  1.07028]\u001b[A\n",
            "Training:  74%|███████▍  | 1317/1772 [08:18<02:41,  2.81it/s, running training loss:  1.07028]\u001b[A\n",
            "Training:  74%|███████▍  | 1317/1772 [08:18<02:41,  2.81it/s, running training loss:  0.96847]\u001b[A\n",
            "Training:  74%|███████▍  | 1318/1772 [08:18<02:41,  2.82it/s, running training loss:  0.96847]\u001b[A\n",
            "Training:  74%|███████▍  | 1318/1772 [08:19<02:41,  2.82it/s, running training loss:  0.90891]\u001b[A\n",
            "Training:  74%|███████▍  | 1319/1772 [08:19<02:35,  2.92it/s, running training loss:  0.90891]\u001b[A\n",
            "Training:  74%|███████▍  | 1319/1772 [08:19<02:35,  2.92it/s, running training loss:  1.02907]\u001b[A\n",
            "Training:  74%|███████▍  | 1320/1772 [08:19<02:28,  3.03it/s, running training loss:  1.02907]\u001b[A\n",
            "Training:  74%|███████▍  | 1320/1772 [08:19<02:28,  3.03it/s, running training loss:  0.91205]\u001b[A\n",
            "Training:  75%|███████▍  | 1321/1772 [08:19<02:43,  2.76it/s, running training loss:  0.91205]\u001b[A\n",
            "Training:  75%|███████▍  | 1321/1772 [08:20<02:43,  2.76it/s, running training loss:  0.74578]\u001b[A\n",
            "Training:  75%|███████▍  | 1322/1772 [08:20<02:31,  2.97it/s, running training loss:  0.74578]\u001b[A\n",
            "Training:  75%|███████▍  | 1322/1772 [08:20<02:31,  2.97it/s, running training loss:  1.16788]\u001b[A\n",
            "Training:  75%|███████▍  | 1323/1772 [08:20<02:27,  3.05it/s, running training loss:  1.16788]\u001b[A\n",
            "Training:  75%|███████▍  | 1323/1772 [08:20<02:27,  3.05it/s, running training loss:  0.91197]\u001b[A\n",
            "Training:  75%|███████▍  | 1324/1772 [08:20<02:23,  3.12it/s, running training loss:  0.91197]\u001b[A\n",
            "Training:  75%|███████▍  | 1324/1772 [08:21<02:23,  3.12it/s, running training loss:  1.01845]\u001b[A\n",
            "Training:  75%|███████▍  | 1325/1772 [08:21<02:31,  2.94it/s, running training loss:  1.01845]\u001b[A\n",
            "Training:  75%|███████▍  | 1325/1772 [08:21<02:31,  2.94it/s, running training loss:  1.14029]\u001b[A\n",
            "Training:  75%|███████▍  | 1326/1772 [08:21<02:22,  3.12it/s, running training loss:  1.14029]\u001b[A\n",
            "Training:  75%|███████▍  | 1326/1772 [08:21<02:22,  3.12it/s, running training loss:  1.22179]\u001b[A\n",
            "Training:  75%|███████▍  | 1327/1772 [08:21<02:34,  2.87it/s, running training loss:  1.22179]\u001b[A\n",
            "Training:  75%|███████▍  | 1327/1772 [08:21<02:34,  2.87it/s, running training loss:  1.05926]\u001b[A\n",
            "Training:  75%|███████▍  | 1328/1772 [08:22<02:23,  3.10it/s, running training loss:  1.05926]\u001b[A\n",
            "Training:  75%|███████▍  | 1328/1772 [08:22<02:23,  3.10it/s, running training loss:  1.01988]\u001b[A\n",
            "Training:  75%|███████▌  | 1329/1772 [08:22<02:30,  2.95it/s, running training loss:  1.01988]\u001b[A\n",
            "Training:  75%|███████▌  | 1329/1772 [08:22<02:30,  2.95it/s, running training loss:  0.84822]\u001b[A\n",
            "Training:  75%|███████▌  | 1330/1772 [08:22<02:21,  3.12it/s, running training loss:  0.84822]\u001b[A\n",
            "Training:  75%|███████▌  | 1330/1772 [08:23<02:21,  3.12it/s, running training loss:  0.92153]\u001b[A\n",
            "Training:  75%|███████▌  | 1331/1772 [08:23<02:28,  2.97it/s, running training loss:  0.92153]\u001b[A\n",
            "Training:  75%|███████▌  | 1331/1772 [08:23<02:28,  2.97it/s, running training loss:  0.91518]\u001b[A\n",
            "Training:  75%|███████▌  | 1332/1772 [08:23<02:59,  2.46it/s, running training loss:  0.91518]\u001b[A\n",
            "Training:  75%|███████▌  | 1332/1772 [08:23<02:59,  2.46it/s, running training loss:  0.78231]\u001b[A\n",
            "Training:  75%|███████▌  | 1333/1772 [08:23<02:45,  2.66it/s, running training loss:  0.78231]\u001b[A\n",
            "Training:  75%|███████▌  | 1333/1772 [08:24<02:45,  2.66it/s, running training loss:  0.72752]\u001b[A\n",
            "Training:  75%|███████▌  | 1334/1772 [08:24<02:36,  2.81it/s, running training loss:  0.72752]\u001b[A\n",
            "Training:  75%|███████▌  | 1334/1772 [08:24<02:36,  2.81it/s, running training loss:  0.68310]\u001b[A\n",
            "Training:  75%|███████▌  | 1335/1772 [08:24<02:28,  2.95it/s, running training loss:  0.68310]\u001b[A\n",
            "Training:  75%|███████▌  | 1335/1772 [08:24<02:28,  2.95it/s, running training loss:  1.06361]\u001b[A\n",
            "Training:  75%|███████▌  | 1336/1772 [08:24<02:44,  2.66it/s, running training loss:  1.06361]\u001b[A\n",
            "Training:  75%|███████▌  | 1336/1772 [08:25<02:44,  2.66it/s, running training loss:  0.81108]\u001b[A\n",
            "Training:  75%|███████▌  | 1337/1772 [08:25<02:41,  2.70it/s, running training loss:  0.81108]\u001b[A\n",
            "Training:  75%|███████▌  | 1337/1772 [08:25<02:41,  2.70it/s, running training loss:  1.01306]\u001b[A\n",
            "Training:  76%|███████▌  | 1338/1772 [08:25<02:34,  2.80it/s, running training loss:  1.01306]\u001b[A\n",
            "Training:  76%|███████▌  | 1338/1772 [08:25<02:34,  2.80it/s, running training loss:  0.87955]\u001b[A\n",
            "Training:  76%|███████▌  | 1339/1772 [08:25<02:31,  2.85it/s, running training loss:  0.87955]\u001b[A\n",
            "Training:  76%|███████▌  | 1339/1772 [08:26<02:31,  2.85it/s, running training loss:  1.03187]\u001b[A\n",
            "Training:  76%|███████▌  | 1340/1772 [08:26<02:47,  2.58it/s, running training loss:  1.03187]\u001b[A\n",
            "Training:  76%|███████▌  | 1340/1772 [08:26<02:47,  2.58it/s, running training loss:  1.35176]\u001b[A\n",
            "Training:  76%|███████▌  | 1341/1772 [08:26<02:38,  2.73it/s, running training loss:  1.35176]\u001b[A\n",
            "Training:  76%|███████▌  | 1341/1772 [08:27<02:38,  2.73it/s, running training loss:  1.26324]\u001b[A\n",
            "Training:  76%|███████▌  | 1342/1772 [08:27<02:31,  2.85it/s, running training loss:  1.26324]\u001b[A\n",
            "Training:  76%|███████▌  | 1342/1772 [08:27<02:31,  2.85it/s, running training loss:  1.15819]\u001b[A\n",
            "Training:  76%|███████▌  | 1343/1772 [08:27<02:20,  3.06it/s, running training loss:  1.15819]\u001b[A\n",
            "Training:  76%|███████▌  | 1343/1772 [08:27<02:20,  3.06it/s, running training loss:  0.98728]\u001b[A\n",
            "Training:  76%|███████▌  | 1344/1772 [08:27<02:22,  3.01it/s, running training loss:  0.98728]\u001b[A\n",
            "Training:  76%|███████▌  | 1344/1772 [08:28<02:22,  3.01it/s, running training loss:  0.99662]\u001b[A\n",
            "Training:  76%|███████▌  | 1345/1772 [08:28<02:37,  2.70it/s, running training loss:  0.99662]\u001b[A\n",
            "Training:  76%|███████▌  | 1345/1772 [08:28<02:37,  2.70it/s, running training loss:  1.00331]\u001b[A\n",
            "Training:  76%|███████▌  | 1346/1772 [08:28<02:29,  2.85it/s, running training loss:  1.00331]\u001b[A\n",
            "Training:  76%|███████▌  | 1346/1772 [08:28<02:29,  2.85it/s, running training loss:  1.08316]\u001b[A\n",
            "Training:  76%|███████▌  | 1347/1772 [08:28<02:44,  2.58it/s, running training loss:  1.08316]\u001b[A\n",
            "Training:  76%|███████▌  | 1347/1772 [08:29<02:44,  2.58it/s, running training loss:  0.87858]\u001b[A\n",
            "Training:  76%|███████▌  | 1348/1772 [08:29<02:38,  2.67it/s, running training loss:  0.87858]\u001b[A\n",
            "Training:  76%|███████▌  | 1348/1772 [08:29<02:38,  2.67it/s, running training loss:  0.79692]\u001b[A\n",
            "Training:  76%|███████▌  | 1349/1772 [08:29<02:32,  2.78it/s, running training loss:  0.79692]\u001b[A\n",
            "Training:  76%|███████▌  | 1349/1772 [08:29<02:32,  2.78it/s, running training loss:  0.81374]\u001b[A\n",
            "Training:  76%|███████▌  | 1350/1772 [08:29<02:20,  3.01it/s, running training loss:  0.81374]\u001b[A\n",
            "Training:  76%|███████▌  | 1350/1772 [08:30<02:20,  3.01it/s, running training loss:  0.94521]\u001b[A\n",
            "Training:  76%|███████▌  | 1351/1772 [08:30<02:25,  2.89it/s, running training loss:  0.94521]\u001b[A\n",
            "Training:  76%|███████▌  | 1351/1772 [08:30<02:25,  2.89it/s, running training loss:  1.06851]\u001b[A\n",
            "Training:  76%|███████▋  | 1352/1772 [08:30<02:13,  3.14it/s, running training loss:  1.06851]\u001b[A\n",
            "Training:  76%|███████▋  | 1352/1772 [08:30<02:13,  3.14it/s, running training loss:  1.03002]\u001b[A\n",
            "Training:  76%|███████▋  | 1353/1772 [08:30<02:16,  3.06it/s, running training loss:  1.03002]\u001b[A\n",
            "Training:  76%|███████▋  | 1353/1772 [08:31<02:16,  3.06it/s, running training loss:  0.91312]\u001b[A\n",
            "Training:  76%|███████▋  | 1354/1772 [08:31<02:18,  3.02it/s, running training loss:  0.91312]\u001b[A\n",
            "Training:  76%|███████▋  | 1354/1772 [08:31<02:18,  3.02it/s, running training loss:  0.91268]\u001b[A\n",
            "Training:  76%|███████▋  | 1355/1772 [08:31<02:22,  2.92it/s, running training loss:  0.91268]\u001b[A\n",
            "Training:  76%|███████▋  | 1355/1772 [08:31<02:22,  2.92it/s, running training loss:  1.04374]\u001b[A\n",
            "Training:  77%|███████▋  | 1356/1772 [08:31<02:24,  2.88it/s, running training loss:  1.04374]\u001b[A\n",
            "Training:  77%|███████▋  | 1356/1772 [08:32<02:24,  2.88it/s, running training loss:  0.97904]\u001b[A\n",
            "Training:  77%|███████▋  | 1357/1772 [08:32<02:28,  2.79it/s, running training loss:  0.97904]\u001b[A\n",
            "Training:  77%|███████▋  | 1357/1772 [08:32<02:28,  2.79it/s, running training loss:  0.96510]\u001b[A\n",
            "Training:  77%|███████▋  | 1358/1772 [08:32<02:21,  2.92it/s, running training loss:  0.96510]\u001b[A\n",
            "Training:  77%|███████▋  | 1358/1772 [08:33<02:21,  2.92it/s, running training loss:  1.02009]\u001b[A\n",
            "Training:  77%|███████▋  | 1359/1772 [08:33<02:26,  2.82it/s, running training loss:  1.02009]\u001b[A\n",
            "Training:  77%|███████▋  | 1359/1772 [08:33<02:26,  2.82it/s, running training loss:  1.28242]\u001b[A\n",
            "Training:  77%|███████▋  | 1360/1772 [08:33<02:32,  2.70it/s, running training loss:  1.28242]\u001b[A\n",
            "Training:  77%|███████▋  | 1360/1772 [08:33<02:32,  2.70it/s, running training loss:  1.08513]\u001b[A\n",
            "Training:  77%|███████▋  | 1361/1772 [08:33<02:26,  2.81it/s, running training loss:  1.08513]\u001b[A\n",
            "Training:  77%|███████▋  | 1361/1772 [08:34<02:26,  2.81it/s, running training loss:  0.85778]\u001b[A\n",
            "Training:  77%|███████▋  | 1362/1772 [08:34<02:28,  2.77it/s, running training loss:  0.85778]\u001b[A\n",
            "Training:  77%|███████▋  | 1362/1772 [08:34<02:28,  2.77it/s, running training loss:  0.78631]\u001b[A\n",
            "Training:  77%|███████▋  | 1363/1772 [08:34<02:44,  2.49it/s, running training loss:  0.78631]\u001b[A\n",
            "Training:  77%|███████▋  | 1363/1772 [08:34<02:44,  2.49it/s, running training loss:  0.94814]\u001b[A\n",
            "Training:  77%|███████▋  | 1364/1772 [08:34<02:38,  2.58it/s, running training loss:  0.94814]\u001b[A\n",
            "Training:  77%|███████▋  | 1364/1772 [08:35<02:38,  2.58it/s, running training loss:  0.93527]\u001b[A\n",
            "Training:  77%|███████▋  | 1365/1772 [08:35<02:29,  2.72it/s, running training loss:  0.93527]\u001b[A\n",
            "Training:  77%|███████▋  | 1365/1772 [08:35<02:29,  2.72it/s, running training loss:  0.96503]\u001b[A\n",
            "Training:  77%|███████▋  | 1366/1772 [08:35<02:30,  2.71it/s, running training loss:  0.96503]\u001b[A\n",
            "Training:  77%|███████▋  | 1366/1772 [08:35<02:30,  2.71it/s, running training loss:  0.76147]\u001b[A\n",
            "Training:  77%|███████▋  | 1367/1772 [08:35<02:15,  2.99it/s, running training loss:  0.76147]\u001b[A\n",
            "Training:  77%|███████▋  | 1367/1772 [08:36<02:15,  2.99it/s, running training loss:  0.82233]\u001b[A\n",
            "Training:  77%|███████▋  | 1368/1772 [08:36<02:19,  2.89it/s, running training loss:  0.82233]\u001b[A\n",
            "Training:  77%|███████▋  | 1368/1772 [08:36<02:19,  2.89it/s, running training loss:  1.08887]\u001b[A\n",
            "Training:  77%|███████▋  | 1369/1772 [08:36<02:22,  2.82it/s, running training loss:  1.08887]\u001b[A\n",
            "Training:  77%|███████▋  | 1369/1772 [08:36<02:22,  2.82it/s, running training loss:  1.04004]\u001b[A\n",
            "Training:  77%|███████▋  | 1370/1772 [08:36<02:14,  2.99it/s, running training loss:  1.04004]\u001b[A\n",
            "Training:  77%|███████▋  | 1370/1772 [08:37<02:14,  2.99it/s, running training loss:  0.93629]\u001b[A\n",
            "Training:  77%|███████▋  | 1371/1772 [08:37<02:08,  3.11it/s, running training loss:  0.93629]\u001b[A\n",
            "Training:  77%|███████▋  | 1371/1772 [08:37<02:08,  3.11it/s, running training loss:  0.92831]\u001b[A\n",
            "Training:  77%|███████▋  | 1372/1772 [08:37<02:08,  3.11it/s, running training loss:  0.92831]\u001b[A\n",
            "Training:  77%|███████▋  | 1372/1772 [08:37<02:08,  3.11it/s, running training loss:  0.94943]\u001b[A\n",
            "Training:  77%|███████▋  | 1373/1772 [08:38<02:22,  2.79it/s, running training loss:  0.94943]\u001b[A\n",
            "Training:  77%|███████▋  | 1373/1772 [08:38<02:22,  2.79it/s, running training loss:  0.88316]\u001b[A\n",
            "Training:  78%|███████▊  | 1374/1772 [08:38<02:15,  2.94it/s, running training loss:  0.88316]\u001b[A\n",
            "Training:  78%|███████▊  | 1374/1772 [08:38<02:15,  2.94it/s, running training loss:  0.94637]\u001b[A\n",
            "Training:  78%|███████▊  | 1375/1772 [08:38<02:28,  2.66it/s, running training loss:  0.94637]\u001b[A\n",
            "Training:  78%|███████▊  | 1375/1772 [08:39<02:28,  2.66it/s, running training loss:  0.80172]\u001b[A\n",
            "Training:  78%|███████▊  | 1376/1772 [08:39<02:25,  2.73it/s, running training loss:  0.80172]\u001b[A\n",
            "Training:  78%|███████▊  | 1376/1772 [08:39<02:25,  2.73it/s, running training loss:  0.88292]\u001b[A\n",
            "Training:  78%|███████▊  | 1377/1772 [08:39<02:27,  2.68it/s, running training loss:  0.88292]\u001b[A\n",
            "Training:  78%|███████▊  | 1377/1772 [08:39<02:27,  2.68it/s, running training loss:  1.09810]\u001b[A\n",
            "Training:  78%|███████▊  | 1378/1772 [08:39<02:23,  2.74it/s, running training loss:  1.09810]\u001b[A\n",
            "Training:  78%|███████▊  | 1378/1772 [08:40<02:23,  2.74it/s, running training loss:  1.05157]\u001b[A\n",
            "Training:  78%|███████▊  | 1379/1772 [08:40<02:12,  2.98it/s, running training loss:  1.05157]\u001b[A\n",
            "Training:  78%|███████▊  | 1379/1772 [08:40<02:12,  2.98it/s, running training loss:  1.04677]\u001b[A\n",
            "Training:  78%|███████▊  | 1380/1772 [08:40<02:06,  3.10it/s, running training loss:  1.04677]\u001b[A\n",
            "Training:  78%|███████▊  | 1380/1772 [08:40<02:06,  3.10it/s, running training loss:  0.94413]\u001b[A\n",
            "Training:  78%|███████▊  | 1381/1772 [08:40<02:33,  2.54it/s, running training loss:  0.94413]\u001b[A\n",
            "Training:  78%|███████▊  | 1381/1772 [08:41<02:33,  2.54it/s, running training loss:  1.11873]\u001b[A\n",
            "Training:  78%|███████▊  | 1382/1772 [08:41<02:26,  2.67it/s, running training loss:  1.11873]\u001b[A\n",
            "Training:  78%|███████▊  | 1382/1772 [08:41<02:26,  2.67it/s, running training loss:  0.80201]\u001b[A\n",
            "Training:  78%|███████▊  | 1383/1772 [08:41<02:23,  2.72it/s, running training loss:  0.80201]\u001b[A\n",
            "Training:  78%|███████▊  | 1383/1772 [08:42<02:23,  2.72it/s, running training loss:  0.89362]\u001b[A\n",
            "Training:  78%|███████▊  | 1384/1772 [08:42<02:24,  2.68it/s, running training loss:  0.89362]\u001b[A\n",
            "Training:  78%|███████▊  | 1384/1772 [08:42<02:24,  2.68it/s, running training loss:  0.75231]\u001b[A\n",
            "Training:  78%|███████▊  | 1385/1772 [08:42<02:26,  2.63it/s, running training loss:  0.75231]\u001b[A\n",
            "Training:  78%|███████▊  | 1385/1772 [08:42<02:26,  2.63it/s, running training loss:  0.70070]\u001b[A\n",
            "Training:  78%|███████▊  | 1386/1772 [08:42<02:16,  2.83it/s, running training loss:  0.70070]\u001b[A\n",
            "Training:  78%|███████▊  | 1386/1772 [08:43<02:16,  2.83it/s, running training loss:  0.90253]\u001b[A\n",
            "Training:  78%|███████▊  | 1387/1772 [08:43<02:17,  2.79it/s, running training loss:  0.90253]\u001b[A\n",
            "Training:  78%|███████▊  | 1387/1772 [08:43<02:17,  2.79it/s, running training loss:  0.88482]\u001b[A\n",
            "Training:  78%|███████▊  | 1388/1772 [08:43<02:09,  2.97it/s, running training loss:  0.88482]\u001b[A\n",
            "Training:  78%|███████▊  | 1388/1772 [08:43<02:09,  2.97it/s, running training loss:  0.91246]\u001b[A\n",
            "Training:  78%|███████▊  | 1389/1772 [08:43<02:01,  3.15it/s, running training loss:  0.91246]\u001b[A\n",
            "Training:  78%|███████▊  | 1389/1772 [08:43<02:01,  3.15it/s, running training loss:  0.71305]\u001b[A\n",
            "Training:  78%|███████▊  | 1390/1772 [08:43<01:55,  3.32it/s, running training loss:  0.71305]\u001b[A\n",
            "Training:  78%|███████▊  | 1390/1772 [08:44<01:55,  3.32it/s, running training loss:  1.07569]\u001b[A\n",
            "Training:  78%|███████▊  | 1391/1772 [08:44<01:54,  3.33it/s, running training loss:  1.07569]\u001b[A\n",
            "Training:  78%|███████▊  | 1391/1772 [08:44<01:54,  3.33it/s, running training loss:  1.10767]\u001b[A\n",
            "Training:  79%|███████▊  | 1392/1772 [08:44<02:10,  2.91it/s, running training loss:  1.10767]\u001b[A\n",
            "Training:  79%|███████▊  | 1392/1772 [08:44<02:10,  2.91it/s, running training loss:  0.89583]\u001b[A\n",
            "Training:  79%|███████▊  | 1393/1772 [08:44<02:06,  2.99it/s, running training loss:  0.89583]\u001b[A\n",
            "Training:  79%|███████▊  | 1393/1772 [08:45<02:06,  2.99it/s, running training loss:  1.22819]\u001b[A\n",
            "Training:  79%|███████▊  | 1394/1772 [08:45<02:08,  2.93it/s, running training loss:  1.22819]\u001b[A\n",
            "Training:  79%|███████▊  | 1394/1772 [08:45<02:08,  2.93it/s, running training loss:  1.07980]\u001b[A\n",
            "Training:  79%|███████▊  | 1395/1772 [08:45<02:08,  2.94it/s, running training loss:  1.07980]\u001b[A\n",
            "Training:  79%|███████▊  | 1395/1772 [08:46<02:08,  2.94it/s, running training loss:  0.78631]\u001b[A\n",
            "Training:  79%|███████▉  | 1396/1772 [08:46<02:12,  2.84it/s, running training loss:  0.78631]\u001b[A\n",
            "Training:  79%|███████▉  | 1396/1772 [08:46<02:12,  2.84it/s, running training loss:  1.18419]\u001b[A\n",
            "Training:  79%|███████▉  | 1397/1772 [08:46<02:07,  2.95it/s, running training loss:  1.18419]\u001b[A\n",
            "Training:  79%|███████▉  | 1397/1772 [08:46<02:07,  2.95it/s, running training loss:  1.04923]\u001b[A\n",
            "Training:  79%|███████▉  | 1398/1772 [08:46<02:03,  3.02it/s, running training loss:  1.04923]\u001b[A\n",
            "Training:  79%|███████▉  | 1398/1772 [08:46<02:03,  3.02it/s, running training loss:  1.14926]\u001b[A\n",
            "Training:  79%|███████▉  | 1399/1772 [08:46<02:02,  3.04it/s, running training loss:  1.14926]\u001b[A\n",
            "Training:  79%|███████▉  | 1399/1772 [08:47<02:02,  3.04it/s, running training loss:  1.01721]\u001b[A\n",
            "Training:  79%|███████▉  | 1400/1772 [08:47<02:02,  3.05it/s, running training loss:  1.01721]\u001b[A\n",
            "Training:  79%|███████▉  | 1400/1772 [08:47<02:02,  3.05it/s, running training loss:  0.82579]\u001b[A\n",
            "Training:  79%|███████▉  | 1401/1772 [08:47<01:53,  3.27it/s, running training loss:  0.82579]\u001b[A\n",
            "Training:  79%|███████▉  | 1401/1772 [08:47<01:53,  3.27it/s, running training loss:  1.03134]\u001b[A\n",
            "Training:  79%|███████▉  | 1402/1772 [08:47<01:51,  3.31it/s, running training loss:  1.03134]\u001b[A\n",
            "Training:  79%|███████▉  | 1402/1772 [08:48<01:51,  3.31it/s, running training loss:  0.87046]\u001b[A\n",
            "Training:  79%|███████▉  | 1403/1772 [08:48<01:51,  3.31it/s, running training loss:  0.87046]\u001b[A\n",
            "Training:  79%|███████▉  | 1403/1772 [08:48<01:51,  3.31it/s, running training loss:  0.80149]\u001b[A\n",
            "Training:  79%|███████▉  | 1404/1772 [08:48<02:01,  3.02it/s, running training loss:  0.80149]\u001b[A\n",
            "Training:  79%|███████▉  | 1404/1772 [08:48<02:01,  3.02it/s, running training loss:  0.86299]\u001b[A\n",
            "Training:  79%|███████▉  | 1405/1772 [08:48<02:00,  3.05it/s, running training loss:  0.86299]\u001b[A\n",
            "Training:  79%|███████▉  | 1405/1772 [08:49<02:00,  3.05it/s, running training loss:  1.21331]\u001b[A\n",
            "Training:  79%|███████▉  | 1406/1772 [08:49<01:51,  3.28it/s, running training loss:  1.21331]\u001b[A\n",
            "Training:  79%|███████▉  | 1406/1772 [08:49<01:51,  3.28it/s, running training loss:  0.76826]\u001b[A\n",
            "Training:  79%|███████▉  | 1407/1772 [08:49<01:52,  3.25it/s, running training loss:  0.76826]\u001b[A\n",
            "Training:  79%|███████▉  | 1407/1772 [08:49<01:52,  3.25it/s, running training loss:  1.02101]\u001b[A\n",
            "Training:  79%|███████▉  | 1408/1772 [08:49<02:14,  2.70it/s, running training loss:  1.02101]\u001b[A\n",
            "Training:  79%|███████▉  | 1408/1772 [08:50<02:14,  2.70it/s, running training loss:  0.94910]\u001b[A\n",
            "Training:  80%|███████▉  | 1409/1772 [08:50<02:06,  2.86it/s, running training loss:  0.94910]\u001b[A\n",
            "Training:  80%|███████▉  | 1409/1772 [08:50<02:06,  2.86it/s, running training loss:  0.94317]\u001b[A\n",
            "Training:  80%|███████▉  | 1410/1772 [08:50<02:03,  2.94it/s, running training loss:  0.94317]\u001b[A\n",
            "Training:  80%|███████▉  | 1410/1772 [08:50<02:03,  2.94it/s, running training loss:  1.06706]\u001b[A\n",
            "Training:  80%|███████▉  | 1411/1772 [08:50<02:07,  2.83it/s, running training loss:  1.06706]\u001b[A\n",
            "Training:  80%|███████▉  | 1411/1772 [08:51<02:07,  2.83it/s, running training loss:  0.88688]\u001b[A\n",
            "Training:  80%|███████▉  | 1412/1772 [08:51<02:01,  2.96it/s, running training loss:  0.88688]\u001b[A\n",
            "Training:  80%|███████▉  | 1412/1772 [08:51<02:01,  2.96it/s, running training loss:  0.92330]\u001b[A\n",
            "Training:  80%|███████▉  | 1413/1772 [08:51<01:55,  3.10it/s, running training loss:  0.92330]\u001b[A\n",
            "Training:  80%|███████▉  | 1413/1772 [08:51<01:55,  3.10it/s, running training loss:  0.83910]\u001b[A\n",
            "Training:  80%|███████▉  | 1414/1772 [08:51<01:49,  3.28it/s, running training loss:  0.83910]\u001b[A\n",
            "Training:  80%|███████▉  | 1414/1772 [08:52<01:49,  3.28it/s, running training loss:  0.91632]\u001b[A\n",
            "Training:  80%|███████▉  | 1415/1772 [08:52<02:04,  2.87it/s, running training loss:  0.91632]\u001b[A\n",
            "Training:  80%|███████▉  | 1415/1772 [08:52<02:04,  2.87it/s, running training loss:  0.94601]\u001b[A\n",
            "Training:  80%|███████▉  | 1416/1772 [08:52<02:22,  2.50it/s, running training loss:  0.94601]\u001b[A\n",
            "Training:  80%|███████▉  | 1416/1772 [08:53<02:22,  2.50it/s, running training loss:  1.16073]\u001b[A\n",
            "Training:  80%|███████▉  | 1417/1772 [08:53<02:09,  2.74it/s, running training loss:  1.16073]\u001b[A\n",
            "Training:  80%|███████▉  | 1417/1772 [08:53<02:09,  2.74it/s, running training loss:  1.12380]\u001b[A\n",
            "Training:  80%|████████  | 1418/1772 [08:53<02:24,  2.44it/s, running training loss:  1.12380]\u001b[A\n",
            "Training:  80%|████████  | 1418/1772 [08:54<02:24,  2.44it/s, running training loss:  1.41949]\u001b[A\n",
            "Training:  80%|████████  | 1419/1772 [08:54<02:41,  2.18it/s, running training loss:  1.41949]\u001b[A\n",
            "Training:  80%|████████  | 1419/1772 [08:54<02:41,  2.18it/s, running training loss:  1.22561]\u001b[A\n",
            "Training:  80%|████████  | 1420/1772 [08:54<02:34,  2.28it/s, running training loss:  1.22561]\u001b[A\n",
            "Training:  80%|████████  | 1420/1772 [08:55<02:34,  2.28it/s, running training loss:  1.16028]\u001b[A\n",
            "Training:  80%|████████  | 1421/1772 [08:55<02:37,  2.23it/s, running training loss:  1.16028]\u001b[A\n",
            "Training:  80%|████████  | 1421/1772 [08:55<02:37,  2.23it/s, running training loss:  0.90370]\u001b[A\n",
            "Training:  80%|████████  | 1422/1772 [08:55<02:17,  2.54it/s, running training loss:  0.90370]\u001b[A\n",
            "Training:  80%|████████  | 1422/1772 [08:55<02:17,  2.54it/s, running training loss:  1.00008]\u001b[A\n",
            "Training:  80%|████████  | 1423/1772 [08:55<02:11,  2.66it/s, running training loss:  1.00008]\u001b[A\n",
            "Training:  80%|████████  | 1423/1772 [08:55<02:11,  2.66it/s, running training loss:  0.81341]\u001b[A\n",
            "Training:  80%|████████  | 1424/1772 [08:55<01:55,  3.00it/s, running training loss:  0.81341]\u001b[A\n",
            "Training:  80%|████████  | 1424/1772 [08:56<01:55,  3.00it/s, running training loss:  0.92957]\u001b[A\n",
            "Training:  80%|████████  | 1425/1772 [08:56<02:00,  2.89it/s, running training loss:  0.92957]\u001b[A\n",
            "Training:  80%|████████  | 1425/1772 [08:56<02:00,  2.89it/s, running training loss:  0.83866]\u001b[A\n",
            "Training:  80%|████████  | 1426/1772 [08:56<01:56,  2.97it/s, running training loss:  0.83866]\u001b[A\n",
            "Training:  80%|████████  | 1426/1772 [08:56<01:56,  2.97it/s, running training loss:  1.03175]\u001b[A\n",
            "Training:  81%|████████  | 1427/1772 [08:56<01:56,  2.96it/s, running training loss:  1.03175]\u001b[A\n",
            "Training:  81%|████████  | 1427/1772 [08:57<01:56,  2.96it/s, running training loss:  0.85191]\u001b[A\n",
            "Training:  81%|████████  | 1428/1772 [08:57<01:59,  2.88it/s, running training loss:  0.85191]\u001b[A\n",
            "Training:  81%|████████  | 1428/1772 [08:57<01:59,  2.88it/s, running training loss:  0.83754]\u001b[A\n",
            "Training:  81%|████████  | 1429/1772 [08:57<02:13,  2.58it/s, running training loss:  0.83754]\u001b[A\n",
            "Training:  81%|████████  | 1429/1772 [08:57<02:13,  2.58it/s, running training loss:  0.87921]\u001b[A\n",
            "Training:  81%|████████  | 1430/1772 [08:58<01:59,  2.86it/s, running training loss:  0.87921]\u001b[A\n",
            "Training:  81%|████████  | 1430/1772 [08:58<01:59,  2.86it/s, running training loss:  0.87280]\u001b[A\n",
            "Training:  81%|████████  | 1431/1772 [08:58<02:06,  2.69it/s, running training loss:  0.87280]\u001b[A\n",
            "Training:  81%|████████  | 1431/1772 [08:58<02:06,  2.69it/s, running training loss:  1.18792]\u001b[A\n",
            "Training:  81%|████████  | 1432/1772 [08:58<02:07,  2.67it/s, running training loss:  1.18792]\u001b[A\n",
            "Training:  81%|████████  | 1432/1772 [08:59<02:07,  2.67it/s, running training loss:  1.17007]\u001b[A\n",
            "Training:  81%|████████  | 1433/1772 [08:59<02:01,  2.79it/s, running training loss:  1.17007]\u001b[A\n",
            "Training:  81%|████████  | 1433/1772 [08:59<02:01,  2.79it/s, running training loss:  1.35640]\u001b[A\n",
            "Training:  81%|████████  | 1434/1772 [08:59<02:23,  2.36it/s, running training loss:  1.35640]\u001b[A\n",
            "Training:  81%|████████  | 1434/1772 [09:00<02:23,  2.36it/s, running training loss:  0.97988]\u001b[A\n",
            "Training:  81%|████████  | 1435/1772 [09:00<02:11,  2.55it/s, running training loss:  0.97988]\u001b[A\n",
            "Training:  81%|████████  | 1435/1772 [09:00<02:11,  2.55it/s, running training loss:  1.05503]\u001b[A\n",
            "Training:  81%|████████  | 1436/1772 [09:00<02:02,  2.73it/s, running training loss:  1.05503]\u001b[A\n",
            "Training:  81%|████████  | 1436/1772 [09:00<02:02,  2.73it/s, running training loss:  0.55996]\u001b[A\n",
            "Training:  81%|████████  | 1437/1772 [09:00<02:01,  2.75it/s, running training loss:  0.55996]\u001b[A\n",
            "Training:  81%|████████  | 1437/1772 [09:00<02:01,  2.75it/s, running training loss:  1.01328]\u001b[A\n",
            "Training:  81%|████████  | 1438/1772 [09:00<01:52,  2.98it/s, running training loss:  1.01328]\u001b[A\n",
            "Training:  81%|████████  | 1438/1772 [09:01<01:52,  2.98it/s, running training loss:  0.88514]\u001b[A\n",
            "Training:  81%|████████  | 1439/1772 [09:01<01:51,  3.00it/s, running training loss:  0.88514]\u001b[A\n",
            "Training:  81%|████████  | 1439/1772 [09:01<01:51,  3.00it/s, running training loss:  1.18785]\u001b[A\n",
            "Training:  81%|████████▏ | 1440/1772 [09:01<01:53,  2.93it/s, running training loss:  1.18785]\u001b[A\n",
            "Training:  81%|████████▏ | 1440/1772 [09:02<01:53,  2.93it/s, running training loss:  1.22691]\u001b[A\n",
            "Training:  81%|████████▏ | 1441/1772 [09:02<02:07,  2.59it/s, running training loss:  1.22691]\u001b[A\n",
            "Training:  81%|████████▏ | 1441/1772 [09:02<02:07,  2.59it/s, running training loss:  0.81069]\u001b[A\n",
            "Training:  81%|████████▏ | 1442/1772 [09:02<02:08,  2.57it/s, running training loss:  0.81069]\u001b[A\n",
            "Training:  81%|████████▏ | 1442/1772 [09:02<02:08,  2.57it/s, running training loss:  1.12036]\u001b[A\n",
            "Training:  81%|████████▏ | 1443/1772 [09:02<01:55,  2.85it/s, running training loss:  1.12036]\u001b[A\n",
            "Training:  81%|████████▏ | 1443/1772 [09:03<01:55,  2.85it/s, running training loss:  0.70450]\u001b[A\n",
            "Training:  81%|████████▏ | 1444/1772 [09:03<02:10,  2.50it/s, running training loss:  0.70450]\u001b[A\n",
            "Training:  81%|████████▏ | 1444/1772 [09:03<02:10,  2.50it/s, running training loss:  1.01345]\u001b[A\n",
            "Training:  82%|████████▏ | 1445/1772 [09:03<02:04,  2.63it/s, running training loss:  1.01345]\u001b[A\n",
            "Training:  82%|████████▏ | 1445/1772 [09:03<02:04,  2.63it/s, running training loss:  0.88439]\u001b[A\n",
            "Training:  82%|████████▏ | 1446/1772 [09:03<01:54,  2.85it/s, running training loss:  0.88439]\u001b[A\n",
            "Training:  82%|████████▏ | 1446/1772 [09:04<01:54,  2.85it/s, running training loss:  0.89343]\u001b[A\n",
            "Training:  82%|████████▏ | 1447/1772 [09:04<01:52,  2.90it/s, running training loss:  0.89343]\u001b[A\n",
            "Training:  82%|████████▏ | 1447/1772 [09:04<01:52,  2.90it/s, running training loss:  0.81955]\u001b[A\n",
            "Training:  82%|████████▏ | 1448/1772 [09:04<01:54,  2.83it/s, running training loss:  0.81955]\u001b[A\n",
            "Training:  82%|████████▏ | 1448/1772 [09:04<01:54,  2.83it/s, running training loss:  0.83252]\u001b[A\n",
            "Training:  82%|████████▏ | 1449/1772 [09:04<01:51,  2.91it/s, running training loss:  0.83252]\u001b[A\n",
            "Training:  82%|████████▏ | 1449/1772 [09:05<01:51,  2.91it/s, running training loss:  0.94819]\u001b[A\n",
            "Training:  82%|████████▏ | 1450/1772 [09:05<01:57,  2.74it/s, running training loss:  0.94819]\u001b[A\n",
            "Training:  82%|████████▏ | 1450/1772 [09:05<01:57,  2.74it/s, running training loss:  0.84999]\u001b[A\n",
            "Training:  82%|████████▏ | 1451/1772 [09:05<01:54,  2.81it/s, running training loss:  0.84999]\u001b[A\n",
            "Training:  82%|████████▏ | 1451/1772 [09:06<01:54,  2.81it/s, running training loss:  0.99753]\u001b[A\n",
            "Training:  82%|████████▏ | 1452/1772 [09:06<02:09,  2.47it/s, running training loss:  0.99753]\u001b[A\n",
            "Training:  82%|████████▏ | 1452/1772 [09:06<02:09,  2.47it/s, running training loss:  0.89735]\u001b[A\n",
            "Training:  82%|████████▏ | 1453/1772 [09:06<01:58,  2.69it/s, running training loss:  0.89735]\u001b[A\n",
            "Training:  82%|████████▏ | 1453/1772 [09:06<01:58,  2.69it/s, running training loss:  0.96959]\u001b[A\n",
            "Training:  82%|████████▏ | 1454/1772 [09:06<02:03,  2.57it/s, running training loss:  0.96959]\u001b[A\n",
            "Training:  82%|████████▏ | 1454/1772 [09:07<02:03,  2.57it/s, running training loss:  0.79949]\u001b[A\n",
            "Training:  82%|████████▏ | 1455/1772 [09:07<01:52,  2.81it/s, running training loss:  0.79949]\u001b[A\n",
            "Training:  82%|████████▏ | 1455/1772 [09:07<01:52,  2.81it/s, running training loss:  0.90423]\u001b[A\n",
            "Training:  82%|████████▏ | 1456/1772 [09:07<01:51,  2.84it/s, running training loss:  0.90423]\u001b[A\n",
            "Training:  82%|████████▏ | 1456/1772 [09:07<01:51,  2.84it/s, running training loss:  1.01693]\u001b[A\n",
            "Training:  82%|████████▏ | 1457/1772 [09:07<01:47,  2.94it/s, running training loss:  1.01693]\u001b[A\n",
            "Training:  82%|████████▏ | 1457/1772 [09:08<01:47,  2.94it/s, running training loss:  0.85713]\u001b[A\n",
            "Training:  82%|████████▏ | 1458/1772 [09:08<01:39,  3.17it/s, running training loss:  0.85713]\u001b[A\n",
            "Training:  82%|████████▏ | 1458/1772 [09:08<01:39,  3.17it/s, running training loss:  1.19028]\u001b[A\n",
            "Training:  82%|████████▏ | 1459/1772 [09:08<01:49,  2.87it/s, running training loss:  1.19028]\u001b[A\n",
            "Training:  82%|████████▏ | 1459/1772 [09:08<01:49,  2.87it/s, running training loss:  1.33590]\u001b[A\n",
            "Training:  82%|████████▏ | 1460/1772 [09:08<01:44,  2.99it/s, running training loss:  1.33590]\u001b[A\n",
            "Training:  82%|████████▏ | 1460/1772 [09:09<01:44,  2.99it/s, running training loss:  1.38338]\u001b[A\n",
            "Training:  82%|████████▏ | 1461/1772 [09:09<01:40,  3.09it/s, running training loss:  1.38338]\u001b[A\n",
            "Training:  82%|████████▏ | 1461/1772 [09:09<01:40,  3.09it/s, running training loss:  1.10313]\u001b[A\n",
            "Training:  83%|████████▎ | 1462/1772 [09:09<01:37,  3.16it/s, running training loss:  1.10313]\u001b[A\n",
            "Training:  83%|████████▎ | 1462/1772 [09:09<01:37,  3.16it/s, running training loss:  1.08623]\u001b[A\n",
            "Training:  83%|████████▎ | 1463/1772 [09:09<01:31,  3.37it/s, running training loss:  1.08623]\u001b[A\n",
            "Training:  83%|████████▎ | 1463/1772 [09:10<01:31,  3.37it/s, running training loss:  0.80234]\u001b[A\n",
            "Training:  83%|████████▎ | 1464/1772 [09:10<01:34,  3.25it/s, running training loss:  0.80234]\u001b[A\n",
            "Training:  83%|████████▎ | 1464/1772 [09:10<01:34,  3.25it/s, running training loss:  0.90016]\u001b[A\n",
            "Training:  83%|████████▎ | 1465/1772 [09:10<01:30,  3.39it/s, running training loss:  0.90016]\u001b[A\n",
            "Training:  83%|████████▎ | 1465/1772 [09:10<01:30,  3.39it/s, running training loss:  1.11096]\u001b[A\n",
            "Training:  83%|████████▎ | 1466/1772 [09:10<01:39,  3.08it/s, running training loss:  1.11096]\u001b[A\n",
            "Training:  83%|████████▎ | 1466/1772 [09:11<01:39,  3.08it/s, running training loss:  1.10438]\u001b[A\n",
            "Training:  83%|████████▎ | 1467/1772 [09:11<01:45,  2.89it/s, running training loss:  1.10438]\u001b[A\n",
            "Training:  83%|████████▎ | 1467/1772 [09:11<01:45,  2.89it/s, running training loss:  0.74456]\u001b[A\n",
            "Training:  83%|████████▎ | 1468/1772 [09:11<01:54,  2.65it/s, running training loss:  0.74456]\u001b[A\n",
            "Training:  83%|████████▎ | 1468/1772 [09:11<01:54,  2.65it/s, running training loss:  0.94014]\u001b[A\n",
            "Training:  83%|████████▎ | 1469/1772 [09:11<01:50,  2.74it/s, running training loss:  0.94014]\u001b[A\n",
            "Training:  83%|████████▎ | 1469/1772 [09:12<01:50,  2.74it/s, running training loss:  0.80957]\u001b[A\n",
            "Training:  83%|████████▎ | 1470/1772 [09:12<01:47,  2.80it/s, running training loss:  0.80957]\u001b[A\n",
            "Training:  83%|████████▎ | 1470/1772 [09:12<01:47,  2.80it/s, running training loss:  0.78252]\u001b[A\n",
            "Training:  83%|████████▎ | 1471/1772 [09:12<01:54,  2.62it/s, running training loss:  0.78252]\u001b[A\n",
            "Training:  83%|████████▎ | 1471/1772 [09:12<01:54,  2.62it/s, running training loss:  0.71838]\u001b[A\n",
            "Training:  83%|████████▎ | 1472/1772 [09:12<01:44,  2.86it/s, running training loss:  0.71838]\u001b[A\n",
            "Training:  83%|████████▎ | 1472/1772 [09:13<01:44,  2.86it/s, running training loss:  0.75703]\u001b[A\n",
            "Training:  83%|████████▎ | 1473/1772 [09:13<01:42,  2.92it/s, running training loss:  0.75703]\u001b[A\n",
            "Training:  83%|████████▎ | 1473/1772 [09:13<01:42,  2.92it/s, running training loss:  0.93043]\u001b[A\n",
            "Training:  83%|████████▎ | 1474/1772 [09:13<01:39,  2.99it/s, running training loss:  0.93043]\u001b[A\n",
            "Training:  83%|████████▎ | 1474/1772 [09:13<01:39,  2.99it/s, running training loss:  0.80784]\u001b[A\n",
            "Training:  83%|████████▎ | 1475/1772 [09:13<01:36,  3.07it/s, running training loss:  0.80784]\u001b[A\n",
            "Training:  83%|████████▎ | 1475/1772 [09:14<01:36,  3.07it/s, running training loss:  1.11688]\u001b[A\n",
            "Training:  83%|████████▎ | 1476/1772 [09:14<01:33,  3.16it/s, running training loss:  1.11688]\u001b[A\n",
            "Training:  83%|████████▎ | 1476/1772 [09:14<01:33,  3.16it/s, running training loss:  1.08639]\u001b[A\n",
            "Training:  83%|████████▎ | 1477/1772 [09:14<01:39,  2.96it/s, running training loss:  1.08639]\u001b[A\n",
            "Training:  83%|████████▎ | 1477/1772 [09:14<01:39,  2.96it/s, running training loss:  0.94283]\u001b[A\n",
            "Training:  83%|████████▎ | 1478/1772 [09:14<01:37,  3.02it/s, running training loss:  0.94283]\u001b[A\n",
            "Training:  83%|████████▎ | 1478/1772 [09:15<01:37,  3.02it/s, running training loss:  1.16521]\u001b[A\n",
            "Training:  83%|████████▎ | 1479/1772 [09:15<01:34,  3.10it/s, running training loss:  1.16521]\u001b[A\n",
            "Training:  83%|████████▎ | 1479/1772 [09:15<01:34,  3.10it/s, running training loss:  1.14803]\u001b[A\n",
            "Training:  84%|████████▎ | 1480/1772 [09:15<01:36,  3.03it/s, running training loss:  1.14803]\u001b[A\n",
            "Training:  84%|████████▎ | 1480/1772 [09:15<01:36,  3.03it/s, running training loss:  1.13714]\u001b[A\n",
            "Training:  84%|████████▎ | 1481/1772 [09:15<01:33,  3.11it/s, running training loss:  1.13714]\u001b[A\n",
            "Training:  84%|████████▎ | 1481/1772 [09:16<01:33,  3.11it/s, running training loss:  0.72095]\u001b[A\n",
            "Training:  84%|████████▎ | 1482/1772 [09:16<01:27,  3.33it/s, running training loss:  0.72095]\u001b[A\n",
            "Training:  84%|████████▎ | 1482/1772 [09:16<01:27,  3.33it/s, running training loss:  0.77645]\u001b[A\n",
            "Training:  84%|████████▎ | 1483/1772 [09:16<01:24,  3.44it/s, running training loss:  0.77645]\u001b[A\n",
            "Training:  84%|████████▎ | 1483/1772 [09:16<01:24,  3.44it/s, running training loss:  0.72481]\u001b[A\n",
            "Training:  84%|████████▎ | 1484/1772 [09:16<01:31,  3.13it/s, running training loss:  0.72481]\u001b[A\n",
            "Training:  84%|████████▎ | 1484/1772 [09:17<01:31,  3.13it/s, running training loss:  1.18996]\u001b[A\n",
            "Training:  84%|████████▍ | 1485/1772 [09:17<01:31,  3.12it/s, running training loss:  1.18996]\u001b[A\n",
            "Training:  84%|████████▍ | 1485/1772 [09:17<01:31,  3.12it/s, running training loss:  1.14811]\u001b[A\n",
            "Training:  84%|████████▍ | 1486/1772 [09:17<01:49,  2.61it/s, running training loss:  1.14811]\u001b[A\n",
            "Training:  84%|████████▍ | 1486/1772 [09:17<01:49,  2.61it/s, running training loss:  1.07623]\u001b[A\n",
            "Training:  84%|████████▍ | 1487/1772 [09:17<01:42,  2.79it/s, running training loss:  1.07623]\u001b[A\n",
            "Training:  84%|████████▍ | 1487/1772 [09:18<01:42,  2.79it/s, running training loss:  0.74719]\u001b[A\n",
            "Training:  84%|████████▍ | 1488/1772 [09:18<01:44,  2.73it/s, running training loss:  0.74719]\u001b[A\n",
            "Training:  84%|████████▍ | 1488/1772 [09:18<01:44,  2.73it/s, running training loss:  1.23772]\u001b[A\n",
            "Training:  84%|████████▍ | 1489/1772 [09:18<01:38,  2.87it/s, running training loss:  1.23772]\u001b[A\n",
            "Training:  84%|████████▍ | 1489/1772 [09:18<01:38,  2.87it/s, running training loss:  0.82427]\u001b[A\n",
            "Training:  84%|████████▍ | 1490/1772 [09:18<01:40,  2.82it/s, running training loss:  0.82427]\u001b[A\n",
            "Training:  84%|████████▍ | 1490/1772 [09:19<01:40,  2.82it/s, running training loss:  0.90814]\u001b[A\n",
            "Training:  84%|████████▍ | 1491/1772 [09:19<01:48,  2.59it/s, running training loss:  0.90814]\u001b[A\n",
            "Training:  84%|████████▍ | 1491/1772 [09:19<01:48,  2.59it/s, running training loss:  0.89705]\u001b[A\n",
            "Training:  84%|████████▍ | 1492/1772 [09:19<01:45,  2.65it/s, running training loss:  0.89705]\u001b[A\n",
            "Training:  84%|████████▍ | 1492/1772 [09:20<01:45,  2.65it/s, running training loss:  1.04742]\u001b[A\n",
            "Training:  84%|████████▍ | 1493/1772 [09:20<01:38,  2.83it/s, running training loss:  1.04742]\u001b[A\n",
            "Training:  84%|████████▍ | 1493/1772 [09:20<01:38,  2.83it/s, running training loss:  0.80782]\u001b[A\n",
            "Training:  84%|████████▍ | 1494/1772 [09:20<01:39,  2.79it/s, running training loss:  0.80782]\u001b[A\n",
            "Training:  84%|████████▍ | 1494/1772 [09:20<01:39,  2.79it/s, running training loss:  1.02889]\u001b[A\n",
            "Training:  84%|████████▍ | 1495/1772 [09:20<01:34,  2.94it/s, running training loss:  1.02889]\u001b[A\n",
            "Training:  84%|████████▍ | 1495/1772 [09:21<01:34,  2.94it/s, running training loss:  0.71368]\u001b[A\n",
            "Training:  84%|████████▍ | 1496/1772 [09:21<01:34,  2.91it/s, running training loss:  0.71368]\u001b[A\n",
            "Training:  84%|████████▍ | 1496/1772 [09:21<01:34,  2.91it/s, running training loss:  0.93806]\u001b[A\n",
            "Training:  84%|████████▍ | 1497/1772 [09:21<01:25,  3.22it/s, running training loss:  0.93806]\u001b[A\n",
            "Training:  84%|████████▍ | 1497/1772 [09:21<01:25,  3.22it/s, running training loss:  0.67217]\u001b[A\n",
            "Training:  85%|████████▍ | 1498/1772 [09:21<01:22,  3.32it/s, running training loss:  0.67217]\u001b[A\n",
            "Training:  85%|████████▍ | 1498/1772 [09:22<01:22,  3.32it/s, running training loss:  0.83687]\u001b[A\n",
            "Training:  85%|████████▍ | 1499/1772 [09:22<01:36,  2.82it/s, running training loss:  0.83687]\u001b[A\n",
            "Training:  85%|████████▍ | 1499/1772 [09:22<01:36,  2.82it/s, running training loss:  0.77272]\u001b[A\n",
            "\n",
            "Evaluation:   0%|          | 0/270 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   0%|          | 1/270 [00:00<01:16,  3.50it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   1%|          | 3/270 [00:00<00:31,  8.43it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   2%|▏         | 5/270 [00:00<00:22, 11.66it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   3%|▎         | 7/270 [00:00<00:18, 13.99it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   3%|▎         | 9/270 [00:00<00:17, 15.16it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   4%|▍         | 12/270 [00:00<00:13, 18.46it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   5%|▌         | 14/270 [00:00<00:13, 18.39it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   6%|▌         | 16/270 [00:01<00:13, 18.44it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   7%|▋         | 18/270 [00:01<00:13, 18.11it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   7%|▋         | 20/270 [00:01<00:14, 17.32it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   9%|▊         | 23/270 [00:01<00:12, 19.48it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   9%|▉         | 25/270 [00:01<00:12, 19.14it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  10%|█         | 28/270 [00:01<00:12, 19.71it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  11%|█         | 30/270 [00:01<00:12, 18.54it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  12%|█▏        | 32/270 [00:01<00:12, 18.67it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  13%|█▎        | 35/270 [00:02<00:12, 19.01it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  14%|█▍        | 38/270 [00:02<00:11, 20.82it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  15%|█▌        | 41/270 [00:02<00:11, 20.23it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  16%|█▋        | 44/270 [00:02<00:11, 19.41it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  17%|█▋        | 46/270 [00:02<00:11, 19.33it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  18%|█▊        | 49/270 [00:02<00:11, 19.65it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  19%|█▉        | 51/270 [00:02<00:11, 18.79it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  20%|█▉        | 53/270 [00:02<00:11, 18.92it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  21%|██        | 56/270 [00:03<00:11, 19.06it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  21%|██▏       | 58/270 [00:03<00:11, 18.83it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  22%|██▏       | 60/270 [00:03<00:11, 18.62it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  23%|██▎       | 62/270 [00:03<00:11, 18.46it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  24%|██▎       | 64/270 [00:03<00:11, 18.56it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  25%|██▍       | 67/270 [00:03<00:10, 19.69it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  26%|██▌       | 70/270 [00:03<00:09, 21.00it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  27%|██▋       | 73/270 [00:04<00:09, 20.60it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  28%|██▊       | 76/270 [00:04<00:09, 21.24it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  29%|██▉       | 79/270 [00:04<00:09, 20.84it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  30%|███       | 82/270 [00:04<00:09, 19.76it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  31%|███       | 84/270 [00:04<00:09, 19.52it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  32%|███▏      | 87/270 [00:04<00:09, 19.94it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  33%|███▎      | 89/270 [00:04<00:09, 19.08it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  34%|███▎      | 91/270 [00:04<00:09, 19.09it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  35%|███▍      | 94/270 [00:05<00:08, 20.13it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  36%|███▌      | 97/270 [00:05<00:08, 20.71it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  37%|███▋      | 100/270 [00:05<00:08, 20.49it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  38%|███▊      | 103/270 [00:05<00:07, 21.05it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  39%|███▉      | 106/270 [00:05<00:08, 20.19it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  40%|████      | 109/270 [00:05<00:07, 20.22it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  41%|████▏     | 112/270 [00:05<00:07, 20.37it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  43%|████▎     | 115/270 [00:06<00:07, 20.59it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  44%|████▎     | 118/270 [00:06<00:07, 20.72it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  45%|████▍     | 121/270 [00:06<00:07, 20.45it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  46%|████▌     | 124/270 [00:06<00:06, 21.33it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  47%|████▋     | 127/270 [00:06<00:07, 19.51it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  48%|████▊     | 129/270 [00:06<00:07, 18.69it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  49%|████▉     | 132/270 [00:06<00:07, 19.21it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  50%|████▉     | 134/270 [00:07<00:07, 19.18it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  51%|█████     | 137/270 [00:07<00:06, 20.27it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  52%|█████▏    | 140/270 [00:07<00:06, 20.27it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  53%|█████▎    | 143/270 [00:07<00:06, 19.20it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  54%|█████▎    | 145/270 [00:07<00:06, 19.34it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  54%|█████▍    | 147/270 [00:07<00:06, 19.39it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  56%|█████▌    | 150/270 [00:07<00:05, 20.19it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  57%|█████▋    | 153/270 [00:08<00:06, 19.11it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  57%|█████▋    | 155/270 [00:08<00:06, 19.10it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  58%|█████▊    | 157/270 [00:08<00:05, 19.22it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  59%|█████▉    | 160/270 [00:08<00:05, 19.53it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  60%|██████    | 162/270 [00:08<00:05, 19.38it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  61%|██████    | 164/270 [00:08<00:05, 18.78it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  61%|██████▏   | 166/270 [00:08<00:05, 18.81it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  63%|██████▎   | 169/270 [00:08<00:05, 18.80it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  63%|██████▎   | 171/270 [00:08<00:05, 19.03it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  64%|██████▍   | 173/270 [00:09<00:05, 19.20it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  65%|██████▍   | 175/270 [00:09<00:05, 18.71it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  66%|██████▌   | 177/270 [00:09<00:05, 17.75it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  66%|██████▋   | 179/270 [00:09<00:05, 18.18it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  67%|██████▋   | 181/270 [00:09<00:04, 18.18it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  68%|██████▊   | 183/270 [00:09<00:04, 18.09it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  69%|██████▊   | 185/270 [00:09<00:04, 18.08it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  69%|██████▉   | 187/270 [00:09<00:04, 18.49it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  70%|███████   | 189/270 [00:09<00:04, 18.74it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  71%|███████   | 192/270 [00:10<00:04, 19.12it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  72%|███████▏  | 194/270 [00:10<00:04, 18.81it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  73%|███████▎  | 196/270 [00:10<00:04, 18.27it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  73%|███████▎  | 198/270 [00:10<00:03, 18.41it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  74%|███████▍  | 200/270 [00:10<00:03, 17.71it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  75%|███████▍  | 202/270 [00:10<00:03, 17.38it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  76%|███████▌  | 205/270 [00:10<00:03, 19.68it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  77%|███████▋  | 207/270 [00:10<00:03, 19.21it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  77%|███████▋  | 209/270 [00:11<00:03, 18.32it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  78%|███████▊  | 211/270 [00:11<00:03, 18.45it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  79%|███████▉  | 213/270 [00:11<00:03, 18.11it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  80%|████████  | 216/270 [00:11<00:02, 19.09it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  81%|████████  | 219/270 [00:11<00:02, 20.19it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  82%|████████▏ | 222/270 [00:11<00:02, 21.24it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  83%|████████▎ | 225/270 [00:11<00:02, 22.05it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  84%|████████▍ | 228/270 [00:11<00:02, 20.22it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  86%|████████▌ | 231/270 [00:12<00:02, 18.98it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  87%|████████▋ | 234/270 [00:12<00:01, 20.14it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  88%|████████▊ | 237/270 [00:12<00:01, 20.46it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  89%|████████▉ | 240/270 [00:12<00:01, 19.70it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  90%|████████▉ | 242/270 [00:12<00:01, 19.53it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  90%|█████████ | 244/270 [00:12<00:01, 19.13it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  91%|█████████ | 246/270 [00:12<00:01, 18.17it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  92%|█████████▏| 248/270 [00:13<00:01, 17.54it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  93%|█████████▎| 250/270 [00:13<00:01, 17.30it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  93%|█████████▎| 252/270 [00:13<00:01, 17.22it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  94%|█████████▍| 254/270 [00:13<00:00, 17.10it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  95%|█████████▍| 256/270 [00:13<00:00, 16.77it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  96%|█████████▌| 259/270 [00:13<00:00, 18.64it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  97%|█████████▋| 262/270 [00:13<00:00, 19.11it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  98%|█████████▊| 264/270 [00:13<00:00, 18.24it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  99%|█████████▊| 266/270 [00:14<00:00, 18.13it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  99%|█████████▉| 268/270 [00:14<00:00, 18.46it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation: 100%|██████████| 270/270 [00:14<00:00, 18.70it/s]\n",
            "\n",
            "Training:  85%|████████▍ | 1500/1772 [09:38<23:01,  5.08s/it, running training loss:  0.77272]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            ">>> training loss: 0.980055, valid loss: 0.615226,valid f1: 0.000000, valid acc:0.689991\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  85%|████████▍ | 1500/1772 [09:38<23:01,  5.08s/it, running training loss:  1.05210]\u001b[A\n",
            "Training:  85%|████████▍ | 1501/1772 [09:38<16:28,  3.65s/it, running training loss:  1.05210]\u001b[A\n",
            "Training:  85%|████████▍ | 1501/1772 [09:38<16:28,  3.65s/it, running training loss:  0.90251]\u001b[A\n",
            "Training:  85%|████████▍ | 1502/1772 [09:38<11:57,  2.66s/it, running training loss:  0.90251]\u001b[A\n",
            "Training:  85%|████████▍ | 1502/1772 [09:39<11:57,  2.66s/it, running training loss:  1.30597]\u001b[A\n",
            "Training:  85%|████████▍ | 1503/1772 [09:39<08:49,  1.97s/it, running training loss:  1.30597]\u001b[A\n",
            "Training:  85%|████████▍ | 1503/1772 [09:39<08:49,  1.97s/it, running training loss:  1.23146]\u001b[A\n",
            "Training:  85%|████████▍ | 1504/1772 [09:39<06:43,  1.50s/it, running training loss:  1.23146]\u001b[A\n",
            "Training:  85%|████████▍ | 1504/1772 [09:39<06:43,  1.50s/it, running training loss:  1.26753]\u001b[A\n",
            "Training:  85%|████████▍ | 1505/1772 [09:39<05:11,  1.17s/it, running training loss:  1.26753]\u001b[A\n",
            "Training:  85%|████████▍ | 1505/1772 [09:40<05:11,  1.17s/it, running training loss:  1.11411]\u001b[A\n",
            "Training:  85%|████████▍ | 1506/1772 [09:40<03:58,  1.11it/s, running training loss:  1.11411]\u001b[A\n",
            "Training:  85%|████████▍ | 1506/1772 [09:40<03:58,  1.11it/s, running training loss:  1.31056]\u001b[A\n",
            "Training:  85%|████████▌ | 1507/1772 [09:40<03:03,  1.44it/s, running training loss:  1.31056]\u001b[A\n",
            "Training:  85%|████████▌ | 1507/1772 [09:40<03:03,  1.44it/s, running training loss:  0.99844]\u001b[A\n",
            "Training:  85%|████████▌ | 1508/1772 [09:40<02:36,  1.68it/s, running training loss:  0.99844]\u001b[A\n",
            "Training:  85%|████████▌ | 1508/1772 [09:41<02:36,  1.68it/s, running training loss:  1.00829]\u001b[A\n",
            "Training:  85%|████████▌ | 1509/1772 [09:41<02:12,  1.98it/s, running training loss:  1.00829]\u001b[A\n",
            "Training:  85%|████████▌ | 1509/1772 [09:41<02:12,  1.98it/s, running training loss:  0.92543]\u001b[A\n",
            "Training:  85%|████████▌ | 1510/1772 [09:41<02:03,  2.12it/s, running training loss:  0.92543]\u001b[A\n",
            "Training:  85%|████████▌ | 1510/1772 [09:41<02:03,  2.12it/s, running training loss:  0.70980]\u001b[A\n",
            "Training:  85%|████████▌ | 1511/1772 [09:41<01:51,  2.34it/s, running training loss:  0.70980]\u001b[A\n",
            "Training:  85%|████████▌ | 1511/1772 [09:42<01:51,  2.34it/s, running training loss:  1.04362]\u001b[A\n",
            "Training:  85%|████████▌ | 1512/1772 [09:42<01:39,  2.63it/s, running training loss:  1.04362]\u001b[A\n",
            "Training:  85%|████████▌ | 1512/1772 [09:42<01:39,  2.63it/s, running training loss:  0.69576]\u001b[A\n",
            "Training:  85%|████████▌ | 1513/1772 [09:42<01:30,  2.85it/s, running training loss:  0.69576]\u001b[A\n",
            "Training:  85%|████████▌ | 1513/1772 [09:42<01:30,  2.85it/s, running training loss:  0.89537]\u001b[A\n",
            "Training:  85%|████████▌ | 1514/1772 [09:42<01:25,  3.01it/s, running training loss:  0.89537]\u001b[A\n",
            "Training:  85%|████████▌ | 1514/1772 [09:43<01:25,  3.01it/s, running training loss:  0.66491]\u001b[A\n",
            "Training:  85%|████████▌ | 1515/1772 [09:43<01:28,  2.91it/s, running training loss:  0.66491]\u001b[A\n",
            "Training:  85%|████████▌ | 1515/1772 [09:43<01:28,  2.91it/s, running training loss:  0.76602]\u001b[A\n",
            "Training:  86%|████████▌ | 1516/1772 [09:43<01:23,  3.06it/s, running training loss:  0.76602]\u001b[A\n",
            "Training:  86%|████████▌ | 1516/1772 [09:43<01:23,  3.06it/s, running training loss:  0.78030]\u001b[A\n",
            "Training:  86%|████████▌ | 1517/1772 [09:43<01:25,  2.98it/s, running training loss:  0.78030]\u001b[A\n",
            "Training:  86%|████████▌ | 1517/1772 [09:44<01:25,  2.98it/s, running training loss:  0.92615]\u001b[A\n",
            "Training:  86%|████████▌ | 1518/1772 [09:44<01:25,  2.96it/s, running training loss:  0.92615]\u001b[A\n",
            "Training:  86%|████████▌ | 1518/1772 [09:44<01:25,  2.96it/s, running training loss:  0.87395]\u001b[A\n",
            "Training:  86%|████████▌ | 1519/1772 [09:44<01:20,  3.13it/s, running training loss:  0.87395]\u001b[A\n",
            "Training:  86%|████████▌ | 1519/1772 [09:44<01:20,  3.13it/s, running training loss:  0.61168]\u001b[A\n",
            "Training:  86%|████████▌ | 1520/1772 [09:44<01:19,  3.19it/s, running training loss:  0.61168]\u001b[A\n",
            "Training:  86%|████████▌ | 1520/1772 [09:44<01:19,  3.19it/s, running training loss:  0.87304]\u001b[A\n",
            "Training:  86%|████████▌ | 1521/1772 [09:44<01:16,  3.28it/s, running training loss:  0.87304]\u001b[A\n",
            "Training:  86%|████████▌ | 1521/1772 [09:45<01:16,  3.28it/s, running training loss:  0.94482]\u001b[A\n",
            "Training:  86%|████████▌ | 1522/1772 [09:45<01:13,  3.40it/s, running training loss:  0.94482]\u001b[A\n",
            "Training:  86%|████████▌ | 1522/1772 [09:45<01:13,  3.40it/s, running training loss:  1.16995]\u001b[A\n",
            "Training:  86%|████████▌ | 1523/1772 [09:45<01:28,  2.80it/s, running training loss:  1.16995]\u001b[A\n",
            "Training:  86%|████████▌ | 1523/1772 [09:46<01:28,  2.80it/s, running training loss:  1.10239]\u001b[A\n",
            "Training:  86%|████████▌ | 1524/1772 [09:46<01:38,  2.51it/s, running training loss:  1.10239]\u001b[A\n",
            "Training:  86%|████████▌ | 1524/1772 [09:46<01:38,  2.51it/s, running training loss:  1.01143]\u001b[A\n",
            "Training:  86%|████████▌ | 1525/1772 [09:46<01:31,  2.69it/s, running training loss:  1.01143]\u001b[A\n",
            "Training:  86%|████████▌ | 1525/1772 [09:46<01:31,  2.69it/s, running training loss:  1.18481]\u001b[A\n",
            "Training:  86%|████████▌ | 1526/1772 [09:46<01:26,  2.85it/s, running training loss:  1.18481]\u001b[A\n",
            "Training:  86%|████████▌ | 1526/1772 [09:47<01:26,  2.85it/s, running training loss:  1.52468]\u001b[A\n",
            "Training:  86%|████████▌ | 1527/1772 [09:47<01:23,  2.94it/s, running training loss:  1.52468]\u001b[A\n",
            "Training:  86%|████████▌ | 1527/1772 [09:47<01:23,  2.94it/s, running training loss:  0.90863]\u001b[A\n",
            "Training:  86%|████████▌ | 1528/1772 [09:47<01:22,  2.96it/s, running training loss:  0.90863]\u001b[A\n",
            "Training:  86%|████████▌ | 1528/1772 [09:47<01:22,  2.96it/s, running training loss:  0.69595]\u001b[A\n",
            "Training:  86%|████████▋ | 1529/1772 [09:47<01:21,  2.97it/s, running training loss:  0.69595]\u001b[A\n",
            "Training:  86%|████████▋ | 1529/1772 [09:48<01:21,  2.97it/s, running training loss:  1.07432]\u001b[A\n",
            "Training:  86%|████████▋ | 1530/1772 [09:48<01:30,  2.66it/s, running training loss:  1.07432]\u001b[A\n",
            "Training:  86%|████████▋ | 1530/1772 [09:48<01:30,  2.66it/s, running training loss:  0.71286]\u001b[A\n",
            "Training:  86%|████████▋ | 1531/1772 [09:48<01:31,  2.64it/s, running training loss:  0.71286]\u001b[A\n",
            "Training:  86%|████████▋ | 1531/1772 [09:48<01:31,  2.64it/s, running training loss:  0.95028]\u001b[A\n",
            "Training:  86%|████████▋ | 1532/1772 [09:48<01:29,  2.69it/s, running training loss:  0.95028]\u001b[A\n",
            "Training:  86%|████████▋ | 1532/1772 [09:49<01:29,  2.69it/s, running training loss:  0.77157]\u001b[A\n",
            "Training:  87%|████████▋ | 1533/1772 [09:49<01:26,  2.78it/s, running training loss:  0.77157]\u001b[A\n",
            "Training:  87%|████████▋ | 1533/1772 [09:49<01:26,  2.78it/s, running training loss:  0.99079]\u001b[A\n",
            "Training:  87%|████████▋ | 1534/1772 [09:49<01:19,  3.00it/s, running training loss:  0.99079]\u001b[A\n",
            "Training:  87%|████████▋ | 1534/1772 [09:49<01:19,  3.00it/s, running training loss:  0.86113]\u001b[A\n",
            "Training:  87%|████████▋ | 1535/1772 [09:49<01:16,  3.09it/s, running training loss:  0.86113]\u001b[A\n",
            "Training:  87%|████████▋ | 1535/1772 [09:50<01:16,  3.09it/s, running training loss:  0.84242]\u001b[A\n",
            "Training:  87%|████████▋ | 1536/1772 [09:50<01:17,  3.04it/s, running training loss:  0.84242]\u001b[A\n",
            "Training:  87%|████████▋ | 1536/1772 [09:50<01:17,  3.04it/s, running training loss:  1.05716]\u001b[A\n",
            "Training:  87%|████████▋ | 1537/1772 [09:50<01:13,  3.18it/s, running training loss:  1.05716]\u001b[A\n",
            "Training:  87%|████████▋ | 1537/1772 [09:50<01:13,  3.18it/s, running training loss:  0.72116]\u001b[A\n",
            "Training:  87%|████████▋ | 1538/1772 [09:50<01:18,  2.96it/s, running training loss:  0.72116]\u001b[A\n",
            "Training:  87%|████████▋ | 1538/1772 [09:51<01:18,  2.96it/s, running training loss:  1.30001]\u001b[A\n",
            "Training:  87%|████████▋ | 1539/1772 [09:51<01:19,  2.92it/s, running training loss:  1.30001]\u001b[A\n",
            "Training:  87%|████████▋ | 1539/1772 [09:51<01:19,  2.92it/s, running training loss:  0.91230]\u001b[A\n",
            "Training:  87%|████████▋ | 1540/1772 [09:51<01:15,  3.07it/s, running training loss:  0.91230]\u001b[A\n",
            "Training:  87%|████████▋ | 1540/1772 [09:51<01:15,  3.07it/s, running training loss:  1.25564]\u001b[A\n",
            "Training:  87%|████████▋ | 1541/1772 [09:51<01:18,  2.94it/s, running training loss:  1.25564]\u001b[A\n",
            "Training:  87%|████████▋ | 1541/1772 [09:52<01:18,  2.94it/s, running training loss:  1.48227]\u001b[A\n",
            "Training:  87%|████████▋ | 1542/1772 [09:52<01:15,  3.05it/s, running training loss:  1.48227]\u001b[A\n",
            "Training:  87%|████████▋ | 1542/1772 [09:52<01:15,  3.05it/s, running training loss:  1.11763]\u001b[A\n",
            "Training:  87%|████████▋ | 1543/1772 [09:52<01:17,  2.96it/s, running training loss:  1.11763]\u001b[A\n",
            "Training:  87%|████████▋ | 1543/1772 [09:52<01:17,  2.96it/s, running training loss:  1.13756]\u001b[A\n",
            "Training:  87%|████████▋ | 1544/1772 [09:52<01:15,  3.03it/s, running training loss:  1.13756]\u001b[A\n",
            "Training:  87%|████████▋ | 1544/1772 [09:53<01:15,  3.03it/s, running training loss:  1.24605]\u001b[A\n",
            "Training:  87%|████████▋ | 1545/1772 [09:53<01:23,  2.73it/s, running training loss:  1.24605]\u001b[A\n",
            "Training:  87%|████████▋ | 1545/1772 [09:53<01:23,  2.73it/s, running training loss:  1.25816]\u001b[A\n",
            "Training:  87%|████████▋ | 1546/1772 [09:53<01:19,  2.85it/s, running training loss:  1.25816]\u001b[A\n",
            "Training:  87%|████████▋ | 1546/1772 [09:53<01:19,  2.85it/s, running training loss:  0.71276]\u001b[A\n",
            "Training:  87%|████████▋ | 1547/1772 [09:53<01:16,  2.94it/s, running training loss:  0.71276]\u001b[A\n",
            "Training:  87%|████████▋ | 1547/1772 [09:54<01:16,  2.94it/s, running training loss:  0.75553]\u001b[A\n",
            "Training:  87%|████████▋ | 1548/1772 [09:54<01:12,  3.07it/s, running training loss:  0.75553]\u001b[A\n",
            "Training:  87%|████████▋ | 1548/1772 [09:54<01:12,  3.07it/s, running training loss:  1.20093]\u001b[A\n",
            "Training:  87%|████████▋ | 1549/1772 [09:54<01:11,  3.13it/s, running training loss:  1.20093]\u001b[A\n",
            "Training:  87%|████████▋ | 1549/1772 [09:54<01:11,  3.13it/s, running training loss:  0.77112]\u001b[A\n",
            "Training:  87%|████████▋ | 1550/1772 [09:54<01:09,  3.18it/s, running training loss:  0.77112]\u001b[A\n",
            "Training:  87%|████████▋ | 1550/1772 [09:55<01:09,  3.18it/s, running training loss:  1.29501]\u001b[A\n",
            "Training:  88%|████████▊ | 1551/1772 [09:55<01:07,  3.25it/s, running training loss:  1.29501]\u001b[A\n",
            "Training:  88%|████████▊ | 1551/1772 [09:55<01:07,  3.25it/s, running training loss:  1.00198]\u001b[A\n",
            "Training:  88%|████████▊ | 1552/1772 [09:55<01:10,  3.12it/s, running training loss:  1.00198]\u001b[A\n",
            "Training:  88%|████████▊ | 1552/1772 [09:55<01:10,  3.12it/s, running training loss:  0.91977]\u001b[A\n",
            "Training:  88%|████████▊ | 1553/1772 [09:55<01:12,  3.03it/s, running training loss:  0.91977]\u001b[A\n",
            "Training:  88%|████████▊ | 1553/1772 [09:56<01:12,  3.03it/s, running training loss:  0.61209]\u001b[A\n",
            "Training:  88%|████████▊ | 1554/1772 [09:56<01:13,  2.96it/s, running training loss:  0.61209]\u001b[A\n",
            "Training:  88%|████████▊ | 1554/1772 [09:56<01:13,  2.96it/s, running training loss:  0.87608]\u001b[A\n",
            "Training:  88%|████████▊ | 1555/1772 [09:56<01:09,  3.12it/s, running training loss:  0.87608]\u001b[A\n",
            "Training:  88%|████████▊ | 1555/1772 [09:56<01:09,  3.12it/s, running training loss:  0.71933]\u001b[A\n",
            "Training:  88%|████████▊ | 1556/1772 [09:56<01:11,  3.03it/s, running training loss:  0.71933]\u001b[A\n",
            "Training:  88%|████████▊ | 1556/1772 [09:57<01:11,  3.03it/s, running training loss:  0.67199]\u001b[A\n",
            "Training:  88%|████████▊ | 1557/1772 [09:57<01:09,  3.09it/s, running training loss:  0.67199]\u001b[A\n",
            "Training:  88%|████████▊ | 1557/1772 [09:57<01:09,  3.09it/s, running training loss:  0.95661]\u001b[A\n",
            "Training:  88%|████████▊ | 1558/1772 [09:57<01:12,  2.94it/s, running training loss:  0.95661]\u001b[A\n",
            "Training:  88%|████████▊ | 1558/1772 [09:57<01:12,  2.94it/s, running training loss:  0.97003]\u001b[A\n",
            "Training:  88%|████████▊ | 1559/1772 [09:57<01:09,  3.08it/s, running training loss:  0.97003]\u001b[A\n",
            "Training:  88%|████████▊ | 1559/1772 [09:58<01:09,  3.08it/s, running training loss:  0.94709]\u001b[A\n",
            "Training:  88%|████████▊ | 1560/1772 [09:58<01:05,  3.24it/s, running training loss:  0.94709]\u001b[A\n",
            "Training:  88%|████████▊ | 1560/1772 [09:58<01:05,  3.24it/s, running training loss:  0.82503]\u001b[A\n",
            "Training:  88%|████████▊ | 1561/1772 [09:58<01:05,  3.24it/s, running training loss:  0.82503]\u001b[A\n",
            "Training:  88%|████████▊ | 1561/1772 [09:58<01:05,  3.24it/s, running training loss:  1.03505]\u001b[A\n",
            "Training:  88%|████████▊ | 1562/1772 [09:58<01:02,  3.35it/s, running training loss:  1.03505]\u001b[A\n",
            "Training:  88%|████████▊ | 1562/1772 [09:58<01:02,  3.35it/s, running training loss:  0.70067]\u001b[A\n",
            "Training:  88%|████████▊ | 1563/1772 [09:58<01:00,  3.47it/s, running training loss:  0.70067]\u001b[A\n",
            "Training:  88%|████████▊ | 1563/1772 [09:59<01:00,  3.47it/s, running training loss:  0.78146]\u001b[A\n",
            "Training:  88%|████████▊ | 1564/1772 [09:59<01:00,  3.41it/s, running training loss:  0.78146]\u001b[A\n",
            "Training:  88%|████████▊ | 1564/1772 [09:59<01:00,  3.41it/s, running training loss:  0.81369]\u001b[A\n",
            "Training:  88%|████████▊ | 1565/1772 [09:59<01:03,  3.28it/s, running training loss:  0.81369]\u001b[A\n",
            "Training:  88%|████████▊ | 1565/1772 [09:59<01:03,  3.28it/s, running training loss:  0.75572]\u001b[A\n",
            "Training:  88%|████████▊ | 1566/1772 [09:59<01:10,  2.94it/s, running training loss:  0.75572]\u001b[A\n",
            "Training:  88%|████████▊ | 1566/1772 [10:00<01:10,  2.94it/s, running training loss:  0.83890]\u001b[A\n",
            "Training:  88%|████████▊ | 1567/1772 [10:00<01:10,  2.92it/s, running training loss:  0.83890]\u001b[A\n",
            "Training:  88%|████████▊ | 1567/1772 [10:00<01:10,  2.92it/s, running training loss:  0.61114]\u001b[A\n",
            "Training:  88%|████████▊ | 1568/1772 [10:00<01:20,  2.52it/s, running training loss:  0.61114]\u001b[A\n",
            "Training:  88%|████████▊ | 1568/1772 [10:01<01:20,  2.52it/s, running training loss:  0.91203]\u001b[A\n",
            "Training:  89%|████████▊ | 1569/1772 [10:01<01:15,  2.70it/s, running training loss:  0.91203]\u001b[A\n",
            "Training:  89%|████████▊ | 1569/1772 [10:01<01:15,  2.70it/s, running training loss:  0.65863]\u001b[A\n",
            "Training:  89%|████████▊ | 1570/1772 [10:01<01:12,  2.77it/s, running training loss:  0.65863]\u001b[A\n",
            "Training:  89%|████████▊ | 1570/1772 [10:01<01:12,  2.77it/s, running training loss:  1.17156]\u001b[A\n",
            "Training:  89%|████████▊ | 1571/1772 [10:01<01:18,  2.56it/s, running training loss:  1.17156]\u001b[A\n",
            "Training:  89%|████████▊ | 1571/1772 [10:02<01:18,  2.56it/s, running training loss:  1.34716]\u001b[A\n",
            "Training:  89%|████████▊ | 1572/1772 [10:02<01:19,  2.52it/s, running training loss:  1.34716]\u001b[A\n",
            "Training:  89%|████████▊ | 1572/1772 [10:02<01:19,  2.52it/s, running training loss:  1.37528]\u001b[A\n",
            "Training:  89%|████████▉ | 1573/1772 [10:02<01:16,  2.61it/s, running training loss:  1.37528]\u001b[A\n",
            "Training:  89%|████████▉ | 1573/1772 [10:03<01:16,  2.61it/s, running training loss:  1.54762]\u001b[A\n",
            "Training:  89%|████████▉ | 1574/1772 [10:03<01:14,  2.65it/s, running training loss:  1.54762]\u001b[A\n",
            "Training:  89%|████████▉ | 1574/1772 [10:03<01:14,  2.65it/s, running training loss:  1.35053]\u001b[A\n",
            "Training:  89%|████████▉ | 1575/1772 [10:03<01:09,  2.85it/s, running training loss:  1.35053]\u001b[A\n",
            "Training:  89%|████████▉ | 1575/1772 [10:03<01:09,  2.85it/s, running training loss:  0.85317]\u001b[A\n",
            "Training:  89%|████████▉ | 1576/1772 [10:03<01:15,  2.60it/s, running training loss:  0.85317]\u001b[A\n",
            "Training:  89%|████████▉ | 1576/1772 [10:04<01:15,  2.60it/s, running training loss:  0.76071]\u001b[A\n",
            "Training:  89%|████████▉ | 1577/1772 [10:04<01:14,  2.60it/s, running training loss:  0.76071]\u001b[A\n",
            "Training:  89%|████████▉ | 1577/1772 [10:04<01:14,  2.60it/s, running training loss:  1.11694]\u001b[A\n",
            "Training:  89%|████████▉ | 1578/1772 [10:04<01:09,  2.79it/s, running training loss:  1.11694]\u001b[A\n",
            "Training:  89%|████████▉ | 1578/1772 [10:04<01:09,  2.79it/s, running training loss:  1.04621]\u001b[A\n",
            "Training:  89%|████████▉ | 1579/1772 [10:04<01:12,  2.65it/s, running training loss:  1.04621]\u001b[A\n",
            "Training:  89%|████████▉ | 1579/1772 [10:05<01:12,  2.65it/s, running training loss:  0.74618]\u001b[A\n",
            "Training:  89%|████████▉ | 1580/1772 [10:05<01:14,  2.58it/s, running training loss:  0.74618]\u001b[A\n",
            "Training:  89%|████████▉ | 1580/1772 [10:05<01:14,  2.58it/s, running training loss:  0.65076]\u001b[A\n",
            "Training:  89%|████████▉ | 1581/1772 [10:05<01:08,  2.78it/s, running training loss:  0.65076]\u001b[A\n",
            "Training:  89%|████████▉ | 1581/1772 [10:06<01:08,  2.78it/s, running training loss:  0.82430]\u001b[A\n",
            "Training:  89%|████████▉ | 1582/1772 [10:06<01:07,  2.83it/s, running training loss:  0.82430]\u001b[A\n",
            "Training:  89%|████████▉ | 1582/1772 [10:06<01:07,  2.83it/s, running training loss:  0.94121]\u001b[A\n",
            "Training:  89%|████████▉ | 1583/1772 [10:06<01:03,  2.96it/s, running training loss:  0.94121]\u001b[A\n",
            "Training:  89%|████████▉ | 1583/1772 [10:06<01:03,  2.96it/s, running training loss:  1.05378]\u001b[A\n",
            "Training:  89%|████████▉ | 1584/1772 [10:06<01:02,  3.03it/s, running training loss:  1.05378]\u001b[A\n",
            "Training:  89%|████████▉ | 1584/1772 [10:06<01:02,  3.03it/s, running training loss:  0.75454]\u001b[A\n",
            "Training:  89%|████████▉ | 1585/1772 [10:06<00:58,  3.20it/s, running training loss:  0.75454]\u001b[A\n",
            "Training:  89%|████████▉ | 1585/1772 [10:07<00:58,  3.20it/s, running training loss:  0.78460]\u001b[A\n",
            "Training:  90%|████████▉ | 1586/1772 [10:07<00:57,  3.26it/s, running training loss:  0.78460]\u001b[A\n",
            "Training:  90%|████████▉ | 1586/1772 [10:07<00:57,  3.26it/s, running training loss:  0.84216]\u001b[A\n",
            "Training:  90%|████████▉ | 1587/1772 [10:07<01:04,  2.88it/s, running training loss:  0.84216]\u001b[A\n",
            "Training:  90%|████████▉ | 1587/1772 [10:07<01:04,  2.88it/s, running training loss:  1.00072]\u001b[A\n",
            "Training:  90%|████████▉ | 1588/1772 [10:07<01:04,  2.86it/s, running training loss:  1.00072]\u001b[A\n",
            "Training:  90%|████████▉ | 1588/1772 [10:08<01:04,  2.86it/s, running training loss:  0.98060]\u001b[A\n",
            "Training:  90%|████████▉ | 1589/1772 [10:08<01:01,  2.99it/s, running training loss:  0.98060]\u001b[A\n",
            "Training:  90%|████████▉ | 1589/1772 [10:08<01:01,  2.99it/s, running training loss:  1.17350]\u001b[A\n",
            "Training:  90%|████████▉ | 1590/1772 [10:08<01:06,  2.74it/s, running training loss:  1.17350]\u001b[A\n",
            "Training:  90%|████████▉ | 1590/1772 [10:09<01:06,  2.74it/s, running training loss:  0.68178]\u001b[A\n",
            "Training:  90%|████████▉ | 1591/1772 [10:09<01:03,  2.83it/s, running training loss:  0.68178]\u001b[A\n",
            "Training:  90%|████████▉ | 1591/1772 [10:09<01:03,  2.83it/s, running training loss:  1.02418]\u001b[A\n",
            "Training:  90%|████████▉ | 1592/1772 [10:09<01:01,  2.91it/s, running training loss:  1.02418]\u001b[A\n",
            "Training:  90%|████████▉ | 1592/1772 [10:09<01:01,  2.91it/s, running training loss:  0.80006]\u001b[A\n",
            "Training:  90%|████████▉ | 1593/1772 [10:09<01:04,  2.77it/s, running training loss:  0.80006]\u001b[A\n",
            "Training:  90%|████████▉ | 1593/1772 [10:09<01:04,  2.77it/s, running training loss:  0.76407]\u001b[A\n",
            "Training:  90%|████████▉ | 1594/1772 [10:10<00:58,  3.06it/s, running training loss:  0.76407]\u001b[A\n",
            "Training:  90%|████████▉ | 1594/1772 [10:10<00:58,  3.06it/s, running training loss:  0.83928]\u001b[A\n",
            "Training:  90%|█████████ | 1595/1772 [10:10<01:02,  2.84it/s, running training loss:  0.83928]\u001b[A\n",
            "Training:  90%|█████████ | 1595/1772 [10:10<01:02,  2.84it/s, running training loss:  0.74771]\u001b[A\n",
            "Training:  90%|█████████ | 1596/1772 [10:10<01:03,  2.79it/s, running training loss:  0.74771]\u001b[A\n",
            "Training:  90%|█████████ | 1596/1772 [10:11<01:03,  2.79it/s, running training loss:  1.25936]\u001b[A\n",
            "Training:  90%|█████████ | 1597/1772 [10:11<01:04,  2.70it/s, running training loss:  1.25936]\u001b[A\n",
            "Training:  90%|█████████ | 1597/1772 [10:11<01:04,  2.70it/s, running training loss:  0.90682]\u001b[A\n",
            "Training:  90%|█████████ | 1598/1772 [10:11<01:06,  2.60it/s, running training loss:  0.90682]\u001b[A\n",
            "Training:  90%|█████████ | 1598/1772 [10:11<01:06,  2.60it/s, running training loss:  0.79804]\u001b[A\n",
            "Training:  90%|█████████ | 1599/1772 [10:11<01:03,  2.74it/s, running training loss:  0.79804]\u001b[A\n",
            "Training:  90%|█████████ | 1599/1772 [10:12<01:03,  2.74it/s, running training loss:  1.29619]\u001b[A\n",
            "Training:  90%|█████████ | 1600/1772 [10:12<01:13,  2.33it/s, running training loss:  1.29619]\u001b[A\n",
            "Training:  90%|█████████ | 1600/1772 [10:12<01:13,  2.33it/s, running training loss:  0.55810]\u001b[A\n",
            "Training:  90%|█████████ | 1601/1772 [10:12<01:06,  2.58it/s, running training loss:  0.55810]\u001b[A\n",
            "Training:  90%|█████████ | 1601/1772 [10:13<01:06,  2.58it/s, running training loss:  0.53323]\u001b[A\n",
            "Training:  90%|█████████ | 1602/1772 [10:13<01:01,  2.74it/s, running training loss:  0.53323]\u001b[A\n",
            "Training:  90%|█████████ | 1602/1772 [10:13<01:01,  2.74it/s, running training loss:  1.40082]\u001b[A\n",
            "Training:  90%|█████████ | 1603/1772 [10:13<01:00,  2.78it/s, running training loss:  1.40082]\u001b[A\n",
            "Training:  90%|█████████ | 1603/1772 [10:13<01:00,  2.78it/s, running training loss:  1.99391]\u001b[A\n",
            "Training:  91%|█████████ | 1604/1772 [10:13<00:56,  2.97it/s, running training loss:  1.99391]\u001b[A\n",
            "Training:  91%|█████████ | 1604/1772 [10:14<00:56,  2.97it/s, running training loss:  1.00857]\u001b[A\n",
            "Training:  91%|█████████ | 1605/1772 [10:14<01:07,  2.49it/s, running training loss:  1.00857]\u001b[A\n",
            "Training:  91%|█████████ | 1605/1772 [10:14<01:07,  2.49it/s, running training loss:  1.36506]\u001b[A\n",
            "Training:  91%|█████████ | 1606/1772 [10:14<01:07,  2.46it/s, running training loss:  1.36506]\u001b[A\n",
            "Training:  91%|█████████ | 1606/1772 [10:15<01:07,  2.46it/s, running training loss:  0.71512]\u001b[A\n",
            "Training:  91%|█████████ | 1607/1772 [10:15<01:06,  2.50it/s, running training loss:  0.71512]\u001b[A\n",
            "Training:  91%|█████████ | 1607/1772 [10:15<01:06,  2.50it/s, running training loss:  0.93909]\u001b[A\n",
            "Training:  91%|█████████ | 1608/1772 [10:15<01:03,  2.60it/s, running training loss:  0.93909]\u001b[A\n",
            "Training:  91%|█████████ | 1608/1772 [10:15<01:03,  2.60it/s, running training loss:  1.06690]\u001b[A\n",
            "Training:  91%|█████████ | 1609/1772 [10:15<00:58,  2.80it/s, running training loss:  1.06690]\u001b[A\n",
            "Training:  91%|█████████ | 1609/1772 [10:16<00:58,  2.80it/s, running training loss:  0.88525]\u001b[A\n",
            "Training:  91%|█████████ | 1610/1772 [10:16<00:56,  2.88it/s, running training loss:  0.88525]\u001b[A\n",
            "Training:  91%|█████████ | 1610/1772 [10:16<00:56,  2.88it/s, running training loss:  0.77068]\u001b[A\n",
            "Training:  91%|█████████ | 1611/1772 [10:16<01:01,  2.62it/s, running training loss:  0.77068]\u001b[A\n",
            "Training:  91%|█████████ | 1611/1772 [10:16<01:01,  2.62it/s, running training loss:  0.67963]\u001b[A\n",
            "Training:  91%|█████████ | 1612/1772 [10:16<00:57,  2.77it/s, running training loss:  0.67963]\u001b[A\n",
            "Training:  91%|█████████ | 1612/1772 [10:17<00:57,  2.77it/s, running training loss:  1.10917]\u001b[A\n",
            "Training:  91%|█████████ | 1613/1772 [10:17<00:57,  2.77it/s, running training loss:  1.10917]\u001b[A\n",
            "Training:  91%|█████████ | 1613/1772 [10:17<00:57,  2.77it/s, running training loss:  1.31080]\u001b[A\n",
            "Training:  91%|█████████ | 1614/1772 [10:17<00:54,  2.89it/s, running training loss:  1.31080]\u001b[A\n",
            "Training:  91%|█████████ | 1614/1772 [10:17<00:54,  2.89it/s, running training loss:  0.84989]\u001b[A\n",
            "Training:  91%|█████████ | 1615/1772 [10:17<00:50,  3.12it/s, running training loss:  0.84989]\u001b[A\n",
            "Training:  91%|█████████ | 1615/1772 [10:18<00:50,  3.12it/s, running training loss:  1.02854]\u001b[A\n",
            "Training:  91%|█████████ | 1616/1772 [10:18<00:48,  3.19it/s, running training loss:  1.02854]\u001b[A\n",
            "Training:  91%|█████████ | 1616/1772 [10:18<00:48,  3.19it/s, running training loss:  0.74487]\u001b[A\n",
            "Training:  91%|█████████▏| 1617/1772 [10:18<00:48,  3.19it/s, running training loss:  0.74487]\u001b[A\n",
            "Training:  91%|█████████▏| 1617/1772 [10:18<00:48,  3.19it/s, running training loss:  0.69687]\u001b[A\n",
            "Training:  91%|█████████▏| 1618/1772 [10:18<00:50,  3.06it/s, running training loss:  0.69687]\u001b[A\n",
            "Training:  91%|█████████▏| 1618/1772 [10:19<00:50,  3.06it/s, running training loss:  0.60585]\u001b[A\n",
            "Training:  91%|█████████▏| 1619/1772 [10:19<00:51,  2.99it/s, running training loss:  0.60585]\u001b[A\n",
            "Training:  91%|█████████▏| 1619/1772 [10:19<00:51,  2.99it/s, running training loss:  1.05900]\u001b[A\n",
            "Training:  91%|█████████▏| 1620/1772 [10:19<00:47,  3.17it/s, running training loss:  1.05900]\u001b[A\n",
            "Training:  91%|█████████▏| 1620/1772 [10:19<00:47,  3.17it/s, running training loss:  0.81144]\u001b[A\n",
            "Training:  91%|█████████▏| 1621/1772 [10:19<00:53,  2.81it/s, running training loss:  0.81144]\u001b[A\n",
            "Training:  91%|█████████▏| 1621/1772 [10:20<00:53,  2.81it/s, running training loss:  0.87697]\u001b[A\n",
            "Training:  92%|█████████▏| 1622/1772 [10:20<00:52,  2.87it/s, running training loss:  0.87697]\u001b[A\n",
            "Training:  92%|█████████▏| 1622/1772 [10:20<00:52,  2.87it/s, running training loss:  0.75769]\u001b[A\n",
            "Training:  92%|█████████▏| 1623/1772 [10:20<00:52,  2.86it/s, running training loss:  0.75769]\u001b[A\n",
            "Training:  92%|█████████▏| 1623/1772 [10:20<00:52,  2.86it/s, running training loss:  1.08159]\u001b[A\n",
            "Training:  92%|█████████▏| 1624/1772 [10:20<00:50,  2.96it/s, running training loss:  1.08159]\u001b[A\n",
            "Training:  92%|█████████▏| 1624/1772 [10:21<00:50,  2.96it/s, running training loss:  0.85202]\u001b[A\n",
            "Training:  92%|█████████▏| 1625/1772 [10:21<00:48,  3.01it/s, running training loss:  0.85202]\u001b[A\n",
            "Training:  92%|█████████▏| 1625/1772 [10:21<00:48,  3.01it/s, running training loss:  0.77956]\u001b[A\n",
            "Training:  92%|█████████▏| 1626/1772 [10:21<00:52,  2.79it/s, running training loss:  0.77956]\u001b[A\n",
            "Training:  92%|█████████▏| 1626/1772 [10:21<00:52,  2.79it/s, running training loss:  1.08627]\u001b[A\n",
            "Training:  92%|█████████▏| 1627/1772 [10:21<00:51,  2.81it/s, running training loss:  1.08627]\u001b[A\n",
            "Training:  92%|█████████▏| 1627/1772 [10:22<00:51,  2.81it/s, running training loss:  0.93479]\u001b[A\n",
            "Training:  92%|█████████▏| 1628/1772 [10:22<00:48,  2.96it/s, running training loss:  0.93479]\u001b[A\n",
            "Training:  92%|█████████▏| 1628/1772 [10:22<00:48,  2.96it/s, running training loss:  1.20119]\u001b[A\n",
            "Training:  92%|█████████▏| 1629/1772 [10:22<00:47,  2.99it/s, running training loss:  1.20119]\u001b[A\n",
            "Training:  92%|█████████▏| 1629/1772 [10:22<00:47,  2.99it/s, running training loss:  0.89422]\u001b[A\n",
            "Training:  92%|█████████▏| 1630/1772 [10:22<00:46,  3.05it/s, running training loss:  0.89422]\u001b[A\n",
            "Training:  92%|█████████▏| 1630/1772 [10:23<00:46,  3.05it/s, running training loss:  0.95766]\u001b[A\n",
            "Training:  92%|█████████▏| 1631/1772 [10:23<00:44,  3.19it/s, running training loss:  0.95766]\u001b[A\n",
            "Training:  92%|█████████▏| 1631/1772 [10:23<00:44,  3.19it/s, running training loss:  0.89396]\u001b[A\n",
            "Training:  92%|█████████▏| 1632/1772 [10:23<00:43,  3.22it/s, running training loss:  0.89396]\u001b[A\n",
            "Training:  92%|█████████▏| 1632/1772 [10:23<00:43,  3.22it/s, running training loss:  0.74313]\u001b[A\n",
            "Training:  92%|█████████▏| 1633/1772 [10:23<00:42,  3.25it/s, running training loss:  0.74313]\u001b[A\n",
            "Training:  92%|█████████▏| 1633/1772 [10:23<00:42,  3.25it/s, running training loss:  0.73109]\u001b[A\n",
            "Training:  92%|█████████▏| 1634/1772 [10:24<00:41,  3.30it/s, running training loss:  0.73109]\u001b[A\n",
            "Training:  92%|█████████▏| 1634/1772 [10:24<00:41,  3.30it/s, running training loss:  0.81221]\u001b[A\n",
            "Training:  92%|█████████▏| 1635/1772 [10:24<00:45,  2.98it/s, running training loss:  0.81221]\u001b[A\n",
            "Training:  92%|█████████▏| 1635/1772 [10:24<00:45,  2.98it/s, running training loss:  0.77775]\u001b[A\n",
            "Training:  92%|█████████▏| 1636/1772 [10:24<00:45,  2.96it/s, running training loss:  0.77775]\u001b[A\n",
            "Training:  92%|█████████▏| 1636/1772 [10:25<00:45,  2.96it/s, running training loss:  0.90610]\u001b[A\n",
            "Training:  92%|█████████▏| 1637/1772 [10:25<00:45,  2.93it/s, running training loss:  0.90610]\u001b[A\n",
            "Training:  92%|█████████▏| 1637/1772 [10:25<00:45,  2.93it/s, running training loss:  1.07393]\u001b[A\n",
            "Training:  92%|█████████▏| 1638/1772 [10:25<00:54,  2.45it/s, running training loss:  1.07393]\u001b[A\n",
            "Training:  92%|█████████▏| 1638/1772 [10:25<00:54,  2.45it/s, running training loss:  1.02611]\u001b[A\n",
            "Training:  92%|█████████▏| 1639/1772 [10:25<00:50,  2.63it/s, running training loss:  1.02611]\u001b[A\n",
            "Training:  92%|█████████▏| 1639/1772 [10:26<00:50,  2.63it/s, running training loss:  0.97820]\u001b[A\n",
            "Training:  93%|█████████▎| 1640/1772 [10:26<00:47,  2.79it/s, running training loss:  0.97820]\u001b[A\n",
            "Training:  93%|█████████▎| 1640/1772 [10:26<00:47,  2.79it/s, running training loss:  0.75943]\u001b[A\n",
            "Training:  93%|█████████▎| 1641/1772 [10:26<00:45,  2.90it/s, running training loss:  0.75943]\u001b[A\n",
            "Training:  93%|█████████▎| 1641/1772 [10:26<00:45,  2.90it/s, running training loss:  1.09553]\u001b[A\n",
            "Training:  93%|█████████▎| 1642/1772 [10:26<00:43,  3.01it/s, running training loss:  1.09553]\u001b[A\n",
            "Training:  93%|█████████▎| 1642/1772 [10:27<00:43,  3.01it/s, running training loss:  0.58483]\u001b[A\n",
            "Training:  93%|█████████▎| 1643/1772 [10:27<00:44,  2.89it/s, running training loss:  0.58483]\u001b[A\n",
            "Training:  93%|█████████▎| 1643/1772 [10:27<00:44,  2.89it/s, running training loss:  0.80071]\u001b[A\n",
            "Training:  93%|█████████▎| 1644/1772 [10:27<00:40,  3.18it/s, running training loss:  0.80071]\u001b[A\n",
            "Training:  93%|█████████▎| 1644/1772 [10:28<00:40,  3.18it/s, running training loss:  0.65103]\u001b[A\n",
            "Training:  93%|█████████▎| 1645/1772 [10:28<00:47,  2.70it/s, running training loss:  0.65103]\u001b[A\n",
            "Training:  93%|█████████▎| 1645/1772 [10:28<00:47,  2.70it/s, running training loss:  0.64695]\u001b[A\n",
            "Training:  93%|█████████▎| 1646/1772 [10:28<00:44,  2.85it/s, running training loss:  0.64695]\u001b[A\n",
            "Training:  93%|█████████▎| 1646/1772 [10:28<00:44,  2.85it/s, running training loss:  0.81902]\u001b[A\n",
            "Training:  93%|█████████▎| 1647/1772 [10:28<00:46,  2.67it/s, running training loss:  0.81902]\u001b[A\n",
            "Training:  93%|█████████▎| 1647/1772 [10:29<00:46,  2.67it/s, running training loss:  0.74669]\u001b[A\n",
            "Training:  93%|█████████▎| 1648/1772 [10:29<00:43,  2.84it/s, running training loss:  0.74669]\u001b[A\n",
            "Training:  93%|█████████▎| 1648/1772 [10:29<00:43,  2.84it/s, running training loss:  0.88201]\u001b[A\n",
            "Training:  93%|█████████▎| 1649/1772 [10:29<00:47,  2.60it/s, running training loss:  0.88201]\u001b[A\n",
            "Training:  93%|█████████▎| 1649/1772 [10:29<00:47,  2.60it/s, running training loss:  1.22690]\u001b[A\n",
            "Training:  93%|█████████▎| 1650/1772 [10:29<00:47,  2.57it/s, running training loss:  1.22690]\u001b[A\n",
            "Training:  93%|█████████▎| 1650/1772 [10:30<00:47,  2.57it/s, running training loss:  1.45415]\u001b[A\n",
            "Training:  93%|█████████▎| 1651/1772 [10:30<00:44,  2.75it/s, running training loss:  1.45415]\u001b[A\n",
            "Training:  93%|█████████▎| 1651/1772 [10:30<00:44,  2.75it/s, running training loss:  1.43468]\u001b[A\n",
            "Training:  93%|█████████▎| 1652/1772 [10:30<00:43,  2.77it/s, running training loss:  1.43468]\u001b[A\n",
            "Training:  93%|█████████▎| 1652/1772 [10:30<00:43,  2.77it/s, running training loss:  0.69603]\u001b[A\n",
            "Training:  93%|█████████▎| 1653/1772 [10:30<00:41,  2.88it/s, running training loss:  0.69603]\u001b[A\n",
            "Training:  93%|█████████▎| 1653/1772 [10:31<00:41,  2.88it/s, running training loss:  0.96406]\u001b[A\n",
            "Training:  93%|█████████▎| 1654/1772 [10:31<00:38,  3.05it/s, running training loss:  0.96406]\u001b[A\n",
            "Training:  93%|█████████▎| 1654/1772 [10:31<00:38,  3.05it/s, running training loss:  1.21705]\u001b[A\n",
            "Training:  93%|█████████▎| 1655/1772 [10:31<00:39,  2.93it/s, running training loss:  1.21705]\u001b[A\n",
            "Training:  93%|█████████▎| 1655/1772 [10:31<00:39,  2.93it/s, running training loss:  1.29465]\u001b[A\n",
            "Training:  93%|█████████▎| 1656/1772 [10:31<00:42,  2.73it/s, running training loss:  1.29465]\u001b[A\n",
            "Training:  93%|█████████▎| 1656/1772 [10:32<00:42,  2.73it/s, running training loss:  0.84234]\u001b[A\n",
            "Training:  94%|█████████▎| 1657/1772 [10:32<00:42,  2.69it/s, running training loss:  0.84234]\u001b[A\n",
            "Training:  94%|█████████▎| 1657/1772 [10:32<00:42,  2.69it/s, running training loss:  0.88611]\u001b[A\n",
            "Training:  94%|█████████▎| 1658/1772 [10:32<00:43,  2.63it/s, running training loss:  0.88611]\u001b[A\n",
            "Training:  94%|█████████▎| 1658/1772 [10:33<00:43,  2.63it/s, running training loss:  0.95001]\u001b[A\n",
            "Training:  94%|█████████▎| 1659/1772 [10:33<00:41,  2.74it/s, running training loss:  0.95001]\u001b[A\n",
            "Training:  94%|█████████▎| 1659/1772 [10:33<00:41,  2.74it/s, running training loss:  0.72346]\u001b[A\n",
            "Training:  94%|█████████▎| 1660/1772 [10:33<00:46,  2.43it/s, running training loss:  0.72346]\u001b[A\n",
            "Training:  94%|█████████▎| 1660/1772 [10:33<00:46,  2.43it/s, running training loss:  0.51940]\u001b[A\n",
            "Training:  94%|█████████▎| 1661/1772 [10:33<00:41,  2.68it/s, running training loss:  0.51940]\u001b[A\n",
            "Training:  94%|█████████▎| 1661/1772 [10:34<00:41,  2.68it/s, running training loss:  0.88073]\u001b[A\n",
            "Training:  94%|█████████▍| 1662/1772 [10:34<00:43,  2.51it/s, running training loss:  0.88073]\u001b[A\n",
            "Training:  94%|█████████▍| 1662/1772 [10:34<00:43,  2.51it/s, running training loss:  0.79341]\u001b[A\n",
            "Training:  94%|█████████▍| 1663/1772 [10:34<00:42,  2.57it/s, running training loss:  0.79341]\u001b[A\n",
            "Training:  94%|█████████▍| 1663/1772 [10:35<00:42,  2.57it/s, running training loss:  0.66436]\u001b[A\n",
            "Training:  94%|█████████▍| 1664/1772 [10:35<00:39,  2.71it/s, running training loss:  0.66436]\u001b[A\n",
            "Training:  94%|█████████▍| 1664/1772 [10:35<00:39,  2.71it/s, running training loss:  1.00995]\u001b[A\n",
            "Training:  94%|█████████▍| 1665/1772 [10:35<00:46,  2.32it/s, running training loss:  1.00995]\u001b[A\n",
            "Training:  94%|█████████▍| 1665/1772 [10:35<00:46,  2.32it/s, running training loss:  1.14212]\u001b[A\n",
            "Training:  94%|█████████▍| 1666/1772 [10:35<00:41,  2.58it/s, running training loss:  1.14212]\u001b[A\n",
            "Training:  94%|█████████▍| 1666/1772 [10:36<00:41,  2.58it/s, running training loss:  0.85419]\u001b[A\n",
            "Training:  94%|█████████▍| 1667/1772 [10:36<00:40,  2.57it/s, running training loss:  0.85419]\u001b[A\n",
            "Training:  94%|█████████▍| 1667/1772 [10:36<00:40,  2.57it/s, running training loss:  0.56382]\u001b[A\n",
            "Training:  94%|█████████▍| 1668/1772 [10:36<00:39,  2.60it/s, running training loss:  0.56382]\u001b[A\n",
            "Training:  94%|█████████▍| 1668/1772 [10:36<00:39,  2.60it/s, running training loss:  0.64114]\u001b[A\n",
            "Training:  94%|█████████▍| 1669/1772 [10:36<00:35,  2.90it/s, running training loss:  0.64114]\u001b[A\n",
            "Training:  94%|█████████▍| 1669/1772 [10:37<00:35,  2.90it/s, running training loss:  0.65044]\u001b[A\n",
            "Training:  94%|█████████▍| 1670/1772 [10:37<00:34,  2.96it/s, running training loss:  0.65044]\u001b[A\n",
            "Training:  94%|█████████▍| 1670/1772 [10:37<00:34,  2.96it/s, running training loss:  0.68509]\u001b[A\n",
            "Training:  94%|█████████▍| 1671/1772 [10:37<00:32,  3.14it/s, running training loss:  0.68509]\u001b[A\n",
            "Training:  94%|█████████▍| 1671/1772 [10:37<00:32,  3.14it/s, running training loss:  0.38427]\u001b[A\n",
            "Training:  94%|█████████▍| 1672/1772 [10:37<00:30,  3.23it/s, running training loss:  0.38427]\u001b[A\n",
            "Training:  94%|█████████▍| 1672/1772 [10:38<00:30,  3.23it/s, running training loss:  1.38780]\u001b[A\n",
            "Training:  94%|█████████▍| 1673/1772 [10:38<00:32,  3.04it/s, running training loss:  1.38780]\u001b[A\n",
            "Training:  94%|█████████▍| 1673/1772 [10:38<00:32,  3.04it/s, running training loss:  0.67353]\u001b[A\n",
            "Training:  94%|█████████▍| 1674/1772 [10:38<00:33,  2.94it/s, running training loss:  0.67353]\u001b[A\n",
            "Training:  94%|█████████▍| 1674/1772 [10:38<00:33,  2.94it/s, running training loss:  0.63030]\u001b[A\n",
            "Training:  95%|█████████▍| 1675/1772 [10:38<00:31,  3.06it/s, running training loss:  0.63030]\u001b[A\n",
            "Training:  95%|█████████▍| 1675/1772 [10:39<00:31,  3.06it/s, running training loss:  0.89180]\u001b[A\n",
            "Training:  95%|█████████▍| 1676/1772 [10:39<00:30,  3.12it/s, running training loss:  0.89180]\u001b[A\n",
            "Training:  95%|█████████▍| 1676/1772 [10:39<00:30,  3.12it/s, running training loss:  1.15628]\u001b[A\n",
            "Training:  95%|█████████▍| 1677/1772 [10:39<00:32,  2.93it/s, running training loss:  1.15628]\u001b[A\n",
            "Training:  95%|█████████▍| 1677/1772 [10:39<00:32,  2.93it/s, running training loss:  0.73845]\u001b[A\n",
            "Training:  95%|█████████▍| 1678/1772 [10:39<00:31,  2.97it/s, running training loss:  0.73845]\u001b[A\n",
            "Training:  95%|█████████▍| 1678/1772 [10:40<00:31,  2.97it/s, running training loss:  0.99843]\u001b[A\n",
            "Training:  95%|█████████▍| 1679/1772 [10:40<00:32,  2.85it/s, running training loss:  0.99843]\u001b[A\n",
            "Training:  95%|█████████▍| 1679/1772 [10:40<00:32,  2.85it/s, running training loss:  0.72015]\u001b[A\n",
            "Training:  95%|█████████▍| 1680/1772 [10:40<00:32,  2.84it/s, running training loss:  0.72015]\u001b[A\n",
            "Training:  95%|█████████▍| 1680/1772 [10:40<00:32,  2.84it/s, running training loss:  1.14125]\u001b[A\n",
            "Training:  95%|█████████▍| 1681/1772 [10:40<00:31,  2.85it/s, running training loss:  1.14125]\u001b[A\n",
            "Training:  95%|█████████▍| 1681/1772 [10:41<00:31,  2.85it/s, running training loss:  0.54363]\u001b[A\n",
            "Training:  95%|█████████▍| 1682/1772 [10:41<00:30,  2.94it/s, running training loss:  0.54363]\u001b[A\n",
            "Training:  95%|█████████▍| 1682/1772 [10:41<00:30,  2.94it/s, running training loss:  1.07513]\u001b[A\n",
            "Training:  95%|█████████▍| 1683/1772 [10:41<00:29,  2.97it/s, running training loss:  1.07513]\u001b[A\n",
            "Training:  95%|█████████▍| 1683/1772 [10:41<00:29,  2.97it/s, running training loss:  0.98373]\u001b[A\n",
            "Training:  95%|█████████▌| 1684/1772 [10:41<00:29,  3.02it/s, running training loss:  0.98373]\u001b[A\n",
            "Training:  95%|█████████▌| 1684/1772 [10:42<00:29,  3.02it/s, running training loss:  0.72853]\u001b[A\n",
            "Training:  95%|█████████▌| 1685/1772 [10:42<00:27,  3.12it/s, running training loss:  0.72853]\u001b[A\n",
            "Training:  95%|█████████▌| 1685/1772 [10:42<00:27,  3.12it/s, running training loss:  0.92299]\u001b[A\n",
            "Training:  95%|█████████▌| 1686/1772 [10:42<00:29,  2.94it/s, running training loss:  0.92299]\u001b[A\n",
            "Training:  95%|█████████▌| 1686/1772 [10:43<00:29,  2.94it/s, running training loss:  0.43286]\u001b[A\n",
            "Training:  95%|█████████▌| 1687/1772 [10:43<00:30,  2.75it/s, running training loss:  0.43286]\u001b[A\n",
            "Training:  95%|█████████▌| 1687/1772 [10:43<00:30,  2.75it/s, running training loss:  0.72178]\u001b[A\n",
            "Training:  95%|█████████▌| 1688/1772 [10:43<00:30,  2.74it/s, running training loss:  0.72178]\u001b[A\n",
            "Training:  95%|█████████▌| 1688/1772 [10:43<00:30,  2.74it/s, running training loss:  0.81532]\u001b[A\n",
            "Training:  95%|█████████▌| 1689/1772 [10:43<00:30,  2.69it/s, running training loss:  0.81532]\u001b[A\n",
            "Training:  95%|█████████▌| 1689/1772 [10:44<00:30,  2.69it/s, running training loss:  0.70972]\u001b[A\n",
            "Training:  95%|█████████▌| 1690/1772 [10:44<00:27,  2.94it/s, running training loss:  0.70972]\u001b[A\n",
            "Training:  95%|█████████▌| 1690/1772 [10:44<00:27,  2.94it/s, running training loss:  0.64416]\u001b[A\n",
            "Training:  95%|█████████▌| 1691/1772 [10:44<00:25,  3.15it/s, running training loss:  0.64416]\u001b[A\n",
            "Training:  95%|█████████▌| 1691/1772 [10:44<00:25,  3.15it/s, running training loss:  0.87230]\u001b[A\n",
            "Training:  95%|█████████▌| 1692/1772 [10:44<00:24,  3.27it/s, running training loss:  0.87230]\u001b[A\n",
            "Training:  95%|█████████▌| 1692/1772 [10:44<00:24,  3.27it/s, running training loss:  0.71587]\u001b[A\n",
            "Training:  96%|█████████▌| 1693/1772 [10:44<00:23,  3.40it/s, running training loss:  0.71587]\u001b[A\n",
            "Training:  96%|█████████▌| 1693/1772 [10:45<00:23,  3.40it/s, running training loss:  0.58584]\u001b[A\n",
            "Training:  96%|█████████▌| 1694/1772 [10:45<00:23,  3.28it/s, running training loss:  0.58584]\u001b[A\n",
            "Training:  96%|█████████▌| 1694/1772 [10:45<00:23,  3.28it/s, running training loss:  1.10655]\u001b[A\n",
            "Training:  96%|█████████▌| 1695/1772 [10:45<00:22,  3.36it/s, running training loss:  1.10655]\u001b[A\n",
            "Training:  96%|█████████▌| 1695/1772 [10:45<00:22,  3.36it/s, running training loss:  0.79125]\u001b[A\n",
            "Training:  96%|█████████▌| 1696/1772 [10:45<00:22,  3.43it/s, running training loss:  0.79125]\u001b[A\n",
            "Training:  96%|█████████▌| 1696/1772 [10:46<00:22,  3.43it/s, running training loss:  1.27074]\u001b[A\n",
            "Training:  96%|█████████▌| 1697/1772 [10:46<00:22,  3.27it/s, running training loss:  1.27074]\u001b[A\n",
            "Training:  96%|█████████▌| 1697/1772 [10:46<00:22,  3.27it/s, running training loss:  0.85281]\u001b[A\n",
            "Training:  96%|█████████▌| 1698/1772 [10:46<00:23,  3.12it/s, running training loss:  0.85281]\u001b[A\n",
            "Training:  96%|█████████▌| 1698/1772 [10:46<00:23,  3.12it/s, running training loss:  0.59790]\u001b[A\n",
            "Training:  96%|█████████▌| 1699/1772 [10:46<00:22,  3.20it/s, running training loss:  0.59790]\u001b[A\n",
            "Training:  96%|█████████▌| 1699/1772 [10:46<00:22,  3.20it/s, running training loss:  0.72644]\u001b[A\n",
            "Training:  96%|█████████▌| 1700/1772 [10:47<00:21,  3.32it/s, running training loss:  0.72644]\u001b[A\n",
            "Training:  96%|█████████▌| 1700/1772 [10:47<00:21,  3.32it/s, running training loss:  0.33367]\u001b[A\n",
            "Training:  96%|█████████▌| 1701/1772 [10:47<00:21,  3.26it/s, running training loss:  0.33367]\u001b[A\n",
            "Training:  96%|█████████▌| 1701/1772 [10:47<00:21,  3.26it/s, running training loss:  0.99422]\u001b[A\n",
            "Training:  96%|█████████▌| 1702/1772 [10:47<00:21,  3.32it/s, running training loss:  0.99422]\u001b[A\n",
            "Training:  96%|█████████▌| 1702/1772 [10:48<00:21,  3.32it/s, running training loss:  0.90701]\u001b[A\n",
            "Training:  96%|█████████▌| 1703/1772 [10:48<00:23,  2.97it/s, running training loss:  0.90701]\u001b[A\n",
            "Training:  96%|█████████▌| 1703/1772 [10:48<00:23,  2.97it/s, running training loss:  0.70977]\u001b[A\n",
            "Training:  96%|█████████▌| 1704/1772 [10:48<00:22,  3.02it/s, running training loss:  0.70977]\u001b[A\n",
            "Training:  96%|█████████▌| 1704/1772 [10:48<00:22,  3.02it/s, running training loss:  0.63896]\u001b[A\n",
            "Training:  96%|█████████▌| 1705/1772 [10:48<00:21,  3.12it/s, running training loss:  0.63896]\u001b[A\n",
            "Training:  96%|█████████▌| 1705/1772 [10:48<00:21,  3.12it/s, running training loss:  0.68452]\u001b[A\n",
            "Training:  96%|█████████▋| 1706/1772 [10:48<00:21,  3.04it/s, running training loss:  0.68452]\u001b[A\n",
            "Training:  96%|█████████▋| 1706/1772 [10:49<00:21,  3.04it/s, running training loss:  1.00444]\u001b[A\n",
            "Training:  96%|█████████▋| 1707/1772 [10:49<00:21,  3.09it/s, running training loss:  1.00444]\u001b[A\n",
            "Training:  96%|█████████▋| 1707/1772 [10:49<00:21,  3.09it/s, running training loss:  1.38787]\u001b[A\n",
            "Training:  96%|█████████▋| 1708/1772 [10:49<00:21,  2.98it/s, running training loss:  1.38787]\u001b[A\n",
            "Training:  96%|█████████▋| 1708/1772 [10:49<00:21,  2.98it/s, running training loss:  1.02978]\u001b[A\n",
            "Training:  96%|█████████▋| 1709/1772 [10:49<00:20,  3.15it/s, running training loss:  1.02978]\u001b[A\n",
            "Training:  96%|█████████▋| 1709/1772 [10:50<00:20,  3.15it/s, running training loss:  0.70510]\u001b[A\n",
            "Training:  97%|█████████▋| 1710/1772 [10:50<00:19,  3.12it/s, running training loss:  0.70510]\u001b[A\n",
            "Training:  97%|█████████▋| 1710/1772 [10:50<00:19,  3.12it/s, running training loss:  0.52425]\u001b[A\n",
            "Training:  97%|█████████▋| 1711/1772 [10:50<00:18,  3.26it/s, running training loss:  0.52425]\u001b[A\n",
            "Training:  97%|█████████▋| 1711/1772 [10:50<00:18,  3.26it/s, running training loss:  0.67445]\u001b[A\n",
            "Training:  97%|█████████▋| 1712/1772 [10:51<00:21,  2.83it/s, running training loss:  0.67445]\u001b[A\n",
            "Training:  97%|█████████▋| 1712/1772 [10:51<00:21,  2.83it/s, running training loss:  0.62916]\u001b[A\n",
            "Training:  97%|█████████▋| 1713/1772 [10:51<00:20,  2.94it/s, running training loss:  0.62916]\u001b[A\n",
            "Training:  97%|█████████▋| 1713/1772 [10:51<00:20,  2.94it/s, running training loss:  1.12136]\u001b[A\n",
            "Training:  97%|█████████▋| 1714/1772 [10:51<00:21,  2.65it/s, running training loss:  1.12136]\u001b[A\n",
            "Training:  97%|█████████▋| 1714/1772 [10:52<00:21,  2.65it/s, running training loss:  0.75735]\u001b[A\n",
            "Training:  97%|█████████▋| 1715/1772 [10:52<00:20,  2.83it/s, running training loss:  0.75735]\u001b[A\n",
            "Training:  97%|█████████▋| 1715/1772 [10:52<00:20,  2.83it/s, running training loss:  1.15759]\u001b[A\n",
            "Training:  97%|█████████▋| 1716/1772 [10:52<00:18,  3.05it/s, running training loss:  1.15759]\u001b[A\n",
            "Training:  97%|█████████▋| 1716/1772 [10:52<00:18,  3.05it/s, running training loss:  1.02112]\u001b[A\n",
            "Training:  97%|█████████▋| 1717/1772 [10:52<00:18,  2.94it/s, running training loss:  1.02112]\u001b[A\n",
            "Training:  97%|█████████▋| 1717/1772 [10:53<00:18,  2.94it/s, running training loss:  0.66344]\u001b[A\n",
            "Training:  97%|█████████▋| 1718/1772 [10:53<00:17,  3.03it/s, running training loss:  0.66344]\u001b[A\n",
            "Training:  97%|█████████▋| 1718/1772 [10:53<00:17,  3.03it/s, running training loss:  0.76809]\u001b[A\n",
            "Training:  97%|█████████▋| 1719/1772 [10:53<00:16,  3.14it/s, running training loss:  0.76809]\u001b[A\n",
            "Training:  97%|█████████▋| 1719/1772 [10:53<00:16,  3.14it/s, running training loss:  1.09542]\u001b[A\n",
            "Training:  97%|█████████▋| 1720/1772 [10:53<00:16,  3.19it/s, running training loss:  1.09542]\u001b[A\n",
            "Training:  97%|█████████▋| 1720/1772 [10:53<00:16,  3.19it/s, running training loss:  1.03309]\u001b[A\n",
            "Training:  97%|█████████▋| 1721/1772 [10:53<00:15,  3.23it/s, running training loss:  1.03309]\u001b[A\n",
            "Training:  97%|█████████▋| 1721/1772 [10:54<00:15,  3.23it/s, running training loss:  0.93101]\u001b[A\n",
            "Training:  97%|█████████▋| 1722/1772 [10:54<00:16,  3.08it/s, running training loss:  0.93101]\u001b[A\n",
            "Training:  97%|█████████▋| 1722/1772 [10:54<00:16,  3.08it/s, running training loss:  0.59636]\u001b[A\n",
            "Training:  97%|█████████▋| 1723/1772 [10:54<00:15,  3.19it/s, running training loss:  0.59636]\u001b[A\n",
            "Training:  97%|█████████▋| 1723/1772 [10:54<00:15,  3.19it/s, running training loss:  0.77173]\u001b[A\n",
            "Training:  97%|█████████▋| 1724/1772 [10:54<00:14,  3.43it/s, running training loss:  0.77173]\u001b[A\n",
            "Training:  97%|█████████▋| 1724/1772 [10:55<00:14,  3.43it/s, running training loss:  0.90799]\u001b[A\n",
            "Training:  97%|█████████▋| 1725/1772 [10:55<00:15,  3.12it/s, running training loss:  0.90799]\u001b[A\n",
            "Training:  97%|█████████▋| 1725/1772 [10:55<00:15,  3.12it/s, running training loss:  0.92436]\u001b[A\n",
            "Training:  97%|█████████▋| 1726/1772 [10:55<00:14,  3.14it/s, running training loss:  0.92436]\u001b[A\n",
            "Training:  97%|█████████▋| 1726/1772 [10:55<00:14,  3.14it/s, running training loss:  0.68245]\u001b[A\n",
            "Training:  97%|█████████▋| 1727/1772 [10:55<00:15,  3.00it/s, running training loss:  0.68245]\u001b[A\n",
            "Training:  97%|█████████▋| 1727/1772 [10:56<00:15,  3.00it/s, running training loss:  0.66001]\u001b[A\n",
            "Training:  98%|█████████▊| 1728/1772 [10:56<00:14,  3.03it/s, running training loss:  0.66001]\u001b[A\n",
            "Training:  98%|█████████▊| 1728/1772 [10:56<00:14,  3.03it/s, running training loss:  0.57629]\u001b[A\n",
            "Training:  98%|█████████▊| 1729/1772 [10:56<00:13,  3.19it/s, running training loss:  0.57629]\u001b[A\n",
            "Training:  98%|█████████▊| 1729/1772 [10:56<00:13,  3.19it/s, running training loss:  0.82130]\u001b[A\n",
            "Training:  98%|█████████▊| 1730/1772 [10:56<00:12,  3.43it/s, running training loss:  0.82130]\u001b[A\n",
            "Training:  98%|█████████▊| 1730/1772 [10:57<00:12,  3.43it/s, running training loss:  0.73098]\u001b[A\n",
            "Training:  98%|█████████▊| 1731/1772 [10:57<00:12,  3.28it/s, running training loss:  0.73098]\u001b[A\n",
            "Training:  98%|█████████▊| 1731/1772 [10:57<00:12,  3.28it/s, running training loss:  0.77451]\u001b[A\n",
            "Training:  98%|█████████▊| 1732/1772 [10:57<00:12,  3.13it/s, running training loss:  0.77451]\u001b[A\n",
            "Training:  98%|█████████▊| 1732/1772 [10:57<00:12,  3.13it/s, running training loss:  0.87076]\u001b[A\n",
            "Training:  98%|█████████▊| 1733/1772 [10:57<00:13,  2.93it/s, running training loss:  0.87076]\u001b[A\n",
            "Training:  98%|█████████▊| 1733/1772 [10:58<00:13,  2.93it/s, running training loss:  0.73483]\u001b[A\n",
            "Training:  98%|█████████▊| 1734/1772 [10:58<00:13,  2.80it/s, running training loss:  0.73483]\u001b[A\n",
            "Training:  98%|█████████▊| 1734/1772 [10:58<00:13,  2.80it/s, running training loss:  0.49288]\u001b[A\n",
            "Training:  98%|█████████▊| 1735/1772 [10:58<00:14,  2.59it/s, running training loss:  0.49288]\u001b[A\n",
            "Training:  98%|█████████▊| 1735/1772 [10:59<00:14,  2.59it/s, running training loss:  0.57465]\u001b[A\n",
            "Training:  98%|█████████▊| 1736/1772 [10:59<00:13,  2.63it/s, running training loss:  0.57465]\u001b[A\n",
            "Training:  98%|█████████▊| 1736/1772 [10:59<00:13,  2.63it/s, running training loss:  0.82517]\u001b[A\n",
            "Training:  98%|█████████▊| 1737/1772 [10:59<00:13,  2.58it/s, running training loss:  0.82517]\u001b[A\n",
            "Training:  98%|█████████▊| 1737/1772 [10:59<00:13,  2.58it/s, running training loss:  0.83646]\u001b[A\n",
            "Training:  98%|█████████▊| 1738/1772 [10:59<00:15,  2.24it/s, running training loss:  0.83646]\u001b[A\n",
            "Training:  98%|█████████▊| 1738/1772 [11:00<00:15,  2.24it/s, running training loss:  0.81070]\u001b[A\n",
            "Training:  98%|█████████▊| 1739/1772 [11:00<00:14,  2.30it/s, running training loss:  0.81070]\u001b[A\n",
            "Training:  98%|█████████▊| 1739/1772 [11:00<00:14,  2.30it/s, running training loss:  0.80863]\u001b[A\n",
            "Training:  98%|█████████▊| 1740/1772 [11:00<00:12,  2.48it/s, running training loss:  0.80863]\u001b[A\n",
            "Training:  98%|█████████▊| 1740/1772 [11:01<00:12,  2.48it/s, running training loss:  0.38948]\u001b[A\n",
            "Training:  98%|█████████▊| 1741/1772 [11:01<00:12,  2.58it/s, running training loss:  0.38948]\u001b[A\n",
            "Training:  98%|█████████▊| 1741/1772 [11:01<00:12,  2.58it/s, running training loss:  0.64118]\u001b[A\n",
            "Training:  98%|█████████▊| 1742/1772 [11:01<00:11,  2.64it/s, running training loss:  0.64118]\u001b[A\n",
            "Training:  98%|█████████▊| 1742/1772 [11:01<00:11,  2.64it/s, running training loss:  0.93061]\u001b[A\n",
            "Training:  98%|█████████▊| 1743/1772 [11:01<00:10,  2.89it/s, running training loss:  0.93061]\u001b[A\n",
            "Training:  98%|█████████▊| 1743/1772 [11:01<00:10,  2.89it/s, running training loss:  1.02339]\u001b[A\n",
            "Training:  98%|█████████▊| 1744/1772 [11:02<00:09,  3.03it/s, running training loss:  1.02339]\u001b[A\n",
            "Training:  98%|█████████▊| 1744/1772 [11:02<00:09,  3.03it/s, running training loss:  0.87404]\u001b[A\n",
            "Training:  98%|█████████▊| 1745/1772 [11:02<00:09,  2.84it/s, running training loss:  0.87404]\u001b[A\n",
            "Training:  98%|█████████▊| 1745/1772 [11:02<00:09,  2.84it/s, running training loss:  1.03872]\u001b[A\n",
            "Training:  99%|█████████▊| 1746/1772 [11:02<00:09,  2.87it/s, running training loss:  1.03872]\u001b[A\n",
            "Training:  99%|█████████▊| 1746/1772 [11:03<00:09,  2.87it/s, running training loss:  0.49605]\u001b[A\n",
            "Training:  99%|█████████▊| 1747/1772 [11:03<00:08,  2.97it/s, running training loss:  0.49605]\u001b[A\n",
            "Training:  99%|█████████▊| 1747/1772 [11:03<00:08,  2.97it/s, running training loss:  0.82868]\u001b[A\n",
            "Training:  99%|█████████▊| 1748/1772 [11:03<00:08,  2.94it/s, running training loss:  0.82868]\u001b[A\n",
            "Training:  99%|█████████▊| 1748/1772 [11:03<00:08,  2.94it/s, running training loss:  0.90206]\u001b[A\n",
            "Training:  99%|█████████▊| 1749/1772 [11:03<00:07,  3.11it/s, running training loss:  0.90206]\u001b[A\n",
            "Training:  99%|█████████▊| 1749/1772 [11:04<00:07,  3.11it/s, running training loss:  1.18432]\u001b[A\n",
            "Training:  99%|█████████▉| 1750/1772 [11:04<00:08,  2.60it/s, running training loss:  1.18432]\u001b[A\n",
            "Training:  99%|█████████▉| 1750/1772 [11:04<00:08,  2.60it/s, running training loss:  1.04858]\u001b[A\n",
            "Training:  99%|█████████▉| 1751/1772 [11:04<00:08,  2.38it/s, running training loss:  1.04858]\u001b[A\n",
            "Training:  99%|█████████▉| 1751/1772 [11:05<00:08,  2.38it/s, running training loss:  0.74874]\u001b[A\n",
            "Training:  99%|█████████▉| 1752/1772 [11:05<00:08,  2.44it/s, running training loss:  0.74874]\u001b[A\n",
            "Training:  99%|█████████▉| 1752/1772 [11:05<00:08,  2.44it/s, running training loss:  1.09811]\u001b[A\n",
            "Training:  99%|█████████▉| 1753/1772 [11:05<00:06,  2.74it/s, running training loss:  1.09811]\u001b[A\n",
            "Training:  99%|█████████▉| 1753/1772 [11:05<00:06,  2.74it/s, running training loss:  0.74430]\u001b[A\n",
            "Training:  99%|█████████▉| 1754/1772 [11:05<00:06,  2.83it/s, running training loss:  0.74430]\u001b[A\n",
            "Training:  99%|█████████▉| 1754/1772 [11:06<00:06,  2.83it/s, running training loss:  0.86057]\u001b[A\n",
            "Training:  99%|█████████▉| 1755/1772 [11:06<00:05,  2.88it/s, running training loss:  0.86057]\u001b[A\n",
            "Training:  99%|█████████▉| 1755/1772 [11:06<00:05,  2.88it/s, running training loss:  0.74273]\u001b[A\n",
            "Training:  99%|█████████▉| 1756/1772 [11:06<00:05,  2.78it/s, running training loss:  0.74273]\u001b[A\n",
            "Training:  99%|█████████▉| 1756/1772 [11:06<00:05,  2.78it/s, running training loss:  0.98574]\u001b[A\n",
            "Training:  99%|█████████▉| 1757/1772 [11:06<00:05,  2.74it/s, running training loss:  0.98574]\u001b[A\n",
            "Training:  99%|█████████▉| 1757/1772 [11:07<00:05,  2.74it/s, running training loss:  0.59534]\u001b[A\n",
            "Training:  99%|█████████▉| 1758/1772 [11:07<00:05,  2.69it/s, running training loss:  0.59534]\u001b[A\n",
            "Training:  99%|█████████▉| 1758/1772 [11:07<00:05,  2.69it/s, running training loss:  0.52552]\u001b[A\n",
            "Training:  99%|█████████▉| 1759/1772 [11:07<00:04,  2.68it/s, running training loss:  0.52552]\u001b[A\n",
            "Training:  99%|█████████▉| 1759/1772 [11:07<00:04,  2.68it/s, running training loss:  0.59260]\u001b[A\n",
            "Training:  99%|█████████▉| 1760/1772 [11:07<00:04,  2.80it/s, running training loss:  0.59260]\u001b[A\n",
            "Training:  99%|█████████▉| 1760/1772 [11:08<00:04,  2.80it/s, running training loss:  0.81283]\u001b[A\n",
            "Training:  99%|█████████▉| 1761/1772 [11:08<00:03,  2.92it/s, running training loss:  0.81283]\u001b[A\n",
            "Training:  99%|█████████▉| 1761/1772 [11:08<00:03,  2.92it/s, running training loss:  0.77365]\u001b[A\n",
            "Training:  99%|█████████▉| 1762/1772 [11:08<00:03,  2.92it/s, running training loss:  0.77365]\u001b[A\n",
            "Training:  99%|█████████▉| 1762/1772 [11:09<00:03,  2.92it/s, running training loss:  0.58641]\u001b[A\n",
            "Training:  99%|█████████▉| 1763/1772 [11:09<00:03,  2.56it/s, running training loss:  0.58641]\u001b[A\n",
            "Training:  99%|█████████▉| 1763/1772 [11:09<00:03,  2.56it/s, running training loss:  0.65261]\u001b[A\n",
            "Training: 100%|█████████▉| 1764/1772 [11:09<00:03,  2.63it/s, running training loss:  0.65261]\u001b[A\n",
            "Training: 100%|█████████▉| 1764/1772 [11:09<00:03,  2.63it/s, running training loss:  0.55794]\u001b[A\n",
            "Training: 100%|█████████▉| 1765/1772 [11:09<00:02,  2.71it/s, running training loss:  0.55794]\u001b[A\n",
            "Training: 100%|█████████▉| 1765/1772 [11:10<00:02,  2.71it/s, running training loss:  0.69051]\u001b[A\n",
            "Training: 100%|█████████▉| 1766/1772 [11:10<00:02,  2.74it/s, running training loss:  0.69051]\u001b[A\n",
            "Training: 100%|█████████▉| 1766/1772 [11:10<00:02,  2.74it/s, running training loss:  0.45840]\u001b[A\n",
            "Training: 100%|█████████▉| 1767/1772 [11:10<00:01,  2.84it/s, running training loss:  0.45840]\u001b[A\n",
            "Training: 100%|█████████▉| 1767/1772 [11:10<00:01,  2.84it/s, running training loss:  0.62856]\u001b[A\n",
            "Training: 100%|█████████▉| 1768/1772 [11:10<00:01,  2.87it/s, running training loss:  0.62856]\u001b[A\n",
            "Training: 100%|█████████▉| 1768/1772 [11:11<00:01,  2.87it/s, running training loss:  0.90193]\u001b[A\n",
            "Training: 100%|█████████▉| 1769/1772 [11:11<00:01,  2.94it/s, running training loss:  0.90193]\u001b[A\n",
            "Training: 100%|█████████▉| 1769/1772 [11:11<00:01,  2.94it/s, running training loss:  1.22730]\u001b[A\n",
            "Training: 100%|█████████▉| 1770/1772 [11:11<00:00,  3.15it/s, running training loss:  1.22730]\u001b[A\n",
            "Training: 100%|█████████▉| 1770/1772 [11:11<00:00,  3.15it/s, running training loss:  1.02132]\u001b[A\n",
            "Training: 100%|█████████▉| 1771/1772 [11:11<00:00,  3.25it/s, running training loss:  1.02132]\u001b[A\n",
            "Training: 100%|█████████▉| 1771/1772 [11:12<00:00,  3.25it/s, running training loss:  1.18034]\u001b[A\n",
            "Training: 100%|██████████| 1772/1772 [11:12<00:00,  2.64it/s, running training loss:  1.18034]\n",
            "100%|██████████| 1/1 [11:12<00:00, 672.56s/it]\n"
          ]
        }
      ]
    }
  ]
}