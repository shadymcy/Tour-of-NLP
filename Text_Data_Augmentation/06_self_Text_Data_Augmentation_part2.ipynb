{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "06_self_Text_Data_Augmentation_part2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bDd1SLjpFhY",
        "outputId": "ca1303cb-5c8c-47b0-8fa2-8999c1a7fc71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu May 19 06:50:11 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P8    29W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import sys\n",
        "drive.mount('/content/drive')\n",
        "#设置路径\n",
        "sys.path.append('/content/drive/MyDrive/Colab Notebooks')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2WrbHfHxpjWG",
        "outputId": "2d2ccd0d-96df-4aec-b4a8-46ead2f7ab3c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -U synonyms"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IitZuf_Cplw1",
        "outputId": "91105e53-a3d2-40cc-ec42-91964c0cb925"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting synonyms\n",
            "  Downloading synonyms-3.16.0.tar.gz (10.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.7 MB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from synonyms) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.13.1 in /usr/local/lib/python3.7/dist-packages (from synonyms) (1.21.6)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from synonyms) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from synonyms) (1.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.1->synonyms) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.1->synonyms) (1.1.0)\n",
            "Building wheels for collected packages: synonyms\n",
            "  Building wheel for synonyms (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for synonyms: filename=synonyms-3.16.0-py3-none-any.whl size=10832785 sha256=ec2d073d36c798722ca1938348365e3576e5964403ef59106b0e5418cbcd43bf\n",
            "  Stored in directory: /root/.cache/pip/wheels/e4/cd/43/b4548753509a94471fc946967a07116252d49aeeb689db8f7c\n",
            "Successfully built synonyms\n",
            "Installing collected packages: synonyms\n",
            "Successfully installed synonyms-3.16.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install torch==1.6.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frmB8caapm32",
        "outputId": "a21f457a-7bad-4c7e-ff23-db32cca79988"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==1.6.0\n",
            "  Downloading torch-1.6.0-cp37-cp37m-manylinux1_x86_64.whl (748.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 748.8 MB 14 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0) (1.21.6)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0) (0.16.0)\n",
            "Installing collected packages: torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.11.0+cu113\n",
            "    Uninstalling torch-1.11.0+cu113:\n",
            "      Successfully uninstalled torch-1.11.0+cu113\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.12.0+cu113 requires torch==1.11.0, but you have torch 1.6.0 which is incompatible.\n",
            "torchtext 0.12.0 requires torch==1.11.0, but you have torch 1.6.0 which is incompatible.\n",
            "torchaudio 0.11.0+cu113 requires torch==1.11.0, but you have torch 1.6.0 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install transformers==4.0.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6SSwE6yppv-",
        "outputId": "261d9919-aad1-4cee-9123-783b2f18f786"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers==4.0.1\n",
            "  Downloading transformers-4.0.1-py3-none-any.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.0.1) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 38.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.0.1) (4.64.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.0.1) (3.7.0)\n",
            "Collecting tokenizers==0.9.4\n",
            "  Downloading tokenizers-0.9.4-cp37-cp37m-manylinux2010_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 34.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.0.1) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.0.1) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==4.0.1) (1.21.6)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.0.1) (3.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.0.1) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.0.1) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.0.1) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.0.1) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.0.1) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.0.1) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.0.1) (1.1.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=d2183a0fbdf8fcc9b869e4d22337a472e0e87d7badeedf73c5369086e752d667\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.53 tokenizers-0.9.4 transformers-4.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import synonyms"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSoEhm8xprxX",
        "outputId": "a7154801-0527-44ef-e6f5-6a35a33e0f1f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[jieba] default dict file path ../data/vocab.txt\n",
            "[jieba] default dict file path ../data/vocab.txt\n",
            "[jieba] load default dict ../data/vocab.txt ...\n",
            "[jieba] load default dict ../data/vocab.txt ...\n",
            ">> Synonyms load wordseg dict [/usr/local/lib/python3.7/dist-packages/synonyms/data/vocab.txt] ... \n",
            ">> Synonyms on loading stopwords [/usr/local/lib/python3.7/dist-packages/synonyms/data/stopwords.txt] ...\n",
            "[Synonyms] on loading vectors [/usr/local/lib/python3.7/dist-packages/synonyms/data/words.vector.gz] ...\n",
            "\n",
            "[Synonyms] downloading data from https://github.com/chatopera/Synonyms/releases/download/3.15.0/words.vector.gz to /usr/local/lib/python3.7/dist-packages/synonyms/data/words.vector.gz ... \n",
            " this only happens if SYNONYMS_WORD2VEC_BIN_URL_ZH_CN is not present and Synonyms initialization for the first time. \n",
            " It would take minutes that depends on network.\n",
            "\n",
            "[Synonyms] downloaded.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EDA（Easy Data Augmentation）\n",
        "![EDA3](https://img-blog.csdnimg.cn/50c22b4212714b509ce053ff921d6bdd.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTI4NzA2MA==,size_16,color_FFFFFF,t_70)"
      ],
      "metadata": {
        "id": "RIeS3F2QrMZV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 对于训练集中的给定句子，随机选择并执行以下操作之一：\n",
        "* 同义词替换（SR）：从句子中随机选择 n 个不是停用词的词。 用随机选择的同义词之一替换这些单词中的每一个。\n",
        "* 随机插入 (RI)：在句子中随机找到一个词，并找出其同义词，且该同义词不是停用词。 将该同义词插入句子中的随机位置。 这样做n次。\n",
        "* 随机交换（RS）：随机选择句子中的两个单词并交换它们的位置。 这样做n次。\n",
        "* 随机删除（RD）：以概率 p 随机删除句子中的每个单词。"
      ],
      "metadata": {
        "id": "wuNtIMkDrSoN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 读取停用词表\n",
        "import random\n",
        "import re\n",
        "from random import shuffle\n",
        "# strip() 方法用于移除字符串头尾指定的字符（默认为空格或换行符）或字符序列。\n",
        "stop_words = {word.strip() for word in open('/content/drive/MyDrive/Colab Notebooks/dataset/baidu_stopwords.txt', 'r', encoding='utf8').readlines()}"
      ],
      "metadata": {
        "id": "9BUv5AFRptie"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 同义词替换（SR）：从句子中随机选择 n 个不是停用词的词。 用随机选择的同义词之一替换这些单词中的每一个。\n",
        "\n",
        "# 得到同义词列表\n",
        "def get_synonym(word):\n",
        "  # nearby返回一个元组，位置0返回同义词，位置1返回相似度\n",
        "  sys = set(synonyms.nearby(word)[0])\n",
        "  # 去除原词\n",
        "  if word in sys:\n",
        "    sys.remove(word)\n",
        "  return list(sys)\n",
        "  # 如果输入\"给力\" 可能没有同义词（同义词只有他自己） 则返回  ([],[])\n",
        "\n",
        "# 同义词替换\n",
        "# 传入一个词列表和替换词的数量\n",
        "def synonym_replacement(words, n):\n",
        "\n",
        "  new_words = words.copy()\n",
        "  # 去除停用词，去重，变成列表\n",
        "  random_word_list = list(set([word for word in words if word not in stop_words]))\n",
        "  # 打乱\n",
        "  random.shuffle(random_word_list)\n",
        "\n",
        "  num_replaced = 0\n",
        "  for random_word in random_word_list:\n",
        "    synonym_words = get_synonym(random_word)\n",
        "    if len(synonym_words)>=1:\n",
        "        # 随机选取一个同义词\n",
        "        synonym = random.choice(list(synonym_words))\n",
        "        # 如果word是要替换的词 替换成同义词 ，否则返回原词\n",
        "        new_words = [synonym if word == random_word else word for word in new_words]\n",
        "        # 同义词替换数量+1\n",
        "        num_replaced += 1\n",
        "        \n",
        "    if num_replaced >= n:\n",
        "        break\n",
        "  # 为什么加这两句话？ 看note1\n",
        "  sentence = ' '.join(new_words)\n",
        "  new_words = sentence.split(' ')\n",
        "\n",
        "  return new_words"
      ],
      "metadata": {
        "id": "FoteXbv0swx1"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 使用eda进行数据增强\n",
        "# 同义词替换的比例、 增强的句子数目\n",
        "def eda(sentence, alpha_sr=0.1, num_aug=9):\n",
        "\n",
        "  # 位置0是词组、1是词性\n",
        "  words = synonyms.seg(sentence)[0]\n",
        "  num_words = len(words)\n",
        "  n_sr = max(1, int(alpha_sr * num_words))\n",
        "\n",
        "  augmented_sentences = []\n",
        "\n",
        "  for _ in range(num_aug):\n",
        "    a_words = synonym_replacement(words, n_sr)\n",
        "    augmented_sentences.append(' '.join(a_words))\n",
        "  return augmented_sentences"
      ],
      "metadata": {
        "id": "HdAYQ0i5u69t"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# note1\n",
        "# 存在这样一种情况\n",
        "sentence = ['in', 'war', 'one', 'must', 'be', 'a', 'good', 'actor']\n",
        "word = 'actor'\n",
        "example_synonyms = ['actress', 'film star', 'performer', 'comedian', 'entertainer']\n",
        "new_sentence = ['in', 'war', 'one', 'must', 'be', 'a', 'good', 'film star']\n",
        "# 为了消除空格\n",
        "new_sentence = ['in', 'war', 'one', 'must', 'be', 'a', 'good', 'film', 'star']"
      ],
      "metadata": {
        "id": "5HHl5NL13t5z"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eda('9月15日以来，台积电、高通、三星等华为的重要合作伙伴，只要没有美国的相关许可证，都无法供应芯片给华为，而中芯国际等国产芯片企业，也因采用美国技术，而无法供货给华为。目前华为部分型号的手机产品出现货少的现象，若该形势持续下去，华为手机业务将遭受重创。')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mz-l0Yxj30JT",
        "outputId": "ed0a566e-5f08-4b20-e22c-831abfdbce8e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['9 月 15 日 以来 ， 台积电 、 高通 、 三星 等 华为 的 重要 合作伙伴 ， 只要 没有 古巴 的 相应 许可证 ， 都 无法 供应 芯片 给 华为 ， 而 中芯国际 等 国产 芯片 企业 ， 也 因 采用 古巴 控制技术 ， 而 无法 OEM 给 华为 。 目前 华为 部分 型号 的 手机 产品 出现 货 少 的 弊端 ， 若 该 形势 持续 下去 ， 华为 手机 业务 将 遭到 顽强抵抗 。',\n",
              " '9 月 15 日 以来 ， 台积电 、 高通 、 三星 等 华为 的 重要 服务商 ， 只要 没有 新西兰 的 相关机构 证书 ， 即便 无法 供应 模组 给 华为 ， 而 中芯国际 等 国产 模组 企业 ， 也 因 采用 新西兰 技术 ， 而 无法 供货 给 华为 。 目前 华为 部分 型号 的 手机 产品 出现 货 少 的 现象 ， 若 该 形势 持续 下去 ， 华为 手机 业务 将 遭受 沉重打击 。',\n",
              " '9 月 15 日 以来 ， 宏碁 、 高通 、 三星 等 华为 的 重要 合作伙伴 ， 只要 没有 美国 的 前述 许可证 ， 即便 无法 供应 器件 给 华为 ， 而 中芯国际 等 国产 器件 企业 ， 也 因 采用 美国 技术 ， 而 无法 供货 给 华为 。 目前 华为 部分 型号 的 手机 商品 出现 货 少 的 弊端 ， 若 该 形势 持续 下去 ， 华为 手机 业务 将 遭受 顽强抵抗 。',\n",
              " '9 月 15 日 以来 ， Tektronix 、 高通 、 三星 等 华为 的 重要 合作伙伴 ， 只要 没有 墨西哥 的 相关 许可证 ， 都 无法 供应 芯片 给 华为 ， 而 SE9 等 改良版 芯片 企业 ， 也 因 采用 墨西哥 技术 ， 而 无法 接单 给 华为 。 目前 华为 部分 型号 的 手机 产品 出现 货 少 的 现象 ， 若 该 严峻形势 持续 下去 ， 华为 手机 业务 将 遭受重创 重创 。',\n",
              " '9 月 15 年 以来 ， 台积电 、 高通 、 三星 等 华为 的 重要 合作伙伴 ， 只要 没有 美国 的 相关 许可证 ， 都 无法 市场供应 芯片 给 华为 ， 而 中芯国际 等 国产 芯片 跨国公司 ， 也 因 采用 美国 技术开发 ， 而 无法 发货 给 华为 。 目前 华为 部分 型号 的 手机 配件 出现 猪仔 少 的 现象 ， 若 该 形势 持续 下去 ， 华为 手机 业务 将 遭受 重创 。',\n",
              " '9 年初 15 日 以来 ， 台积电 、 高通 、 三星 等 OPPO 的 重要 合作伙伴 ， 只要 没有 美国 的 相关机构 证 ， 都 无法 物资供应 积体电路 给 OPPO ， 而 中芯国际 等 国产 积体电路 企业 ， 也 因 采用 美国 技术开发 ， 而 无法 供货 给 OPPO 。 目前 OPPO 部分 型号 的 手机 产品 出现 货 少 的 现象 ， 若 该 形势 持续 下去 ， OPPO 手机 业务 将 遭受 重创 。',\n",
              " '9 年初 15 日 以来 ， 台积电 、 高通 、 三星 等 宏碁 的 重要 合作伙伴 ， 只要 没有 美国 的 相关 许可证 ， 都 无法 货源 芯片 给 宏碁 ， 而 中芯国际 等 国产 芯片 中小企业 ， 也 因 采用 美国 技术 ， 而 无法 供货 给 宏碁 。 目前 宏碁 部分 型号 的 新手机 产品 出现 货 少 的 现象 ， 若 该 严峻形势 继续 下去 ， 宏碁 新手机 业务 将 遭受 重创 。',\n",
              " '9 月 15 下旬 以来 ， VIA 、 高通 、 Note 等 华为 的 重要 合作伙伴 ， 只要 没有 美国 的 相关 许可证 ， 都 无法 供应 芯片 给 华为 ， 而 中芯国际 等 国产 芯片 企业 ， 也 因 采用 美国 技术 ， 而 无法 供货 给 华为 。 目前 华为 部分 型号 的 手机 产品线 出现 货 太小 的 现象 ， 若 该 形势 持续 下去 ， 华为 手机 业务 将 造成 沉重打击 。',\n",
              " '9 月 15 日 以来 ， 台积电 、 高通 、 三星 等 华为 的 重要 合作伙伴 ， 只要 没有 美国 的 相关 许可证 ， 都 无法 供应 微处理器 给 华为 ， 而 卢戈韦 等 国产 微处理器 跨国公司 ， 也 因 采用 美国 技术 ， 而 无法 分销 给 华为 。 目前 华为 部分 型号 的 手机 产品 出现 货 贵 的 弊端 ， 若 该 形势 持续 下去 ， 华为 手机 业务 将 遭受重创 重创 。']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![UDA5](https://img-blog.csdnimg.cn/9d10da70d1d0467e93ef5bb1267ac87f.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTI4NzA2MA==,size_16,color_FFFFFF,t_70)\n",
        "**$ \\tilde{\\theta} $： 参数不变 不进行反向传播**\n",
        "\n",
        "\n",
        "![在这里插入图片描述](https://img-blog.csdnimg.cn/88a3abe95bbd4e369fe4d085533c9c35.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTI4NzA2MA==,size_16,color_FFFFFF,t_70)"
      ],
      "metadata": {
        "id": "vPU8nQ-9Ap3r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bucket_sampler import SortedSampler, BucketBatchSampler\n",
        "from EMA import *"
      ],
      "metadata": {
        "id": "JPf1XYme_WiE"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "config = {\n",
        "        'train_file_path': '/content/drive/MyDrive/Colab Notebooks/dataset/ESIM/train.json',\n",
        "        'dev_file_path': '/content/drive/MyDrive/Colab Notebooks/dataset/ESIM/dev.json',\n",
        "        'test_file_path': '/content/drive/MyDrive/Colab Notebooks/dataset/ESIM/test.json',\n",
        "        'output_path': '.',\n",
        "        'model_path': '/content/drive/MyDrive/Colab Notebooks/dataset/BERT_model',\n",
        "        'batch_size': 16,\n",
        "        'num_epochs': 1,\n",
        "        'max_seq_len': 64,\n",
        "        'learning_rate': 2e-5,\n",
        "        'weight_decay': 0.01,\n",
        "        'use_bucket': True,\n",
        "        'bucket_multiplier': 200,\n",
        "        'unsup_data_ratio': 1.5,\n",
        "        'uda_softmax_temp': 0.4,\n",
        "        'uda_confidence_threshold': 0.8,\n",
        "        'device': 'cuda',\n",
        "        'n_gpus': 0,\n",
        "        'logging_step': 300,\n",
        "        'ema_start_step': 500,\n",
        "        'ema_start': False,\n",
        "        'seed': 2022\n",
        "    }\n",
        "\n",
        "if not torch.cuda.is_available():\n",
        "    config['device'] = 'cpu'\n",
        "else:\n",
        "    config['n_gpus'] = torch.cuda.device_count()\n",
        "    config['batch_size'] *= config['n_gpus']\n",
        "\n",
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    return seed\n",
        "\n",
        "seed_everything(config['seed'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSIh_qnCFxnq",
        "outputId": "8e4e58dc-3abb-4207-961c-37eeb88fe2cb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2022"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(config['model_path'])"
      ],
      "metadata": {
        "id": "Ed8eczWuH7sj"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_bert_inputs(inputs, label, sentence_a, sentence_b, tokenizer):\n",
        "  inputs_dict = tokenizer.encode_plus(sentence_a, sentence_b, add_special_tokens = True, return_token_type_ids =True, return_attention_mask = True)\n",
        "\n",
        "  inputs['input_ids'].append(inputs_dict['input_ids'])\n",
        "  inputs['token_type_ids'].append(inputs_dict['token_type_ids'])\n",
        "  inputs['attention_mask'].append(inputs_dict['attention_mask'])\n",
        "  inputs['labels'].append(label)"
      ],
      "metadata": {
        "id": "aLobuIWSH9Za"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 对偶数据增强\n",
        "\n",
        "**a-b对，变成b-a对, 把两个句子换顺序**\\\n",
        "**我们的无监督数据增强就是用的对偶数据增强**\\\n",
        "**BERT输入 a，b两个句子，现在输入以b,a作为输入，增强样本**"
      ],
      "metadata": {
        "id": "p1OJnYZ3IQsa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "def parse_data(path, data_type='train'):\n",
        "  sentence_a = []\n",
        "  sentence_b = []\n",
        "  labels = []\n",
        "\n",
        "  with open(path, 'r', encoding = 'utf8') as f:\n",
        "    for line in tqdm(f.readlines(), desc=f'Reading {data_type} data'):\n",
        "      line = json.loads(line)\n",
        "      sentence_a.append(line['sentence1'])\n",
        "      sentence_b.append(line['sentence2'])\n",
        "      if data_type != 'test':\n",
        "        labels.append(int(line['label']))\n",
        "      else:\n",
        "        labels.append(0)\n",
        "\n",
        "  df = pd.DataFrame(zip(sentence_a, sentence_b, labels), columns = ['text_a', 'text_b', 'labels'])\n",
        "  return df"
      ],
      "metadata": {
        "id": "q2a4-zAUKFnS"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 无监督BERT输入\n",
        "def build_unsup_bert_inputs(inputs, label, sentence_a, sentence_b, tokenizer):\n",
        "  # 左右\n",
        "  lr_inputs_dict = tokenizer.encode_plus(sentence_a, sentence_b, add_special_tokens = True, return_token_type_ids = True, return_attention_mask = True)\n",
        "  # 右左\n",
        "  rl_inputs_dict = tokenizer.encode_plus(sentence_b, sentence_a, add_special_tokens = True, return_token_type_ids = True, return_attention_mask = True)\n",
        "\n",
        "  # 元组的形式\n",
        "  inputs['input_ids'].append((lr_inputs_dict['input_ids'], rl_inputs_dict['input_ids']))\n",
        "  inputs['token_type_ids'].append((lr_inputs_dict['token_type_ids'], rl_inputs_dict['token_type_ids']))\n",
        "  inputs['attention_mask'].append((lr_inputs_dict['attention_mask'], rl_inputs_dict['attention_mask']))\n",
        "  inputs['labels'].append(label)"
      ],
      "metadata": {
        "id": "ivfX_45aM8fb"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## startswith()方法\n",
        "startswith() 方法用于检查字符串是否是以指定子字符串开头\\\n",
        "如果是则返回 True，否则返回 False。如果参数 beg 和 end 指定值，则在指定范围内检查。\\\n",
        "str.startswith(str, beg=0,end=len(string));\\\n",
        "*参数*\n",
        "```\n",
        "str --检测的字符串。\n",
        "strbeg --可选参数用于设置字符串检测的起始位置。\n",
        "strend --可选参数用于设置字符串检测的结束位置。\n",
        "```"
      ],
      "metadata": {
        "id": "0mKVUaZvs6GF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "def read_data(config, tokenizer):\n",
        "  train_df = parse_data(config['train_file_path'], data_type = 'train')\n",
        "  dev_df = parse_data(config['dev_file_path'], data_type = 'dev')\n",
        "  test_df = parse_data(config['test_file_path'], data_type = 'test')\n",
        "\n",
        "  data_df = {'train': train_df, 'dev': dev_df, 'test': test_df}\n",
        "  processed_data = {}\n",
        "  unsup_data = defaultdict(list)\n",
        "  for data_type, df in data_df.items():\n",
        "    inputs = defaultdict(list)\n",
        "    if data_type == 'train':\n",
        "      reversed_inputs = defaultdict(list)\n",
        "\n",
        "    for i, row in tqdm(df.iterrows(), desc=f'Preprocessing {data_type} data', total = len(df)):\n",
        "      label = 0 if data_type == 'test' else row[2]\n",
        "      sentence_a, sentence_b = row[0], row[1]\n",
        "      build_bert_inputs(inputs, label, sentence_a, sentence_b, tokenizer)\n",
        "\n",
        "      if data_type.startswith('test'):\n",
        "        build_bert_inputs(inputs, label, sentence_b, sentence_a, tokenizer)\n",
        "\n",
        "\n",
        "      build_unsup_bert_inputs(unsup_data, label, sentence_a, sentence_b, tokenizer)\n",
        "\n",
        "    processed_data[data_type] = inputs\n",
        "  processed_data['unsup_data'] = unsup_data\n",
        "  return processed_data\n",
        "\n",
        "# processed_data\n",
        "# {\n",
        "#    'train':,\n",
        "#    'dev':,\n",
        "#    'test':,\n",
        "#    'unsup_data':   # 数据量最大的\n",
        "# }"
      ],
      "metadata": {
        "id": "dwfnsojmrjBm"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = read_data(config, tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NxzjWiL3thie",
        "outputId": "552e5161-2c67-4c77-bef6-ca674bf4c8b1"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reading train data: 100%|██████████| 34334/34334 [00:00<00:00, 60302.59it/s]\n",
            "Reading dev data: 100%|██████████| 4316/4316 [00:00<00:00, 34220.64it/s]\n",
            "Reading test data: 100%|██████████| 3861/3861 [00:00<00:00, 60669.28it/s]\n",
            "Preprocessing train data: 100%|██████████| 34334/34334 [01:02<00:00, 546.73it/s]\n",
            "Preprocessing dev data: 100%|██████████| 4316/4316 [00:07<00:00, 571.66it/s]\n",
            "Preprocessing test data: 100%|██████████| 3861/3861 [00:10<00:00, 385.31it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "class AFQMCDataset(Dataset):\n",
        "  def __init__(self, data_dict):\n",
        "    super(AFQMCDataset, self).__init__()\n",
        "    self.data_dict = data_dict\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    data = (self.data_dict['input_ids'][idx],\n",
        "         self.data_dict['token_type_ids'][idx],\n",
        "         self.data_dict['attention_mask'][idx],\n",
        "         self.data_dict['labels'][idx])\n",
        "    return data\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.data_dict['input_ids'])\n"
      ],
      "metadata": {
        "id": "dHu8cHCuVrH6"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Collator:\n",
        "  def __init__(self, max_seq_len, tokenizer):\n",
        "    self.max_seq_len = max_seq_len\n",
        "    self.tokenizer = tokenizer\n",
        "\n",
        "  def pad_and_truncate(self, input_ids_list, token_type_ids_list, attention_mask_list, labels_list, max_seq_len):\n",
        "    input_ids = torch.zeros((len(input_ids_list), max_seq_len), dtype = torch.long)\n",
        "    token_type_ids = torch.zeros_like(input_ids)\n",
        "    attention_mask = torch.zeros_like(input_ids)\n",
        "    for i in range(len(input_ids_list)):\n",
        "      seq_len = len(input_ids_list[i])\n",
        "      if seq_len <= max_seq_len:\n",
        "        input_ids[i, :seq_len] = torch.tensor(input_ids_list[i], dtype = torch.long)\n",
        "        token_type_ids[i, :seq_len] = torch.tensor(token_type_ids_list[i], dtype = torch.long)\n",
        "        attention_mask[i, :seq_len] = torch.tensor(attention_mask_list[i], dtype = torch.long)\n",
        "\n",
        "      else:\n",
        "        input_ids[i] = torch.tensor(input_ids_list[i][:max_seq_len - 1] + [self.tokenizer.sep_token_id], dtype = torch.long)\n",
        "        token_type_ids[i] = torch.tensor(token_type_ids_list[i][:max_seq_len], dtype = torch.long)\n",
        "        attention_mask[i] = torch.tensor(attention_mask_list[i][:max_seq_len], dtype = torch.long)\n",
        "\n",
        "    labels = torch.tensor(labels_list, dtype = torch.long)\n",
        "    return input_ids, token_type_ids, attention_mask, labels\n",
        "\n",
        "  def __call__(self, examples):\n",
        "    input_ids_list, token_type_ids_list, attention_mask_list, labels_list = list(zip(*examples))\n",
        "    cur_max_seq_len = max(len(input_ids) for input_ids in input_ids_list)\n",
        "    max_seq_len = min(cur_max_seq_len, self.max_seq_len)\n",
        "\n",
        "    input_ids, token_type_ids, attention_mask, labels = self.pad_and_truncate(input_ids_list, token_type_ids_list, attention_mask_list, labels_list, max_seq_len)\n",
        "\n",
        "    data_dict = {\n",
        "        'input_ids':input_ids,\n",
        "        'token_type_ids':token_type_ids,\n",
        "        'attention_mask':attention_mask,\n",
        "        'labels':labels\n",
        "    }\n",
        "    return data_dict"
      ],
      "metadata": {
        "id": "jLRFtNPjWBV0"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "collate_fn = Collator(config['max_seq_len'], tokenizer)"
      ],
      "metadata": {
        "id": "qU-ST7YHWnGT"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# UDA 无监督重新构造dataset 和 collator\n",
        "class UnsupAFQMCDataset(Dataset):\n",
        "  def __init__(self, data_dict):\n",
        "    super(UnsupAFQMCDataset, self).__init__()\n",
        "    self.data_dict = data_dict\n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "    input_ids = self.data_dict['input_ids'][idx]\n",
        "    token_type_ids = self.data_dict['token_type_ids'][idx]\n",
        "    attention_mask = self.data_dict['attention_mask'][idx]\n",
        "    labels = self.data_dict['labels'][idx]\n",
        "    # input_ids[0]：lr_inputs_dict['input_ids']    (build_unsup_bert_inputs)\n",
        "    # input_ids[1]：rl_inputs_dict['input_ids']\n",
        "    return (input_ids[0], token_type_ids[0], attention_mask[0],\n",
        "         input_ids[1], token_type_ids[1], attention_mask[1],\n",
        "         labels)\n",
        "    \n",
        "  def __len__(self):\n",
        "    return len(self.data_dict['input_ids'])"
      ],
      "metadata": {
        "id": "PzCTMQpXWp0q"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UnsupCollator(Collator):\n",
        "  def __init__(self, max_seq_len, tokenizer):\n",
        "    super(UnsupCollator, self).__init__(max_seq_len, tokenizer)\n",
        "\n",
        "  def __call__(self, examples):\n",
        "    # 根据UnsupAFQMCDataset的getitem 有七个数据\n",
        "    (ab_input_ids_list, ab_token_type_ids_list, ab_attention_mask_list,\n",
        "     ba_input_ids_list, ba_token_type_ids_list, ba_attention_mask_list,\n",
        "     labels_list) = list(zip(*examples))\n",
        "    cur_max_seq_len = max(len(input_ids) for input_ids in ab_input_ids_list)\n",
        "    max_seq_len = min(cur_max_seq_len, self.max_seq_len)\n",
        "    # 分批整ab, ba（填充与截断）\n",
        "    ab_input_ids, ab_token_type_ids, ab_attention_mask, labels = self.pad_and_truncate(ab_input_ids_list, ab_token_type_ids_list, ab_attention_mask_list, labels_list, max_seq_len)\n",
        "    ba_input_ids, ba_token_type_ids, ba_attention_mask, labels = self.pad_and_truncate(ba_input_ids_list, ba_token_type_ids_list, ba_attention_mask_list, labels_list, max_seq_len)\n",
        "\n",
        "\n",
        "    data_dict = {\n",
        "        'ab_input_ids':ab_input_ids,\n",
        "        'ab_token_type_ids':ab_token_type_ids,\n",
        "        'ab_attention_mask':ab_attention_mask,\n",
        "        'ba_input_ids':ba_input_ids,\n",
        "        'ba_token_type_ids':ba_token_type_ids,\n",
        "        'ba_attention_mask':ba_attention_mask,\n",
        "        'labels':labels\n",
        "    }\n",
        "    return data_dict"
      ],
      "metadata": {
        "id": "THRD_vhSZhPS"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler\n",
        "def build_dataloader(config, data, tokenizer):\n",
        "  train_dataset = AFQMCDataset(data['train'])\n",
        "  dev_dataset = AFQMCDataset(data['dev'])\n",
        "  test_dataset = AFQMCDataset(data['test'])\n",
        "  unsup_dataset = UnsupAFQMCDataset(data['unsup_data'])\n",
        "\n",
        "  collate_fn = Collator(config['max_seq_len'], tokenizer)\n",
        "  unsup_collate_fn = UnsupCollator(config['max_seq_len'], tokenizer)\n",
        "\n",
        "  # 使用桶采样\n",
        "  if config['use_bucket']:\n",
        "    # 监督数据\n",
        "    # 基采样器RandomSampler\n",
        "    train_sampler = RandomSampler(train_dataset)\n",
        "    # drop_last 最后一个batch小于size 丢弃\n",
        "    bucket_sampler = BucketBatchSampler(train_sampler, batch_size = config['batch_size'],\n",
        "                      drop_last = False, sort_key = lambda x: len(train_dataset[x][0]),# 以 input_id 长度作为排序的指标\n",
        "                      bucket_size_multiplier = config['bucket_multiplier'])\n",
        "    train_dataloader = DataLoader(dataset = train_dataset, batch_sampler = bucket_sampler, num_workers = 4, collate_fn = collate_fn)\n",
        "    # 无监督数据 \n",
        "    # grad_data中(图) 有监督、无监督一起训练， 无监督数据量大， batchsize可以设置大一点\n",
        "    unsup_sampler = RandomSampler(unsup_dataset)\n",
        "    unsup_bucket_sampler = BucketBatchSampler(unsup_sampler, batch_size = int(config['batch_size'] * config['unsup_data_ratio']),\n",
        "                      drop_last = False, sort_key = lambda x: len(unsup_dataset[x][0]),# 以 input_id 长度作为排序的指标\n",
        "                      bucket_size_multiplier = config['bucket_multiplier'])\n",
        "    \n",
        "    unsup_dataloader = DataLoader(dataset = unsup_dataset, batch_sampler = unsup_bucket_sampler, num_workers = 4, collate_fn = unsup_collate_fn)\n",
        "  # 不使用桶采样\n",
        "  else:\n",
        "    # 监督数据\n",
        "    train_dataloader = DataLoader(dataset = train_dataset, batch_size = config['batch_size'], shuffle = True, num_workers = 4, collate_fn = collate_fn)\n",
        "    # 无监督数据\n",
        "    unsup_dataloader = DataLoader(dataset = unsup_dataset, batch_size = int(config['batch_size'] * config['unsup_data_ratio']), \n",
        "                    shuffle = True, num_workers = 4, collate_fn = unsup_collate_fn)\n",
        "  # 验证集、测试集dataloader 与桶采样无关 因为shuffle=false  \n",
        "  dev_dataloader = DataLoader(dataset = dev_dataset, batch_size = config['batch_size'], shuffle = False, num_workers = 4, collate_fn = collate_fn)\n",
        "  test_dataloader = DataLoader(dataset = test_dataset, batch_size = config['batch_size'], shuffle = False, num_workers = 4, collate_fn = collate_fn)\n",
        "\n",
        "  return unsup_dataloader, train_dataloader, dev_dataloader, test_dataloader"
      ],
      "metadata": {
        "id": "CFS6iR02a6Ba"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unsup_dataloader, train_dataloader, dev_dataloader, test_dataloader = build_dataloader(config, data, tokenizer)"
      ],
      "metadata": {
        "id": "V7YWrqMYb516"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "def evaluation(config, model, val_dataloader):\n",
        "  model.eval()\n",
        "  preds = []\n",
        "  labels = []\n",
        "  val_loss = 0.\n",
        "  val_iterator = tqdm(val_dataloader, desc = 'Evaluation', total = len(val_dataloader))\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for batch in val_iterator:\n",
        "      labels.append(batch['labels'])\n",
        "      batch_cuda = {item: value.to(config['device']) for item, value in list(batch.items())}\n",
        "      batch_cuda['mode'] = 'val'\n",
        "      loss, logits = model(**batch_cuda)[:2]\n",
        "\n",
        "      if config['n_gpus'] > 1:\n",
        "        loss = loss.mean()\n",
        "\n",
        "      val_loss += loss.item()\n",
        "      preds.append(logits.argmax(dim = -1).detach().cpu())\n",
        "\n",
        "  avg_val_loss = val_loss / len(val_dataloader)\n",
        "  labels = torch.cat(labels, dim = 0).numpy()\n",
        "  preds = torch.cat(preds, dim = 0).numpy()\n",
        "  f1 = f1_score(labels, preds)\n",
        "  acc = accuracy_score(labels, preds)\n",
        "  return avg_val_loss, f1, acc"
      ],
      "metadata": {
        "id": "ljaJQ6mLcIoJ"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForSequenceClassification\n",
        "import torch.nn as nn\n",
        "class BertForAFQMC(BertForSequenceClassification):\n",
        "   # 复写forward\n",
        "   def forward(self, input_ids, token_type_ids, attention_mask, labels = None, mode= 'train'):\n",
        "\n",
        "     outputs = self.bert(input_ids, token_type_ids = token_type_ids, attention_mask = attention_mask, output_hidden_states = True)\n",
        "     # 维度：[batch_size, hidden_size]\n",
        "     pooled_output = outputs[1]\n",
        "     pooled_output = self.dropout(pooled_output)\n",
        "\n",
        "     logits = self.classifier(pooled_output)\n",
        "     # print('BertForAFQMC中logits：',logits)\n",
        "     outputs = (logits, )\n",
        "     # print('BertForAFQMC中outputs：',outputs)\n",
        "\n",
        "     if mode == 'val':\n",
        "       loss_fct = nn.CrossEntropyLoss()\n",
        "       # X.view(-1)中的-1本意是根据另外一个数来自动调整维度\n",
        "       loss = loss_fct(logits, labels.view(-1))\n",
        "\n",
        "       outputs = (loss, ) + outputs\n",
        "     return outputs"
      ],
      "metadata": {
        "id": "CEdDR6ZUcbJ5"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "![addtitional Training1](https://img-blog.csdnimg.cn/5916fe8ae028469bb877d15a1ac566de.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTI4NzA2MA==,size_16,color_FFFFFF,t_70)\n",
        "### 额外训练技巧\n",
        "### Confidence-based masking用于无监督训练数据中\n",
        "基于置信度的MASK，发现MASK当前模型不自信的examples很有帮助。总结来说，无监督数据（grad_data ba_unsup_value）要 选出置信度>$\\beta$的样本（够自信的样本）"
      ],
      "metadata": {
        "id": "QsX20JoEGbR2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![UDA5](https://img-blog.csdnimg.cn/1ddf28077b88449aa84e0391149467e4.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTI4NzA2MA==,size_16,color_FFFFFF,t_70)\n",
        "\n",
        "###  A.1 \n",
        "在半监督学习中，经常会遇到未标记数据量和标记数据量存在巨大差异的情况\\\n",
        "模型通常很快会在标记数据上过拟合，同时在未标记数据欠拟合。\\\n",
        "为了解决这个问题，引入一种技术，训练信号退火（TSA）. 它随着训练的进行逐渐释放。\n",
        "\n",
        "这是一种MASK\\\n",
        "当$\\eta=1$ 代表所有数据都训练了\\\n",
        "当$\\eta=0.5$  代表不是所有数据都训练"
      ],
      "metadata": {
        "id": "MtZibL2DFv8u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 上方Figure 5公式\n",
        "def get_tsa_threshold(total_steps, global_steps):\n",
        "  return np.exp((global_steps / total_steps - 1) * 5) / 2 + 0.5"
      ],
      "metadata": {
        "id": "UQzUtpzhFEom"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "![在这里插入图片描述](https://img-blog.csdnimg.cn/88a3abe95bbd4e369fe4d085533c9c35.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTI4NzA2MA==,size_16,color_FFFFFF,t_70)\n",
        "## 有监督数据和无监督数据怎么拼接：\n",
        "### 无监督的batchsize大，但句子长度不一定大 图为else的情况\n",
        "### 连接时先有监督后无监督，图有误（重要！）\n",
        "**get_data**\n",
        "\n",
        "![在这里插入图片描述](https://img-blog.csdnimg.cn/38a2b12d76094f17819ae918b25f3c71.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTI4NzA2MA==,size_16,color_FFFFFF,t_70)"
      ],
      "metadata": {
        "id": "tMm046pdMZcV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 返回 grad_data：需要计算梯度，需要进行反向传播的数据\n",
        "# 返回 no_grad_data: 不需要计算梯度，不需要进行反向传播的数据\n",
        "def get_data(sup_batch, unsup_batch, config):\n",
        "  # 定义成字典\n",
        "  grad_data = {}\n",
        "  no_grad_data = {}\n",
        "  # sup_batch [bs, seq_len] bs:batchsize\n",
        "  # unsup_batch [bs, seq_len]\n",
        "  # 监督数据的 最长 长度\n",
        "  sup_max_len = sup_batch['input_ids'].size(1)\n",
        "  # 无监督数据 的最长 长度\n",
        "  unsup_max_len = unsup_batch['ba_input_ids'].size(1)\n",
        "  \n",
        "  # 当前数据 的最长 长度(谁短补谁)\n",
        "  cur_max_len = max(sup_max_len, unsup_max_len)\n",
        "  # sup_batch是个字典\n",
        "  for item, sup_value in sup_batch.items():\n",
        "    # 如果键是标签 直接放进来\n",
        "    if item == 'labels':\n",
        "      grad_data[item] = sup_value.to(config['device'])\n",
        "      continue\n",
        "\n",
        "    ba_unsup_value = unsup_batch[f'ba_{item}']\n",
        "    ab_unsup_value = unsup_batch[f'ab_{item}']\n",
        "    \n",
        "    # 谁短补谁，ba_unsup_value短\n",
        "    if sup_max_len == cur_max_len:\n",
        "      padding_value = torch.zeros((ba_unsup_value.size(0), cur_max_len - unsup_max_len), dtype = ba_unsup_value.dtype)\n",
        "      ba_unsup_value = torch.cat([ba_unsup_value, padding_value], dim = -1)\n",
        "    \n",
        "    else:\n",
        "      padding_value = torch.zeros((sup_value.size(0), cur_max_len - sup_max_len), dtype = sup_value.dtype)\n",
        "      sup_value = torch.cat([sup_value, padding_value], dim = -1)\n",
        "    \n",
        "    # 把 sup_batch 和 ba 的 数据放在一起\n",
        "    grad_value = torch.cat([sup_value, ba_unsup_value], dim = 0)\n",
        "    grad_data[item] = grad_value.to(config['device'])\n",
        "    # 对它不用进行操作直接放入字典  \n",
        "    no_grad_data[item] = ab_unsup_value.to(config['device'])\n",
        "\n",
        "  return grad_data, no_grad_data\n"
      ],
      "metadata": {
        "id": "zP1AeM6xGrcd"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sharpen操作\n",
        "import torch.nn as nn\n",
        "logits = torch.randn(2,3)\n",
        "print('logits:',logits)\n",
        "t_softmax = torch.softmax(logits, dim=1)\n",
        "# 一个[]中的数加起来为1\n",
        "print('t_softmax:',t_softmax)\n",
        "# 0.4 为config['uda_softmax_temp']\n",
        "# 让大的更大小的更小，变得更硬标签\n",
        "t_sharpen = torch.softmax(logits/0.4, dim=1)\n",
        "print('t_sharpen:',t_sharpen)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55aDnZv6MAu0",
        "outputId": "95d32188-7874-445a-c64c-27524534c63a"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logits: tensor([[ 0.1915,  0.3306,  0.2306],\n",
            "        [ 0.8936, -0.2044, -0.9081]])\n",
            "t_softmax: tensor([[0.3136, 0.3604, 0.3261],\n",
            "        [0.6673, 0.2226, 0.1101]])\n",
            "t_sharpen: tensor([[0.2842, 0.4024, 0.3134],\n",
            "        [0.9300, 0.0597, 0.0103]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### no_grad_data 经过前向传播，产生ab的逻辑值，做ba逻辑值的标签"
      ],
      "metadata": {
        "id": "SXCEkcK2Nbjk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 无监督数据 (ab) 只需要正向传播\n",
        "# Confidence-based masking\n",
        "def forward_no_grad(no_grad_data, config, model):\n",
        "  with torch.no_grad():\n",
        "    # 取逻辑值\n",
        "    np_grad_logits = model(**no_grad_data)[0]\n",
        "    # ----------- sharpen操作(config['uda_softmax_temp']) -------------#\n",
        "    # 概率值\n",
        "    no_grad_probs = torch.softmax(np_grad_logits / config['uda_softmax_temp'], dim = -1)\n",
        "    # ----------- sharpen -------------#\n",
        "    # 取出最大概率值\n",
        "    # largest_probs [Batchsize] 举例：[0.879, 0.987, 0.234, 0.768, 0.333]\n",
        "    largest_probs, _ = no_grad_probs.max(dim = -1)\n",
        "    # config['uda_confidence_threshold']为0.7  是否大于0.7\n",
        "    unsup_loss_mask = largest_probs.gt(config['uda_confidence_threshold']).float()\n",
        "    # unsup_loss_mask tensor([True, True, False, True, False])\n",
        "\n",
        "    \n",
        "  return unsup_loss_mask, no_grad_probs"
      ],
      "metadata": {
        "id": "mUtSZVeoNcmU"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**与上面的图相差mask**\n",
        "![在这里插入图片描述](https://img-blog.csdnimg.cn/b21349f49ba446b698e6f27823983fc5.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTI4NzA2MA==,size_16,color_FFFFFF,t_70)"
      ],
      "metadata": {
        "id": "Bqjtw3bFSOXk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**在forward_with_grad中reduction='none':**\\\n",
        "CE：交叉熵\n",
        "\n",
        "![ce](https://img-blog.csdnimg.cn/52f18386dbea423f846611c558aa24c7.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTI4NzA2MA==,size_16,color_FFFFFF,t_70)\n",
        "\n",
        "**CE交叉熵  E熵  KLD KL散度**\n",
        "\n",
        "$$CE = -plogq$$   \n",
        "$$E = -plogp$$\n",
        "p-真实分布（已知） q-预测分布\n",
        "$$KLDiv(p||q) = \\sum_{i=1}^{N}p(x_{i})(logp(x_{i})- logq(x_{i}))$$\n",
        "$$ = p(logp-logq) $$\n",
        "$$ = -plogq - (- plogp)$$\n",
        "$$ = CE-E$$\n",
        "\n",
        "**KL散度就是拿交叉熵减去熵，熵又是确定的**\n",
        "\n",
        "\n",
        "*torch接口中，class是类别的索引，是整数\\\n",
        "在无监督中,标签是ab_logits是非整数 因此用KL散度*"
      ],
      "metadata": {
        "id": "_vdI408bSTwD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![cross entropy](https://img-blog.csdnimg.cn/4572c78d76624c49b01b96a1cba42279.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTI4NzA2MA==,size_16,color_FFFFFF,t_70)\n",
        "![KL](https://img-blog.csdnimg.cn/189e4bc953904c199afbc7e6a11e5d9a.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTI4NzA2MA==,size_16,color_FFFFFF,t_70)"
      ],
      "metadata": {
        "id": "MBNNFWuwSl1G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_with_grad(unsup_loss_mask, unsup_probs, config, cur_bs, model, grad_data, total_steps, global_steps):\n",
        "  # 得到\\eta值， 随着训练的进行，阈值逐渐变大，最后是1，把所有监督数据都用上了\n",
        "  tsa_threshold = get_tsa_threshold(total_steps, global_steps)\n",
        "  # 逻辑值包括有监督的和无监督的\n",
        "  logits = model(**grad_data)[0]\n",
        "  # --------- 有监督损失 -------#\n",
        "  # cur_bs 无监督 ba 的 batch_size\n",
        "  # 前面一部分是有监督 train 的 sup_data, 后面是unsup_data\n",
        "  sup_logits, unsup_logits = logits.split([logits.size(0) - cur_bs, cur_bs])\n",
        "  # 得到 sup_labels\n",
        "  sup_labels = grad_data['labels'][:logits.size(0) - cur_bs]\n",
        "  # 计算交叉熵损失 （每个样本）\n",
        "  per_example_loss = nn.CrossEntropyLoss(reduction = 'none')(sup_logits, sup_labels)\n",
        "  # 拿出 正确标签 对应的概率\n",
        "  correct_label_probs = torch.softmax(sup_logits, dim = -1).gather(dim = -1, index = sup_labels.view(-1, 1))\n",
        "  # 监督数据 过于自信不要，留下小于等于 tsa_threshold 的计算损失\n",
        "  sup_loss_mask = correct_label_probs.le(tsa_threshold).squeeze().float()\n",
        "  # 应用mask掩盖有监督数据过度自信的样本损失\n",
        "  per_example_loss *= sup_loss_mask\n",
        "\n",
        "  # 有效监督样本的平均损失\n",
        "  # (参考forward_no_grad)\n",
        "  sup_loss = per_example_loss.sum() / max(sup_loss_mask.sum(), 1) # max(sup_loss_mask.sum(), 1) 有效个数\n",
        "  # --------- 有监督损失 -------#\n",
        "\n",
        "  # --------- 无监督损失 -------#\n",
        "  # log_softmax：为了能输入到KL散度中\n",
        "  unsup_log_probs = torch.log_softmax(unsup_logits, dim = -1)\n",
        "  # input 希望是一个对数概率\n",
        "  # Target 目标为概率值\n",
        "  # ab_logits:unsup_probs\n",
        "  per_example_kl_loss = nn.KLDivLoss(reduction = 'none')(unsup_log_probs, unsup_probs).sum(dim = -1)\n",
        "  # 应用mask掩盖无监督数据中不自信的样本损失\n",
        "  per_example_kl_loss *= unsup_loss_mask\n",
        "  # 计算无监督样本的平均损失\n",
        "  unsup_loss = per_example_kl_loss.sum() / max(unsup_loss_mask.sum(), 1)\n",
        "  # --------- 无监督损失 -------#\n",
        "\n",
        "  # 加权两种损失\n",
        "  loss = sup_loss + unsup_loss\n",
        "  # 多卡取平均\n",
        "  if config['n_gpus'] > 1:\n",
        "    loss = loss.mean()\n",
        "    sup_loss = sup_loss.mean()\n",
        "    unsup_loss = unsup_loss.mean()\n",
        "\n",
        "  return loss, tsa_threshold, unsup_loss, sup_loss"
      ],
      "metadata": {
        "id": "Ben5nJlQNcn5"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AdamW\n",
        "from tqdm import trange\n",
        "import os\n",
        "def train(config, train_dataloader, dev_dataloader, unsup_dataloader=None):\n",
        "  model = BertForAFQMC.from_pretrained(config['model_path'])\n",
        "\n",
        "  optimizer = AdamW(model.parameters(), lr = config['learning_rate'], weight_decay = config['weight_decay'])\n",
        "\n",
        "  model.to(config['device'])\n",
        "  # unsup_dataloader包含 train, dev, test    \n",
        "  # 使用 unsup_dataloader，因为unsup_dataloader比较大\n",
        "  total_steps = len(unsup_dataloader) * config['num_epochs']\n",
        "  epoch_iterator = trange(config['num_epochs'])\n",
        "  global_steps = 0\n",
        "  train_loss = 0.\n",
        "  logging_loss = 0.\n",
        "  best_acc = 0.\n",
        "  UDA_model_path = ''\n",
        "\n",
        "  if config['n_gpus'] > 1:\n",
        "    model =nn.DataParallel(model)\n",
        "\n",
        "  train_iterator = iter(train_dataloader)\n",
        "  for i in epoch_iterator:\n",
        "    unsup_iterator = tqdm(unsup_dataloader, desc = 'Training', total = len(unsup_dataloader))\n",
        "    model.train()\n",
        "    # ----------------------- new ----------------------#\n",
        "    # 遍历无监督的batch\n",
        "    for unsup_batch in unsup_iterator:\n",
        "      cur_bs = unsup_batch['ab_input_ids'].size(0)\n",
        "      try:\n",
        "        # 不断拿监督数据的batch\n",
        "        sup_batch = next(train_iterator)\n",
        "\n",
        "      except StopIteration:\n",
        "        # 监督数据用完了 再重新拿\n",
        "        train_iterator = iter(train_dataloader)\n",
        "        sup_batch = next(train_iterator)\n",
        "      # 返回 grad_data：需要计算梯度，需要进行反向传播的数据\n",
        "      # 返回 no_grad_data: 不需要计算梯度，不需要进行反向传播的数据\n",
        "      grad_data, no_grad_data = get_data(sup_batch, unsup_batch, config)\n",
        "      # 无监督数据 (ab) 只需要正向传播\n",
        "      # mask, ab_logits\n",
        "      unsup_loss_mask, unsup_probs =forward_no_grad(no_grad_data, config, model)\n",
        "      # 得出loss\n",
        "      loss, tsa_threshold, unsup_loss, sup_loss = forward_with_grad(unsup_loss_mask, unsup_probs, config, cur_bs, model, grad_data,\n",
        "                                        total_steps, global_steps)\n",
        "      model.zero_grad()\n",
        "      loss.backward()\n",
        "\n",
        "      nn.utils.clip_grad_norm_(model.parameters(), max_norm = 1.0)\n",
        "      optimizer.step()\n",
        "\n",
        "      if config['ema_start']:\n",
        "        ema.update()\n",
        "\n",
        "      train_loss += loss.item()\n",
        "      global_steps += 1\n",
        "\n",
        "      unsup_iterator.set_postfix_str(f'running training loss: {loss.item(): .5f}')\n",
        "\n",
        "      if global_steps % config['logging_step'] == 0:\n",
        "        if global_steps >= config['ema_start_step'] and not config['ema_start']:\n",
        "          print('\\n>>> EMA starting .....')\n",
        "          config['ema_start'] = True\n",
        "\n",
        "          ema = EMA(model.module if hasattr(model, 'module') else model, decay = 0.99)\n",
        "\n",
        "        print_train_loss = (train_loss - logging_loss) / config['logging_step']\n",
        "        logging_loss = train_loss\n",
        "\n",
        "        if config['ema_start']:\n",
        "          ema.apply_shadow()\n",
        "        val_loss, f1, acc = evaluation(config, model, dev_dataloader)\n",
        "\n",
        "        print_log = f'\\n>>> training loss: {print_train_loss:.6f}, valid loss: {val_loss:.6f},' \n",
        "\n",
        "        if acc > best_acc:\n",
        "          model_save_path = os.path.join(config['output_path'],\n",
        "                          f'checkpoint- {global_steps} - {acc:.6f}')\n",
        "          model_to_save = model.module if hasattr(model, 'module') else model\n",
        "          model_to_save.save_pretrained(model_save_path)\n",
        "          best_acc = acc\n",
        "          UDA_model_path = model_save_path\n",
        "        print_log += f'valid f1: {f1:.6f}, valid acc:{acc:.6f}'\n",
        "\n",
        "        print(print_log)\n",
        "        model.train()\n",
        "\n",
        "        if config['ema_start']:\n",
        "          ema.restore()\n",
        "\n",
        "\n",
        "  return model, UDA_model_path"
      ],
      "metadata": {
        "id": "6YDUNt2Kax9b"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model, UDA_model_path = train(config, train_dataloader, dev_dataloader, unsup_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lD_3C78JgyG4",
        "outputId": "3ca29bd4-5b5c-4f3d-e07f-8688f199eb7c"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at /content/drive/MyDrive/Colab Notebooks/dataset/BERT_model were not used when initializing BertForAFQMC: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForAFQMC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForAFQMC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForAFQMC were not initialized from the model checkpoint at /content/drive/MyDrive/Colab Notebooks/dataset/BERT_model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "Training:   0%|          | 0/1772 [00:00<?, ?it/s]\u001b[A\n",
            "Training:   0%|          | 0/1772 [00:01<?, ?it/s, running training loss:  1.06728]\u001b[A\n",
            "Training:   0%|          | 1/1772 [00:01<31:39,  1.07s/it, running training loss:  1.06728]\u001b[A\n",
            "Training:   0%|          | 1/1772 [00:01<31:39,  1.07s/it, running training loss:  0.89542]\u001b[A\n",
            "Training:   0%|          | 2/1772 [00:01<23:27,  1.26it/s, running training loss:  0.89542]\u001b[A\n",
            "Training:   0%|          | 2/1772 [00:02<23:27,  1.26it/s, running training loss:  0.93099]\u001b[A\n",
            "Training:   0%|          | 3/1772 [00:02<26:13,  1.12it/s, running training loss:  0.93099]\u001b[A\n",
            "Training:   0%|          | 3/1772 [00:03<26:13,  1.12it/s, running training loss:  1.04613]\u001b[A\n",
            "Training:   0%|          | 4/1772 [00:03<21:29,  1.37it/s, running training loss:  1.04613]\u001b[A\n",
            "Training:   0%|          | 4/1772 [00:03<21:29,  1.37it/s, running training loss:  0.94980]\u001b[A\n",
            "Training:   0%|          | 5/1772 [00:03<19:57,  1.48it/s, running training loss:  0.94980]\u001b[A\n",
            "Training:   0%|          | 5/1772 [00:04<19:57,  1.48it/s, running training loss:  1.05198]\u001b[A\n",
            "Training:   0%|          | 6/1772 [00:04<18:34,  1.58it/s, running training loss:  1.05198]\u001b[A\n",
            "Training:   0%|          | 6/1772 [00:04<18:34,  1.58it/s, running training loss:  1.10235]\u001b[A\n",
            "Training:   0%|          | 7/1772 [00:04<17:54,  1.64it/s, running training loss:  1.10235]\u001b[A\n",
            "Training:   0%|          | 7/1772 [00:05<17:54,  1.64it/s, running training loss:  0.81210]\u001b[A\n",
            "Training:   0%|          | 8/1772 [00:05<18:29,  1.59it/s, running training loss:  0.81210]\u001b[A\n",
            "Training:   0%|          | 8/1772 [00:05<18:29,  1.59it/s, running training loss:  0.80491]\u001b[A\n",
            "Training:   1%|          | 9/1772 [00:05<16:38,  1.77it/s, running training loss:  0.80491]\u001b[A\n",
            "Training:   1%|          | 9/1772 [00:06<16:38,  1.77it/s, running training loss:  0.88309]\u001b[A\n",
            "Training:   1%|          | 10/1772 [00:06<15:51,  1.85it/s, running training loss:  0.88309]\u001b[A\n",
            "Training:   1%|          | 10/1772 [00:06<15:51,  1.85it/s, running training loss:  0.99740]\u001b[A\n",
            "Training:   1%|          | 11/1772 [00:06<15:06,  1.94it/s, running training loss:  0.99740]\u001b[A\n",
            "Training:   1%|          | 11/1772 [00:07<15:06,  1.94it/s, running training loss:  0.92195]\u001b[A\n",
            "Training:   1%|          | 12/1772 [00:07<17:45,  1.65it/s, running training loss:  0.92195]\u001b[A\n",
            "Training:   1%|          | 12/1772 [00:08<17:45,  1.65it/s, running training loss:  1.11452]\u001b[A\n",
            "Training:   1%|          | 13/1772 [00:08<18:27,  1.59it/s, running training loss:  1.11452]\u001b[A\n",
            "Training:   1%|          | 13/1772 [00:08<18:27,  1.59it/s, running training loss:  1.09809]\u001b[A\n",
            "Training:   1%|          | 14/1772 [00:08<17:05,  1.71it/s, running training loss:  1.09809]\u001b[A\n",
            "Training:   1%|          | 14/1772 [00:09<17:05,  1.71it/s, running training loss:  1.04925]\u001b[A\n",
            "Training:   1%|          | 15/1772 [00:09<17:38,  1.66it/s, running training loss:  1.04925]\u001b[A\n",
            "Training:   1%|          | 15/1772 [00:09<17:38,  1.66it/s, running training loss:  1.03775]\u001b[A\n",
            "Training:   1%|          | 16/1772 [00:09<16:13,  1.80it/s, running training loss:  1.03775]\u001b[A\n",
            "Training:   1%|          | 16/1772 [00:10<16:13,  1.80it/s, running training loss:  1.07446]\u001b[A\n",
            "Training:   1%|          | 17/1772 [00:10<17:06,  1.71it/s, running training loss:  1.07446]\u001b[A\n",
            "Training:   1%|          | 17/1772 [00:11<17:06,  1.71it/s, running training loss:  1.10667]\u001b[A\n",
            "Training:   1%|          | 18/1772 [00:11<15:53,  1.84it/s, running training loss:  1.10667]\u001b[A\n",
            "Training:   1%|          | 18/1772 [00:11<15:53,  1.84it/s, running training loss:  0.78313]\u001b[A\n",
            "Training:   1%|          | 19/1772 [00:11<15:22,  1.90it/s, running training loss:  0.78313]\u001b[A\n",
            "Training:   1%|          | 19/1772 [00:12<15:22,  1.90it/s, running training loss:  1.09192]\u001b[A\n",
            "Training:   1%|          | 20/1772 [00:12<16:00,  1.82it/s, running training loss:  1.09192]\u001b[A\n",
            "Training:   1%|          | 20/1772 [00:12<16:00,  1.82it/s, running training loss:  0.75619]\u001b[A\n",
            "Training:   1%|          | 21/1772 [00:12<15:39,  1.86it/s, running training loss:  0.75619]\u001b[A\n",
            "Training:   1%|          | 21/1772 [00:13<15:39,  1.86it/s, running training loss:  1.13406]\u001b[A\n",
            "Training:   1%|          | 22/1772 [00:13<15:28,  1.88it/s, running training loss:  1.13406]\u001b[A\n",
            "Training:   1%|          | 22/1772 [00:13<15:28,  1.88it/s, running training loss:  0.79043]\u001b[A\n",
            "Training:   1%|▏         | 23/1772 [00:13<15:18,  1.90it/s, running training loss:  0.79043]\u001b[A\n",
            "Training:   1%|▏         | 23/1772 [00:14<15:18,  1.90it/s, running training loss:  1.25017]\u001b[A\n",
            "Training:   1%|▏         | 24/1772 [00:14<14:24,  2.02it/s, running training loss:  1.25017]\u001b[A\n",
            "Training:   1%|▏         | 24/1772 [00:14<14:24,  2.02it/s, running training loss:  1.05255]\u001b[A\n",
            "Training:   1%|▏         | 25/1772 [00:14<15:04,  1.93it/s, running training loss:  1.05255]\u001b[A\n",
            "Training:   1%|▏         | 25/1772 [00:15<15:04,  1.93it/s, running training loss:  0.86958]\u001b[A\n",
            "Training:   1%|▏         | 26/1772 [00:15<14:26,  2.02it/s, running training loss:  0.86958]\u001b[A\n",
            "Training:   1%|▏         | 26/1772 [00:15<14:26,  2.02it/s, running training loss:  0.77385]\u001b[A\n",
            "Training:   2%|▏         | 27/1772 [00:15<14:45,  1.97it/s, running training loss:  0.77385]\u001b[A\n",
            "Training:   2%|▏         | 27/1772 [00:16<14:45,  1.97it/s, running training loss:  1.02411]\u001b[A\n",
            "Training:   2%|▏         | 28/1772 [00:16<14:34,  1.99it/s, running training loss:  1.02411]\u001b[A\n",
            "Training:   2%|▏         | 28/1772 [00:16<14:34,  1.99it/s, running training loss:  1.01714]\u001b[A\n",
            "Training:   2%|▏         | 29/1772 [00:16<17:29,  1.66it/s, running training loss:  1.01714]\u001b[A\n",
            "Training:   2%|▏         | 29/1772 [00:17<17:29,  1.66it/s, running training loss:  1.07584]\u001b[A\n",
            "Training:   2%|▏         | 30/1772 [00:17<20:30,  1.42it/s, running training loss:  1.07584]\u001b[A\n",
            "Training:   2%|▏         | 30/1772 [00:18<20:30,  1.42it/s, running training loss:  0.91688]\u001b[A\n",
            "Training:   2%|▏         | 31/1772 [00:18<19:56,  1.45it/s, running training loss:  0.91688]\u001b[A\n",
            "Training:   2%|▏         | 31/1772 [00:19<19:56,  1.45it/s, running training loss:  1.01991]\u001b[A\n",
            "Training:   2%|▏         | 32/1772 [00:19<19:53,  1.46it/s, running training loss:  1.01991]\u001b[A\n",
            "Training:   2%|▏         | 32/1772 [00:19<19:53,  1.46it/s, running training loss:  1.05838]\u001b[A\n",
            "Training:   2%|▏         | 33/1772 [00:20<20:24,  1.42it/s, running training loss:  1.05838]\u001b[A\n",
            "Training:   2%|▏         | 33/1772 [00:20<20:24,  1.42it/s, running training loss:  1.20515]\u001b[A\n",
            "Training:   2%|▏         | 34/1772 [00:20<18:41,  1.55it/s, running training loss:  1.20515]\u001b[A\n",
            "Training:   2%|▏         | 34/1772 [00:21<18:41,  1.55it/s, running training loss:  1.13043]\u001b[A\n",
            "Training:   2%|▏         | 35/1772 [00:21<18:24,  1.57it/s, running training loss:  1.13043]\u001b[A\n",
            "Training:   2%|▏         | 35/1772 [00:21<18:24,  1.57it/s, running training loss:  1.15624]\u001b[A\n",
            "Training:   2%|▏         | 36/1772 [00:21<18:54,  1.53it/s, running training loss:  1.15624]\u001b[A\n",
            "Training:   2%|▏         | 36/1772 [00:22<18:54,  1.53it/s, running training loss:  1.00762]\u001b[A\n",
            "Training:   2%|▏         | 37/1772 [00:22<18:08,  1.59it/s, running training loss:  1.00762]\u001b[A\n",
            "Training:   2%|▏         | 37/1772 [00:22<18:08,  1.59it/s, running training loss:  0.93838]\u001b[A\n",
            "Training:   2%|▏         | 38/1772 [00:22<17:49,  1.62it/s, running training loss:  0.93838]\u001b[A\n",
            "Training:   2%|▏         | 38/1772 [00:23<17:49,  1.62it/s, running training loss:  1.12927]\u001b[A\n",
            "Training:   2%|▏         | 39/1772 [00:23<20:52,  1.38it/s, running training loss:  1.12927]\u001b[A\n",
            "Training:   2%|▏         | 39/1772 [00:24<20:52,  1.38it/s, running training loss:  1.08844]\u001b[A\n",
            "Training:   2%|▏         | 40/1772 [00:24<19:55,  1.45it/s, running training loss:  1.08844]\u001b[A\n",
            "Training:   2%|▏         | 40/1772 [00:25<19:55,  1.45it/s, running training loss:  0.83465]\u001b[A\n",
            "Training:   2%|▏         | 41/1772 [00:25<17:52,  1.61it/s, running training loss:  0.83465]\u001b[A\n",
            "Training:   2%|▏         | 41/1772 [00:25<17:52,  1.61it/s, running training loss:  1.04053]\u001b[A\n",
            "Training:   2%|▏         | 42/1772 [00:25<17:01,  1.69it/s, running training loss:  1.04053]\u001b[A\n",
            "Training:   2%|▏         | 42/1772 [00:26<17:01,  1.69it/s, running training loss:  0.98636]\u001b[A\n",
            "Training:   2%|▏         | 43/1772 [00:26<16:05,  1.79it/s, running training loss:  0.98636]\u001b[A\n",
            "Training:   2%|▏         | 43/1772 [00:26<16:05,  1.79it/s, running training loss:  1.03422]\u001b[A\n",
            "Training:   2%|▏         | 44/1772 [00:26<18:38,  1.55it/s, running training loss:  1.03422]\u001b[A\n",
            "Training:   2%|▏         | 44/1772 [00:27<18:38,  1.55it/s, running training loss:  1.04266]\u001b[A\n",
            "Training:   3%|▎         | 45/1772 [00:27<17:24,  1.65it/s, running training loss:  1.04266]\u001b[A\n",
            "Training:   3%|▎         | 45/1772 [00:27<17:24,  1.65it/s, running training loss:  1.10075]\u001b[A\n",
            "Training:   3%|▎         | 46/1772 [00:27<16:41,  1.72it/s, running training loss:  1.10075]\u001b[A\n",
            "Training:   3%|▎         | 46/1772 [00:28<16:41,  1.72it/s, running training loss:  1.23155]\u001b[A\n",
            "Training:   3%|▎         | 47/1772 [00:28<17:25,  1.65it/s, running training loss:  1.23155]\u001b[A\n",
            "Training:   3%|▎         | 47/1772 [00:29<17:25,  1.65it/s, running training loss:  1.08219]\u001b[A\n",
            "Training:   3%|▎         | 48/1772 [00:29<16:51,  1.70it/s, running training loss:  1.08219]\u001b[A\n",
            "Training:   3%|▎         | 48/1772 [00:29<16:51,  1.70it/s, running training loss:  1.02256]\u001b[A\n",
            "Training:   3%|▎         | 49/1772 [00:29<16:42,  1.72it/s, running training loss:  1.02256]\u001b[A\n",
            "Training:   3%|▎         | 49/1772 [00:30<16:42,  1.72it/s, running training loss:  0.98743]\u001b[A\n",
            "Training:   3%|▎         | 50/1772 [00:30<16:59,  1.69it/s, running training loss:  0.98743]\u001b[A\n",
            "Training:   3%|▎         | 50/1772 [00:30<16:59,  1.69it/s, running training loss:  1.02863]\u001b[A\n",
            "Training:   3%|▎         | 51/1772 [00:30<16:30,  1.74it/s, running training loss:  1.02863]\u001b[A\n",
            "Training:   3%|▎         | 51/1772 [00:31<16:30,  1.74it/s, running training loss:  0.99271]\u001b[A\n",
            "Training:   3%|▎         | 52/1772 [00:31<15:52,  1.81it/s, running training loss:  0.99271]\u001b[A\n",
            "Training:   3%|▎         | 52/1772 [00:31<15:52,  1.81it/s, running training loss:  1.01569]\u001b[A\n",
            "Training:   3%|▎         | 53/1772 [00:31<16:15,  1.76it/s, running training loss:  1.01569]\u001b[A\n",
            "Training:   3%|▎         | 53/1772 [00:32<16:15,  1.76it/s, running training loss:  1.14751]\u001b[A\n",
            "Training:   3%|▎         | 54/1772 [00:32<16:04,  1.78it/s, running training loss:  1.14751]\u001b[A\n",
            "Training:   3%|▎         | 54/1772 [00:33<16:04,  1.78it/s, running training loss:  1.03736]\u001b[A\n",
            "Training:   3%|▎         | 55/1772 [00:33<16:37,  1.72it/s, running training loss:  1.03736]\u001b[A\n",
            "Training:   3%|▎         | 55/1772 [00:33<16:37,  1.72it/s, running training loss:  1.28749]\u001b[A\n",
            "Training:   3%|▎         | 56/1772 [00:33<16:19,  1.75it/s, running training loss:  1.28749]\u001b[A\n",
            "Training:   3%|▎         | 56/1772 [00:34<16:19,  1.75it/s, running training loss:  1.03058]\u001b[A\n",
            "Training:   3%|▎         | 57/1772 [00:34<16:56,  1.69it/s, running training loss:  1.03058]\u001b[A\n",
            "Training:   3%|▎         | 57/1772 [00:34<16:56,  1.69it/s, running training loss:  0.95355]\u001b[A\n",
            "Training:   3%|▎         | 58/1772 [00:34<16:01,  1.78it/s, running training loss:  0.95355]\u001b[A\n",
            "Training:   3%|▎         | 58/1772 [00:35<16:01,  1.78it/s, running training loss:  1.18423]\u001b[A\n",
            "Training:   3%|▎         | 59/1772 [00:35<14:58,  1.91it/s, running training loss:  1.18423]\u001b[A\n",
            "Training:   3%|▎         | 59/1772 [00:36<14:58,  1.91it/s, running training loss:  0.92390]\u001b[A\n",
            "Training:   3%|▎         | 60/1772 [00:36<18:56,  1.51it/s, running training loss:  0.92390]\u001b[A\n",
            "Training:   3%|▎         | 60/1772 [00:37<18:56,  1.51it/s, running training loss:  1.10509]\u001b[A\n",
            "Training:   3%|▎         | 61/1772 [00:37<20:57,  1.36it/s, running training loss:  1.10509]\u001b[A\n",
            "Training:   3%|▎         | 61/1772 [00:37<20:57,  1.36it/s, running training loss:  0.94441]\u001b[A\n",
            "Training:   3%|▎         | 62/1772 [00:37<19:44,  1.44it/s, running training loss:  0.94441]\u001b[A\n",
            "Training:   3%|▎         | 62/1772 [00:38<19:44,  1.44it/s, running training loss:  1.07581]\u001b[A\n",
            "Training:   4%|▎         | 63/1772 [00:38<19:00,  1.50it/s, running training loss:  1.07581]\u001b[A\n",
            "Training:   4%|▎         | 63/1772 [00:39<19:00,  1.50it/s, running training loss:  0.97651]\u001b[A\n",
            "Training:   4%|▎         | 64/1772 [00:39<19:55,  1.43it/s, running training loss:  0.97651]\u001b[A\n",
            "Training:   4%|▎         | 64/1772 [00:39<19:55,  1.43it/s, running training loss:  1.08028]\u001b[A\n",
            "Training:   4%|▎         | 65/1772 [00:39<19:28,  1.46it/s, running training loss:  1.08028]\u001b[A\n",
            "Training:   4%|▎         | 65/1772 [00:40<19:28,  1.46it/s, running training loss:  1.01747]\u001b[A\n",
            "Training:   4%|▎         | 66/1772 [00:40<20:20,  1.40it/s, running training loss:  1.01747]\u001b[A\n",
            "Training:   4%|▎         | 66/1772 [00:41<20:20,  1.40it/s, running training loss:  0.93400]\u001b[A\n",
            "Training:   4%|▍         | 67/1772 [00:41<18:40,  1.52it/s, running training loss:  0.93400]\u001b[A\n",
            "Training:   4%|▍         | 67/1772 [00:41<18:40,  1.52it/s, running training loss:  0.76785]\u001b[A\n",
            "Training:   4%|▍         | 68/1772 [00:41<17:31,  1.62it/s, running training loss:  0.76785]\u001b[A\n",
            "Training:   4%|▍         | 68/1772 [00:42<17:31,  1.62it/s, running training loss:  1.06895]\u001b[A\n",
            "Training:   4%|▍         | 69/1772 [00:42<16:49,  1.69it/s, running training loss:  1.06895]\u001b[A\n",
            "Training:   4%|▍         | 69/1772 [00:42<16:49,  1.69it/s, running training loss:  1.12840]\u001b[A\n",
            "Training:   4%|▍         | 70/1772 [00:42<16:27,  1.72it/s, running training loss:  1.12840]\u001b[A\n",
            "Training:   4%|▍         | 70/1772 [00:43<16:27,  1.72it/s, running training loss:  1.06433]\u001b[A\n",
            "Training:   4%|▍         | 71/1772 [00:43<17:55,  1.58it/s, running training loss:  1.06433]\u001b[A\n",
            "Training:   4%|▍         | 71/1772 [00:43<17:55,  1.58it/s, running training loss:  0.94087]\u001b[A\n",
            "Training:   4%|▍         | 72/1772 [00:43<17:10,  1.65it/s, running training loss:  0.94087]\u001b[A\n",
            "Training:   4%|▍         | 72/1772 [00:44<17:10,  1.65it/s, running training loss:  1.06375]\u001b[A\n",
            "Training:   4%|▍         | 73/1772 [00:44<20:22,  1.39it/s, running training loss:  1.06375]\u001b[A\n",
            "Training:   4%|▍         | 73/1772 [00:45<20:22,  1.39it/s, running training loss:  0.95964]\u001b[A\n",
            "Training:   4%|▍         | 74/1772 [00:45<19:14,  1.47it/s, running training loss:  0.95964]\u001b[A\n",
            "Training:   4%|▍         | 74/1772 [00:46<19:14,  1.47it/s, running training loss:  1.17789]\u001b[A\n",
            "Training:   4%|▍         | 75/1772 [00:46<18:45,  1.51it/s, running training loss:  1.17789]\u001b[A\n",
            "Training:   4%|▍         | 75/1772 [00:46<18:45,  1.51it/s, running training loss:  0.94101]\u001b[A\n",
            "Training:   4%|▍         | 76/1772 [00:46<17:18,  1.63it/s, running training loss:  0.94101]\u001b[A\n",
            "Training:   4%|▍         | 76/1772 [00:47<17:18,  1.63it/s, running training loss:  1.22837]\u001b[A\n",
            "Training:   4%|▍         | 77/1772 [00:47<17:23,  1.62it/s, running training loss:  1.22837]\u001b[A\n",
            "Training:   4%|▍         | 77/1772 [00:47<17:23,  1.62it/s, running training loss:  1.13424]\u001b[A\n",
            "Training:   4%|▍         | 78/1772 [00:47<15:58,  1.77it/s, running training loss:  1.13424]\u001b[A\n",
            "Training:   4%|▍         | 78/1772 [00:48<15:58,  1.77it/s, running training loss:  1.07168]\u001b[A\n",
            "Training:   4%|▍         | 79/1772 [00:48<14:55,  1.89it/s, running training loss:  1.07168]\u001b[A\n",
            "Training:   4%|▍         | 79/1772 [00:48<14:55,  1.89it/s, running training loss:  0.98160]\u001b[A\n",
            "Training:   5%|▍         | 80/1772 [00:48<14:49,  1.90it/s, running training loss:  0.98160]\u001b[A\n",
            "Training:   5%|▍         | 80/1772 [00:49<14:49,  1.90it/s, running training loss:  0.92501]\u001b[A\n",
            "Training:   5%|▍         | 81/1772 [00:49<14:14,  1.98it/s, running training loss:  0.92501]\u001b[A\n",
            "Training:   5%|▍         | 81/1772 [00:49<14:14,  1.98it/s, running training loss:  0.99224]\u001b[A\n",
            "Training:   5%|▍         | 82/1772 [00:49<15:13,  1.85it/s, running training loss:  0.99224]\u001b[A\n",
            "Training:   5%|▍         | 82/1772 [00:50<15:13,  1.85it/s, running training loss:  1.16116]\u001b[A\n",
            "Training:   5%|▍         | 83/1772 [00:50<15:36,  1.80it/s, running training loss:  1.16116]\u001b[A\n",
            "Training:   5%|▍         | 83/1772 [00:51<15:36,  1.80it/s, running training loss:  1.03884]\u001b[A\n",
            "Training:   5%|▍         | 84/1772 [00:51<18:32,  1.52it/s, running training loss:  1.03884]\u001b[A\n",
            "Training:   5%|▍         | 84/1772 [00:51<18:32,  1.52it/s, running training loss:  1.24020]\u001b[A\n",
            "Training:   5%|▍         | 85/1772 [00:51<17:37,  1.60it/s, running training loss:  1.24020]\u001b[A\n",
            "Training:   5%|▍         | 85/1772 [00:52<17:37,  1.60it/s, running training loss:  1.02361]\u001b[A\n",
            "Training:   5%|▍         | 86/1772 [00:52<17:41,  1.59it/s, running training loss:  1.02361]\u001b[A\n",
            "Training:   5%|▍         | 86/1772 [00:53<17:41,  1.59it/s, running training loss:  1.18803]\u001b[A\n",
            "Training:   5%|▍         | 87/1772 [00:53<17:31,  1.60it/s, running training loss:  1.18803]\u001b[A\n",
            "Training:   5%|▍         | 87/1772 [00:53<17:31,  1.60it/s, running training loss:  1.00908]\u001b[A\n",
            "Training:   5%|▍         | 88/1772 [00:53<16:30,  1.70it/s, running training loss:  1.00908]\u001b[A\n",
            "Training:   5%|▍         | 88/1772 [00:54<16:30,  1.70it/s, running training loss:  1.07064]\u001b[A\n",
            "Training:   5%|▌         | 89/1772 [00:54<17:14,  1.63it/s, running training loss:  1.07064]\u001b[A\n",
            "Training:   5%|▌         | 89/1772 [00:54<17:14,  1.63it/s, running training loss:  1.00680]\u001b[A\n",
            "Training:   5%|▌         | 90/1772 [00:54<17:29,  1.60it/s, running training loss:  1.00680]\u001b[A\n",
            "Training:   5%|▌         | 90/1772 [00:55<17:29,  1.60it/s, running training loss:  1.07717]\u001b[A\n",
            "Training:   5%|▌         | 91/1772 [00:55<17:26,  1.61it/s, running training loss:  1.07717]\u001b[A\n",
            "Training:   5%|▌         | 91/1772 [00:56<17:26,  1.61it/s, running training loss:  0.93598]\u001b[A\n",
            "Training:   5%|▌         | 92/1772 [00:56<18:04,  1.55it/s, running training loss:  0.93598]\u001b[A\n",
            "Training:   5%|▌         | 92/1772 [00:56<18:04,  1.55it/s, running training loss:  1.10453]\u001b[A\n",
            "Training:   5%|▌         | 93/1772 [00:56<17:10,  1.63it/s, running training loss:  1.10453]\u001b[A\n",
            "Training:   5%|▌         | 93/1772 [00:57<17:10,  1.63it/s, running training loss:  1.00238]\u001b[A\n",
            "Training:   5%|▌         | 94/1772 [00:57<17:21,  1.61it/s, running training loss:  1.00238]\u001b[A\n",
            "Training:   5%|▌         | 94/1772 [00:57<17:21,  1.61it/s, running training loss:  1.10677]\u001b[A\n",
            "Training:   5%|▌         | 95/1772 [00:57<16:08,  1.73it/s, running training loss:  1.10677]\u001b[A\n",
            "Training:   5%|▌         | 95/1772 [00:58<16:08,  1.73it/s, running training loss:  0.94568]\u001b[A\n",
            "Training:   5%|▌         | 96/1772 [00:58<17:48,  1.57it/s, running training loss:  0.94568]\u001b[A\n",
            "Training:   5%|▌         | 96/1772 [00:59<17:48,  1.57it/s, running training loss:  1.03527]\u001b[A\n",
            "Training:   5%|▌         | 97/1772 [00:59<16:31,  1.69it/s, running training loss:  1.03527]\u001b[A\n",
            "Training:   5%|▌         | 97/1772 [00:59<16:31,  1.69it/s, running training loss:  0.96821]\u001b[A\n",
            "Training:   6%|▌         | 98/1772 [00:59<16:05,  1.73it/s, running training loss:  0.96821]\u001b[A\n",
            "Training:   6%|▌         | 98/1772 [01:00<16:05,  1.73it/s, running training loss:  1.08483]\u001b[A\n",
            "Training:   6%|▌         | 99/1772 [01:00<15:06,  1.85it/s, running training loss:  1.08483]\u001b[A\n",
            "Training:   6%|▌         | 99/1772 [01:00<15:06,  1.85it/s, running training loss:  0.99475]\u001b[A\n",
            "Training:   6%|▌         | 100/1772 [01:00<14:46,  1.89it/s, running training loss:  0.99475]\u001b[A\n",
            "Training:   6%|▌         | 100/1772 [01:01<14:46,  1.89it/s, running training loss:  1.12244]\u001b[A\n",
            "Training:   6%|▌         | 101/1772 [01:01<16:51,  1.65it/s, running training loss:  1.12244]\u001b[A\n",
            "Training:   6%|▌         | 101/1772 [01:01<16:51,  1.65it/s, running training loss:  0.97078]\u001b[A\n",
            "Training:   6%|▌         | 102/1772 [01:01<16:29,  1.69it/s, running training loss:  0.97078]\u001b[A\n",
            "Training:   6%|▌         | 102/1772 [01:02<16:29,  1.69it/s, running training loss:  1.02878]\u001b[A\n",
            "Training:   6%|▌         | 103/1772 [01:02<16:49,  1.65it/s, running training loss:  1.02878]\u001b[A\n",
            "Training:   6%|▌         | 103/1772 [01:03<16:49,  1.65it/s, running training loss:  1.05212]\u001b[A\n",
            "Training:   6%|▌         | 104/1772 [01:03<15:52,  1.75it/s, running training loss:  1.05212]\u001b[A\n",
            "Training:   6%|▌         | 104/1772 [01:03<15:52,  1.75it/s, running training loss:  1.02387]\u001b[A\n",
            "Training:   6%|▌         | 105/1772 [01:03<16:39,  1.67it/s, running training loss:  1.02387]\u001b[A\n",
            "Training:   6%|▌         | 105/1772 [01:04<16:39,  1.67it/s, running training loss:  0.92735]\u001b[A\n",
            "Training:   6%|▌         | 106/1772 [01:04<16:09,  1.72it/s, running training loss:  0.92735]\u001b[A\n",
            "Training:   6%|▌         | 106/1772 [01:04<16:09,  1.72it/s, running training loss:  0.95899]\u001b[A\n",
            "Training:   6%|▌         | 107/1772 [01:04<16:41,  1.66it/s, running training loss:  0.95899]\u001b[A\n",
            "Training:   6%|▌         | 107/1772 [01:05<16:41,  1.66it/s, running training loss:  1.05348]\u001b[A\n",
            "Training:   6%|▌         | 108/1772 [01:05<15:46,  1.76it/s, running training loss:  1.05348]\u001b[A\n",
            "Training:   6%|▌         | 108/1772 [01:06<15:46,  1.76it/s, running training loss:  0.87623]\u001b[A\n",
            "Training:   6%|▌         | 109/1772 [01:06<16:33,  1.67it/s, running training loss:  0.87623]\u001b[A\n",
            "Training:   6%|▌         | 109/1772 [01:06<16:33,  1.67it/s, running training loss:  0.98787]\u001b[A\n",
            "Training:   6%|▌         | 110/1772 [01:06<15:20,  1.81it/s, running training loss:  0.98787]\u001b[A\n",
            "Training:   6%|▌         | 110/1772 [01:07<15:20,  1.81it/s, running training loss:  1.00846]\u001b[A\n",
            "Training:   6%|▋         | 111/1772 [01:07<15:07,  1.83it/s, running training loss:  1.00846]\u001b[A\n",
            "Training:   6%|▋         | 111/1772 [01:07<15:07,  1.83it/s, running training loss:  0.98843]\u001b[A\n",
            "Training:   6%|▋         | 112/1772 [01:07<14:46,  1.87it/s, running training loss:  0.98843]\u001b[A\n",
            "Training:   6%|▋         | 112/1772 [01:08<14:46,  1.87it/s, running training loss:  1.18726]\u001b[A\n",
            "Training:   6%|▋         | 113/1772 [01:08<14:21,  1.92it/s, running training loss:  1.18726]\u001b[A\n",
            "Training:   6%|▋         | 113/1772 [01:08<14:21,  1.92it/s, running training loss:  1.01614]\u001b[A\n",
            "Training:   6%|▋         | 114/1772 [01:08<14:34,  1.90it/s, running training loss:  1.01614]\u001b[A\n",
            "Training:   6%|▋         | 114/1772 [01:09<14:34,  1.90it/s, running training loss:  1.18458]\u001b[A\n",
            "Training:   6%|▋         | 115/1772 [01:09<15:02,  1.84it/s, running training loss:  1.18458]\u001b[A\n",
            "Training:   6%|▋         | 115/1772 [01:09<15:02,  1.84it/s, running training loss:  1.06453]\u001b[A\n",
            "Training:   7%|▋         | 116/1772 [01:09<16:20,  1.69it/s, running training loss:  1.06453]\u001b[A\n",
            "Training:   7%|▋         | 116/1772 [01:10<16:20,  1.69it/s, running training loss:  1.07864]\u001b[A\n",
            "Training:   7%|▋         | 117/1772 [01:10<15:53,  1.74it/s, running training loss:  1.07864]\u001b[A\n",
            "Training:   7%|▋         | 117/1772 [01:11<15:53,  1.74it/s, running training loss:  1.11999]\u001b[A\n",
            "Training:   7%|▋         | 118/1772 [01:11<16:30,  1.67it/s, running training loss:  1.11999]\u001b[A\n",
            "Training:   7%|▋         | 118/1772 [01:11<16:30,  1.67it/s, running training loss:  0.93546]\u001b[A\n",
            "Training:   7%|▋         | 119/1772 [01:11<15:37,  1.76it/s, running training loss:  0.93546]\u001b[A\n",
            "Training:   7%|▋         | 119/1772 [01:12<15:37,  1.76it/s, running training loss:  1.11028]\u001b[A\n",
            "Training:   7%|▋         | 120/1772 [01:12<14:58,  1.84it/s, running training loss:  1.11028]\u001b[A\n",
            "Training:   7%|▋         | 120/1772 [01:12<14:58,  1.84it/s, running training loss:  1.12002]\u001b[A\n",
            "Training:   7%|▋         | 121/1772 [01:12<14:55,  1.84it/s, running training loss:  1.12002]\u001b[A\n",
            "Training:   7%|▋         | 121/1772 [01:13<14:55,  1.84it/s, running training loss:  0.98864]\u001b[A\n",
            "Training:   7%|▋         | 122/1772 [01:13<15:27,  1.78it/s, running training loss:  0.98864]\u001b[A\n",
            "Training:   7%|▋         | 122/1772 [01:13<15:27,  1.78it/s, running training loss:  0.94156]\u001b[A\n",
            "Training:   7%|▋         | 123/1772 [01:13<14:56,  1.84it/s, running training loss:  0.94156]\u001b[A\n",
            "Training:   7%|▋         | 123/1772 [01:14<14:56,  1.84it/s, running training loss:  1.02986]\u001b[A\n",
            "Training:   7%|▋         | 124/1772 [01:14<15:21,  1.79it/s, running training loss:  1.02986]\u001b[A\n",
            "Training:   7%|▋         | 124/1772 [01:14<15:21,  1.79it/s, running training loss:  1.01666]\u001b[A\n",
            "Training:   7%|▋         | 125/1772 [01:14<14:57,  1.84it/s, running training loss:  1.01666]\u001b[A\n",
            "Training:   7%|▋         | 125/1772 [01:15<14:57,  1.84it/s, running training loss:  0.88796]\u001b[A\n",
            "Training:   7%|▋         | 126/1772 [01:15<16:30,  1.66it/s, running training loss:  0.88796]\u001b[A\n",
            "Training:   7%|▋         | 126/1772 [01:16<16:30,  1.66it/s, running training loss:  1.12823]\u001b[A\n",
            "Training:   7%|▋         | 127/1772 [01:16<18:19,  1.50it/s, running training loss:  1.12823]\u001b[A\n",
            "Training:   7%|▋         | 127/1772 [01:17<18:19,  1.50it/s, running training loss:  0.85145]\u001b[A\n",
            "Training:   7%|▋         | 128/1772 [01:17<18:39,  1.47it/s, running training loss:  0.85145]\u001b[A\n",
            "Training:   7%|▋         | 128/1772 [01:17<18:39,  1.47it/s, running training loss:  0.95012]\u001b[A\n",
            "Training:   7%|▋         | 129/1772 [01:17<17:29,  1.56it/s, running training loss:  0.95012]\u001b[A\n",
            "Training:   7%|▋         | 129/1772 [01:18<17:29,  1.56it/s, running training loss:  1.01025]\u001b[A\n",
            "Training:   7%|▋         | 130/1772 [01:18<16:24,  1.67it/s, running training loss:  1.01025]\u001b[A\n",
            "Training:   7%|▋         | 130/1772 [01:18<16:24,  1.67it/s, running training loss:  1.00142]\u001b[A\n",
            "Training:   7%|▋         | 131/1772 [01:18<15:34,  1.76it/s, running training loss:  1.00142]\u001b[A\n",
            "Training:   7%|▋         | 131/1772 [01:19<15:34,  1.76it/s, running training loss:  1.10859]\u001b[A\n",
            "Training:   7%|▋         | 132/1772 [01:19<15:35,  1.75it/s, running training loss:  1.10859]\u001b[A\n",
            "Training:   7%|▋         | 132/1772 [01:19<15:35,  1.75it/s, running training loss:  0.89893]\u001b[A\n",
            "Training:   8%|▊         | 133/1772 [01:19<15:09,  1.80it/s, running training loss:  0.89893]\u001b[A\n",
            "Training:   8%|▊         | 133/1772 [01:20<15:09,  1.80it/s, running training loss:  0.97165]\u001b[A\n",
            "Training:   8%|▊         | 134/1772 [01:20<14:27,  1.89it/s, running training loss:  0.97165]\u001b[A\n",
            "Training:   8%|▊         | 134/1772 [01:20<14:27,  1.89it/s, running training loss:  1.05693]\u001b[A\n",
            "Training:   8%|▊         | 135/1772 [01:20<14:13,  1.92it/s, running training loss:  1.05693]\u001b[A\n",
            "Training:   8%|▊         | 135/1772 [01:21<14:13,  1.92it/s, running training loss:  1.05102]\u001b[A\n",
            "Training:   8%|▊         | 136/1772 [01:21<13:51,  1.97it/s, running training loss:  1.05102]\u001b[A\n",
            "Training:   8%|▊         | 136/1772 [01:21<13:51,  1.97it/s, running training loss:  1.00535]\u001b[A\n",
            "Training:   8%|▊         | 137/1772 [01:21<13:30,  2.02it/s, running training loss:  1.00535]\u001b[A\n",
            "Training:   8%|▊         | 137/1772 [01:22<13:30,  2.02it/s, running training loss:  1.00110]\u001b[A\n",
            "Training:   8%|▊         | 138/1772 [01:22<15:16,  1.78it/s, running training loss:  1.00110]\u001b[A\n",
            "Training:   8%|▊         | 138/1772 [01:22<15:16,  1.78it/s, running training loss:  1.01807]\u001b[A\n",
            "Training:   8%|▊         | 139/1772 [01:22<15:11,  1.79it/s, running training loss:  1.01807]\u001b[A\n",
            "Training:   8%|▊         | 139/1772 [01:23<15:11,  1.79it/s, running training loss:  0.95316]\u001b[A\n",
            "Training:   8%|▊         | 140/1772 [01:23<15:28,  1.76it/s, running training loss:  0.95316]\u001b[A\n",
            "Training:   8%|▊         | 140/1772 [01:24<15:28,  1.76it/s, running training loss:  1.00110]\u001b[A\n",
            "Training:   8%|▊         | 141/1772 [01:24<16:03,  1.69it/s, running training loss:  1.00110]\u001b[A\n",
            "Training:   8%|▊         | 141/1772 [01:24<16:03,  1.69it/s, running training loss:  1.21587]\u001b[A\n",
            "Training:   8%|▊         | 142/1772 [01:24<16:16,  1.67it/s, running training loss:  1.21587]\u001b[A\n",
            "Training:   8%|▊         | 142/1772 [01:25<16:16,  1.67it/s, running training loss:  1.09730]\u001b[A\n",
            "Training:   8%|▊         | 143/1772 [01:25<15:43,  1.73it/s, running training loss:  1.09730]\u001b[A\n",
            "Training:   8%|▊         | 143/1772 [01:25<15:43,  1.73it/s, running training loss:  0.99059]\u001b[A\n",
            "Training:   8%|▊         | 144/1772 [01:25<16:02,  1.69it/s, running training loss:  0.99059]\u001b[A\n",
            "Training:   8%|▊         | 144/1772 [01:26<16:02,  1.69it/s, running training loss:  1.02246]\u001b[A\n",
            "Training:   8%|▊         | 145/1772 [01:26<15:47,  1.72it/s, running training loss:  1.02246]\u001b[A\n",
            "Training:   8%|▊         | 145/1772 [01:27<15:47,  1.72it/s, running training loss:  0.80663]\u001b[A\n",
            "Training:   8%|▊         | 146/1772 [01:27<16:22,  1.65it/s, running training loss:  0.80663]\u001b[A\n",
            "Training:   8%|▊         | 146/1772 [01:27<16:22,  1.65it/s, running training loss:  0.99091]\u001b[A\n",
            "Training:   8%|▊         | 147/1772 [01:27<15:48,  1.71it/s, running training loss:  0.99091]\u001b[A\n",
            "Training:   8%|▊         | 147/1772 [01:28<15:48,  1.71it/s, running training loss:  0.82540]\u001b[A\n",
            "Training:   8%|▊         | 148/1772 [01:28<16:14,  1.67it/s, running training loss:  0.82540]\u001b[A\n",
            "Training:   8%|▊         | 148/1772 [01:29<16:14,  1.67it/s, running training loss:  0.83177]\u001b[A\n",
            "Training:   8%|▊         | 149/1772 [01:29<17:33,  1.54it/s, running training loss:  0.83177]\u001b[A\n",
            "Training:   8%|▊         | 149/1772 [01:29<17:33,  1.54it/s, running training loss:  1.08824]\u001b[A\n",
            "Training:   8%|▊         | 150/1772 [01:29<16:38,  1.62it/s, running training loss:  1.08824]\u001b[A\n",
            "Training:   8%|▊         | 150/1772 [01:30<16:38,  1.62it/s, running training loss:  0.94210]\u001b[A\n",
            "Training:   9%|▊         | 151/1772 [01:30<15:56,  1.69it/s, running training loss:  0.94210]\u001b[A\n",
            "Training:   9%|▊         | 151/1772 [01:30<15:56,  1.69it/s, running training loss:  0.81490]\u001b[A\n",
            "Training:   9%|▊         | 152/1772 [01:30<15:14,  1.77it/s, running training loss:  0.81490]\u001b[A\n",
            "Training:   9%|▊         | 152/1772 [01:31<15:14,  1.77it/s, running training loss:  0.93194]\u001b[A\n",
            "Training:   9%|▊         | 153/1772 [01:31<18:02,  1.50it/s, running training loss:  0.93194]\u001b[A\n",
            "Training:   9%|▊         | 153/1772 [01:32<18:02,  1.50it/s, running training loss:  1.16739]\u001b[A\n",
            "Training:   9%|▊         | 154/1772 [01:32<17:22,  1.55it/s, running training loss:  1.16739]\u001b[A\n",
            "Training:   9%|▊         | 154/1772 [01:32<17:22,  1.55it/s, running training loss:  1.00841]\u001b[A\n",
            "Training:   9%|▊         | 155/1772 [01:32<18:55,  1.42it/s, running training loss:  1.00841]\u001b[A\n",
            "Training:   9%|▊         | 155/1772 [01:33<18:55,  1.42it/s, running training loss:  1.09205]\u001b[A\n",
            "Training:   9%|▉         | 156/1772 [01:33<16:56,  1.59it/s, running training loss:  1.09205]\u001b[A\n",
            "Training:   9%|▉         | 156/1772 [01:34<16:56,  1.59it/s, running training loss:  0.96393]\u001b[A\n",
            "Training:   9%|▉         | 157/1772 [01:34<17:07,  1.57it/s, running training loss:  0.96393]\u001b[A\n",
            "Training:   9%|▉         | 157/1772 [01:34<17:07,  1.57it/s, running training loss:  0.94333]\u001b[A\n",
            "Training:   9%|▉         | 158/1772 [01:34<16:21,  1.64it/s, running training loss:  0.94333]\u001b[A\n",
            "Training:   9%|▉         | 158/1772 [01:35<16:21,  1.64it/s, running training loss:  1.11477]\u001b[A\n",
            "Training:   9%|▉         | 159/1772 [01:35<16:12,  1.66it/s, running training loss:  1.11477]\u001b[A\n",
            "Training:   9%|▉         | 159/1772 [01:35<16:12,  1.66it/s, running training loss:  1.02714]\u001b[A\n",
            "Training:   9%|▉         | 160/1772 [01:35<15:43,  1.71it/s, running training loss:  1.02714]\u001b[A\n",
            "Training:   9%|▉         | 160/1772 [01:36<15:43,  1.71it/s, running training loss:  0.99533]\u001b[A\n",
            "Training:   9%|▉         | 161/1772 [01:36<15:42,  1.71it/s, running training loss:  0.99533]\u001b[A\n",
            "Training:   9%|▉         | 161/1772 [01:36<15:42,  1.71it/s, running training loss:  1.16200]\u001b[A\n",
            "Training:   9%|▉         | 162/1772 [01:36<14:16,  1.88it/s, running training loss:  1.16200]\u001b[A\n",
            "Training:   9%|▉         | 162/1772 [01:37<14:16,  1.88it/s, running training loss:  1.05076]\u001b[A\n",
            "Training:   9%|▉         | 163/1772 [01:37<14:36,  1.84it/s, running training loss:  1.05076]\u001b[A\n",
            "Training:   9%|▉         | 163/1772 [01:38<14:36,  1.84it/s, running training loss:  0.95050]\u001b[A\n",
            "Training:   9%|▉         | 164/1772 [01:38<15:35,  1.72it/s, running training loss:  0.95050]\u001b[A\n",
            "Training:   9%|▉         | 164/1772 [01:38<15:35,  1.72it/s, running training loss:  1.08556]\u001b[A\n",
            "Training:   9%|▉         | 165/1772 [01:38<15:49,  1.69it/s, running training loss:  1.08556]\u001b[A\n",
            "Training:   9%|▉         | 165/1772 [01:39<15:49,  1.69it/s, running training loss:  0.92147]\u001b[A\n",
            "Training:   9%|▉         | 166/1772 [01:39<15:53,  1.69it/s, running training loss:  0.92147]\u001b[A\n",
            "Training:   9%|▉         | 166/1772 [01:39<15:53,  1.69it/s, running training loss:  1.11722]\u001b[A\n",
            "Training:   9%|▉         | 167/1772 [01:39<16:03,  1.66it/s, running training loss:  1.11722]\u001b[A\n",
            "Training:   9%|▉         | 167/1772 [01:40<16:03,  1.66it/s, running training loss:  1.01697]\u001b[A\n",
            "Training:   9%|▉         | 168/1772 [01:40<17:15,  1.55it/s, running training loss:  1.01697]\u001b[A\n",
            "Training:   9%|▉         | 168/1772 [01:41<17:15,  1.55it/s, running training loss:  1.01262]\u001b[A\n",
            "Training:  10%|▉         | 169/1772 [01:41<17:00,  1.57it/s, running training loss:  1.01262]\u001b[A\n",
            "Training:  10%|▉         | 169/1772 [01:41<17:00,  1.57it/s, running training loss:  0.83130]\u001b[A\n",
            "Training:  10%|▉         | 170/1772 [01:41<16:50,  1.59it/s, running training loss:  0.83130]\u001b[A\n",
            "Training:  10%|▉         | 170/1772 [01:42<16:50,  1.59it/s, running training loss:  0.94411]\u001b[A\n",
            "Training:  10%|▉         | 171/1772 [01:42<16:56,  1.58it/s, running training loss:  0.94411]\u001b[A\n",
            "Training:  10%|▉         | 171/1772 [01:42<16:56,  1.58it/s, running training loss:  1.15721]\u001b[A\n",
            "Training:  10%|▉         | 172/1772 [01:42<15:43,  1.70it/s, running training loss:  1.15721]\u001b[A\n",
            "Training:  10%|▉         | 172/1772 [01:43<15:43,  1.70it/s, running training loss:  1.00075]\u001b[A\n",
            "Training:  10%|▉         | 173/1772 [01:43<16:23,  1.63it/s, running training loss:  1.00075]\u001b[A\n",
            "Training:  10%|▉         | 173/1772 [01:44<16:23,  1.63it/s, running training loss:  0.99794]\u001b[A\n",
            "Training:  10%|▉         | 174/1772 [01:44<15:51,  1.68it/s, running training loss:  0.99794]\u001b[A\n",
            "Training:  10%|▉         | 174/1772 [01:44<15:51,  1.68it/s, running training loss:  0.85276]\u001b[A\n",
            "Training:  10%|▉         | 175/1772 [01:44<16:12,  1.64it/s, running training loss:  0.85276]\u001b[A\n",
            "Training:  10%|▉         | 175/1772 [01:45<16:12,  1.64it/s, running training loss:  1.06454]\u001b[A\n",
            "Training:  10%|▉         | 176/1772 [01:45<15:53,  1.67it/s, running training loss:  1.06454]\u001b[A\n",
            "Training:  10%|▉         | 176/1772 [01:45<15:53,  1.67it/s, running training loss:  1.22783]\u001b[A\n",
            "Training:  10%|▉         | 177/1772 [01:45<15:25,  1.72it/s, running training loss:  1.22783]\u001b[A\n",
            "Training:  10%|▉         | 177/1772 [01:46<15:25,  1.72it/s, running training loss:  1.37296]\u001b[A\n",
            "Training:  10%|█         | 178/1772 [01:46<15:35,  1.70it/s, running training loss:  1.37296]\u001b[A\n",
            "Training:  10%|█         | 178/1772 [01:47<15:35,  1.70it/s, running training loss:  1.28374]\u001b[A\n",
            "Training:  10%|█         | 179/1772 [01:47<15:55,  1.67it/s, running training loss:  1.28374]\u001b[A\n",
            "Training:  10%|█         | 179/1772 [01:47<15:55,  1.67it/s, running training loss:  1.29676]\u001b[A\n",
            "Training:  10%|█         | 180/1772 [01:47<17:28,  1.52it/s, running training loss:  1.29676]\u001b[A\n",
            "Training:  10%|█         | 180/1772 [01:48<17:28,  1.52it/s, running training loss:  1.27321]\u001b[A\n",
            "Training:  10%|█         | 181/1772 [01:48<16:41,  1.59it/s, running training loss:  1.27321]\u001b[A\n",
            "Training:  10%|█         | 181/1772 [01:49<16:41,  1.59it/s, running training loss:  1.15485]\u001b[A\n",
            "Training:  10%|█         | 182/1772 [01:49<15:55,  1.66it/s, running training loss:  1.15485]\u001b[A\n",
            "Training:  10%|█         | 182/1772 [01:49<15:55,  1.66it/s, running training loss:  0.75723]\u001b[A\n",
            "Training:  10%|█         | 183/1772 [01:49<16:36,  1.59it/s, running training loss:  0.75723]\u001b[A\n",
            "Training:  10%|█         | 183/1772 [01:50<16:36,  1.59it/s, running training loss:  0.84667]\u001b[A\n",
            "Training:  10%|█         | 184/1772 [01:50<16:15,  1.63it/s, running training loss:  0.84667]\u001b[A\n",
            "Training:  10%|█         | 184/1772 [01:50<16:15,  1.63it/s, running training loss:  0.99127]\u001b[A\n",
            "Training:  10%|█         | 185/1772 [01:50<15:47,  1.67it/s, running training loss:  0.99127]\u001b[A\n",
            "Training:  10%|█         | 185/1772 [01:51<15:47,  1.67it/s, running training loss:  0.74117]\u001b[A\n",
            "Training:  10%|█         | 186/1772 [01:51<15:03,  1.76it/s, running training loss:  0.74117]\u001b[A\n",
            "Training:  10%|█         | 186/1772 [01:52<15:03,  1.76it/s, running training loss:  0.85191]\u001b[A\n",
            "Training:  11%|█         | 187/1772 [01:52<17:31,  1.51it/s, running training loss:  0.85191]\u001b[A\n",
            "Training:  11%|█         | 187/1772 [01:52<17:31,  1.51it/s, running training loss:  0.96155]\u001b[A\n",
            "Training:  11%|█         | 188/1772 [01:52<16:41,  1.58it/s, running training loss:  0.96155]\u001b[A\n",
            "Training:  11%|█         | 188/1772 [01:53<16:41,  1.58it/s, running training loss:  1.20899]\u001b[A\n",
            "Training:  11%|█         | 189/1772 [01:53<18:41,  1.41it/s, running training loss:  1.20899]\u001b[A\n",
            "Training:  11%|█         | 189/1772 [01:54<18:41,  1.41it/s, running training loss:  1.22418]\u001b[A\n",
            "Training:  11%|█         | 190/1772 [01:54<18:05,  1.46it/s, running training loss:  1.22418]\u001b[A\n",
            "Training:  11%|█         | 190/1772 [01:54<18:05,  1.46it/s, running training loss:  1.14425]\u001b[A\n",
            "Training:  11%|█         | 191/1772 [01:54<16:46,  1.57it/s, running training loss:  1.14425]\u001b[A\n",
            "Training:  11%|█         | 191/1772 [01:55<16:46,  1.57it/s, running training loss:  1.14032]\u001b[A\n",
            "Training:  11%|█         | 192/1772 [01:55<15:48,  1.67it/s, running training loss:  1.14032]\u001b[A\n",
            "Training:  11%|█         | 192/1772 [01:56<15:48,  1.67it/s, running training loss:  1.16976]\u001b[A\n",
            "Training:  11%|█         | 193/1772 [01:56<16:10,  1.63it/s, running training loss:  1.16976]\u001b[A\n",
            "Training:  11%|█         | 193/1772 [01:56<16:10,  1.63it/s, running training loss:  1.10650]\u001b[A\n",
            "Training:  11%|█         | 194/1772 [01:56<15:58,  1.65it/s, running training loss:  1.10650]\u001b[A\n",
            "Training:  11%|█         | 194/1772 [01:57<15:58,  1.65it/s, running training loss:  0.76246]\u001b[A\n",
            "Training:  11%|█         | 195/1772 [01:57<15:18,  1.72it/s, running training loss:  0.76246]\u001b[A\n",
            "Training:  11%|█         | 195/1772 [01:57<15:18,  1.72it/s, running training loss:  0.98844]\u001b[A\n",
            "Training:  11%|█         | 196/1772 [01:57<14:31,  1.81it/s, running training loss:  0.98844]\u001b[A\n",
            "Training:  11%|█         | 196/1772 [01:58<14:31,  1.81it/s, running training loss:  0.78875]\u001b[A\n",
            "Training:  11%|█         | 197/1772 [01:58<14:29,  1.81it/s, running training loss:  0.78875]\u001b[A\n",
            "Training:  11%|█         | 197/1772 [01:58<14:29,  1.81it/s, running training loss:  0.74603]\u001b[A\n",
            "Training:  11%|█         | 198/1772 [01:58<14:45,  1.78it/s, running training loss:  0.74603]\u001b[A\n",
            "Training:  11%|█         | 198/1772 [01:59<14:45,  1.78it/s, running training loss:  1.09661]\u001b[A\n",
            "Training:  11%|█         | 199/1772 [01:59<14:07,  1.86it/s, running training loss:  1.09661]\u001b[A\n",
            "Training:  11%|█         | 199/1772 [01:59<14:07,  1.86it/s, running training loss:  0.77894]\u001b[A\n",
            "Training:  11%|█▏        | 200/1772 [01:59<14:17,  1.83it/s, running training loss:  0.77894]\u001b[A\n",
            "Training:  11%|█▏        | 200/1772 [02:00<14:17,  1.83it/s, running training loss:  0.76868]\u001b[A\n",
            "Training:  11%|█▏        | 201/1772 [02:00<13:40,  1.91it/s, running training loss:  0.76868]\u001b[A\n",
            "Training:  11%|█▏        | 201/1772 [02:00<13:40,  1.91it/s, running training loss:  0.83910]\u001b[A\n",
            "Training:  11%|█▏        | 202/1772 [02:00<14:11,  1.84it/s, running training loss:  0.83910]\u001b[A\n",
            "Training:  11%|█▏        | 202/1772 [02:01<14:11,  1.84it/s, running training loss:  0.92151]\u001b[A\n",
            "Training:  11%|█▏        | 203/1772 [02:01<14:48,  1.77it/s, running training loss:  0.92151]\u001b[A\n",
            "Training:  11%|█▏        | 203/1772 [02:02<14:48,  1.77it/s, running training loss:  0.83080]\u001b[A\n",
            "Training:  12%|█▏        | 204/1772 [02:02<15:25,  1.69it/s, running training loss:  0.83080]\u001b[A\n",
            "Training:  12%|█▏        | 204/1772 [02:03<15:25,  1.69it/s, running training loss:  1.13541]\u001b[A\n",
            "Training:  12%|█▏        | 205/1772 [02:03<17:31,  1.49it/s, running training loss:  1.13541]\u001b[A\n",
            "Training:  12%|█▏        | 205/1772 [02:03<17:31,  1.49it/s, running training loss:  1.03277]\u001b[A\n",
            "Training:  12%|█▏        | 206/1772 [02:03<16:31,  1.58it/s, running training loss:  1.03277]\u001b[A\n",
            "Training:  12%|█▏        | 206/1772 [02:04<16:31,  1.58it/s, running training loss:  1.13756]\u001b[A\n",
            "Training:  12%|█▏        | 207/1772 [02:04<16:34,  1.57it/s, running training loss:  1.13756]\u001b[A\n",
            "Training:  12%|█▏        | 207/1772 [02:04<16:34,  1.57it/s, running training loss:  1.05963]\u001b[A\n",
            "Training:  12%|█▏        | 208/1772 [02:04<15:51,  1.64it/s, running training loss:  1.05963]\u001b[A\n",
            "Training:  12%|█▏        | 208/1772 [02:05<15:51,  1.64it/s, running training loss:  1.07626]\u001b[A\n",
            "Training:  12%|█▏        | 209/1772 [02:05<17:21,  1.50it/s, running training loss:  1.07626]\u001b[A\n",
            "Training:  12%|█▏        | 209/1772 [02:06<17:21,  1.50it/s, running training loss:  1.08201]\u001b[A\n",
            "Training:  12%|█▏        | 210/1772 [02:06<16:20,  1.59it/s, running training loss:  1.08201]\u001b[A\n",
            "Training:  12%|█▏        | 210/1772 [02:06<16:20,  1.59it/s, running training loss:  1.03028]\u001b[A\n",
            "Training:  12%|█▏        | 211/1772 [02:06<16:02,  1.62it/s, running training loss:  1.03028]\u001b[A\n",
            "Training:  12%|█▏        | 211/1772 [02:07<16:02,  1.62it/s, running training loss:  0.79503]\u001b[A\n",
            "Training:  12%|█▏        | 212/1772 [02:07<16:43,  1.56it/s, running training loss:  0.79503]\u001b[A\n",
            "Training:  12%|█▏        | 212/1772 [02:07<16:43,  1.56it/s, running training loss:  0.81887]\u001b[A\n",
            "Training:  12%|█▏        | 213/1772 [02:07<15:51,  1.64it/s, running training loss:  0.81887]\u001b[A\n",
            "Training:  12%|█▏        | 213/1772 [02:08<15:51,  1.64it/s, running training loss:  1.02701]\u001b[A\n",
            "Training:  12%|█▏        | 214/1772 [02:08<15:53,  1.63it/s, running training loss:  1.02701]\u001b[A\n",
            "Training:  12%|█▏        | 214/1772 [02:09<15:53,  1.63it/s, running training loss:  1.04311]\u001b[A\n",
            "Training:  12%|█▏        | 215/1772 [02:09<15:01,  1.73it/s, running training loss:  1.04311]\u001b[A\n",
            "Training:  12%|█▏        | 215/1772 [02:09<15:01,  1.73it/s, running training loss:  0.97200]\u001b[A\n",
            "Training:  12%|█▏        | 216/1772 [02:09<14:28,  1.79it/s, running training loss:  0.97200]\u001b[A\n",
            "Training:  12%|█▏        | 216/1772 [02:10<14:28,  1.79it/s, running training loss:  1.03498]\u001b[A\n",
            "Training:  12%|█▏        | 217/1772 [02:10<16:26,  1.58it/s, running training loss:  1.03498]\u001b[A\n",
            "Training:  12%|█▏        | 217/1772 [02:11<16:26,  1.58it/s, running training loss:  0.98388]\u001b[A\n",
            "Training:  12%|█▏        | 218/1772 [02:11<19:16,  1.34it/s, running training loss:  0.98388]\u001b[A\n",
            "Training:  12%|█▏        | 218/1772 [02:11<19:16,  1.34it/s, running training loss:  1.15200]\u001b[A\n",
            "Training:  12%|█▏        | 219/1772 [02:11<18:29,  1.40it/s, running training loss:  1.15200]\u001b[A\n",
            "Training:  12%|█▏        | 219/1772 [02:12<18:29,  1.40it/s, running training loss:  0.90449]\u001b[A\n",
            "Training:  12%|█▏        | 220/1772 [02:12<17:14,  1.50it/s, running training loss:  0.90449]\u001b[A\n",
            "Training:  12%|█▏        | 220/1772 [02:13<17:14,  1.50it/s, running training loss:  0.89253]\u001b[A\n",
            "Training:  12%|█▏        | 221/1772 [02:13<15:51,  1.63it/s, running training loss:  0.89253]\u001b[A\n",
            "Training:  12%|█▏        | 221/1772 [02:13<15:51,  1.63it/s, running training loss:  1.04880]\u001b[A\n",
            "Training:  13%|█▎        | 222/1772 [02:13<15:19,  1.68it/s, running training loss:  1.04880]\u001b[A\n",
            "Training:  13%|█▎        | 222/1772 [02:14<15:19,  1.68it/s, running training loss:  1.03311]\u001b[A\n",
            "Training:  13%|█▎        | 223/1772 [02:14<14:40,  1.76it/s, running training loss:  1.03311]\u001b[A\n",
            "Training:  13%|█▎        | 223/1772 [02:14<14:40,  1.76it/s, running training loss:  1.11420]\u001b[A\n",
            "Training:  13%|█▎        | 224/1772 [02:14<14:38,  1.76it/s, running training loss:  1.11420]\u001b[A\n",
            "Training:  13%|█▎        | 224/1772 [02:15<14:38,  1.76it/s, running training loss:  0.93576]\u001b[A\n",
            "Training:  13%|█▎        | 225/1772 [02:15<14:33,  1.77it/s, running training loss:  0.93576]\u001b[A\n",
            "Training:  13%|█▎        | 225/1772 [02:15<14:33,  1.77it/s, running training loss:  1.05428]\u001b[A\n",
            "Training:  13%|█▎        | 226/1772 [02:15<14:05,  1.83it/s, running training loss:  1.05428]\u001b[A\n",
            "Training:  13%|█▎        | 226/1772 [02:16<14:05,  1.83it/s, running training loss:  0.92424]\u001b[A\n",
            "Training:  13%|█▎        | 227/1772 [02:16<14:25,  1.78it/s, running training loss:  0.92424]\u001b[A\n",
            "Training:  13%|█▎        | 227/1772 [02:16<14:25,  1.78it/s, running training loss:  1.00828]\u001b[A\n",
            "Training:  13%|█▎        | 228/1772 [02:16<13:39,  1.88it/s, running training loss:  1.00828]\u001b[A\n",
            "Training:  13%|█▎        | 228/1772 [02:17<13:39,  1.88it/s, running training loss:  1.00541]\u001b[A\n",
            "Training:  13%|█▎        | 229/1772 [02:17<13:55,  1.85it/s, running training loss:  1.00541]\u001b[A\n",
            "Training:  13%|█▎        | 229/1772 [02:17<13:55,  1.85it/s, running training loss:  0.75493]\u001b[A\n",
            "Training:  13%|█▎        | 230/1772 [02:17<13:45,  1.87it/s, running training loss:  0.75493]\u001b[A\n",
            "Training:  13%|█▎        | 230/1772 [02:18<13:45,  1.87it/s, running training loss:  0.91125]\u001b[A\n",
            "Training:  13%|█▎        | 231/1772 [02:18<15:07,  1.70it/s, running training loss:  0.91125]\u001b[A\n",
            "Training:  13%|█▎        | 231/1772 [02:19<15:07,  1.70it/s, running training loss:  0.91096]\u001b[A\n",
            "Training:  13%|█▎        | 232/1772 [02:19<15:18,  1.68it/s, running training loss:  0.91096]\u001b[A\n",
            "Training:  13%|█▎        | 232/1772 [02:19<15:18,  1.68it/s, running training loss:  1.00427]\u001b[A\n",
            "Training:  13%|█▎        | 233/1772 [02:19<14:33,  1.76it/s, running training loss:  1.00427]\u001b[A\n",
            "Training:  13%|█▎        | 233/1772 [02:20<14:33,  1.76it/s, running training loss:  1.01769]\u001b[A\n",
            "Training:  13%|█▎        | 234/1772 [02:20<14:10,  1.81it/s, running training loss:  1.01769]\u001b[A\n",
            "Training:  13%|█▎        | 234/1772 [02:20<14:10,  1.81it/s, running training loss:  1.05619]\u001b[A\n",
            "Training:  13%|█▎        | 235/1772 [02:20<13:43,  1.87it/s, running training loss:  1.05619]\u001b[A\n",
            "Training:  13%|█▎        | 235/1772 [02:21<13:43,  1.87it/s, running training loss:  1.07074]\u001b[A\n",
            "Training:  13%|█▎        | 236/1772 [02:21<14:12,  1.80it/s, running training loss:  1.07074]\u001b[A\n",
            "Training:  13%|█▎        | 236/1772 [02:21<14:12,  1.80it/s, running training loss:  1.00863]\u001b[A\n",
            "Training:  13%|█▎        | 237/1772 [02:21<13:44,  1.86it/s, running training loss:  1.00863]\u001b[A\n",
            "Training:  13%|█▎        | 237/1772 [02:22<13:44,  1.86it/s, running training loss:  1.23428]\u001b[A\n",
            "Training:  13%|█▎        | 238/1772 [02:22<16:38,  1.54it/s, running training loss:  1.23428]\u001b[A\n",
            "Training:  13%|█▎        | 238/1772 [02:23<16:38,  1.54it/s, running training loss:  1.03028]\u001b[A\n",
            "Training:  13%|█▎        | 239/1772 [02:23<17:23,  1.47it/s, running training loss:  1.03028]\u001b[A\n",
            "Training:  13%|█▎        | 239/1772 [02:24<17:23,  1.47it/s, running training loss:  1.09319]\u001b[A\n",
            "Training:  14%|█▎        | 240/1772 [02:24<16:35,  1.54it/s, running training loss:  1.09319]\u001b[A\n",
            "Training:  14%|█▎        | 240/1772 [02:24<16:35,  1.54it/s, running training loss:  0.99820]\u001b[A\n",
            "Training:  14%|█▎        | 241/1772 [02:24<15:36,  1.64it/s, running training loss:  0.99820]\u001b[A\n",
            "Training:  14%|█▎        | 241/1772 [02:25<15:36,  1.64it/s, running training loss:  1.07780]\u001b[A\n",
            "Training:  14%|█▎        | 242/1772 [02:25<15:04,  1.69it/s, running training loss:  1.07780]\u001b[A\n",
            "Training:  14%|█▎        | 242/1772 [02:25<15:04,  1.69it/s, running training loss:  0.79449]\u001b[A\n",
            "Training:  14%|█▎        | 243/1772 [02:25<16:02,  1.59it/s, running training loss:  0.79449]\u001b[A\n",
            "Training:  14%|█▎        | 243/1772 [02:26<16:02,  1.59it/s, running training loss:  0.76956]\u001b[A\n",
            "Training:  14%|█▍        | 244/1772 [02:26<15:42,  1.62it/s, running training loss:  0.76956]\u001b[A\n",
            "Training:  14%|█▍        | 244/1772 [02:27<15:42,  1.62it/s, running training loss:  0.95921]\u001b[A\n",
            "Training:  14%|█▍        | 245/1772 [02:27<15:29,  1.64it/s, running training loss:  0.95921]\u001b[A\n",
            "Training:  14%|█▍        | 245/1772 [02:27<15:29,  1.64it/s, running training loss:  1.17186]\u001b[A\n",
            "Training:  14%|█▍        | 246/1772 [02:27<15:53,  1.60it/s, running training loss:  1.17186]\u001b[A\n",
            "Training:  14%|█▍        | 246/1772 [02:28<15:53,  1.60it/s, running training loss:  1.12992]\u001b[A\n",
            "Training:  14%|█▍        | 247/1772 [02:28<14:21,  1.77it/s, running training loss:  1.12992]\u001b[A\n",
            "Training:  14%|█▍        | 247/1772 [02:28<14:21,  1.77it/s, running training loss:  0.74802]\u001b[A\n",
            "Training:  14%|█▍        | 248/1772 [02:28<14:16,  1.78it/s, running training loss:  0.74802]\u001b[A\n",
            "Training:  14%|█▍        | 248/1772 [02:29<14:16,  1.78it/s, running training loss:  1.09770]\u001b[A\n",
            "Training:  14%|█▍        | 249/1772 [02:29<17:35,  1.44it/s, running training loss:  1.09770]\u001b[A\n",
            "Training:  14%|█▍        | 249/1772 [02:30<17:35,  1.44it/s, running training loss:  0.85950]\u001b[A\n",
            "Training:  14%|█▍        | 250/1772 [02:30<16:20,  1.55it/s, running training loss:  0.85950]\u001b[A\n",
            "Training:  14%|█▍        | 250/1772 [02:31<16:20,  1.55it/s, running training loss:  1.16397]\u001b[A\n",
            "Training:  14%|█▍        | 251/1772 [02:31<18:15,  1.39it/s, running training loss:  1.16397]\u001b[A\n",
            "Training:  14%|█▍        | 251/1772 [02:31<18:15,  1.39it/s, running training loss:  1.00244]\u001b[A\n",
            "Training:  14%|█▍        | 252/1772 [02:31<17:33,  1.44it/s, running training loss:  1.00244]\u001b[A\n",
            "Training:  14%|█▍        | 252/1772 [02:32<17:33,  1.44it/s, running training loss:  1.26033]\u001b[A\n",
            "Training:  14%|█▍        | 253/1772 [02:32<16:12,  1.56it/s, running training loss:  1.26033]\u001b[A\n",
            "Training:  14%|█▍        | 253/1772 [02:32<16:12,  1.56it/s, running training loss:  1.04676]\u001b[A\n",
            "Training:  14%|█▍        | 254/1772 [02:32<15:26,  1.64it/s, running training loss:  1.04676]\u001b[A\n",
            "Training:  14%|█▍        | 254/1772 [02:33<15:26,  1.64it/s, running training loss:  0.96840]\u001b[A\n",
            "Training:  14%|█▍        | 255/1772 [02:33<14:58,  1.69it/s, running training loss:  0.96840]\u001b[A\n",
            "Training:  14%|█▍        | 255/1772 [02:33<14:58,  1.69it/s, running training loss:  0.96863]\u001b[A\n",
            "Training:  14%|█▍        | 256/1772 [02:33<14:50,  1.70it/s, running training loss:  0.96863]\u001b[A\n",
            "Training:  14%|█▍        | 256/1772 [02:34<14:50,  1.70it/s, running training loss:  0.79796]\u001b[A\n",
            "Training:  15%|█▍        | 257/1772 [02:34<14:32,  1.74it/s, running training loss:  0.79796]\u001b[A\n",
            "Training:  15%|█▍        | 257/1772 [02:34<14:32,  1.74it/s, running training loss:  0.80912]\u001b[A\n",
            "Training:  15%|█▍        | 258/1772 [02:34<14:11,  1.78it/s, running training loss:  0.80912]\u001b[A\n",
            "Training:  15%|█▍        | 258/1772 [02:35<14:11,  1.78it/s, running training loss:  0.73596]\u001b[A\n",
            "Training:  15%|█▍        | 259/1772 [02:35<14:04,  1.79it/s, running training loss:  0.73596]\u001b[A\n",
            "Training:  15%|█▍        | 259/1772 [02:36<14:04,  1.79it/s, running training loss:  1.04391]\u001b[A\n",
            "Training:  15%|█▍        | 260/1772 [02:36<16:21,  1.54it/s, running training loss:  1.04391]\u001b[A\n",
            "Training:  15%|█▍        | 260/1772 [02:36<16:21,  1.54it/s, running training loss:  0.77893]\u001b[A\n",
            "Training:  15%|█▍        | 261/1772 [02:36<15:32,  1.62it/s, running training loss:  0.77893]\u001b[A\n",
            "Training:  15%|█▍        | 261/1772 [02:37<15:32,  1.62it/s, running training loss:  0.89583]\u001b[A\n",
            "Training:  15%|█▍        | 262/1772 [02:37<15:45,  1.60it/s, running training loss:  0.89583]\u001b[A\n",
            "Training:  15%|█▍        | 262/1772 [02:38<15:45,  1.60it/s, running training loss:  0.89429]\u001b[A\n",
            "Training:  15%|█▍        | 263/1772 [02:38<15:52,  1.58it/s, running training loss:  0.89429]\u001b[A\n",
            "Training:  15%|█▍        | 263/1772 [02:38<15:52,  1.58it/s, running training loss:  0.89799]\u001b[A\n",
            "Training:  15%|█▍        | 264/1772 [02:38<14:32,  1.73it/s, running training loss:  0.89799]\u001b[A\n",
            "Training:  15%|█▍        | 264/1772 [02:39<14:32,  1.73it/s, running training loss:  1.11984]\u001b[A\n",
            "Training:  15%|█▍        | 265/1772 [02:39<14:56,  1.68it/s, running training loss:  1.11984]\u001b[A\n",
            "Training:  15%|█▍        | 265/1772 [02:39<14:56,  1.68it/s, running training loss:  0.93458]\u001b[A\n",
            "Training:  15%|█▌        | 266/1772 [02:39<15:19,  1.64it/s, running training loss:  0.93458]\u001b[A\n",
            "Training:  15%|█▌        | 266/1772 [02:40<15:19,  1.64it/s, running training loss:  0.88270]\u001b[A\n",
            "Training:  15%|█▌        | 267/1772 [02:40<14:28,  1.73it/s, running training loss:  0.88270]\u001b[A\n",
            "Training:  15%|█▌        | 267/1772 [02:41<14:28,  1.73it/s, running training loss:  1.03965]\u001b[A\n",
            "Training:  15%|█▌        | 268/1772 [02:41<15:00,  1.67it/s, running training loss:  1.03965]\u001b[A\n",
            "Training:  15%|█▌        | 268/1772 [02:41<15:00,  1.67it/s, running training loss:  0.87042]\u001b[A\n",
            "Training:  15%|█▌        | 269/1772 [02:41<15:28,  1.62it/s, running training loss:  0.87042]\u001b[A\n",
            "Training:  15%|█▌        | 269/1772 [02:42<15:28,  1.62it/s, running training loss:  1.02333]\u001b[A\n",
            "Training:  15%|█▌        | 270/1772 [02:42<14:28,  1.73it/s, running training loss:  1.02333]\u001b[A\n",
            "Training:  15%|█▌        | 270/1772 [02:42<14:28,  1.73it/s, running training loss:  1.12620]\u001b[A\n",
            "Training:  15%|█▌        | 271/1772 [02:42<14:09,  1.77it/s, running training loss:  1.12620]\u001b[A\n",
            "Training:  15%|█▌        | 271/1772 [02:43<14:09,  1.77it/s, running training loss:  1.17145]\u001b[A\n",
            "Training:  15%|█▌        | 272/1772 [02:43<14:45,  1.69it/s, running training loss:  1.17145]\u001b[A\n",
            "Training:  15%|█▌        | 272/1772 [02:44<14:45,  1.69it/s, running training loss:  1.12964]\u001b[A\n",
            "Training:  15%|█▌        | 273/1772 [02:44<14:46,  1.69it/s, running training loss:  1.12964]\u001b[A\n",
            "Training:  15%|█▌        | 273/1772 [02:44<14:46,  1.69it/s, running training loss:  1.03928]\u001b[A\n",
            "Training:  15%|█▌        | 274/1772 [02:44<14:51,  1.68it/s, running training loss:  1.03928]\u001b[A\n",
            "Training:  15%|█▌        | 274/1772 [02:45<14:51,  1.68it/s, running training loss:  0.98591]\u001b[A\n",
            "Training:  16%|█▌        | 275/1772 [02:45<14:34,  1.71it/s, running training loss:  0.98591]\u001b[A\n",
            "Training:  16%|█▌        | 275/1772 [02:45<14:34,  1.71it/s, running training loss:  0.91405]\u001b[A\n",
            "Training:  16%|█▌        | 276/1772 [02:45<15:12,  1.64it/s, running training loss:  0.91405]\u001b[A\n",
            "Training:  16%|█▌        | 276/1772 [02:46<15:12,  1.64it/s, running training loss:  0.93116]\u001b[A\n",
            "Training:  16%|█▌        | 277/1772 [02:46<14:00,  1.78it/s, running training loss:  0.93116]\u001b[A\n",
            "Training:  16%|█▌        | 277/1772 [02:46<14:00,  1.78it/s, running training loss:  0.83187]\u001b[A\n",
            "Training:  16%|█▌        | 278/1772 [02:46<13:50,  1.80it/s, running training loss:  0.83187]\u001b[A\n",
            "Training:  16%|█▌        | 278/1772 [02:47<13:50,  1.80it/s, running training loss:  1.05968]\u001b[A\n",
            "Training:  16%|█▌        | 279/1772 [02:47<13:42,  1.81it/s, running training loss:  1.05968]\u001b[A\n",
            "Training:  16%|█▌        | 279/1772 [02:48<13:42,  1.81it/s, running training loss:  1.14395]\u001b[A\n",
            "Training:  16%|█▌        | 280/1772 [02:48<16:56,  1.47it/s, running training loss:  1.14395]\u001b[A\n",
            "Training:  16%|█▌        | 280/1772 [02:49<16:56,  1.47it/s, running training loss:  0.93392]\u001b[A\n",
            "Training:  16%|█▌        | 281/1772 [02:49<17:12,  1.44it/s, running training loss:  0.93392]\u001b[A\n",
            "Training:  16%|█▌        | 281/1772 [02:49<17:12,  1.44it/s, running training loss:  0.82828]\u001b[A\n",
            "Training:  16%|█▌        | 282/1772 [02:49<16:13,  1.53it/s, running training loss:  0.82828]\u001b[A\n",
            "Training:  16%|█▌        | 282/1772 [02:50<16:13,  1.53it/s, running training loss:  0.91326]\u001b[A\n",
            "Training:  16%|█▌        | 283/1772 [02:50<17:26,  1.42it/s, running training loss:  0.91326]\u001b[A\n",
            "Training:  16%|█▌        | 283/1772 [02:51<17:26,  1.42it/s, running training loss:  1.19798]\u001b[A\n",
            "Training:  16%|█▌        | 284/1772 [02:51<16:43,  1.48it/s, running training loss:  1.19798]\u001b[A\n",
            "Training:  16%|█▌        | 284/1772 [02:51<16:43,  1.48it/s, running training loss:  1.15855]\u001b[A\n",
            "Training:  16%|█▌        | 285/1772 [02:51<16:34,  1.50it/s, running training loss:  1.15855]\u001b[A\n",
            "Training:  16%|█▌        | 285/1772 [02:52<16:34,  1.50it/s, running training loss:  0.10891]\u001b[A\n",
            "Training:  16%|█▌        | 286/1772 [02:52<16:55,  1.46it/s, running training loss:  0.10891]\u001b[A\n",
            "Training:  16%|█▌        | 286/1772 [02:53<16:55,  1.46it/s, running training loss:  1.10491]\u001b[A\n",
            "Training:  16%|█▌        | 287/1772 [02:53<16:56,  1.46it/s, running training loss:  1.10491]\u001b[A\n",
            "Training:  16%|█▌        | 287/1772 [02:53<16:56,  1.46it/s, running training loss:  1.36557]\u001b[A\n",
            "Training:  16%|█▋        | 288/1772 [02:53<17:40,  1.40it/s, running training loss:  1.36557]\u001b[A\n",
            "Training:  16%|█▋        | 288/1772 [02:54<17:40,  1.40it/s, running training loss:  1.62853]\u001b[A\n",
            "Training:  16%|█▋        | 289/1772 [02:54<16:02,  1.54it/s, running training loss:  1.62853]\u001b[A\n",
            "Training:  16%|█▋        | 289/1772 [02:54<16:02,  1.54it/s, running training loss:  1.38603]\u001b[A\n",
            "Training:  16%|█▋        | 290/1772 [02:54<15:12,  1.62it/s, running training loss:  1.38603]\u001b[A\n",
            "Training:  16%|█▋        | 290/1772 [02:55<15:12,  1.62it/s, running training loss:  1.16214]\u001b[A\n",
            "Training:  16%|█▋        | 291/1772 [02:55<14:30,  1.70it/s, running training loss:  1.16214]\u001b[A\n",
            "Training:  16%|█▋        | 291/1772 [02:56<14:30,  1.70it/s, running training loss:  1.25817]\u001b[A\n",
            "Training:  16%|█▋        | 292/1772 [02:56<14:14,  1.73it/s, running training loss:  1.25817]\u001b[A\n",
            "Training:  16%|█▋        | 292/1772 [02:56<14:14,  1.73it/s, running training loss:  1.09207]\u001b[A\n",
            "Training:  17%|█▋        | 293/1772 [02:56<14:07,  1.74it/s, running training loss:  1.09207]\u001b[A\n",
            "Training:  17%|█▋        | 293/1772 [02:57<14:07,  1.74it/s, running training loss:  1.17587]\u001b[A\n",
            "Training:  17%|█▋        | 294/1772 [02:57<14:45,  1.67it/s, running training loss:  1.17587]\u001b[A\n",
            "Training:  17%|█▋        | 294/1772 [02:57<14:45,  1.67it/s, running training loss:  1.07271]\u001b[A\n",
            "Training:  17%|█▋        | 295/1772 [02:57<14:10,  1.74it/s, running training loss:  1.07271]\u001b[A\n",
            "Training:  17%|█▋        | 295/1772 [02:58<14:10,  1.74it/s, running training loss:  0.99941]\u001b[A\n",
            "Training:  17%|█▋        | 296/1772 [02:58<17:01,  1.44it/s, running training loss:  0.99941]\u001b[A\n",
            "Training:  17%|█▋        | 296/1772 [02:59<17:01,  1.44it/s, running training loss:  1.01502]\u001b[A\n",
            "Training:  17%|█▋        | 297/1772 [02:59<15:20,  1.60it/s, running training loss:  1.01502]\u001b[A\n",
            "Training:  17%|█▋        | 297/1772 [02:59<15:20,  1.60it/s, running training loss:  0.85941]\u001b[A\n",
            "Training:  17%|█▋        | 298/1772 [02:59<14:21,  1.71it/s, running training loss:  0.85941]\u001b[A\n",
            "Training:  17%|█▋        | 298/1772 [03:00<14:21,  1.71it/s, running training loss:  0.84299]\u001b[A\n",
            "Training:  17%|█▋        | 299/1772 [03:00<13:39,  1.80it/s, running training loss:  0.84299]\u001b[A\n",
            "Training:  17%|█▋        | 299/1772 [03:00<13:39,  1.80it/s, running training loss:  0.96181]\u001b[A\n",
            "\n",
            "Evaluation:   0%|          | 0/270 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   0%|          | 1/270 [00:00<01:43,  2.61it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   1%|          | 2/270 [00:00<01:03,  4.24it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   1%|          | 3/270 [00:00<00:48,  5.50it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   1%|▏         | 4/270 [00:00<00:41,  6.35it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   2%|▏         | 5/270 [00:00<00:37,  7.01it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   2%|▏         | 6/270 [00:00<00:35,  7.50it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   3%|▎         | 8/270 [00:01<00:30,  8.69it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   3%|▎         | 9/270 [00:01<00:30,  8.60it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   4%|▍         | 11/270 [00:01<00:26,  9.74it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   5%|▍         | 13/270 [00:01<00:25, 10.00it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   5%|▌         | 14/270 [00:01<00:27,  9.42it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   6%|▌         | 15/270 [00:01<00:26,  9.50it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   6%|▌         | 16/270 [00:02<00:28,  9.05it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   6%|▋         | 17/270 [00:02<00:28,  8.80it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   7%|▋         | 19/270 [00:02<00:26,  9.41it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   7%|▋         | 20/270 [00:02<00:27,  9.25it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   8%|▊         | 22/270 [00:02<00:24, 10.32it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   9%|▉         | 24/270 [00:02<00:22, 10.78it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  10%|▉         | 26/270 [00:02<00:23, 10.41it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  10%|█         | 28/270 [00:03<00:23, 10.15it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  11%|█         | 30/270 [00:03<00:24,  9.62it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  11%|█▏        | 31/270 [00:03<00:25,  9.35it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  12%|█▏        | 33/270 [00:03<00:24,  9.61it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  13%|█▎        | 35/270 [00:03<00:24,  9.73it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  14%|█▎        | 37/270 [00:04<00:22, 10.51it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  14%|█▍        | 39/270 [00:04<00:22, 10.42it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  15%|█▌        | 41/270 [00:04<00:22, 10.18it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  16%|█▌        | 43/270 [00:04<00:23,  9.53it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  17%|█▋        | 45/270 [00:04<00:22,  9.92it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  17%|█▋        | 47/270 [00:05<00:22,  9.94it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  18%|█▊        | 49/270 [00:05<00:22,  9.88it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  19%|█▊        | 50/270 [00:05<00:23,  9.49it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  19%|█▉        | 51/270 [00:05<00:24,  9.10it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  20%|█▉        | 53/270 [00:05<00:23,  9.43it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  20%|██        | 54/270 [00:05<00:22,  9.51it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  20%|██        | 55/270 [00:05<00:22,  9.61it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  21%|██        | 56/270 [00:06<00:23,  9.11it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  21%|██        | 57/270 [00:06<00:23,  8.90it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  21%|██▏       | 58/270 [00:06<00:24,  8.75it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  22%|██▏       | 59/270 [00:06<00:24,  8.73it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  23%|██▎       | 61/270 [00:06<00:22,  9.33it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  23%|██▎       | 62/270 [00:06<00:22,  9.05it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  23%|██▎       | 63/270 [00:06<00:23,  8.68it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  24%|██▍       | 65/270 [00:07<00:21,  9.69it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  24%|██▍       | 66/270 [00:07<00:20,  9.73it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  25%|██▍       | 67/270 [00:07<00:21,  9.40it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  26%|██▌       | 69/270 [00:07<00:19, 10.20it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  26%|██▋       | 71/270 [00:07<00:18, 10.76it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  27%|██▋       | 73/270 [00:07<00:18, 10.40it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  28%|██▊       | 75/270 [00:08<00:18, 10.45it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  29%|██▊       | 77/270 [00:08<00:18, 10.25it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  29%|██▉       | 79/270 [00:08<00:18, 10.30it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  30%|███       | 81/270 [00:08<00:19,  9.74it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  30%|███       | 82/270 [00:08<00:19,  9.55it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  31%|███       | 83/270 [00:08<00:19,  9.37it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  31%|███       | 84/270 [00:08<00:19,  9.35it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  31%|███▏      | 85/270 [00:09<00:20,  9.18it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  32%|███▏      | 87/270 [00:09<00:18,  9.70it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  33%|███▎      | 88/270 [00:09<00:19,  9.22it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  33%|███▎      | 89/270 [00:09<00:20,  9.02it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  33%|███▎      | 90/270 [00:09<00:19,  9.24it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  34%|███▎      | 91/270 [00:09<00:20,  8.78it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  34%|███▍      | 93/270 [00:09<00:18,  9.64it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  35%|███▌      | 95/270 [00:10<00:17, 10.07it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  36%|███▌      | 96/270 [00:10<00:17,  9.88it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  36%|███▌      | 97/270 [00:10<00:17,  9.85it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  36%|███▋      | 98/270 [00:10<00:17,  9.87it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  37%|███▋      | 99/270 [00:10<00:17,  9.82it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  37%|███▋      | 100/270 [00:10<00:18,  9.43it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  38%|███▊      | 102/270 [00:10<00:16, 10.29it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  39%|███▊      | 104/270 [00:11<00:16,  9.94it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  39%|███▉      | 105/270 [00:11<00:17,  9.35it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  40%|███▉      | 107/270 [00:11<00:16, 10.01it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  40%|████      | 108/270 [00:11<00:16,  9.58it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  41%|████      | 110/270 [00:11<00:15, 10.08it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  41%|████      | 111/270 [00:11<00:16,  9.66it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  41%|████▏     | 112/270 [00:11<00:16,  9.63it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  42%|████▏     | 114/270 [00:12<00:14, 10.44it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  43%|████▎     | 116/270 [00:12<00:16,  9.54it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  43%|████▎     | 117/270 [00:12<00:16,  9.14it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  44%|████▍     | 119/270 [00:12<00:15,  9.78it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  44%|████▍     | 120/270 [00:12<00:15,  9.60it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  45%|████▌     | 122/270 [00:12<00:14, 10.34it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  46%|████▌     | 124/270 [00:13<00:13, 10.54it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  47%|████▋     | 126/270 [00:13<00:14,  9.85it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  47%|████▋     | 127/270 [00:13<00:15,  9.34it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  47%|████▋     | 128/270 [00:13<00:15,  9.08it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  48%|████▊     | 129/270 [00:13<00:15,  8.90it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  49%|████▊     | 131/270 [00:13<00:14,  9.75it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  49%|████▉     | 132/270 [00:13<00:14,  9.27it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  50%|████▉     | 134/270 [00:14<00:14,  9.60it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  50%|█████     | 135/270 [00:14<00:14,  9.64it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  50%|█████     | 136/270 [00:14<00:14,  9.54it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  51%|█████     | 138/270 [00:14<00:13,  9.71it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  52%|█████▏    | 140/270 [00:14<00:13,  9.87it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  52%|█████▏    | 141/270 [00:14<00:13,  9.41it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  53%|█████▎    | 142/270 [00:15<00:14,  9.03it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  53%|█████▎    | 143/270 [00:15<00:14,  8.98it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  54%|█████▎    | 145/270 [00:15<00:13,  9.55it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  54%|█████▍    | 146/270 [00:15<00:13,  9.50it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  54%|█████▍    | 147/270 [00:15<00:13,  9.13it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  55%|█████▌    | 149/270 [00:15<00:12,  9.55it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  56%|█████▌    | 151/270 [00:15<00:12,  9.63it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  56%|█████▋    | 152/270 [00:16<00:12,  9.31it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  57%|█████▋    | 153/270 [00:16<00:12,  9.08it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  57%|█████▋    | 154/270 [00:16<00:12,  9.29it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  57%|█████▋    | 155/270 [00:16<00:12,  9.01it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  58%|█████▊    | 156/270 [00:16<00:13,  8.60it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  59%|█████▊    | 158/270 [00:16<00:11, 10.00it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  59%|█████▉    | 159/270 [00:16<00:11,  9.60it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  59%|█████▉    | 160/270 [00:16<00:12,  9.12it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  60%|█████▉    | 161/270 [00:17<00:11,  9.24it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  60%|██████    | 162/270 [00:17<00:11,  9.02it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  60%|██████    | 163/270 [00:17<00:12,  8.77it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  61%|██████    | 164/270 [00:17<00:12,  8.74it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  61%|██████    | 165/270 [00:17<00:12,  8.56it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  62%|██████▏   | 167/270 [00:17<00:10,  9.45it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  62%|██████▏   | 168/270 [00:17<00:11,  9.01it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  63%|██████▎   | 169/270 [00:17<00:11,  8.68it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  63%|██████▎   | 170/270 [00:18<00:11,  8.97it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  63%|██████▎   | 171/270 [00:18<00:11,  8.75it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  64%|██████▎   | 172/270 [00:18<00:11,  8.73it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  64%|██████▍   | 173/270 [00:18<00:11,  8.74it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  64%|██████▍   | 174/270 [00:18<00:11,  8.66it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  65%|██████▍   | 175/270 [00:18<00:11,  8.49it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  65%|██████▌   | 176/270 [00:18<00:11,  8.34it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  66%|██████▌   | 177/270 [00:18<00:11,  8.26it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  66%|██████▋   | 179/270 [00:19<00:10,  9.04it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  67%|██████▋   | 180/270 [00:19<00:10,  8.77it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  67%|██████▋   | 181/270 [00:19<00:09,  9.02it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  67%|██████▋   | 182/270 [00:19<00:10,  8.63it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  68%|██████▊   | 184/270 [00:19<00:09,  9.08it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  69%|██████▊   | 185/270 [00:19<00:09,  8.74it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  69%|██████▉   | 187/270 [00:20<00:08,  9.23it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  70%|██████▉   | 188/270 [00:20<00:09,  8.88it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  70%|███████   | 190/270 [00:20<00:08,  9.87it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  71%|███████   | 192/270 [00:20<00:07,  9.86it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  71%|███████▏  | 193/270 [00:20<00:07,  9.88it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  72%|███████▏  | 194/270 [00:20<00:07,  9.55it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  72%|███████▏  | 195/270 [00:20<00:08,  9.25it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  73%|███████▎  | 196/270 [00:20<00:08,  8.87it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  73%|███████▎  | 198/270 [00:21<00:07,  9.23it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  74%|███████▎  | 199/270 [00:21<00:07,  8.96it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  74%|███████▍  | 200/270 [00:21<00:07,  8.77it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  74%|███████▍  | 201/270 [00:21<00:07,  8.63it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  75%|███████▍  | 202/270 [00:21<00:08,  8.34it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  76%|███████▌  | 204/270 [00:21<00:06,  9.60it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  76%|███████▋  | 206/270 [00:22<00:06, 10.01it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  77%|███████▋  | 207/270 [00:22<00:06,  9.70it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  77%|███████▋  | 208/270 [00:22<00:06,  9.34it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  77%|███████▋  | 209/270 [00:22<00:06,  8.72it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  78%|███████▊  | 210/270 [00:22<00:06,  8.64it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  78%|███████▊  | 211/270 [00:22<00:06,  8.91it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  79%|███████▊  | 212/270 [00:22<00:06,  8.83it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  79%|███████▉  | 214/270 [00:22<00:05,  9.74it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  80%|████████  | 216/270 [00:23<00:05,  9.80it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  80%|████████  | 217/270 [00:23<00:05,  9.80it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  81%|████████  | 219/270 [00:23<00:05, 10.04it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  81%|████████▏ | 220/270 [00:23<00:05,  9.98it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  82%|████████▏ | 222/270 [00:23<00:04, 10.73it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  83%|████████▎ | 224/270 [00:23<00:04, 10.82it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  84%|████████▎ | 226/270 [00:24<00:03, 11.07it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  84%|████████▍ | 228/270 [00:24<00:04, 10.17it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  85%|████████▌ | 230/270 [00:24<00:04,  9.56it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  86%|████████▌ | 231/270 [00:24<00:04,  9.30it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  86%|████████▋ | 233/270 [00:24<00:03,  9.94it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  87%|████████▋ | 234/270 [00:24<00:03,  9.94it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  87%|████████▋ | 236/270 [00:25<00:03, 10.17it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  88%|████████▊ | 238/270 [00:25<00:03, 10.53it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  89%|████████▉ | 240/270 [00:25<00:03,  9.70it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  89%|████████▉ | 241/270 [00:25<00:03,  9.26it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  90%|█████████ | 243/270 [00:25<00:02, 10.13it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  91%|█████████ | 245/270 [00:26<00:02,  9.56it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  91%|█████████ | 246/270 [00:26<00:02,  9.12it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  91%|█████████▏| 247/270 [00:26<00:02,  8.81it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  92%|█████████▏| 248/270 [00:26<00:02,  8.66it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  92%|█████████▏| 249/270 [00:26<00:02,  8.45it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  93%|█████████▎| 250/270 [00:26<00:02,  8.23it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  93%|█████████▎| 251/270 [00:26<00:02,  8.27it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  93%|█████████▎| 252/270 [00:26<00:02,  8.34it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  94%|█████████▎| 253/270 [00:27<00:02,  8.30it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  94%|█████████▍| 254/270 [00:27<00:01,  8.36it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  94%|█████████▍| 255/270 [00:27<00:01,  8.25it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  95%|█████████▍| 256/270 [00:27<00:01,  8.26it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  95%|█████████▌| 257/270 [00:27<00:01,  8.65it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  96%|█████████▌| 259/270 [00:27<00:01,  9.54it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  96%|█████████▋| 260/270 [00:27<00:01,  9.46it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  97%|█████████▋| 261/270 [00:27<00:00,  9.56it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  97%|█████████▋| 262/270 [00:27<00:00,  9.25it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  97%|█████████▋| 263/270 [00:28<00:00,  8.86it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  98%|█████████▊| 264/270 [00:28<00:00,  8.72it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  98%|█████████▊| 265/270 [00:28<00:00,  8.55it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  99%|█████████▊| 266/270 [00:28<00:00,  8.48it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  99%|█████████▉| 268/270 [00:28<00:00,  9.02it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation: 100%|█████████▉| 269/270 [00:28<00:00,  8.79it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation: 100%|██████████| 270/270 [00:29<00:00,  9.28it/s]\n",
            "\n",
            "Training:  17%|█▋        | 300/1772 [03:31<4:01:33,  9.85s/it, running training loss:  0.96181]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            ">>> training loss: 1.014281, valid loss: 0.659372,valid f1: 0.149620, valid acc:0.662882\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  17%|█▋        | 300/1772 [03:32<4:01:33,  9.85s/it, running training loss:  1.03479]\u001b[A\n",
            "Training:  17%|█▋        | 301/1772 [03:32<2:53:40,  7.08s/it, running training loss:  1.03479]\u001b[A\n",
            "Training:  17%|█▋        | 301/1772 [03:32<2:53:40,  7.08s/it, running training loss:  1.11946]\u001b[A\n",
            "Training:  17%|█▋        | 302/1772 [03:32<2:05:43,  5.13s/it, running training loss:  1.11946]\u001b[A\n",
            "Training:  17%|█▋        | 302/1772 [03:33<2:05:43,  5.13s/it, running training loss:  0.97609]\u001b[A\n",
            "Training:  17%|█▋        | 303/1772 [03:33<1:31:32,  3.74s/it, running training loss:  0.97609]\u001b[A\n",
            "Training:  17%|█▋        | 303/1772 [03:33<1:31:32,  3.74s/it, running training loss:  0.93772]\u001b[A\n",
            "Training:  17%|█▋        | 304/1772 [03:33<1:07:49,  2.77s/it, running training loss:  0.93772]\u001b[A\n",
            "Training:  17%|█▋        | 304/1772 [03:34<1:07:49,  2.77s/it, running training loss:  0.93629]\u001b[A\n",
            "Training:  17%|█▋        | 305/1772 [03:34<51:11,  2.09s/it, running training loss:  0.93629]  \u001b[A\n",
            "Training:  17%|█▋        | 305/1772 [03:34<51:11,  2.09s/it, running training loss:  0.98902]\u001b[A\n",
            "Training:  17%|█▋        | 306/1772 [03:34<39:47,  1.63s/it, running training loss:  0.98902]\u001b[A\n",
            "Training:  17%|█▋        | 306/1772 [03:35<39:47,  1.63s/it, running training loss:  1.01871]\u001b[A\n",
            "Training:  17%|█▋        | 307/1772 [03:35<32:58,  1.35s/it, running training loss:  1.01871]\u001b[A\n",
            "Training:  17%|█▋        | 307/1772 [03:36<32:58,  1.35s/it, running training loss:  0.84926]\u001b[A\n",
            "Training:  17%|█▋        | 308/1772 [03:36<27:28,  1.13s/it, running training loss:  0.84926]\u001b[A\n",
            "Training:  17%|█▋        | 308/1772 [03:36<27:28,  1.13s/it, running training loss:  0.91644]\u001b[A\n",
            "Training:  17%|█▋        | 309/1772 [03:36<22:56,  1.06it/s, running training loss:  0.91644]\u001b[A\n",
            "Training:  17%|█▋        | 309/1772 [03:37<22:56,  1.06it/s, running training loss:  1.06689]\u001b[A\n",
            "Training:  17%|█▋        | 310/1772 [03:37<19:40,  1.24it/s, running training loss:  1.06689]\u001b[A\n",
            "Training:  17%|█▋        | 310/1772 [03:37<19:40,  1.24it/s, running training loss:  0.99248]\u001b[A\n",
            "Training:  18%|█▊        | 311/1772 [03:37<17:24,  1.40it/s, running training loss:  0.99248]\u001b[A\n",
            "Training:  18%|█▊        | 311/1772 [03:38<17:24,  1.40it/s, running training loss:  0.99449]\u001b[A\n",
            "Training:  18%|█▊        | 312/1772 [03:38<16:42,  1.46it/s, running training loss:  0.99449]\u001b[A\n",
            "Training:  18%|█▊        | 312/1772 [03:39<16:42,  1.46it/s, running training loss:  0.97633]\u001b[A\n",
            "Training:  18%|█▊        | 313/1772 [03:39<17:42,  1.37it/s, running training loss:  0.97633]\u001b[A\n",
            "Training:  18%|█▊        | 313/1772 [03:40<17:42,  1.37it/s, running training loss:  1.02592]\u001b[A\n",
            "Training:  18%|█▊        | 314/1772 [03:40<18:02,  1.35it/s, running training loss:  1.02592]\u001b[A\n",
            "Training:  18%|█▊        | 314/1772 [03:40<18:02,  1.35it/s, running training loss:  0.92033]\u001b[A\n",
            "Training:  18%|█▊        | 315/1772 [03:40<16:24,  1.48it/s, running training loss:  0.92033]\u001b[A\n",
            "Training:  18%|█▊        | 315/1772 [03:41<16:24,  1.48it/s, running training loss:  1.01893]\u001b[A\n",
            "Training:  18%|█▊        | 316/1772 [03:41<16:49,  1.44it/s, running training loss:  1.01893]\u001b[A\n",
            "Training:  18%|█▊        | 316/1772 [03:41<16:49,  1.44it/s, running training loss:  1.00366]\u001b[A\n",
            "Training:  18%|█▊        | 317/1772 [03:41<15:19,  1.58it/s, running training loss:  1.00366]\u001b[A\n",
            "Training:  18%|█▊        | 317/1772 [03:42<15:19,  1.58it/s, running training loss:  0.90238]\u001b[A\n",
            "Training:  18%|█▊        | 318/1772 [03:42<16:16,  1.49it/s, running training loss:  0.90238]\u001b[A\n",
            "Training:  18%|█▊        | 318/1772 [03:43<16:16,  1.49it/s, running training loss:  0.91833]\u001b[A\n",
            "Training:  18%|█▊        | 319/1772 [03:43<15:58,  1.52it/s, running training loss:  0.91833]\u001b[A\n",
            "Training:  18%|█▊        | 319/1772 [03:43<15:58,  1.52it/s, running training loss:  1.05691]\u001b[A\n",
            "Training:  18%|█▊        | 320/1772 [03:43<15:50,  1.53it/s, running training loss:  1.05691]\u001b[A\n",
            "Training:  18%|█▊        | 320/1772 [03:44<15:50,  1.53it/s, running training loss:  0.94964]\u001b[A\n",
            "Training:  18%|█▊        | 321/1772 [03:44<14:50,  1.63it/s, running training loss:  0.94964]\u001b[A\n",
            "Training:  18%|█▊        | 321/1772 [03:45<14:50,  1.63it/s, running training loss:  0.93340]\u001b[A\n",
            "Training:  18%|█▊        | 322/1772 [03:45<16:02,  1.51it/s, running training loss:  0.93340]\u001b[A\n",
            "Training:  18%|█▊        | 322/1772 [03:45<16:02,  1.51it/s, running training loss:  1.03793]\u001b[A\n",
            "Training:  18%|█▊        | 323/1772 [03:45<14:57,  1.61it/s, running training loss:  1.03793]\u001b[A\n",
            "Training:  18%|█▊        | 323/1772 [03:46<14:57,  1.61it/s, running training loss:  1.05161]\u001b[A\n",
            "Training:  18%|█▊        | 324/1772 [03:46<14:49,  1.63it/s, running training loss:  1.05161]\u001b[A\n",
            "Training:  18%|█▊        | 324/1772 [03:46<14:49,  1.63it/s, running training loss:  0.94226]\u001b[A\n",
            "Training:  18%|█▊        | 325/1772 [03:46<14:43,  1.64it/s, running training loss:  0.94226]\u001b[A\n",
            "Training:  18%|█▊        | 325/1772 [03:47<14:43,  1.64it/s, running training loss:  1.00689]\u001b[A\n",
            "Training:  18%|█▊        | 326/1772 [03:47<13:23,  1.80it/s, running training loss:  1.00689]\u001b[A\n",
            "Training:  18%|█▊        | 326/1772 [03:47<13:23,  1.80it/s, running training loss:  0.89153]\u001b[A\n",
            "Training:  18%|█▊        | 327/1772 [03:47<13:52,  1.74it/s, running training loss:  0.89153]\u001b[A\n",
            "Training:  18%|█▊        | 327/1772 [03:48<13:52,  1.74it/s, running training loss:  1.03061]\u001b[A\n",
            "Training:  19%|█▊        | 328/1772 [03:48<13:46,  1.75it/s, running training loss:  1.03061]\u001b[A\n",
            "Training:  19%|█▊        | 328/1772 [03:48<13:46,  1.75it/s, running training loss:  1.06573]\u001b[A\n",
            "Training:  19%|█▊        | 329/1772 [03:48<13:25,  1.79it/s, running training loss:  1.06573]\u001b[A\n",
            "Training:  19%|█▊        | 329/1772 [03:49<13:25,  1.79it/s, running training loss:  1.17922]\u001b[A\n",
            "Training:  19%|█▊        | 330/1772 [03:49<13:20,  1.80it/s, running training loss:  1.17922]\u001b[A\n",
            "Training:  19%|█▊        | 330/1772 [03:50<13:20,  1.80it/s, running training loss:  0.98379]\u001b[A\n",
            "Training:  19%|█▊        | 331/1772 [03:50<13:30,  1.78it/s, running training loss:  0.98379]\u001b[A\n",
            "Training:  19%|█▊        | 331/1772 [03:50<13:30,  1.78it/s, running training loss:  1.05364]\u001b[A\n",
            "Training:  19%|█▊        | 332/1772 [03:50<13:50,  1.73it/s, running training loss:  1.05364]\u001b[A\n",
            "Training:  19%|█▊        | 332/1772 [03:51<13:50,  1.73it/s, running training loss:  1.07092]\u001b[A\n",
            "Training:  19%|█▉        | 333/1772 [03:51<14:39,  1.64it/s, running training loss:  1.07092]\u001b[A\n",
            "Training:  19%|█▉        | 333/1772 [03:52<14:39,  1.64it/s, running training loss:  1.02465]\u001b[A\n",
            "Training:  19%|█▉        | 334/1772 [03:52<16:51,  1.42it/s, running training loss:  1.02465]\u001b[A\n",
            "Training:  19%|█▉        | 334/1772 [03:53<16:51,  1.42it/s, running training loss:  1.11107]\u001b[A\n",
            "Training:  19%|█▉        | 335/1772 [03:53<17:44,  1.35it/s, running training loss:  1.11107]\u001b[A\n",
            "Training:  19%|█▉        | 335/1772 [03:53<17:44,  1.35it/s, running training loss:  0.98743]\u001b[A\n",
            "Training:  19%|█▉        | 336/1772 [03:53<16:18,  1.47it/s, running training loss:  0.98743]\u001b[A\n",
            "Training:  19%|█▉        | 336/1772 [03:54<16:18,  1.47it/s, running training loss:  0.95460]\u001b[A\n",
            "Training:  19%|█▉        | 337/1772 [03:54<15:24,  1.55it/s, running training loss:  0.95460]\u001b[A\n",
            "Training:  19%|█▉        | 337/1772 [03:54<15:24,  1.55it/s, running training loss:  0.90004]\u001b[A\n",
            "Training:  19%|█▉        | 338/1772 [03:54<14:35,  1.64it/s, running training loss:  0.90004]\u001b[A\n",
            "Training:  19%|█▉        | 338/1772 [03:55<14:35,  1.64it/s, running training loss:  0.93579]\u001b[A\n",
            "Training:  19%|█▉        | 339/1772 [03:55<15:57,  1.50it/s, running training loss:  0.93579]\u001b[A\n",
            "Training:  19%|█▉        | 339/1772 [03:56<15:57,  1.50it/s, running training loss:  1.10012]\u001b[A\n",
            "Training:  19%|█▉        | 340/1772 [03:56<17:32,  1.36it/s, running training loss:  1.10012]\u001b[A\n",
            "Training:  19%|█▉        | 340/1772 [03:57<17:32,  1.36it/s, running training loss:  0.99470]\u001b[A\n",
            "Training:  19%|█▉        | 341/1772 [03:57<19:13,  1.24it/s, running training loss:  0.99470]\u001b[A\n",
            "Training:  19%|█▉        | 341/1772 [03:58<19:13,  1.24it/s, running training loss:  1.11679]\u001b[A\n",
            "Training:  19%|█▉        | 342/1772 [03:58<18:41,  1.28it/s, running training loss:  1.11679]\u001b[A\n",
            "Training:  19%|█▉        | 342/1772 [03:58<18:41,  1.28it/s, running training loss:  0.89463]\u001b[A\n",
            "Training:  19%|█▉        | 343/1772 [03:58<16:38,  1.43it/s, running training loss:  0.89463]\u001b[A\n",
            "Training:  19%|█▉        | 343/1772 [03:59<16:38,  1.43it/s, running training loss:  1.02345]\u001b[A\n",
            "Training:  19%|█▉        | 344/1772 [03:59<18:46,  1.27it/s, running training loss:  1.02345]\u001b[A\n",
            "Training:  19%|█▉        | 344/1772 [04:00<18:46,  1.27it/s, running training loss:  1.17005]\u001b[A\n",
            "Training:  19%|█▉        | 345/1772 [04:00<16:43,  1.42it/s, running training loss:  1.17005]\u001b[A\n",
            "Training:  19%|█▉        | 345/1772 [04:00<16:43,  1.42it/s, running training loss:  0.87849]\u001b[A\n",
            "Training:  20%|█▉        | 346/1772 [04:00<15:39,  1.52it/s, running training loss:  0.87849]\u001b[A\n",
            "Training:  20%|█▉        | 346/1772 [04:01<15:39,  1.52it/s, running training loss:  1.02351]\u001b[A\n",
            "Training:  20%|█▉        | 347/1772 [04:01<14:50,  1.60it/s, running training loss:  1.02351]\u001b[A\n",
            "Training:  20%|█▉        | 347/1772 [04:01<14:50,  1.60it/s, running training loss:  0.90112]\u001b[A\n",
            "Training:  20%|█▉        | 348/1772 [04:01<15:04,  1.57it/s, running training loss:  0.90112]\u001b[A\n",
            "Training:  20%|█▉        | 348/1772 [04:02<15:04,  1.57it/s, running training loss:  0.95968]\u001b[A\n",
            "Training:  20%|█▉        | 349/1772 [04:02<14:12,  1.67it/s, running training loss:  0.95968]\u001b[A\n",
            "Training:  20%|█▉        | 349/1772 [04:02<14:12,  1.67it/s, running training loss:  0.87869]\u001b[A\n",
            "Training:  20%|█▉        | 350/1772 [04:02<13:43,  1.73it/s, running training loss:  0.87869]\u001b[A\n",
            "Training:  20%|█▉        | 350/1772 [04:03<13:43,  1.73it/s, running training loss:  1.06104]\u001b[A\n",
            "Training:  20%|█▉        | 351/1772 [04:03<13:43,  1.73it/s, running training loss:  1.06104]\u001b[A\n",
            "Training:  20%|█▉        | 351/1772 [04:04<13:43,  1.73it/s, running training loss:  0.97689]\u001b[A\n",
            "Training:  20%|█▉        | 352/1772 [04:04<14:01,  1.69it/s, running training loss:  0.97689]\u001b[A\n",
            "Training:  20%|█▉        | 352/1772 [04:04<14:01,  1.69it/s, running training loss:  0.93664]\u001b[A\n",
            "Training:  20%|█▉        | 353/1772 [04:04<13:25,  1.76it/s, running training loss:  0.93664]\u001b[A\n",
            "Training:  20%|█▉        | 353/1772 [04:05<13:25,  1.76it/s, running training loss:  1.01204]\u001b[A\n",
            "Training:  20%|█▉        | 354/1772 [04:05<13:46,  1.72it/s, running training loss:  1.01204]\u001b[A\n",
            "Training:  20%|█▉        | 354/1772 [04:05<13:46,  1.72it/s, running training loss:  1.07395]\u001b[A\n",
            "Training:  20%|██        | 355/1772 [04:05<14:02,  1.68it/s, running training loss:  1.07395]\u001b[A\n",
            "Training:  20%|██        | 355/1772 [04:06<14:02,  1.68it/s, running training loss:  1.08584]\u001b[A\n",
            "Training:  20%|██        | 356/1772 [04:06<14:15,  1.66it/s, running training loss:  1.08584]\u001b[A\n",
            "Training:  20%|██        | 356/1772 [04:07<14:15,  1.66it/s, running training loss:  0.92068]\u001b[A\n",
            "Training:  20%|██        | 357/1772 [04:07<13:23,  1.76it/s, running training loss:  0.92068]\u001b[A\n",
            "Training:  20%|██        | 357/1772 [04:07<13:23,  1.76it/s, running training loss:  0.98086]\u001b[A\n",
            "Training:  20%|██        | 358/1772 [04:07<14:06,  1.67it/s, running training loss:  0.98086]\u001b[A\n",
            "Training:  20%|██        | 358/1772 [04:08<14:06,  1.67it/s, running training loss:  1.05328]\u001b[A\n",
            "Training:  20%|██        | 359/1772 [04:08<14:25,  1.63it/s, running training loss:  1.05328]\u001b[A\n",
            "Training:  20%|██        | 359/1772 [04:08<14:25,  1.63it/s, running training loss:  0.89317]\u001b[A\n",
            "Training:  20%|██        | 360/1772 [04:08<14:29,  1.62it/s, running training loss:  0.89317]\u001b[A\n",
            "Training:  20%|██        | 360/1772 [04:09<14:29,  1.62it/s, running training loss:  0.97586]\u001b[A\n",
            "Training:  20%|██        | 361/1772 [04:09<14:06,  1.67it/s, running training loss:  0.97586]\u001b[A\n",
            "Training:  20%|██        | 361/1772 [04:10<14:06,  1.67it/s, running training loss:  1.04940]\u001b[A\n",
            "Training:  20%|██        | 362/1772 [04:10<14:02,  1.67it/s, running training loss:  1.04940]\u001b[A\n",
            "Training:  20%|██        | 362/1772 [04:10<14:02,  1.67it/s, running training loss:  1.14966]\u001b[A\n",
            "Training:  20%|██        | 363/1772 [04:10<13:13,  1.78it/s, running training loss:  1.14966]\u001b[A\n",
            "Training:  20%|██        | 363/1772 [04:11<13:13,  1.78it/s, running training loss:  1.18578]\u001b[A\n",
            "Training:  21%|██        | 364/1772 [04:11<13:41,  1.71it/s, running training loss:  1.18578]\u001b[A\n",
            "Training:  21%|██        | 364/1772 [04:11<13:41,  1.71it/s, running training loss:  1.01210]\u001b[A\n",
            "Training:  21%|██        | 365/1772 [04:11<12:42,  1.85it/s, running training loss:  1.01210]\u001b[A\n",
            "Training:  21%|██        | 365/1772 [04:12<12:42,  1.85it/s, running training loss:  0.96302]\u001b[A\n",
            "Training:  21%|██        | 366/1772 [04:12<12:40,  1.85it/s, running training loss:  0.96302]\u001b[A\n",
            "Training:  21%|██        | 366/1772 [04:12<12:40,  1.85it/s, running training loss:  0.88225]\u001b[A\n",
            "Training:  21%|██        | 367/1772 [04:12<13:15,  1.77it/s, running training loss:  0.88225]\u001b[A\n",
            "Training:  21%|██        | 367/1772 [04:13<13:15,  1.77it/s, running training loss:  0.86911]\u001b[A\n",
            "Training:  21%|██        | 368/1772 [04:13<12:24,  1.89it/s, running training loss:  0.86911]\u001b[A\n",
            "Training:  21%|██        | 368/1772 [04:13<12:24,  1.89it/s, running training loss:  0.99836]\u001b[A\n",
            "Training:  21%|██        | 369/1772 [04:13<12:56,  1.81it/s, running training loss:  0.99836]\u001b[A\n",
            "Training:  21%|██        | 369/1772 [04:14<12:56,  1.81it/s, running training loss:  1.11503]\u001b[A\n",
            "Training:  21%|██        | 370/1772 [04:14<12:45,  1.83it/s, running training loss:  1.11503]\u001b[A\n",
            "Training:  21%|██        | 370/1772 [04:14<12:45,  1.83it/s, running training loss:  1.02500]\u001b[A\n",
            "Training:  21%|██        | 371/1772 [04:14<12:40,  1.84it/s, running training loss:  1.02500]\u001b[A\n",
            "Training:  21%|██        | 371/1772 [04:15<12:40,  1.84it/s, running training loss:  0.98057]\u001b[A\n",
            "Training:  21%|██        | 372/1772 [04:15<12:41,  1.84it/s, running training loss:  0.98057]\u001b[A\n",
            "Training:  21%|██        | 372/1772 [04:16<12:41,  1.84it/s, running training loss:  0.88838]\u001b[A\n",
            "Training:  21%|██        | 373/1772 [04:16<12:36,  1.85it/s, running training loss:  0.88838]\u001b[A\n",
            "Training:  21%|██        | 373/1772 [04:16<12:36,  1.85it/s, running training loss:  1.36500]\u001b[A\n",
            "Training:  21%|██        | 374/1772 [04:16<13:31,  1.72it/s, running training loss:  1.36500]\u001b[A\n",
            "Training:  21%|██        | 374/1772 [04:17<13:31,  1.72it/s, running training loss:  0.92945]\u001b[A\n",
            "Training:  21%|██        | 375/1772 [04:17<13:03,  1.78it/s, running training loss:  0.92945]\u001b[A\n",
            "Training:  21%|██        | 375/1772 [04:17<13:03,  1.78it/s, running training loss:  0.89388]\u001b[A\n",
            "Training:  21%|██        | 376/1772 [04:17<13:18,  1.75it/s, running training loss:  0.89388]\u001b[A\n",
            "Training:  21%|██        | 376/1772 [04:18<13:18,  1.75it/s, running training loss:  1.03929]\u001b[A\n",
            "Training:  21%|██▏       | 377/1772 [04:18<13:04,  1.78it/s, running training loss:  1.03929]\u001b[A\n",
            "Training:  21%|██▏       | 377/1772 [04:18<13:04,  1.78it/s, running training loss:  0.97472]\u001b[A\n",
            "Training:  21%|██▏       | 378/1772 [04:18<13:00,  1.79it/s, running training loss:  0.97472]\u001b[A\n",
            "Training:  21%|██▏       | 378/1772 [04:19<13:00,  1.79it/s, running training loss:  0.93834]\u001b[A\n",
            "Training:  21%|██▏       | 379/1772 [04:19<15:22,  1.51it/s, running training loss:  0.93834]\u001b[A\n",
            "Training:  21%|██▏       | 379/1772 [04:20<15:22,  1.51it/s, running training loss:  0.98272]\u001b[A\n",
            "Training:  21%|██▏       | 380/1772 [04:20<14:45,  1.57it/s, running training loss:  0.98272]\u001b[A\n",
            "Training:  21%|██▏       | 380/1772 [04:21<14:45,  1.57it/s, running training loss:  0.97257]\u001b[A\n",
            "Training:  22%|██▏       | 381/1772 [04:21<16:04,  1.44it/s, running training loss:  0.97257]\u001b[A\n",
            "Training:  22%|██▏       | 381/1772 [04:21<16:04,  1.44it/s, running training loss:  0.98358]\u001b[A\n",
            "Training:  22%|██▏       | 382/1772 [04:21<14:55,  1.55it/s, running training loss:  0.98358]\u001b[A\n",
            "Training:  22%|██▏       | 382/1772 [04:22<14:55,  1.55it/s, running training loss:  1.10279]\u001b[A\n",
            "Training:  22%|██▏       | 383/1772 [04:22<14:42,  1.57it/s, running training loss:  1.10279]\u001b[A\n",
            "Training:  22%|██▏       | 383/1772 [04:22<14:42,  1.57it/s, running training loss:  1.01828]\u001b[A\n",
            "Training:  22%|██▏       | 384/1772 [04:22<14:31,  1.59it/s, running training loss:  1.01828]\u001b[A\n",
            "Training:  22%|██▏       | 384/1772 [04:23<14:31,  1.59it/s, running training loss:  1.04083]\u001b[A\n",
            "Training:  22%|██▏       | 385/1772 [04:23<14:52,  1.55it/s, running training loss:  1.04083]\u001b[A\n",
            "Training:  22%|██▏       | 385/1772 [04:24<14:52,  1.55it/s, running training loss:  0.87268]\u001b[A\n",
            "Training:  22%|██▏       | 386/1772 [04:24<14:06,  1.64it/s, running training loss:  0.87268]\u001b[A\n",
            "Training:  22%|██▏       | 386/1772 [04:24<14:06,  1.64it/s, running training loss:  1.16828]\u001b[A\n",
            "Training:  22%|██▏       | 387/1772 [04:24<13:15,  1.74it/s, running training loss:  1.16828]\u001b[A\n",
            "Training:  22%|██▏       | 387/1772 [04:25<13:15,  1.74it/s, running training loss:  0.97301]\u001b[A\n",
            "Training:  22%|██▏       | 388/1772 [04:25<13:01,  1.77it/s, running training loss:  0.97301]\u001b[A\n",
            "Training:  22%|██▏       | 388/1772 [04:25<13:01,  1.77it/s, running training loss:  0.91467]\u001b[A\n",
            "Training:  22%|██▏       | 389/1772 [04:25<13:40,  1.69it/s, running training loss:  0.91467]\u001b[A\n",
            "Training:  22%|██▏       | 389/1772 [04:26<13:40,  1.69it/s, running training loss:  0.87113]\u001b[A\n",
            "Training:  22%|██▏       | 390/1772 [04:26<13:08,  1.75it/s, running training loss:  0.87113]\u001b[A\n",
            "Training:  22%|██▏       | 390/1772 [04:27<13:08,  1.75it/s, running training loss:  1.13577]\u001b[A\n",
            "Training:  22%|██▏       | 391/1772 [04:27<13:47,  1.67it/s, running training loss:  1.13577]\u001b[A\n",
            "Training:  22%|██▏       | 391/1772 [04:27<13:47,  1.67it/s, running training loss:  1.24331]\u001b[A\n",
            "Training:  22%|██▏       | 392/1772 [04:27<13:02,  1.76it/s, running training loss:  1.24331]\u001b[A\n",
            "Training:  22%|██▏       | 392/1772 [04:28<13:02,  1.76it/s, running training loss:  0.92185]\u001b[A\n",
            "Training:  22%|██▏       | 393/1772 [04:28<13:03,  1.76it/s, running training loss:  0.92185]\u001b[A\n",
            "Training:  22%|██▏       | 393/1772 [04:28<13:03,  1.76it/s, running training loss:  1.15535]\u001b[A\n",
            "Training:  22%|██▏       | 394/1772 [04:28<12:40,  1.81it/s, running training loss:  1.15535]\u001b[A\n",
            "Training:  22%|██▏       | 394/1772 [04:29<12:40,  1.81it/s, running training loss:  0.98584]\u001b[A\n",
            "Training:  22%|██▏       | 395/1772 [04:29<13:10,  1.74it/s, running training loss:  0.98584]\u001b[A\n",
            "Training:  22%|██▏       | 395/1772 [04:29<13:10,  1.74it/s, running training loss:  0.89041]\u001b[A\n",
            "Training:  22%|██▏       | 396/1772 [04:29<13:58,  1.64it/s, running training loss:  0.89041]\u001b[A\n",
            "Training:  22%|██▏       | 396/1772 [04:30<13:58,  1.64it/s, running training loss:  1.04084]\u001b[A\n",
            "Training:  22%|██▏       | 397/1772 [04:30<14:09,  1.62it/s, running training loss:  1.04084]\u001b[A\n",
            "Training:  22%|██▏       | 397/1772 [04:31<14:09,  1.62it/s, running training loss:  1.20164]\u001b[A\n",
            "Training:  22%|██▏       | 398/1772 [04:31<14:03,  1.63it/s, running training loss:  1.20164]\u001b[A\n",
            "Training:  22%|██▏       | 398/1772 [04:31<14:03,  1.63it/s, running training loss:  1.84771]\u001b[A\n",
            "Training:  23%|██▎       | 399/1772 [04:31<13:13,  1.73it/s, running training loss:  1.84771]\u001b[A\n",
            "Training:  23%|██▎       | 399/1772 [04:32<13:13,  1.73it/s, running training loss:  1.19239]\u001b[A\n",
            "Training:  23%|██▎       | 400/1772 [04:32<12:44,  1.79it/s, running training loss:  1.19239]\u001b[A\n",
            "Training:  23%|██▎       | 400/1772 [04:32<12:44,  1.79it/s, running training loss:  1.06579]\u001b[A\n",
            "Training:  23%|██▎       | 401/1772 [04:32<12:00,  1.90it/s, running training loss:  1.06579]\u001b[A\n",
            "Training:  23%|██▎       | 401/1772 [04:33<12:00,  1.90it/s, running training loss:  1.33079]\u001b[A\n",
            "Training:  23%|██▎       | 402/1772 [04:33<12:54,  1.77it/s, running training loss:  1.33079]\u001b[A\n",
            "Training:  23%|██▎       | 402/1772 [04:33<12:54,  1.77it/s, running training loss:  1.44370]\u001b[A\n",
            "Training:  23%|██▎       | 403/1772 [04:33<12:29,  1.83it/s, running training loss:  1.44370]\u001b[A\n",
            "Training:  23%|██▎       | 403/1772 [04:34<12:29,  1.83it/s, running training loss:  1.38842]\u001b[A\n",
            "Training:  23%|██▎       | 404/1772 [04:34<12:23,  1.84it/s, running training loss:  1.38842]\u001b[A\n",
            "Training:  23%|██▎       | 404/1772 [04:34<12:23,  1.84it/s, running training loss:  1.12276]\u001b[A\n",
            "Training:  23%|██▎       | 405/1772 [04:34<12:28,  1.83it/s, running training loss:  1.12276]\u001b[A\n",
            "Training:  23%|██▎       | 405/1772 [04:35<12:28,  1.83it/s, running training loss:  1.17216]\u001b[A\n",
            "Training:  23%|██▎       | 406/1772 [04:35<14:31,  1.57it/s, running training loss:  1.17216]\u001b[A\n",
            "Training:  23%|██▎       | 406/1772 [04:36<14:31,  1.57it/s, running training loss:  1.06218]\u001b[A\n",
            "Training:  23%|██▎       | 407/1772 [04:36<13:45,  1.65it/s, running training loss:  1.06218]\u001b[A\n",
            "Training:  23%|██▎       | 407/1772 [04:36<13:45,  1.65it/s, running training loss:  0.98052]\u001b[A\n",
            "Training:  23%|██▎       | 408/1772 [04:36<13:40,  1.66it/s, running training loss:  0.98052]\u001b[A\n",
            "Training:  23%|██▎       | 408/1772 [04:37<13:40,  1.66it/s, running training loss:  1.22156]\u001b[A\n",
            "Training:  23%|██▎       | 409/1772 [04:37<12:44,  1.78it/s, running training loss:  1.22156]\u001b[A\n",
            "Training:  23%|██▎       | 409/1772 [04:37<12:44,  1.78it/s, running training loss:  1.12799]\u001b[A\n",
            "Training:  23%|██▎       | 410/1772 [04:37<12:28,  1.82it/s, running training loss:  1.12799]\u001b[A\n",
            "Training:  23%|██▎       | 410/1772 [04:38<12:28,  1.82it/s, running training loss:  0.81414]\u001b[A\n",
            "Training:  23%|██▎       | 411/1772 [04:38<14:35,  1.56it/s, running training loss:  0.81414]\u001b[A\n",
            "Training:  23%|██▎       | 411/1772 [04:39<14:35,  1.56it/s, running training loss:  1.02084]\u001b[A\n",
            "Training:  23%|██▎       | 412/1772 [04:39<13:30,  1.68it/s, running training loss:  1.02084]\u001b[A\n",
            "Training:  23%|██▎       | 412/1772 [04:39<13:30,  1.68it/s, running training loss:  0.93119]\u001b[A\n",
            "Training:  23%|██▎       | 413/1772 [04:39<13:46,  1.64it/s, running training loss:  0.93119]\u001b[A\n",
            "Training:  23%|██▎       | 413/1772 [04:40<13:46,  1.64it/s, running training loss:  1.04995]\u001b[A\n",
            "Training:  23%|██▎       | 414/1772 [04:40<13:12,  1.71it/s, running training loss:  1.04995]\u001b[A\n",
            "Training:  23%|██▎       | 414/1772 [04:40<13:12,  1.71it/s, running training loss:  1.09714]\u001b[A\n",
            "Training:  23%|██▎       | 415/1772 [04:41<13:21,  1.69it/s, running training loss:  1.09714]\u001b[A\n",
            "Training:  23%|██▎       | 415/1772 [04:41<13:21,  1.69it/s, running training loss:  0.95842]\u001b[A\n",
            "Training:  23%|██▎       | 416/1772 [04:41<13:12,  1.71it/s, running training loss:  0.95842]\u001b[A\n",
            "Training:  23%|██▎       | 416/1772 [04:42<13:12,  1.71it/s, running training loss:  0.90571]\u001b[A\n",
            "Training:  24%|██▎       | 417/1772 [04:42<12:59,  1.74it/s, running training loss:  0.90571]\u001b[A\n",
            "Training:  24%|██▎       | 417/1772 [04:42<12:59,  1.74it/s, running training loss:  1.00031]\u001b[A\n",
            "Training:  24%|██▎       | 418/1772 [04:42<12:47,  1.76it/s, running training loss:  1.00031]\u001b[A\n",
            "Training:  24%|██▎       | 418/1772 [04:43<12:47,  1.76it/s, running training loss:  0.93232]\u001b[A\n",
            "Training:  24%|██▎       | 419/1772 [04:43<13:54,  1.62it/s, running training loss:  0.93232]\u001b[A\n",
            "Training:  24%|██▎       | 419/1772 [04:44<13:54,  1.62it/s, running training loss:  1.05241]\u001b[A\n",
            "Training:  24%|██▎       | 420/1772 [04:44<15:08,  1.49it/s, running training loss:  1.05241]\u001b[A\n",
            "Training:  24%|██▎       | 420/1772 [04:45<15:08,  1.49it/s, running training loss:  1.08765]\u001b[A\n",
            "Training:  24%|██▍       | 421/1772 [04:45<16:06,  1.40it/s, running training loss:  1.08765]\u001b[A\n",
            "Training:  24%|██▍       | 421/1772 [04:45<16:06,  1.40it/s, running training loss:  1.00174]\u001b[A\n",
            "Training:  24%|██▍       | 422/1772 [04:45<15:55,  1.41it/s, running training loss:  1.00174]\u001b[A\n",
            "Training:  24%|██▍       | 422/1772 [04:46<15:55,  1.41it/s, running training loss:  1.06879]\u001b[A\n",
            "Training:  24%|██▍       | 423/1772 [04:46<17:41,  1.27it/s, running training loss:  1.06879]\u001b[A\n",
            "Training:  24%|██▍       | 423/1772 [04:47<17:41,  1.27it/s, running training loss:  1.32172]\u001b[A\n",
            "Training:  24%|██▍       | 424/1772 [04:47<15:57,  1.41it/s, running training loss:  1.32172]\u001b[A\n",
            "Training:  24%|██▍       | 424/1772 [04:47<15:57,  1.41it/s, running training loss:  1.15087]\u001b[A\n",
            "Training:  24%|██▍       | 425/1772 [04:47<15:22,  1.46it/s, running training loss:  1.15087]\u001b[A\n",
            "Training:  24%|██▍       | 425/1772 [04:48<15:22,  1.46it/s, running training loss:  1.07126]\u001b[A\n",
            "Training:  24%|██▍       | 426/1772 [04:48<14:42,  1.52it/s, running training loss:  1.07126]\u001b[A\n",
            "Training:  24%|██▍       | 426/1772 [04:48<14:42,  1.52it/s, running training loss:  1.10804]\u001b[A\n",
            "Training:  24%|██▍       | 427/1772 [04:48<13:38,  1.64it/s, running training loss:  1.10804]\u001b[A\n",
            "Training:  24%|██▍       | 427/1772 [04:49<13:38,  1.64it/s, running training loss:  1.02641]\u001b[A\n",
            "Training:  24%|██▍       | 428/1772 [04:49<13:17,  1.69it/s, running training loss:  1.02641]\u001b[A\n",
            "Training:  24%|██▍       | 428/1772 [04:50<13:17,  1.69it/s, running training loss:  1.02335]\u001b[A\n",
            "Training:  24%|██▍       | 429/1772 [04:50<14:03,  1.59it/s, running training loss:  1.02335]\u001b[A\n",
            "Training:  24%|██▍       | 429/1772 [04:50<14:03,  1.59it/s, running training loss:  1.00797]\u001b[A\n",
            "Training:  24%|██▍       | 430/1772 [04:50<13:52,  1.61it/s, running training loss:  1.00797]\u001b[A\n",
            "Training:  24%|██▍       | 430/1772 [04:51<13:52,  1.61it/s, running training loss:  1.09444]\u001b[A\n",
            "Training:  24%|██▍       | 431/1772 [04:51<13:09,  1.70it/s, running training loss:  1.09444]\u001b[A\n",
            "Training:  24%|██▍       | 431/1772 [04:51<13:09,  1.70it/s, running training loss:  0.98114]\u001b[A\n",
            "Training:  24%|██▍       | 432/1772 [04:51<12:48,  1.74it/s, running training loss:  0.98114]\u001b[A\n",
            "Training:  24%|██▍       | 432/1772 [04:52<12:48,  1.74it/s, running training loss:  0.89104]\u001b[A\n",
            "Training:  24%|██▍       | 433/1772 [04:52<12:24,  1.80it/s, running training loss:  0.89104]\u001b[A\n",
            "Training:  24%|██▍       | 433/1772 [04:52<12:24,  1.80it/s, running training loss:  0.95249]\u001b[A\n",
            "Training:  24%|██▍       | 434/1772 [04:52<12:04,  1.85it/s, running training loss:  0.95249]\u001b[A\n",
            "Training:  24%|██▍       | 434/1772 [04:53<12:04,  1.85it/s, running training loss:  1.00643]\u001b[A\n",
            "Training:  25%|██▍       | 435/1772 [04:53<12:43,  1.75it/s, running training loss:  1.00643]\u001b[A\n",
            "Training:  25%|██▍       | 435/1772 [04:54<12:43,  1.75it/s, running training loss:  1.14739]\u001b[A\n",
            "Training:  25%|██▍       | 436/1772 [04:54<14:14,  1.56it/s, running training loss:  1.14739]\u001b[A\n",
            "Training:  25%|██▍       | 436/1772 [04:54<14:14,  1.56it/s, running training loss:  0.95586]\u001b[A\n",
            "Training:  25%|██▍       | 437/1772 [04:54<14:06,  1.58it/s, running training loss:  0.95586]\u001b[A\n",
            "Training:  25%|██▍       | 437/1772 [04:55<14:06,  1.58it/s, running training loss:  0.90270]\u001b[A\n",
            "Training:  25%|██▍       | 438/1772 [04:55<15:24,  1.44it/s, running training loss:  0.90270]\u001b[A\n",
            "Training:  25%|██▍       | 438/1772 [04:56<15:24,  1.44it/s, running training loss:  0.91462]\u001b[A\n",
            "Training:  25%|██▍       | 439/1772 [04:56<15:04,  1.47it/s, running training loss:  0.91462]\u001b[A\n",
            "Training:  25%|██▍       | 439/1772 [04:56<15:04,  1.47it/s, running training loss:  1.10681]\u001b[A\n",
            "Training:  25%|██▍       | 440/1772 [04:56<14:24,  1.54it/s, running training loss:  1.10681]\u001b[A\n",
            "Training:  25%|██▍       | 440/1772 [04:57<14:24,  1.54it/s, running training loss:  1.00063]\u001b[A\n",
            "Training:  25%|██▍       | 441/1772 [04:57<13:39,  1.62it/s, running training loss:  1.00063]\u001b[A\n",
            "Training:  25%|██▍       | 441/1772 [04:58<13:39,  1.62it/s, running training loss:  0.88859]\u001b[A\n",
            "Training:  25%|██▍       | 442/1772 [04:58<13:45,  1.61it/s, running training loss:  0.88859]\u001b[A\n",
            "Training:  25%|██▍       | 442/1772 [04:58<13:45,  1.61it/s, running training loss:  0.99855]\u001b[A\n",
            "Training:  25%|██▌       | 443/1772 [04:58<13:09,  1.68it/s, running training loss:  0.99855]\u001b[A\n",
            "Training:  25%|██▌       | 443/1772 [04:59<13:09,  1.68it/s, running training loss:  1.06653]\u001b[A\n",
            "Training:  25%|██▌       | 444/1772 [04:59<12:51,  1.72it/s, running training loss:  1.06653]\u001b[A\n",
            "Training:  25%|██▌       | 444/1772 [04:59<12:51,  1.72it/s, running training loss:  1.04867]\u001b[A\n",
            "Training:  25%|██▌       | 445/1772 [04:59<13:16,  1.67it/s, running training loss:  1.04867]\u001b[A\n",
            "Training:  25%|██▌       | 445/1772 [05:00<13:16,  1.67it/s, running training loss:  1.10933]\u001b[A\n",
            "Training:  25%|██▌       | 446/1772 [05:00<13:10,  1.68it/s, running training loss:  1.10933]\u001b[A\n",
            "Training:  25%|██▌       | 446/1772 [05:00<13:10,  1.68it/s, running training loss:  1.16519]\u001b[A\n",
            "Training:  25%|██▌       | 447/1772 [05:00<12:33,  1.76it/s, running training loss:  1.16519]\u001b[A\n",
            "Training:  25%|██▌       | 447/1772 [05:01<12:33,  1.76it/s, running training loss:  1.09852]\u001b[A\n",
            "Training:  25%|██▌       | 448/1772 [05:01<12:28,  1.77it/s, running training loss:  1.09852]\u001b[A\n",
            "Training:  25%|██▌       | 448/1772 [05:02<12:28,  1.77it/s, running training loss:  1.10329]\u001b[A\n",
            "Training:  25%|██▌       | 449/1772 [05:02<12:32,  1.76it/s, running training loss:  1.10329]\u001b[A\n",
            "Training:  25%|██▌       | 449/1772 [05:02<12:32,  1.76it/s, running training loss:  1.26930]\u001b[A\n",
            "Training:  25%|██▌       | 450/1772 [05:02<12:08,  1.82it/s, running training loss:  1.26930]\u001b[A\n",
            "Training:  25%|██▌       | 450/1772 [05:03<12:08,  1.82it/s, running training loss:  1.30253]\u001b[A\n",
            "Training:  25%|██▌       | 451/1772 [05:03<13:00,  1.69it/s, running training loss:  1.30253]\u001b[A\n",
            "Training:  25%|██▌       | 451/1772 [05:04<13:00,  1.69it/s, running training loss:  1.06009]\u001b[A\n",
            "Training:  26%|██▌       | 452/1772 [05:04<14:14,  1.54it/s, running training loss:  1.06009]\u001b[A\n",
            "Training:  26%|██▌       | 452/1772 [05:04<14:14,  1.54it/s, running training loss:  0.88837]\u001b[A\n",
            "Training:  26%|██▌       | 453/1772 [05:04<13:12,  1.67it/s, running training loss:  0.88837]\u001b[A\n",
            "Training:  26%|██▌       | 453/1772 [05:05<13:12,  1.67it/s, running training loss:  1.03694]\u001b[A\n",
            "Training:  26%|██▌       | 454/1772 [05:05<13:39,  1.61it/s, running training loss:  1.03694]\u001b[A\n",
            "Training:  26%|██▌       | 454/1772 [05:05<13:39,  1.61it/s, running training loss:  1.02258]\u001b[A\n",
            "Training:  26%|██▌       | 455/1772 [05:05<13:35,  1.62it/s, running training loss:  1.02258]\u001b[A\n",
            "Training:  26%|██▌       | 455/1772 [05:06<13:35,  1.62it/s, running training loss:  1.04185]\u001b[A\n",
            "Training:  26%|██▌       | 456/1772 [05:06<13:26,  1.63it/s, running training loss:  1.04185]\u001b[A\n",
            "Training:  26%|██▌       | 456/1772 [05:07<13:26,  1.63it/s, running training loss:  1.03803]\u001b[A\n",
            "Training:  26%|██▌       | 457/1772 [05:07<13:21,  1.64it/s, running training loss:  1.03803]\u001b[A\n",
            "Training:  26%|██▌       | 457/1772 [05:07<13:21,  1.64it/s, running training loss:  1.04380]\u001b[A\n",
            "Training:  26%|██▌       | 458/1772 [05:07<12:33,  1.74it/s, running training loss:  1.04380]\u001b[A\n",
            "Training:  26%|██▌       | 458/1772 [05:08<12:33,  1.74it/s, running training loss:  0.89184]\u001b[A\n",
            "Training:  26%|██▌       | 459/1772 [05:08<12:42,  1.72it/s, running training loss:  0.89184]\u001b[A\n",
            "Training:  26%|██▌       | 459/1772 [05:08<12:42,  1.72it/s, running training loss:  1.00916]\u001b[A\n",
            "Training:  26%|██▌       | 460/1772 [05:08<12:25,  1.76it/s, running training loss:  1.00916]\u001b[A\n",
            "Training:  26%|██▌       | 460/1772 [05:09<12:25,  1.76it/s, running training loss:  1.02251]\u001b[A\n",
            "Training:  26%|██▌       | 461/1772 [05:09<12:09,  1.80it/s, running training loss:  1.02251]\u001b[A\n",
            "Training:  26%|██▌       | 461/1772 [05:09<12:09,  1.80it/s, running training loss:  1.20894]\u001b[A\n",
            "Training:  26%|██▌       | 462/1772 [05:09<11:18,  1.93it/s, running training loss:  1.20894]\u001b[A\n",
            "Training:  26%|██▌       | 462/1772 [05:10<11:18,  1.93it/s, running training loss:  0.81907]\u001b[A\n",
            "Training:  26%|██▌       | 463/1772 [05:10<11:47,  1.85it/s, running training loss:  0.81907]\u001b[A\n",
            "Training:  26%|██▌       | 463/1772 [05:10<11:47,  1.85it/s, running training loss:  1.04200]\u001b[A\n",
            "Training:  26%|██▌       | 464/1772 [05:10<11:25,  1.91it/s, running training loss:  1.04200]\u001b[A\n",
            "Training:  26%|██▌       | 464/1772 [05:11<11:25,  1.91it/s, running training loss:  1.22247]\u001b[A\n",
            "Training:  26%|██▌       | 465/1772 [05:11<11:12,  1.94it/s, running training loss:  1.22247]\u001b[A\n",
            "Training:  26%|██▌       | 465/1772 [05:11<11:12,  1.94it/s, running training loss:  1.02038]\u001b[A\n",
            "Training:  26%|██▋       | 466/1772 [05:11<11:26,  1.90it/s, running training loss:  1.02038]\u001b[A\n",
            "Training:  26%|██▋       | 466/1772 [05:12<11:26,  1.90it/s, running training loss:  0.99527]\u001b[A\n",
            "Training:  26%|██▋       | 467/1772 [05:12<12:57,  1.68it/s, running training loss:  0.99527]\u001b[A\n",
            "Training:  26%|██▋       | 467/1772 [05:12<12:57,  1.68it/s, running training loss:  0.93539]\u001b[A\n",
            "Training:  26%|██▋       | 468/1772 [05:12<11:55,  1.82it/s, running training loss:  0.93539]\u001b[A\n",
            "Training:  26%|██▋       | 468/1772 [05:13<11:55,  1.82it/s, running training loss:  0.91317]\u001b[A\n",
            "Training:  26%|██▋       | 469/1772 [05:13<12:11,  1.78it/s, running training loss:  0.91317]\u001b[A\n",
            "Training:  26%|██▋       | 469/1772 [05:14<12:11,  1.78it/s, running training loss:  1.10479]\u001b[A\n",
            "Training:  27%|██▋       | 470/1772 [05:14<13:03,  1.66it/s, running training loss:  1.10479]\u001b[A\n",
            "Training:  27%|██▋       | 470/1772 [05:14<13:03,  1.66it/s, running training loss:  1.08192]\u001b[A\n",
            "Training:  27%|██▋       | 471/1772 [05:14<12:36,  1.72it/s, running training loss:  1.08192]\u001b[A\n",
            "Training:  27%|██▋       | 471/1772 [05:15<12:36,  1.72it/s, running training loss:  0.91898]\u001b[A\n",
            "Training:  27%|██▋       | 472/1772 [05:15<14:59,  1.44it/s, running training loss:  0.91898]\u001b[A\n",
            "Training:  27%|██▋       | 472/1772 [05:16<14:59,  1.44it/s, running training loss:  1.21117]\u001b[A\n",
            "Training:  27%|██▋       | 473/1772 [05:16<16:57,  1.28it/s, running training loss:  1.21117]\u001b[A\n",
            "Training:  27%|██▋       | 473/1772 [05:17<16:57,  1.28it/s, running training loss:  1.27273]\u001b[A\n",
            "Training:  27%|██▋       | 474/1772 [05:17<15:25,  1.40it/s, running training loss:  1.27273]\u001b[A\n",
            "Training:  27%|██▋       | 474/1772 [05:17<15:25,  1.40it/s, running training loss:  1.38081]\u001b[A\n",
            "Training:  27%|██▋       | 475/1772 [05:17<14:12,  1.52it/s, running training loss:  1.38081]\u001b[A\n",
            "Training:  27%|██▋       | 475/1772 [05:18<14:12,  1.52it/s, running training loss:  1.12670]\u001b[A\n",
            "Training:  27%|██▋       | 476/1772 [05:18<13:55,  1.55it/s, running training loss:  1.12670]\u001b[A\n",
            "Training:  27%|██▋       | 476/1772 [05:18<13:55,  1.55it/s, running training loss:  1.38690]\u001b[A\n",
            "Training:  27%|██▋       | 477/1772 [05:18<13:14,  1.63it/s, running training loss:  1.38690]\u001b[A\n",
            "Training:  27%|██▋       | 477/1772 [05:19<13:14,  1.63it/s, running training loss:  0.93213]\u001b[A\n",
            "Training:  27%|██▋       | 478/1772 [05:19<13:36,  1.58it/s, running training loss:  0.93213]\u001b[A\n",
            "Training:  27%|██▋       | 478/1772 [05:20<13:36,  1.58it/s, running training loss:  1.02088]\u001b[A\n",
            "Training:  27%|██▋       | 479/1772 [05:20<13:15,  1.63it/s, running training loss:  1.02088]\u001b[A\n",
            "Training:  27%|██▋       | 479/1772 [05:20<13:15,  1.63it/s, running training loss:  1.13009]\u001b[A\n",
            "Training:  27%|██▋       | 480/1772 [05:20<12:41,  1.70it/s, running training loss:  1.13009]\u001b[A\n",
            "Training:  27%|██▋       | 480/1772 [05:21<12:41,  1.70it/s, running training loss:  1.20954]\u001b[A\n",
            "Training:  27%|██▋       | 481/1772 [05:21<13:08,  1.64it/s, running training loss:  1.20954]\u001b[A\n",
            "Training:  27%|██▋       | 481/1772 [05:22<13:08,  1.64it/s, running training loss:  0.94064]\u001b[A\n",
            "Training:  27%|██▋       | 482/1772 [05:22<13:12,  1.63it/s, running training loss:  0.94064]\u001b[A\n",
            "Training:  27%|██▋       | 482/1772 [05:22<13:12,  1.63it/s, running training loss:  0.97204]\u001b[A\n",
            "Training:  27%|██▋       | 483/1772 [05:22<12:04,  1.78it/s, running training loss:  0.97204]\u001b[A\n",
            "Training:  27%|██▋       | 483/1772 [05:23<12:04,  1.78it/s, running training loss:  1.12687]\u001b[A\n",
            "Training:  27%|██▋       | 484/1772 [05:23<12:17,  1.75it/s, running training loss:  1.12687]\u001b[A\n",
            "Training:  27%|██▋       | 484/1772 [05:23<12:17,  1.75it/s, running training loss:  1.24094]\u001b[A\n",
            "Training:  27%|██▋       | 485/1772 [05:23<11:24,  1.88it/s, running training loss:  1.24094]\u001b[A\n",
            "Training:  27%|██▋       | 485/1772 [05:24<11:24,  1.88it/s, running training loss:  1.01020]\u001b[A\n",
            "Training:  27%|██▋       | 486/1772 [05:24<12:21,  1.73it/s, running training loss:  1.01020]\u001b[A\n",
            "Training:  27%|██▋       | 486/1772 [05:24<12:21,  1.73it/s, running training loss:  0.98895]\u001b[A\n",
            "Training:  27%|██▋       | 487/1772 [05:24<12:08,  1.76it/s, running training loss:  0.98895]\u001b[A\n",
            "Training:  27%|██▋       | 487/1772 [05:25<12:08,  1.76it/s, running training loss:  0.87988]\u001b[A\n",
            "Training:  28%|██▊       | 488/1772 [05:25<13:20,  1.60it/s, running training loss:  0.87988]\u001b[A\n",
            "Training:  28%|██▊       | 488/1772 [05:26<13:20,  1.60it/s, running training loss:  0.91353]\u001b[A\n",
            "Training:  28%|██▊       | 489/1772 [05:26<13:08,  1.63it/s, running training loss:  0.91353]\u001b[A\n",
            "Training:  28%|██▊       | 489/1772 [05:26<13:08,  1.63it/s, running training loss:  1.06966]\u001b[A\n",
            "Training:  28%|██▊       | 490/1772 [05:26<12:29,  1.71it/s, running training loss:  1.06966]\u001b[A\n",
            "Training:  28%|██▊       | 490/1772 [05:27<12:29,  1.71it/s, running training loss:  1.07169]\u001b[A\n",
            "Training:  28%|██▊       | 491/1772 [05:27<12:10,  1.75it/s, running training loss:  1.07169]\u001b[A\n",
            "Training:  28%|██▊       | 491/1772 [05:27<12:10,  1.75it/s, running training loss:  1.10097]\u001b[A\n",
            "Training:  28%|██▊       | 492/1772 [05:27<11:58,  1.78it/s, running training loss:  1.10097]\u001b[A\n",
            "Training:  28%|██▊       | 492/1772 [05:28<11:58,  1.78it/s, running training loss:  1.00138]\u001b[A\n",
            "Training:  28%|██▊       | 493/1772 [05:28<11:45,  1.81it/s, running training loss:  1.00138]\u001b[A\n",
            "Training:  28%|██▊       | 493/1772 [05:28<11:45,  1.81it/s, running training loss:  0.95809]\u001b[A\n",
            "Training:  28%|██▊       | 494/1772 [05:28<11:39,  1.83it/s, running training loss:  0.95809]\u001b[A\n",
            "Training:  28%|██▊       | 494/1772 [05:29<11:39,  1.83it/s, running training loss:  1.01117]\u001b[A\n",
            "Training:  28%|██▊       | 495/1772 [05:29<11:51,  1.80it/s, running training loss:  1.01117]\u001b[A\n",
            "Training:  28%|██▊       | 495/1772 [05:29<11:51,  1.80it/s, running training loss:  0.90820]\u001b[A\n",
            "Training:  28%|██▊       | 496/1772 [05:29<12:20,  1.72it/s, running training loss:  0.90820]\u001b[A\n",
            "Training:  28%|██▊       | 496/1772 [05:30<12:20,  1.72it/s, running training loss:  1.08974]\u001b[A\n",
            "Training:  28%|██▊       | 497/1772 [05:30<14:38,  1.45it/s, running training loss:  1.08974]\u001b[A\n",
            "Training:  28%|██▊       | 497/1772 [05:31<14:38,  1.45it/s, running training loss:  1.05595]\u001b[A\n",
            "Training:  28%|██▊       | 498/1772 [05:31<13:29,  1.57it/s, running training loss:  1.05595]\u001b[A\n",
            "Training:  28%|██▊       | 498/1772 [05:32<13:29,  1.57it/s, running training loss:  1.33240]\u001b[A\n",
            "Training:  28%|██▊       | 499/1772 [05:32<13:38,  1.56it/s, running training loss:  1.33240]\u001b[A\n",
            "Training:  28%|██▊       | 499/1772 [05:32<13:38,  1.56it/s, running training loss:  1.06546]\u001b[A\n",
            "Training:  28%|██▊       | 500/1772 [05:32<13:35,  1.56it/s, running training loss:  1.06546]\u001b[A\n",
            "Training:  28%|██▊       | 500/1772 [05:33<13:35,  1.56it/s, running training loss:  1.02909]\u001b[A\n",
            "Training:  28%|██▊       | 501/1772 [05:33<12:27,  1.70it/s, running training loss:  1.02909]\u001b[A\n",
            "Training:  28%|██▊       | 501/1772 [05:33<12:27,  1.70it/s, running training loss:  0.99096]\u001b[A\n",
            "Training:  28%|██▊       | 502/1772 [05:33<13:35,  1.56it/s, running training loss:  0.99096]\u001b[A\n",
            "Training:  28%|██▊       | 502/1772 [05:34<13:35,  1.56it/s, running training loss:  1.07826]\u001b[A\n",
            "Training:  28%|██▊       | 503/1772 [05:34<13:08,  1.61it/s, running training loss:  1.07826]\u001b[A\n",
            "Training:  28%|██▊       | 503/1772 [05:35<13:08,  1.61it/s, running training loss:  0.93825]\u001b[A\n",
            "Training:  28%|██▊       | 504/1772 [05:35<13:38,  1.55it/s, running training loss:  0.93825]\u001b[A\n",
            "Training:  28%|██▊       | 504/1772 [05:35<13:38,  1.55it/s, running training loss:  1.02773]\u001b[A\n",
            "Training:  28%|██▊       | 505/1772 [05:35<13:49,  1.53it/s, running training loss:  1.02773]\u001b[A\n",
            "Training:  28%|██▊       | 505/1772 [05:36<13:49,  1.53it/s, running training loss:  0.95858]\u001b[A\n",
            "Training:  29%|██▊       | 506/1772 [05:36<14:44,  1.43it/s, running training loss:  0.95858]\u001b[A\n",
            "Training:  29%|██▊       | 506/1772 [05:37<14:44,  1.43it/s, running training loss:  1.20800]\u001b[A\n",
            "Training:  29%|██▊       | 507/1772 [05:37<13:11,  1.60it/s, running training loss:  1.20800]\u001b[A\n",
            "Training:  29%|██▊       | 507/1772 [05:37<13:11,  1.60it/s, running training loss:  1.39300]\u001b[A\n",
            "Training:  29%|██▊       | 508/1772 [05:37<12:13,  1.72it/s, running training loss:  1.39300]\u001b[A\n",
            "Training:  29%|██▊       | 508/1772 [05:38<12:13,  1.72it/s, running training loss:  1.15427]\u001b[A\n",
            "Training:  29%|██▊       | 509/1772 [05:38<14:17,  1.47it/s, running training loss:  1.15427]\u001b[A\n",
            "Training:  29%|██▊       | 509/1772 [05:38<14:17,  1.47it/s, running training loss:  1.08529]\u001b[A\n",
            "Training:  29%|██▉       | 510/1772 [05:39<12:57,  1.62it/s, running training loss:  1.08529]\u001b[A\n",
            "Training:  29%|██▉       | 510/1772 [05:39<12:57,  1.62it/s, running training loss:  0.86854]\u001b[A\n",
            "Training:  29%|██▉       | 511/1772 [05:39<12:04,  1.74it/s, running training loss:  0.86854]\u001b[A\n",
            "Training:  29%|██▉       | 511/1772 [05:40<12:04,  1.74it/s, running training loss:  1.43756]\u001b[A\n",
            "Training:  29%|██▉       | 512/1772 [05:40<11:54,  1.76it/s, running training loss:  1.43756]\u001b[A\n",
            "Training:  29%|██▉       | 512/1772 [05:40<11:54,  1.76it/s, running training loss:  1.05445]\u001b[A\n",
            "Training:  29%|██▉       | 513/1772 [05:40<12:51,  1.63it/s, running training loss:  1.05445]\u001b[A\n",
            "Training:  29%|██▉       | 513/1772 [05:41<12:51,  1.63it/s, running training loss:  1.05557]\u001b[A\n",
            "Training:  29%|██▉       | 514/1772 [05:41<11:55,  1.76it/s, running training loss:  1.05557]\u001b[A\n",
            "Training:  29%|██▉       | 514/1772 [05:41<11:55,  1.76it/s, running training loss:  1.42868]\u001b[A\n",
            "Training:  29%|██▉       | 515/1772 [05:41<12:15,  1.71it/s, running training loss:  1.42868]\u001b[A\n",
            "Training:  29%|██▉       | 515/1772 [05:42<12:15,  1.71it/s, running training loss:  0.86108]\u001b[A\n",
            "Training:  29%|██▉       | 516/1772 [05:42<12:04,  1.73it/s, running training loss:  0.86108]\u001b[A\n",
            "Training:  29%|██▉       | 516/1772 [05:42<12:04,  1.73it/s, running training loss:  0.95943]\u001b[A\n",
            "Training:  29%|██▉       | 517/1772 [05:42<11:52,  1.76it/s, running training loss:  0.95943]\u001b[A\n",
            "Training:  29%|██▉       | 517/1772 [05:43<11:52,  1.76it/s, running training loss:  1.20108]\u001b[A\n",
            "Training:  29%|██▉       | 518/1772 [05:43<11:46,  1.78it/s, running training loss:  1.20108]\u001b[A\n",
            "Training:  29%|██▉       | 518/1772 [05:43<11:46,  1.78it/s, running training loss:  1.25926]\u001b[A\n",
            "Training:  29%|██▉       | 519/1772 [05:43<11:04,  1.89it/s, running training loss:  1.25926]\u001b[A\n",
            "Training:  29%|██▉       | 519/1772 [05:44<11:04,  1.89it/s, running training loss:  1.11720]\u001b[A\n",
            "Training:  29%|██▉       | 520/1772 [05:44<11:50,  1.76it/s, running training loss:  1.11720]\u001b[A\n",
            "Training:  29%|██▉       | 520/1772 [05:45<11:50,  1.76it/s, running training loss:  1.45597]\u001b[A\n",
            "Training:  29%|██▉       | 521/1772 [05:45<12:41,  1.64it/s, running training loss:  1.45597]\u001b[A\n",
            "Training:  29%|██▉       | 521/1772 [05:45<12:41,  1.64it/s, running training loss:  1.03088]\u001b[A\n",
            "Training:  29%|██▉       | 522/1772 [05:45<13:04,  1.59it/s, running training loss:  1.03088]\u001b[A\n",
            "Training:  29%|██▉       | 522/1772 [05:46<13:04,  1.59it/s, running training loss:  1.09390]\u001b[A\n",
            "Training:  30%|██▉       | 523/1772 [05:46<12:54,  1.61it/s, running training loss:  1.09390]\u001b[A\n",
            "Training:  30%|██▉       | 523/1772 [05:47<12:54,  1.61it/s, running training loss:  1.27769]\u001b[A\n",
            "Training:  30%|██▉       | 524/1772 [05:47<12:27,  1.67it/s, running training loss:  1.27769]\u001b[A\n",
            "Training:  30%|██▉       | 524/1772 [05:47<12:27,  1.67it/s, running training loss:  1.22583]\u001b[A\n",
            "Training:  30%|██▉       | 525/1772 [05:47<12:30,  1.66it/s, running training loss:  1.22583]\u001b[A\n",
            "Training:  30%|██▉       | 525/1772 [05:48<12:30,  1.66it/s, running training loss:  1.00486]\u001b[A\n",
            "Training:  30%|██▉       | 526/1772 [05:48<11:57,  1.74it/s, running training loss:  1.00486]\u001b[A\n",
            "Training:  30%|██▉       | 526/1772 [05:48<11:57,  1.74it/s, running training loss:  0.95526]\u001b[A\n",
            "Training:  30%|██▉       | 527/1772 [05:48<11:51,  1.75it/s, running training loss:  0.95526]\u001b[A\n",
            "Training:  30%|██▉       | 527/1772 [05:49<11:51,  1.75it/s, running training loss:  0.96453]\u001b[A\n",
            "Training:  30%|██▉       | 528/1772 [05:49<11:34,  1.79it/s, running training loss:  0.96453]\u001b[A\n",
            "Training:  30%|██▉       | 528/1772 [05:49<11:34,  1.79it/s, running training loss:  1.02206]\u001b[A\n",
            "Training:  30%|██▉       | 529/1772 [05:49<11:59,  1.73it/s, running training loss:  1.02206]\u001b[A\n",
            "Training:  30%|██▉       | 529/1772 [05:50<11:59,  1.73it/s, running training loss:  1.02604]\u001b[A\n",
            "Training:  30%|██▉       | 530/1772 [05:50<13:06,  1.58it/s, running training loss:  1.02604]\u001b[A\n",
            "Training:  30%|██▉       | 530/1772 [05:51<13:06,  1.58it/s, running training loss:  1.04086]\u001b[A\n",
            "Training:  30%|██▉       | 531/1772 [05:51<12:13,  1.69it/s, running training loss:  1.04086]\u001b[A\n",
            "Training:  30%|██▉       | 531/1772 [05:51<12:13,  1.69it/s, running training loss:  0.95450]\u001b[A\n",
            "Training:  30%|███       | 532/1772 [05:51<12:24,  1.67it/s, running training loss:  0.95450]\u001b[A\n",
            "Training:  30%|███       | 532/1772 [05:52<12:24,  1.67it/s, running training loss:  0.97947]\u001b[A\n",
            "Training:  30%|███       | 533/1772 [05:52<12:56,  1.60it/s, running training loss:  0.97947]\u001b[A\n",
            "Training:  30%|███       | 533/1772 [05:53<12:56,  1.60it/s, running training loss:  0.93899]\u001b[A\n",
            "Training:  30%|███       | 534/1772 [05:53<12:54,  1.60it/s, running training loss:  0.93899]\u001b[A\n",
            "Training:  30%|███       | 534/1772 [05:53<12:54,  1.60it/s, running training loss:  1.02148]\u001b[A\n",
            "Training:  30%|███       | 535/1772 [05:53<12:17,  1.68it/s, running training loss:  1.02148]\u001b[A\n",
            "Training:  30%|███       | 535/1772 [05:54<12:17,  1.68it/s, running training loss:  1.02941]\u001b[A\n",
            "Training:  30%|███       | 536/1772 [05:54<12:59,  1.59it/s, running training loss:  1.02941]\u001b[A\n",
            "Training:  30%|███       | 536/1772 [05:54<12:59,  1.59it/s, running training loss:  1.09292]\u001b[A\n",
            "Training:  30%|███       | 537/1772 [05:54<12:19,  1.67it/s, running training loss:  1.09292]\u001b[A\n",
            "Training:  30%|███       | 537/1772 [05:55<12:19,  1.67it/s, running training loss:  1.01391]\u001b[A\n",
            "Training:  30%|███       | 538/1772 [05:55<12:00,  1.71it/s, running training loss:  1.01391]\u001b[A\n",
            "Training:  30%|███       | 538/1772 [05:56<12:00,  1.71it/s, running training loss:  1.03817]\u001b[A\n",
            "Training:  30%|███       | 539/1772 [05:56<12:16,  1.68it/s, running training loss:  1.03817]\u001b[A\n",
            "Training:  30%|███       | 539/1772 [05:56<12:16,  1.68it/s, running training loss:  1.12265]\u001b[A\n",
            "Training:  30%|███       | 540/1772 [05:56<11:42,  1.75it/s, running training loss:  1.12265]\u001b[A\n",
            "Training:  30%|███       | 540/1772 [05:57<11:42,  1.75it/s, running training loss:  1.01350]\u001b[A\n",
            "Training:  31%|███       | 541/1772 [05:57<12:13,  1.68it/s, running training loss:  1.01350]\u001b[A\n",
            "Training:  31%|███       | 541/1772 [05:57<12:13,  1.68it/s, running training loss:  1.05031]\u001b[A\n",
            "Training:  31%|███       | 542/1772 [05:57<12:34,  1.63it/s, running training loss:  1.05031]\u001b[A\n",
            "Training:  31%|███       | 542/1772 [05:58<12:34,  1.63it/s, running training loss:  1.16801]\u001b[A\n",
            "Training:  31%|███       | 543/1772 [05:58<13:01,  1.57it/s, running training loss:  1.16801]\u001b[A\n",
            "Training:  31%|███       | 543/1772 [05:59<13:01,  1.57it/s, running training loss:  1.35092]\u001b[A\n",
            "Training:  31%|███       | 544/1772 [05:59<12:18,  1.66it/s, running training loss:  1.35092]\u001b[A\n",
            "Training:  31%|███       | 544/1772 [05:59<12:18,  1.66it/s, running training loss:  1.02895]\u001b[A\n",
            "Training:  31%|███       | 545/1772 [05:59<11:48,  1.73it/s, running training loss:  1.02895]\u001b[A\n",
            "Training:  31%|███       | 545/1772 [06:00<11:48,  1.73it/s, running training loss:  1.10078]\u001b[A\n",
            "Training:  31%|███       | 546/1772 [06:00<13:07,  1.56it/s, running training loss:  1.10078]\u001b[A\n",
            "Training:  31%|███       | 546/1772 [06:00<13:07,  1.56it/s, running training loss:  0.92597]\u001b[A\n",
            "Training:  31%|███       | 547/1772 [06:01<12:36,  1.62it/s, running training loss:  0.92597]\u001b[A\n",
            "Training:  31%|███       | 547/1772 [06:01<12:36,  1.62it/s, running training loss:  1.20954]\u001b[A\n",
            "Training:  31%|███       | 548/1772 [06:01<11:59,  1.70it/s, running training loss:  1.20954]\u001b[A\n",
            "Training:  31%|███       | 548/1772 [06:02<11:59,  1.70it/s, running training loss:  1.05848]\u001b[A\n",
            "Training:  31%|███       | 549/1772 [06:02<12:37,  1.61it/s, running training loss:  1.05848]\u001b[A\n",
            "Training:  31%|███       | 549/1772 [06:02<12:37,  1.61it/s, running training loss:  0.96446]\u001b[A\n",
            "Training:  31%|███       | 550/1772 [06:02<12:47,  1.59it/s, running training loss:  0.96446]\u001b[A\n",
            "Training:  31%|███       | 550/1772 [06:03<12:47,  1.59it/s, running training loss:  1.01593]\u001b[A\n",
            "Training:  31%|███       | 551/1772 [06:03<14:59,  1.36it/s, running training loss:  1.01593]\u001b[A\n",
            "Training:  31%|███       | 551/1772 [06:04<14:59,  1.36it/s, running training loss:  1.00876]\u001b[A\n",
            "Training:  31%|███       | 552/1772 [06:04<14:10,  1.44it/s, running training loss:  1.00876]\u001b[A\n",
            "Training:  31%|███       | 552/1772 [06:05<14:10,  1.44it/s, running training loss:  0.95905]\u001b[A\n",
            "Training:  31%|███       | 553/1772 [06:05<13:29,  1.51it/s, running training loss:  0.95905]\u001b[A\n",
            "Training:  31%|███       | 553/1772 [06:05<13:29,  1.51it/s, running training loss:  0.97775]\u001b[A\n",
            "Training:  31%|███▏      | 554/1772 [06:05<12:55,  1.57it/s, running training loss:  0.97775]\u001b[A\n",
            "Training:  31%|███▏      | 554/1772 [06:06<12:55,  1.57it/s, running training loss:  1.26019]\u001b[A\n",
            "Training:  31%|███▏      | 555/1772 [06:06<12:08,  1.67it/s, running training loss:  1.26019]\u001b[A\n",
            "Training:  31%|███▏      | 555/1772 [06:06<12:08,  1.67it/s, running training loss:  0.88937]\u001b[A\n",
            "Training:  31%|███▏      | 556/1772 [06:06<11:50,  1.71it/s, running training loss:  0.88937]\u001b[A\n",
            "Training:  31%|███▏      | 556/1772 [06:07<11:50,  1.71it/s, running training loss:  1.04606]\u001b[A\n",
            "Training:  31%|███▏      | 557/1772 [06:07<11:57,  1.69it/s, running training loss:  1.04606]\u001b[A\n",
            "Training:  31%|███▏      | 557/1772 [06:07<11:57,  1.69it/s, running training loss:  1.50067]\u001b[A\n",
            "Training:  31%|███▏      | 558/1772 [06:07<11:35,  1.75it/s, running training loss:  1.50067]\u001b[A\n",
            "Training:  31%|███▏      | 558/1772 [06:08<11:35,  1.75it/s, running training loss:  1.48086]\u001b[A\n",
            "Training:  32%|███▏      | 559/1772 [06:08<12:03,  1.68it/s, running training loss:  1.48086]\u001b[A\n",
            "Training:  32%|███▏      | 559/1772 [06:08<12:03,  1.68it/s, running training loss:  1.17658]\u001b[A\n",
            "Training:  32%|███▏      | 560/1772 [06:08<11:34,  1.75it/s, running training loss:  1.17658]\u001b[A\n",
            "Training:  32%|███▏      | 560/1772 [06:09<11:34,  1.75it/s, running training loss:  1.08262]\u001b[A\n",
            "Training:  32%|███▏      | 561/1772 [06:09<11:54,  1.69it/s, running training loss:  1.08262]\u001b[A\n",
            "Training:  32%|███▏      | 561/1772 [06:10<11:54,  1.69it/s, running training loss:  0.91746]\u001b[A\n",
            "Training:  32%|███▏      | 562/1772 [06:10<11:36,  1.74it/s, running training loss:  0.91746]\u001b[A\n",
            "Training:  32%|███▏      | 562/1772 [06:10<11:36,  1.74it/s, running training loss:  1.11335]\u001b[A\n",
            "Training:  32%|███▏      | 563/1772 [06:10<11:39,  1.73it/s, running training loss:  1.11335]\u001b[A\n",
            "Training:  32%|███▏      | 563/1772 [06:11<11:39,  1.73it/s, running training loss:  0.97192]\u001b[A\n",
            "Training:  32%|███▏      | 564/1772 [06:11<11:45,  1.71it/s, running training loss:  0.97192]\u001b[A\n",
            "Training:  32%|███▏      | 564/1772 [06:11<11:45,  1.71it/s, running training loss:  1.01446]\u001b[A\n",
            "Training:  32%|███▏      | 565/1772 [06:11<11:39,  1.73it/s, running training loss:  1.01446]\u001b[A\n",
            "Training:  32%|███▏      | 565/1772 [06:12<11:39,  1.73it/s, running training loss:  1.03342]\u001b[A\n",
            "Training:  32%|███▏      | 566/1772 [06:12<12:46,  1.57it/s, running training loss:  1.03342]\u001b[A\n",
            "Training:  32%|███▏      | 566/1772 [06:13<12:46,  1.57it/s, running training loss:  0.97895]\u001b[A\n",
            "Training:  32%|███▏      | 567/1772 [06:13<12:26,  1.61it/s, running training loss:  0.97895]\u001b[A\n",
            "Training:  32%|███▏      | 567/1772 [06:13<12:26,  1.61it/s, running training loss:  1.15329]\u001b[A\n",
            "Training:  32%|███▏      | 568/1772 [06:13<11:36,  1.73it/s, running training loss:  1.15329]\u001b[A\n",
            "Training:  32%|███▏      | 568/1772 [06:14<11:36,  1.73it/s, running training loss:  1.13140]\u001b[A\n",
            "Training:  32%|███▏      | 569/1772 [06:14<11:05,  1.81it/s, running training loss:  1.13140]\u001b[A\n",
            "Training:  32%|███▏      | 569/1772 [06:14<11:05,  1.81it/s, running training loss:  0.95412]\u001b[A\n",
            "Training:  32%|███▏      | 570/1772 [06:14<11:51,  1.69it/s, running training loss:  0.95412]\u001b[A\n",
            "Training:  32%|███▏      | 570/1772 [06:15<11:51,  1.69it/s, running training loss:  1.05510]\u001b[A\n",
            "Training:  32%|███▏      | 571/1772 [06:15<13:19,  1.50it/s, running training loss:  1.05510]\u001b[A\n",
            "Training:  32%|███▏      | 571/1772 [06:16<13:19,  1.50it/s, running training loss:  0.88462]\u001b[A\n",
            "Training:  32%|███▏      | 572/1772 [06:16<12:45,  1.57it/s, running training loss:  0.88462]\u001b[A\n",
            "Training:  32%|███▏      | 572/1772 [06:17<12:45,  1.57it/s, running training loss:  1.00588]\u001b[A\n",
            "Training:  32%|███▏      | 573/1772 [06:17<14:35,  1.37it/s, running training loss:  1.00588]\u001b[A\n",
            "Training:  32%|███▏      | 573/1772 [06:18<14:35,  1.37it/s, running training loss:  0.90629]\u001b[A\n",
            "Training:  32%|███▏      | 574/1772 [06:18<14:52,  1.34it/s, running training loss:  0.90629]\u001b[A\n",
            "Training:  32%|███▏      | 574/1772 [06:18<14:52,  1.34it/s, running training loss:  1.08540]\u001b[A\n",
            "Training:  32%|███▏      | 575/1772 [06:18<15:25,  1.29it/s, running training loss:  1.08540]\u001b[A\n",
            "Training:  32%|███▏      | 575/1772 [06:19<15:25,  1.29it/s, running training loss:  1.07598]\u001b[A\n",
            "Training:  33%|███▎      | 576/1772 [06:19<14:03,  1.42it/s, running training loss:  1.07598]\u001b[A\n",
            "Training:  33%|███▎      | 576/1772 [06:20<14:03,  1.42it/s, running training loss:  1.00704]\u001b[A\n",
            "Training:  33%|███▎      | 577/1772 [06:20<15:46,  1.26it/s, running training loss:  1.00704]\u001b[A\n",
            "Training:  33%|███▎      | 577/1772 [06:20<15:46,  1.26it/s, running training loss:  0.89745]\u001b[A\n",
            "Training:  33%|███▎      | 578/1772 [06:20<14:11,  1.40it/s, running training loss:  0.89745]\u001b[A\n",
            "Training:  33%|███▎      | 578/1772 [06:21<14:11,  1.40it/s, running training loss:  0.76831]\u001b[A\n",
            "Training:  33%|███▎      | 579/1772 [06:21<13:13,  1.50it/s, running training loss:  0.76831]\u001b[A\n",
            "Training:  33%|███▎      | 579/1772 [06:22<13:13,  1.50it/s, running training loss:  0.86445]\u001b[A\n",
            "Training:  33%|███▎      | 580/1772 [06:22<12:37,  1.57it/s, running training loss:  0.86445]\u001b[A\n",
            "Training:  33%|███▎      | 580/1772 [06:22<12:37,  1.57it/s, running training loss:  0.94424]\u001b[A\n",
            "Training:  33%|███▎      | 581/1772 [06:22<12:40,  1.57it/s, running training loss:  0.94424]\u001b[A\n",
            "Training:  33%|███▎      | 581/1772 [06:23<12:40,  1.57it/s, running training loss:  0.94526]\u001b[A\n",
            "Training:  33%|███▎      | 582/1772 [06:23<11:33,  1.72it/s, running training loss:  0.94526]\u001b[A\n",
            "Training:  33%|███▎      | 582/1772 [06:23<11:33,  1.72it/s, running training loss:  1.02617]\u001b[A\n",
            "Training:  33%|███▎      | 583/1772 [06:23<10:58,  1.80it/s, running training loss:  1.02617]\u001b[A\n",
            "Training:  33%|███▎      | 583/1772 [06:24<10:58,  1.80it/s, running training loss:  0.90147]\u001b[A\n",
            "Training:  33%|███▎      | 584/1772 [06:24<10:58,  1.80it/s, running training loss:  0.90147]\u001b[A\n",
            "Training:  33%|███▎      | 584/1772 [06:24<10:58,  1.80it/s, running training loss:  0.87211]\u001b[A\n",
            "Training:  33%|███▎      | 585/1772 [06:24<12:10,  1.63it/s, running training loss:  0.87211]\u001b[A\n",
            "Training:  33%|███▎      | 585/1772 [06:25<12:10,  1.63it/s, running training loss:  0.81434]\u001b[A\n",
            "Training:  33%|███▎      | 586/1772 [06:25<11:44,  1.68it/s, running training loss:  0.81434]\u001b[A\n",
            "Training:  33%|███▎      | 586/1772 [06:26<11:44,  1.68it/s, running training loss:  0.99538]\u001b[A\n",
            "Training:  33%|███▎      | 587/1772 [06:26<12:07,  1.63it/s, running training loss:  0.99538]\u001b[A\n",
            "Training:  33%|███▎      | 587/1772 [06:26<12:07,  1.63it/s, running training loss:  0.85933]\u001b[A\n",
            "Training:  33%|███▎      | 588/1772 [06:26<12:06,  1.63it/s, running training loss:  0.85933]\u001b[A\n",
            "Training:  33%|███▎      | 588/1772 [06:27<12:06,  1.63it/s, running training loss:  0.82558]\u001b[A\n",
            "Training:  33%|███▎      | 589/1772 [06:27<11:38,  1.69it/s, running training loss:  0.82558]\u001b[A\n",
            "Training:  33%|███▎      | 589/1772 [06:27<11:38,  1.69it/s, running training loss:  0.93702]\u001b[A\n",
            "Training:  33%|███▎      | 590/1772 [06:27<11:25,  1.72it/s, running training loss:  0.93702]\u001b[A\n",
            "Training:  33%|███▎      | 590/1772 [06:28<11:25,  1.72it/s, running training loss:  0.98101]\u001b[A\n",
            "Training:  33%|███▎      | 591/1772 [06:28<10:42,  1.84it/s, running training loss:  0.98101]\u001b[A\n",
            "Training:  33%|███▎      | 591/1772 [06:28<10:42,  1.84it/s, running training loss:  1.10507]\u001b[A\n",
            "Training:  33%|███▎      | 592/1772 [06:28<10:53,  1.81it/s, running training loss:  1.10507]\u001b[A\n",
            "Training:  33%|███▎      | 592/1772 [06:29<10:53,  1.81it/s, running training loss:  0.99275]\u001b[A\n",
            "Training:  33%|███▎      | 593/1772 [06:29<11:05,  1.77it/s, running training loss:  0.99275]\u001b[A\n",
            "Training:  33%|███▎      | 593/1772 [06:30<11:05,  1.77it/s, running training loss:  0.91033]\u001b[A\n",
            "Training:  34%|███▎      | 594/1772 [06:30<11:37,  1.69it/s, running training loss:  0.91033]\u001b[A\n",
            "Training:  34%|███▎      | 594/1772 [06:30<11:37,  1.69it/s, running training loss:  0.87481]\u001b[A\n",
            "Training:  34%|███▎      | 595/1772 [06:30<11:27,  1.71it/s, running training loss:  0.87481]\u001b[A\n",
            "Training:  34%|███▎      | 595/1772 [06:31<11:27,  1.71it/s, running training loss:  1.09787]\u001b[A\n",
            "Training:  34%|███▎      | 596/1772 [06:31<13:04,  1.50it/s, running training loss:  1.09787]\u001b[A\n",
            "Training:  34%|███▎      | 596/1772 [06:32<13:04,  1.50it/s, running training loss:  1.00830]\u001b[A\n",
            "Training:  34%|███▎      | 597/1772 [06:32<13:23,  1.46it/s, running training loss:  1.00830]\u001b[A\n",
            "Training:  34%|███▎      | 597/1772 [06:33<13:23,  1.46it/s, running training loss:  1.09135]\u001b[A\n",
            "Training:  34%|███▎      | 598/1772 [06:33<14:35,  1.34it/s, running training loss:  1.09135]\u001b[A\n",
            "Training:  34%|███▎      | 598/1772 [06:33<14:35,  1.34it/s, running training loss:  0.92409]\u001b[A\n",
            "Training:  34%|███▍      | 599/1772 [06:33<14:24,  1.36it/s, running training loss:  0.92409]\u001b[A\n",
            "Training:  34%|███▍      | 599/1772 [06:34<14:24,  1.36it/s, running training loss:  0.95734]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            ">>> EMA starting .....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Evaluation:   0%|          | 0/270 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   0%|          | 1/270 [00:00<01:46,  2.51it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   1%|          | 2/270 [00:00<01:04,  4.16it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   1%|          | 3/270 [00:00<00:48,  5.53it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   1%|▏         | 4/270 [00:00<00:41,  6.35it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   2%|▏         | 5/270 [00:00<00:37,  7.08it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   2%|▏         | 6/270 [00:00<00:35,  7.51it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   3%|▎         | 8/270 [00:01<00:29,  8.83it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   3%|▎         | 9/270 [00:01<00:29,  8.94it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   4%|▎         | 10/270 [00:01<00:28,  9.16it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   4%|▍         | 12/270 [00:01<00:24, 10.37it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   5%|▌         | 14/270 [00:01<00:26,  9.73it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   6%|▌         | 15/270 [00:01<00:26,  9.75it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   6%|▌         | 16/270 [00:02<00:27,  9.09it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   6%|▋         | 17/270 [00:02<00:28,  8.87it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   7%|▋         | 19/270 [00:02<00:26,  9.50it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   7%|▋         | 20/270 [00:02<00:27,  9.08it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   8%|▊         | 22/270 [00:02<00:24, 10.18it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   9%|▉         | 24/270 [00:02<00:22, 10.71it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  10%|▉         | 26/270 [00:02<00:23, 10.42it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  10%|█         | 28/270 [00:03<00:24, 10.02it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  11%|█         | 30/270 [00:03<00:25,  9.58it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  11%|█▏        | 31/270 [00:03<00:25,  9.27it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  12%|█▏        | 33/270 [00:03<00:25,  9.47it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  13%|█▎        | 35/270 [00:03<00:24,  9.63it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  14%|█▎        | 37/270 [00:04<00:22, 10.41it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  14%|█▍        | 39/270 [00:04<00:22, 10.28it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  15%|█▌        | 41/270 [00:04<00:22, 10.01it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  16%|█▌        | 43/270 [00:04<00:23,  9.46it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  16%|█▋        | 44/270 [00:04<00:23,  9.54it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  17%|█▋        | 45/270 [00:04<00:23,  9.53it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  17%|█▋        | 46/270 [00:05<00:24,  9.22it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  18%|█▊        | 48/270 [00:05<00:22, 10.05it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  18%|█▊        | 49/270 [00:05<00:22,  9.61it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  19%|█▊        | 50/270 [00:05<00:23,  9.34it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  19%|█▉        | 51/270 [00:05<00:24,  8.87it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  20%|█▉        | 53/270 [00:05<00:23,  9.43it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  20%|██        | 55/270 [00:05<00:21,  9.94it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  21%|██        | 56/270 [00:06<00:22,  9.53it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  21%|██        | 57/270 [00:06<00:23,  9.20it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  21%|██▏       | 58/270 [00:06<00:23,  8.92it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  22%|██▏       | 59/270 [00:06<00:24,  8.75it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  23%|██▎       | 61/270 [00:06<00:22,  9.16it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  23%|██▎       | 62/270 [00:06<00:23,  8.87it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  23%|██▎       | 63/270 [00:06<00:23,  8.75it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  24%|██▍       | 65/270 [00:07<00:21,  9.73it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  25%|██▍       | 67/270 [00:07<00:20, 10.03it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  26%|██▌       | 69/270 [00:07<00:19, 10.47it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  26%|██▋       | 71/270 [00:07<00:18, 10.71it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  27%|██▋       | 73/270 [00:07<00:19, 10.33it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  28%|██▊       | 75/270 [00:08<00:18, 10.44it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  29%|██▊       | 77/270 [00:08<00:18, 10.28it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  29%|██▉       | 79/270 [00:08<00:18, 10.37it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  30%|███       | 81/270 [00:08<00:19,  9.81it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  30%|███       | 82/270 [00:08<00:19,  9.48it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  31%|███       | 83/270 [00:08<00:20,  9.21it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  31%|███       | 84/270 [00:09<00:19,  9.37it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  31%|███▏      | 85/270 [00:09<00:20,  9.06it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  32%|███▏      | 87/270 [00:09<00:19,  9.55it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  33%|███▎      | 88/270 [00:09<00:19,  9.20it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  33%|███▎      | 89/270 [00:09<00:20,  8.96it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  33%|███▎      | 90/270 [00:09<00:20,  9.00it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  34%|███▎      | 91/270 [00:09<00:20,  8.73it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  34%|███▍      | 92/270 [00:09<00:19,  9.00it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  34%|███▍      | 93/270 [00:10<00:19,  9.13it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  35%|███▌      | 95/270 [00:10<00:17,  9.88it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  36%|███▌      | 96/270 [00:10<00:17,  9.79it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  36%|███▌      | 97/270 [00:10<00:17,  9.75it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  36%|███▋      | 98/270 [00:10<00:17,  9.80it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  37%|███▋      | 100/270 [00:10<00:17,  9.77it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  38%|███▊      | 102/270 [00:10<00:16, 10.17it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  39%|███▊      | 104/270 [00:11<00:16, 10.01it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  39%|███▉      | 105/270 [00:11<00:17,  9.57it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  40%|███▉      | 107/270 [00:11<00:15, 10.19it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  40%|████      | 109/270 [00:11<00:16,  9.88it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  41%|████      | 110/270 [00:11<00:16,  9.77it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  41%|████      | 111/270 [00:11<00:17,  9.30it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  41%|████▏     | 112/270 [00:11<00:16,  9.42it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  42%|████▏     | 113/270 [00:12<00:16,  9.47it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  43%|████▎     | 115/270 [00:12<00:16,  9.66it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  43%|████▎     | 116/270 [00:12<00:16,  9.28it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  43%|████▎     | 117/270 [00:12<00:16,  9.02it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  44%|████▍     | 119/270 [00:12<00:15,  9.81it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  44%|████▍     | 120/270 [00:12<00:15,  9.80it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  45%|████▌     | 122/270 [00:12<00:14, 10.48it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  46%|████▌     | 124/270 [00:13<00:13, 10.71it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  47%|████▋     | 126/270 [00:13<00:14,  9.77it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  47%|████▋     | 127/270 [00:13<00:15,  9.23it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  47%|████▋     | 128/270 [00:13<00:15,  9.00it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  48%|████▊     | 129/270 [00:13<00:15,  8.85it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  49%|████▊     | 131/270 [00:13<00:14,  9.78it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  49%|████▉     | 132/270 [00:14<00:14,  9.28it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  50%|████▉     | 134/270 [00:14<00:14,  9.46it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  50%|█████     | 136/270 [00:14<00:13,  9.94it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  51%|█████     | 137/270 [00:14<00:13,  9.86it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  51%|█████     | 138/270 [00:14<00:13,  9.49it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  52%|█████▏    | 140/270 [00:14<00:13,  9.82it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  52%|█████▏    | 141/270 [00:14<00:13,  9.46it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  53%|█████▎    | 142/270 [00:15<00:14,  9.11it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  53%|█████▎    | 144/270 [00:15<00:12, 10.04it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  54%|█████▎    | 145/270 [00:15<00:13,  9.57it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  54%|█████▍    | 147/270 [00:15<00:12,  9.58it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  55%|█████▌    | 149/270 [00:15<00:12,  9.83it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  56%|█████▌    | 151/270 [00:15<00:12,  9.86it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  56%|█████▋    | 152/270 [00:16<00:12,  9.49it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  57%|█████▋    | 153/270 [00:16<00:12,  9.27it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  57%|█████▋    | 154/270 [00:16<00:12,  9.34it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  57%|█████▋    | 155/270 [00:16<00:12,  8.97it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  58%|█████▊    | 156/270 [00:16<00:13,  8.63it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  59%|█████▊    | 158/270 [00:16<00:11,  9.86it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  59%|█████▉    | 159/270 [00:16<00:11,  9.53it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  59%|█████▉    | 160/270 [00:16<00:11,  9.22it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  60%|█████▉    | 161/270 [00:17<00:11,  9.25it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  60%|██████    | 162/270 [00:17<00:11,  9.03it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  60%|██████    | 163/270 [00:17<00:11,  8.93it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  61%|██████    | 164/270 [00:17<00:11,  8.84it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  61%|██████    | 165/270 [00:17<00:12,  8.64it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  62%|██████▏   | 167/270 [00:17<00:10,  9.54it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  62%|██████▏   | 168/270 [00:17<00:11,  9.12it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  63%|██████▎   | 169/270 [00:17<00:11,  8.91it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  63%|██████▎   | 171/270 [00:18<00:10,  9.31it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  64%|██████▎   | 172/270 [00:18<00:10,  9.04it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  64%|██████▍   | 173/270 [00:18<00:10,  8.91it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  64%|██████▍   | 174/270 [00:18<00:10,  8.75it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  65%|██████▍   | 175/270 [00:18<00:11,  8.52it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  65%|██████▌   | 176/270 [00:18<00:11,  8.41it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  66%|██████▌   | 177/270 [00:18<00:11,  8.35it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  66%|██████▋   | 179/270 [00:19<00:10,  9.07it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  67%|██████▋   | 180/270 [00:19<00:10,  8.87it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  67%|██████▋   | 181/270 [00:19<00:09,  9.03it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  67%|██████▋   | 182/270 [00:19<00:10,  8.59it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  68%|██████▊   | 183/270 [00:19<00:09,  8.90it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  68%|██████▊   | 184/270 [00:19<00:09,  8.61it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  69%|██████▊   | 185/270 [00:19<00:09,  8.50it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  69%|██████▉   | 186/270 [00:19<00:09,  8.86it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  69%|██████▉   | 187/270 [00:20<00:09,  8.79it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  70%|██████▉   | 188/270 [00:20<00:09,  8.63it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  70%|███████   | 190/270 [00:20<00:07, 10.13it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  71%|███████   | 191/270 [00:20<00:07,  9.92it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  71%|███████   | 192/270 [00:20<00:08,  9.47it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  72%|███████▏  | 194/270 [00:20<00:07,  9.62it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  72%|███████▏  | 195/270 [00:20<00:08,  9.37it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  73%|███████▎  | 196/270 [00:20<00:08,  8.86it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  73%|███████▎  | 197/270 [00:21<00:08,  9.00it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  73%|███████▎  | 198/270 [00:21<00:08,  8.79it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  74%|███████▎  | 199/270 [00:21<00:08,  8.67it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  74%|███████▍  | 200/270 [00:21<00:08,  8.60it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  74%|███████▍  | 201/270 [00:21<00:08,  8.52it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  75%|███████▍  | 202/270 [00:21<00:08,  8.32it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  76%|███████▌  | 204/270 [00:21<00:06,  9.83it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  76%|███████▋  | 206/270 [00:22<00:06, 10.09it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  77%|███████▋  | 207/270 [00:22<00:06,  9.54it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  77%|███████▋  | 208/270 [00:22<00:06,  9.11it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  77%|███████▋  | 209/270 [00:22<00:06,  8.81it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  78%|███████▊  | 210/270 [00:22<00:06,  8.65it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  78%|███████▊  | 211/270 [00:22<00:06,  8.92it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  79%|███████▊  | 212/270 [00:22<00:06,  8.71it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  79%|███████▉  | 214/270 [00:22<00:05,  9.62it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  80%|████████  | 216/270 [00:23<00:05,  9.56it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  81%|████████  | 218/270 [00:23<00:05, 10.22it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  81%|████████▏ | 220/270 [00:23<00:04, 10.01it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  82%|████████▏ | 222/270 [00:23<00:04, 10.70it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  83%|████████▎ | 224/270 [00:23<00:04, 10.71it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  84%|████████▎ | 226/270 [00:24<00:04, 10.97it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  84%|████████▍ | 228/270 [00:24<00:04, 10.09it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  85%|████████▌ | 230/270 [00:24<00:04,  9.55it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  86%|████████▌ | 231/270 [00:24<00:04,  9.35it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  86%|████████▋ | 233/270 [00:24<00:03, 10.04it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  87%|████████▋ | 235/270 [00:24<00:03, 10.50it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  88%|████████▊ | 237/270 [00:25<00:03, 10.46it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  89%|████████▊ | 239/270 [00:25<00:03, 10.27it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  89%|████████▉ | 241/270 [00:25<00:03,  9.61it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  90%|█████████ | 243/270 [00:25<00:02, 10.22it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  91%|█████████ | 245/270 [00:26<00:02,  9.78it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  91%|█████████ | 246/270 [00:26<00:02,  9.25it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  91%|█████████▏| 247/270 [00:26<00:02,  8.94it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  92%|█████████▏| 248/270 [00:26<00:02,  8.76it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  92%|█████████▏| 249/270 [00:26<00:02,  8.63it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  93%|█████████▎| 250/270 [00:26<00:02,  8.42it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  93%|█████████▎| 251/270 [00:26<00:02,  8.33it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  93%|█████████▎| 252/270 [00:26<00:02,  7.97it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  94%|█████████▎| 253/270 [00:27<00:02,  8.04it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  94%|█████████▍| 254/270 [00:27<00:01,  8.13it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  94%|█████████▍| 255/270 [00:27<00:01,  8.07it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  95%|█████████▍| 256/270 [00:27<00:01,  8.10it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  95%|█████████▌| 257/270 [00:27<00:01,  8.50it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  96%|█████████▌| 258/270 [00:27<00:01,  8.80it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  96%|█████████▋| 260/270 [00:27<00:01,  9.71it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  97%|█████████▋| 262/270 [00:27<00:00,  9.68it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  97%|█████████▋| 263/270 [00:28<00:00,  9.32it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  98%|█████████▊| 264/270 [00:28<00:00,  9.06it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  98%|█████████▊| 265/270 [00:28<00:00,  8.84it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  99%|█████████▊| 266/270 [00:28<00:00,  8.71it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  99%|█████████▉| 268/270 [00:28<00:00,  9.19it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation: 100%|█████████▉| 269/270 [00:28<00:00,  8.79it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation: 100%|██████████| 270/270 [00:29<00:00,  9.29it/s]\n",
            "\n",
            "Training:  34%|███▍      | 600/1772 [07:05<3:14:22,  9.95s/it, running training loss:  0.95734]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            ">>> training loss: 1.040918, valid loss: 0.646380,valid f1: 0.000000, valid acc:0.689991\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  34%|███▍      | 600/1772 [07:05<3:14:22,  9.95s/it, running training loss:  1.07809]\u001b[A\n",
            "Training:  34%|███▍      | 601/1772 [07:05<2:19:18,  7.14s/it, running training loss:  1.07809]\u001b[A\n",
            "Training:  34%|███▍      | 601/1772 [07:06<2:19:18,  7.14s/it, running training loss:  0.86145]\u001b[A\n",
            "Training:  34%|███▍      | 602/1772 [07:06<1:40:30,  5.15s/it, running training loss:  0.86145]\u001b[A\n",
            "Training:  34%|███▍      | 602/1772 [07:07<1:40:30,  5.15s/it, running training loss:  0.96227]\u001b[A\n",
            "Training:  34%|███▍      | 603/1772 [07:07<1:13:34,  3.78s/it, running training loss:  0.96227]\u001b[A\n",
            "Training:  34%|███▍      | 603/1772 [07:07<1:13:34,  3.78s/it, running training loss:  1.07957]\u001b[A\n",
            "Training:  34%|███▍      | 604/1772 [07:07<55:10,  2.83s/it, running training loss:  1.07957]  \u001b[A\n",
            "Training:  34%|███▍      | 604/1772 [07:08<55:10,  2.83s/it, running training loss:  0.98569]\u001b[A\n",
            "Training:  34%|███▍      | 605/1772 [07:08<41:45,  2.15s/it, running training loss:  0.98569]\u001b[A\n",
            "Training:  34%|███▍      | 605/1772 [07:08<41:45,  2.15s/it, running training loss:  1.05424]\u001b[A\n",
            "Training:  34%|███▍      | 606/1772 [07:08<33:36,  1.73s/it, running training loss:  1.05424]\u001b[A\n",
            "Training:  34%|███▍      | 606/1772 [07:09<33:36,  1.73s/it, running training loss:  1.07469]\u001b[A\n",
            "Training:  34%|███▍      | 607/1772 [07:09<26:13,  1.35s/it, running training loss:  1.07469]\u001b[A\n",
            "Training:  34%|███▍      | 607/1772 [07:09<26:13,  1.35s/it, running training loss:  0.94290]\u001b[A\n",
            "Training:  34%|███▍      | 608/1772 [07:09<21:08,  1.09s/it, running training loss:  0.94290]\u001b[A\n",
            "Training:  34%|███▍      | 608/1772 [07:10<21:08,  1.09s/it, running training loss:  1.12284]\u001b[A\n",
            "Training:  34%|███▍      | 609/1772 [07:10<18:41,  1.04it/s, running training loss:  1.12284]\u001b[A\n",
            "Training:  34%|███▍      | 609/1772 [07:11<18:41,  1.04it/s, running training loss:  1.27336]\u001b[A\n",
            "Training:  34%|███▍      | 610/1772 [07:11<16:59,  1.14it/s, running training loss:  1.27336]\u001b[A\n",
            "Training:  34%|███▍      | 610/1772 [07:11<16:59,  1.14it/s, running training loss:  1.12783]\u001b[A\n",
            "Training:  34%|███▍      | 611/1772 [07:11<15:12,  1.27it/s, running training loss:  1.12783]\u001b[A\n",
            "Training:  34%|███▍      | 611/1772 [07:12<15:12,  1.27it/s, running training loss:  1.10183]\u001b[A\n",
            "Training:  35%|███▍      | 612/1772 [07:12<13:33,  1.43it/s, running training loss:  1.10183]\u001b[A\n",
            "Training:  35%|███▍      | 612/1772 [07:12<13:33,  1.43it/s, running training loss:  1.03846]\u001b[A\n",
            "Training:  35%|███▍      | 613/1772 [07:12<13:07,  1.47it/s, running training loss:  1.03846]\u001b[A\n",
            "Training:  35%|███▍      | 613/1772 [07:13<13:07,  1.47it/s, running training loss:  1.12318]\u001b[A\n",
            "Training:  35%|███▍      | 614/1772 [07:13<12:31,  1.54it/s, running training loss:  1.12318]\u001b[A\n",
            "Training:  35%|███▍      | 614/1772 [07:14<12:31,  1.54it/s, running training loss:  0.97631]\u001b[A\n",
            "Training:  35%|███▍      | 615/1772 [07:14<13:20,  1.45it/s, running training loss:  0.97631]\u001b[A\n",
            "Training:  35%|███▍      | 615/1772 [07:14<13:20,  1.45it/s, running training loss:  1.06941]\u001b[A\n",
            "Training:  35%|███▍      | 616/1772 [07:14<12:46,  1.51it/s, running training loss:  1.06941]\u001b[A\n",
            "Training:  35%|███▍      | 616/1772 [07:15<12:46,  1.51it/s, running training loss:  1.03992]\u001b[A\n",
            "Training:  35%|███▍      | 617/1772 [07:15<13:15,  1.45it/s, running training loss:  1.03992]\u001b[A\n",
            "Training:  35%|███▍      | 617/1772 [07:16<13:15,  1.45it/s, running training loss:  1.01064]\u001b[A\n",
            "Training:  35%|███▍      | 618/1772 [07:16<12:02,  1.60it/s, running training loss:  1.01064]\u001b[A\n",
            "Training:  35%|███▍      | 618/1772 [07:16<12:02,  1.60it/s, running training loss:  0.82873]\u001b[A\n",
            "Training:  35%|███▍      | 619/1772 [07:16<12:03,  1.59it/s, running training loss:  0.82873]\u001b[A\n",
            "Training:  35%|███▍      | 619/1772 [07:17<12:03,  1.59it/s, running training loss:  0.92939]\u001b[A\n",
            "Training:  35%|███▍      | 620/1772 [07:17<11:47,  1.63it/s, running training loss:  0.92939]\u001b[A\n",
            "Training:  35%|███▍      | 620/1772 [07:18<11:47,  1.63it/s, running training loss:  0.92250]\u001b[A\n",
            "Training:  35%|███▌      | 621/1772 [07:18<13:53,  1.38it/s, running training loss:  0.92250]\u001b[A\n",
            "Training:  35%|███▌      | 621/1772 [07:18<13:53,  1.38it/s, running training loss:  0.82373]\u001b[A\n",
            "Training:  35%|███▌      | 622/1772 [07:18<13:00,  1.47it/s, running training loss:  0.82373]\u001b[A\n",
            "Training:  35%|███▌      | 622/1772 [07:19<13:00,  1.47it/s, running training loss:  1.02018]\u001b[A\n",
            "Training:  35%|███▌      | 623/1772 [07:19<11:54,  1.61it/s, running training loss:  1.02018]\u001b[A\n",
            "Training:  35%|███▌      | 623/1772 [07:19<11:54,  1.61it/s, running training loss:  0.78155]\u001b[A\n",
            "Training:  35%|███▌      | 624/1772 [07:19<11:25,  1.68it/s, running training loss:  0.78155]\u001b[A\n",
            "Training:  35%|███▌      | 624/1772 [07:20<11:25,  1.68it/s, running training loss:  0.86283]\u001b[A\n",
            "Training:  35%|███▌      | 625/1772 [07:20<13:53,  1.38it/s, running training loss:  0.86283]\u001b[A\n",
            "Training:  35%|███▌      | 625/1772 [07:21<13:53,  1.38it/s, running training loss:  0.94051]\u001b[A\n",
            "Training:  35%|███▌      | 626/1772 [07:21<12:24,  1.54it/s, running training loss:  0.94051]\u001b[A\n",
            "Training:  35%|███▌      | 626/1772 [07:21<12:24,  1.54it/s, running training loss:  0.79921]\u001b[A\n",
            "Training:  35%|███▌      | 627/1772 [07:21<11:40,  1.63it/s, running training loss:  0.79921]\u001b[A\n",
            "Training:  35%|███▌      | 627/1772 [07:22<11:40,  1.63it/s, running training loss:  0.78470]\u001b[A\n",
            "Training:  35%|███▌      | 628/1772 [07:22<10:58,  1.74it/s, running training loss:  0.78470]\u001b[A\n",
            "Training:  35%|███▌      | 628/1772 [07:23<10:58,  1.74it/s, running training loss:  1.11233]\u001b[A\n",
            "Training:  35%|███▌      | 629/1772 [07:23<11:32,  1.65it/s, running training loss:  1.11233]\u001b[A\n",
            "Training:  35%|███▌      | 629/1772 [07:23<11:32,  1.65it/s, running training loss:  0.84334]\u001b[A\n",
            "Training:  36%|███▌      | 630/1772 [07:23<11:45,  1.62it/s, running training loss:  0.84334]\u001b[A\n",
            "Training:  36%|███▌      | 630/1772 [07:24<11:45,  1.62it/s, running training loss:  1.01292]\u001b[A\n",
            "Training:  36%|███▌      | 631/1772 [07:24<14:04,  1.35it/s, running training loss:  1.01292]\u001b[A\n",
            "Training:  36%|███▌      | 631/1772 [07:25<14:04,  1.35it/s, running training loss:  0.94904]\u001b[A\n",
            "Training:  36%|███▌      | 632/1772 [07:25<13:35,  1.40it/s, running training loss:  0.94904]\u001b[A\n",
            "Training:  36%|███▌      | 632/1772 [07:26<13:35,  1.40it/s, running training loss:  0.97002]\u001b[A\n",
            "Training:  36%|███▌      | 633/1772 [07:26<14:55,  1.27it/s, running training loss:  0.97002]\u001b[A\n",
            "Training:  36%|███▌      | 633/1772 [07:27<14:55,  1.27it/s, running training loss:  0.88091]\u001b[A\n",
            "Training:  36%|███▌      | 634/1772 [07:27<15:17,  1.24it/s, running training loss:  0.88091]\u001b[A\n",
            "Training:  36%|███▌      | 634/1772 [07:27<15:17,  1.24it/s, running training loss:  0.89998]\u001b[A\n",
            "Training:  36%|███▌      | 635/1772 [07:27<14:15,  1.33it/s, running training loss:  0.89998]\u001b[A\n",
            "Training:  36%|███▌      | 635/1772 [07:28<14:15,  1.33it/s, running training loss:  1.02174]\u001b[A\n",
            "Training:  36%|███▌      | 636/1772 [07:28<13:19,  1.42it/s, running training loss:  1.02174]\u001b[A\n",
            "Training:  36%|███▌      | 636/1772 [07:29<13:19,  1.42it/s, running training loss:  1.07012]\u001b[A\n",
            "Training:  36%|███▌      | 637/1772 [07:29<12:43,  1.49it/s, running training loss:  1.07012]\u001b[A\n",
            "Training:  36%|███▌      | 637/1772 [07:29<12:43,  1.49it/s, running training loss:  0.96762]\u001b[A\n",
            "Training:  36%|███▌      | 638/1772 [07:29<12:20,  1.53it/s, running training loss:  0.96762]\u001b[A\n",
            "Training:  36%|███▌      | 638/1772 [07:30<12:20,  1.53it/s, running training loss:  0.86308]\u001b[A\n",
            "Training:  36%|███▌      | 639/1772 [07:30<11:47,  1.60it/s, running training loss:  0.86308]\u001b[A\n",
            "Training:  36%|███▌      | 639/1772 [07:30<11:47,  1.60it/s, running training loss:  0.99858]\u001b[A\n",
            "Training:  36%|███▌      | 640/1772 [07:30<12:07,  1.55it/s, running training loss:  0.99858]\u001b[A\n",
            "Training:  36%|███▌      | 640/1772 [07:31<12:07,  1.55it/s, running training loss:  1.00753]\u001b[A\n",
            "Training:  36%|███▌      | 641/1772 [07:31<11:36,  1.62it/s, running training loss:  1.00753]\u001b[A\n",
            "Training:  36%|███▌      | 641/1772 [07:32<11:36,  1.62it/s, running training loss:  0.92821]\u001b[A\n",
            "Training:  36%|███▌      | 642/1772 [07:32<11:55,  1.58it/s, running training loss:  0.92821]\u001b[A\n",
            "Training:  36%|███▌      | 642/1772 [07:32<11:55,  1.58it/s, running training loss:  1.21904]\u001b[A\n",
            "Training:  36%|███▋      | 643/1772 [07:32<11:32,  1.63it/s, running training loss:  1.21904]\u001b[A\n",
            "Training:  36%|███▋      | 643/1772 [07:33<11:32,  1.63it/s, running training loss:  1.24896]\u001b[A\n",
            "Training:  36%|███▋      | 644/1772 [07:33<11:57,  1.57it/s, running training loss:  1.24896]\u001b[A\n",
            "Training:  36%|███▋      | 644/1772 [07:34<11:57,  1.57it/s, running training loss:  0.91982]\u001b[A\n",
            "Training:  36%|███▋      | 645/1772 [07:34<12:00,  1.56it/s, running training loss:  0.91982]\u001b[A\n",
            "Training:  36%|███▋      | 645/1772 [07:34<12:00,  1.56it/s, running training loss:  1.02790]\u001b[A\n",
            "Training:  36%|███▋      | 646/1772 [07:34<11:35,  1.62it/s, running training loss:  1.02790]\u001b[A\n",
            "Training:  36%|███▋      | 646/1772 [07:35<11:35,  1.62it/s, running training loss:  0.96701]\u001b[A\n",
            "Training:  37%|███▋      | 647/1772 [07:35<12:51,  1.46it/s, running training loss:  0.96701]\u001b[A\n",
            "Training:  37%|███▋      | 647/1772 [07:36<12:51,  1.46it/s, running training loss:  1.10826]\u001b[A\n",
            "Training:  37%|███▋      | 648/1772 [07:36<12:04,  1.55it/s, running training loss:  1.10826]\u001b[A\n",
            "Training:  37%|███▋      | 648/1772 [07:36<12:04,  1.55it/s, running training loss:  1.01072]\u001b[A\n",
            "Training:  37%|███▋      | 649/1772 [07:36<12:13,  1.53it/s, running training loss:  1.01072]\u001b[A\n",
            "Training:  37%|███▋      | 649/1772 [07:37<12:13,  1.53it/s, running training loss:  1.01965]\u001b[A\n",
            "Training:  37%|███▋      | 650/1772 [07:37<12:09,  1.54it/s, running training loss:  1.01965]\u001b[A\n",
            "Training:  37%|███▋      | 650/1772 [07:37<12:09,  1.54it/s, running training loss:  0.97317]\u001b[A\n",
            "Training:  37%|███▋      | 651/1772 [07:37<11:58,  1.56it/s, running training loss:  0.97317]\u001b[A\n",
            "Training:  37%|███▋      | 651/1772 [07:38<11:58,  1.56it/s, running training loss:  1.07008]\u001b[A\n",
            "Training:  37%|███▋      | 652/1772 [07:38<12:50,  1.45it/s, running training loss:  1.07008]\u001b[A\n",
            "Training:  37%|███▋      | 652/1772 [07:39<12:50,  1.45it/s, running training loss:  1.04035]\u001b[A\n",
            "Training:  37%|███▋      | 653/1772 [07:39<12:25,  1.50it/s, running training loss:  1.04035]\u001b[A\n",
            "Training:  37%|███▋      | 653/1772 [07:40<12:25,  1.50it/s, running training loss:  1.05179]\u001b[A\n",
            "Training:  37%|███▋      | 654/1772 [07:40<12:19,  1.51it/s, running training loss:  1.05179]\u001b[A\n",
            "Training:  37%|███▋      | 654/1772 [07:40<12:19,  1.51it/s, running training loss:  0.99526]\u001b[A\n",
            "Training:  37%|███▋      | 655/1772 [07:40<11:40,  1.59it/s, running training loss:  0.99526]\u001b[A\n",
            "Training:  37%|███▋      | 655/1772 [07:41<11:40,  1.59it/s, running training loss:  1.15730]\u001b[A\n",
            "Training:  37%|███▋      | 656/1772 [07:41<11:15,  1.65it/s, running training loss:  1.15730]\u001b[A\n",
            "Training:  37%|███▋      | 656/1772 [07:41<11:15,  1.65it/s, running training loss:  1.01247]\u001b[A\n",
            "Training:  37%|███▋      | 657/1772 [07:41<11:50,  1.57it/s, running training loss:  1.01247]\u001b[A\n",
            "Training:  37%|███▋      | 657/1772 [07:42<11:50,  1.57it/s, running training loss:  1.01979]\u001b[A\n",
            "Training:  37%|███▋      | 658/1772 [07:42<10:29,  1.77it/s, running training loss:  1.01979]\u001b[A\n",
            "Training:  37%|███▋      | 658/1772 [07:43<10:29,  1.77it/s, running training loss:  0.90075]\u001b[A\n",
            "Training:  37%|███▋      | 659/1772 [07:43<12:58,  1.43it/s, running training loss:  0.90075]\u001b[A\n",
            "Training:  37%|███▋      | 659/1772 [07:44<12:58,  1.43it/s, running training loss:  0.98923]\u001b[A\n",
            "Training:  37%|███▋      | 660/1772 [07:44<13:22,  1.39it/s, running training loss:  0.98923]\u001b[A\n",
            "Training:  37%|███▋      | 660/1772 [07:44<13:22,  1.39it/s, running training loss:  0.92524]\u001b[A\n",
            "Training:  37%|███▋      | 661/1772 [07:44<11:58,  1.55it/s, running training loss:  0.92524]\u001b[A\n",
            "Training:  37%|███▋      | 661/1772 [07:45<11:58,  1.55it/s, running training loss:  1.07157]\u001b[A\n",
            "Training:  37%|███▋      | 662/1772 [07:45<11:26,  1.62it/s, running training loss:  1.07157]\u001b[A\n",
            "Training:  37%|███▋      | 662/1772 [07:45<11:26,  1.62it/s, running training loss:  1.11363]\u001b[A\n",
            "Training:  37%|███▋      | 663/1772 [07:45<12:22,  1.49it/s, running training loss:  1.11363]\u001b[A\n",
            "Training:  37%|███▋      | 663/1772 [07:46<12:22,  1.49it/s, running training loss:  0.97806]\u001b[A\n",
            "Training:  37%|███▋      | 664/1772 [07:46<11:35,  1.59it/s, running training loss:  0.97806]\u001b[A\n",
            "Training:  37%|███▋      | 664/1772 [07:47<11:35,  1.59it/s, running training loss:  1.01389]\u001b[A\n",
            "Training:  38%|███▊      | 665/1772 [07:47<11:37,  1.59it/s, running training loss:  1.01389]\u001b[A\n",
            "Training:  38%|███▊      | 665/1772 [07:47<11:37,  1.59it/s, running training loss:  1.03658]\u001b[A\n",
            "Training:  38%|███▊      | 666/1772 [07:47<11:17,  1.63it/s, running training loss:  1.03658]\u001b[A\n",
            "Training:  38%|███▊      | 666/1772 [07:48<11:17,  1.63it/s, running training loss:  0.97310]\u001b[A\n",
            "Training:  38%|███▊      | 667/1772 [07:48<11:06,  1.66it/s, running training loss:  0.97310]\u001b[A\n",
            "Training:  38%|███▊      | 667/1772 [07:48<11:06,  1.66it/s, running training loss:  1.04333]\u001b[A\n",
            "Training:  38%|███▊      | 668/1772 [07:48<10:49,  1.70it/s, running training loss:  1.04333]\u001b[A\n",
            "Training:  38%|███▊      | 668/1772 [07:49<10:49,  1.70it/s, running training loss:  0.96307]\u001b[A\n",
            "Training:  38%|███▊      | 669/1772 [07:49<11:27,  1.60it/s, running training loss:  0.96307]\u001b[A\n",
            "Training:  38%|███▊      | 669/1772 [07:50<11:27,  1.60it/s, running training loss:  1.03756]\u001b[A\n",
            "Training:  38%|███▊      | 670/1772 [07:50<11:30,  1.60it/s, running training loss:  1.03756]\u001b[A\n",
            "Training:  38%|███▊      | 670/1772 [07:50<11:30,  1.60it/s, running training loss:  0.96926]\u001b[A\n",
            "Training:  38%|███▊      | 671/1772 [07:50<10:59,  1.67it/s, running training loss:  0.96926]\u001b[A\n",
            "Training:  38%|███▊      | 671/1772 [07:51<10:59,  1.67it/s, running training loss:  0.94174]\u001b[A\n",
            "Training:  38%|███▊      | 672/1772 [07:51<12:02,  1.52it/s, running training loss:  0.94174]\u001b[A\n",
            "Training:  38%|███▊      | 672/1772 [07:51<12:02,  1.52it/s, running training loss:  1.01141]\u001b[A\n",
            "Training:  38%|███▊      | 673/1772 [07:51<11:16,  1.63it/s, running training loss:  1.01141]\u001b[A\n",
            "Training:  38%|███▊      | 673/1772 [07:52<11:16,  1.63it/s, running training loss:  1.06291]\u001b[A\n",
            "Training:  38%|███▊      | 674/1772 [07:52<10:48,  1.69it/s, running training loss:  1.06291]\u001b[A\n",
            "Training:  38%|███▊      | 674/1772 [07:53<10:48,  1.69it/s, running training loss:  1.00819]\u001b[A\n",
            "Training:  38%|███▊      | 675/1772 [07:53<12:35,  1.45it/s, running training loss:  1.00819]\u001b[A\n",
            "Training:  38%|███▊      | 675/1772 [07:53<12:35,  1.45it/s, running training loss:  0.93525]\u001b[A\n",
            "Training:  38%|███▊      | 676/1772 [07:53<11:59,  1.52it/s, running training loss:  0.93525]\u001b[A\n",
            "Training:  38%|███▊      | 676/1772 [07:54<11:59,  1.52it/s, running training loss:  1.11050]\u001b[A\n",
            "Training:  38%|███▊      | 677/1772 [07:54<13:59,  1.30it/s, running training loss:  1.11050]\u001b[A\n",
            "Training:  38%|███▊      | 677/1772 [07:55<13:59,  1.30it/s, running training loss:  0.88500]\u001b[A\n",
            "Training:  38%|███▊      | 678/1772 [07:55<13:33,  1.34it/s, running training loss:  0.88500]\u001b[A\n",
            "Training:  38%|███▊      | 678/1772 [07:56<13:33,  1.34it/s, running training loss:  0.98004]\u001b[A\n",
            "Training:  38%|███▊      | 679/1772 [07:56<13:17,  1.37it/s, running training loss:  0.98004]\u001b[A\n",
            "Training:  38%|███▊      | 679/1772 [07:57<13:17,  1.37it/s, running training loss:  0.93057]\u001b[A\n",
            "Training:  38%|███▊      | 680/1772 [07:57<12:58,  1.40it/s, running training loss:  0.93057]\u001b[A\n",
            "Training:  38%|███▊      | 680/1772 [07:57<12:58,  1.40it/s, running training loss:  1.06876]\u001b[A\n",
            "Training:  38%|███▊      | 681/1772 [07:57<12:02,  1.51it/s, running training loss:  1.06876]\u001b[A\n",
            "Training:  38%|███▊      | 681/1772 [07:58<12:02,  1.51it/s, running training loss:  0.83363]\u001b[A\n",
            "Training:  38%|███▊      | 682/1772 [07:58<11:54,  1.53it/s, running training loss:  0.83363]\u001b[A\n",
            "Training:  38%|███▊      | 682/1772 [07:58<11:54,  1.53it/s, running training loss:  1.12008]\u001b[A\n",
            "Training:  39%|███▊      | 683/1772 [07:58<11:02,  1.64it/s, running training loss:  1.12008]\u001b[A\n",
            "Training:  39%|███▊      | 683/1772 [07:59<11:02,  1.64it/s, running training loss:  0.99805]\u001b[A\n",
            "Training:  39%|███▊      | 684/1772 [07:59<10:31,  1.72it/s, running training loss:  0.99805]\u001b[A\n",
            "Training:  39%|███▊      | 684/1772 [07:59<10:31,  1.72it/s, running training loss:  1.03258]\u001b[A\n",
            "Training:  39%|███▊      | 685/1772 [07:59<10:48,  1.68it/s, running training loss:  1.03258]\u001b[A\n",
            "Training:  39%|███▊      | 685/1772 [08:00<10:48,  1.68it/s, running training loss:  0.98139]\u001b[A\n",
            "Training:  39%|███▊      | 686/1772 [08:00<10:37,  1.70it/s, running training loss:  0.98139]\u001b[A\n",
            "Training:  39%|███▊      | 686/1772 [08:00<10:37,  1.70it/s, running training loss:  0.98985]\u001b[A\n",
            "Training:  39%|███▉      | 687/1772 [08:00<10:25,  1.74it/s, running training loss:  0.98985]\u001b[A\n",
            "Training:  39%|███▉      | 687/1772 [08:01<10:25,  1.74it/s, running training loss:  0.93771]\u001b[A\n",
            "Training:  39%|███▉      | 688/1772 [08:01<11:07,  1.62it/s, running training loss:  0.93771]\u001b[A\n",
            "Training:  39%|███▉      | 688/1772 [08:02<11:07,  1.62it/s, running training loss:  1.04896]\u001b[A\n",
            "Training:  39%|███▉      | 689/1772 [08:02<10:45,  1.68it/s, running training loss:  1.04896]\u001b[A\n",
            "Training:  39%|███▉      | 689/1772 [08:02<10:45,  1.68it/s, running training loss:  0.98706]\u001b[A\n",
            "Training:  39%|███▉      | 690/1772 [08:02<10:36,  1.70it/s, running training loss:  0.98706]\u001b[A\n",
            "Training:  39%|███▉      | 690/1772 [08:03<10:36,  1.70it/s, running training loss:  0.78651]\u001b[A\n",
            "Training:  39%|███▉      | 691/1772 [08:03<10:49,  1.66it/s, running training loss:  0.78651]\u001b[A\n",
            "Training:  39%|███▉      | 691/1772 [08:03<10:49,  1.66it/s, running training loss:  0.97567]\u001b[A\n",
            "Training:  39%|███▉      | 692/1772 [08:03<10:17,  1.75it/s, running training loss:  0.97567]\u001b[A\n",
            "Training:  39%|███▉      | 692/1772 [08:04<10:17,  1.75it/s, running training loss:  0.94854]\u001b[A\n",
            "Training:  39%|███▉      | 693/1772 [08:04<09:29,  1.89it/s, running training loss:  0.94854]\u001b[A\n",
            "Training:  39%|███▉      | 693/1772 [08:04<09:29,  1.89it/s, running training loss:  0.84408]\u001b[A\n",
            "Training:  39%|███▉      | 694/1772 [08:04<09:39,  1.86it/s, running training loss:  0.84408]\u001b[A\n",
            "Training:  39%|███▉      | 694/1772 [08:05<09:39,  1.86it/s, running training loss:  0.97086]\u001b[A\n",
            "Training:  39%|███▉      | 695/1772 [08:05<11:52,  1.51it/s, running training loss:  0.97086]\u001b[A\n",
            "Training:  39%|███▉      | 695/1772 [08:06<11:52,  1.51it/s, running training loss:  0.83023]\u001b[A\n",
            "Training:  39%|███▉      | 696/1772 [08:06<11:05,  1.62it/s, running training loss:  0.83023]\u001b[A\n",
            "Training:  39%|███▉      | 696/1772 [08:07<11:05,  1.62it/s, running training loss:  0.99417]\u001b[A\n",
            "Training:  39%|███▉      | 697/1772 [08:07<11:11,  1.60it/s, running training loss:  0.99417]\u001b[A\n",
            "Training:  39%|███▉      | 697/1772 [08:07<11:11,  1.60it/s, running training loss:  0.76441]\u001b[A\n",
            "Training:  39%|███▉      | 698/1772 [08:07<11:22,  1.57it/s, running training loss:  0.76441]\u001b[A\n",
            "Training:  39%|███▉      | 698/1772 [08:08<11:22,  1.57it/s, running training loss:  0.84589]\u001b[A\n",
            "Training:  39%|███▉      | 699/1772 [08:08<12:21,  1.45it/s, running training loss:  0.84589]\u001b[A\n",
            "Training:  39%|███▉      | 699/1772 [08:09<12:21,  1.45it/s, running training loss:  0.94729]\u001b[A\n",
            "Training:  40%|███▉      | 700/1772 [08:09<12:06,  1.48it/s, running training loss:  0.94729]\u001b[A\n",
            "Training:  40%|███▉      | 700/1772 [08:09<12:06,  1.48it/s, running training loss:  0.95336]\u001b[A\n",
            "Training:  40%|███▉      | 701/1772 [08:09<11:13,  1.59it/s, running training loss:  0.95336]\u001b[A\n",
            "Training:  40%|███▉      | 701/1772 [08:10<11:13,  1.59it/s, running training loss:  0.93222]\u001b[A\n",
            "Training:  40%|███▉      | 702/1772 [08:10<11:36,  1.54it/s, running training loss:  0.93222]\u001b[A\n",
            "Training:  40%|███▉      | 702/1772 [08:10<11:36,  1.54it/s, running training loss:  0.91623]\u001b[A\n",
            "Training:  40%|███▉      | 703/1772 [08:10<11:15,  1.58it/s, running training loss:  0.91623]\u001b[A\n",
            "Training:  40%|███▉      | 703/1772 [08:11<11:15,  1.58it/s, running training loss:  0.94194]\u001b[A\n",
            "Training:  40%|███▉      | 704/1772 [08:11<12:30,  1.42it/s, running training loss:  0.94194]\u001b[A\n",
            "Training:  40%|███▉      | 704/1772 [08:12<12:30,  1.42it/s, running training loss:  0.85738]\u001b[A\n",
            "Training:  40%|███▉      | 705/1772 [08:12<11:19,  1.57it/s, running training loss:  0.85738]\u001b[A\n",
            "Training:  40%|███▉      | 705/1772 [08:12<11:19,  1.57it/s, running training loss:  1.04949]\u001b[A\n",
            "Training:  40%|███▉      | 706/1772 [08:12<10:40,  1.67it/s, running training loss:  1.04949]\u001b[A\n",
            "Training:  40%|███▉      | 706/1772 [08:13<10:40,  1.67it/s, running training loss:  0.81696]\u001b[A\n",
            "Training:  40%|███▉      | 707/1772 [08:13<11:03,  1.61it/s, running training loss:  0.81696]\u001b[A\n",
            "Training:  40%|███▉      | 707/1772 [08:14<11:03,  1.61it/s, running training loss:  0.88973]\u001b[A\n",
            "Training:  40%|███▉      | 708/1772 [08:14<10:40,  1.66it/s, running training loss:  0.88973]\u001b[A\n",
            "Training:  40%|███▉      | 708/1772 [08:14<10:40,  1.66it/s, running training loss:  1.27141]\u001b[A\n",
            "Training:  40%|████      | 709/1772 [08:14<10:55,  1.62it/s, running training loss:  1.27141]\u001b[A\n",
            "Training:  40%|████      | 709/1772 [08:15<10:55,  1.62it/s, running training loss:  1.09075]\u001b[A\n",
            "Training:  40%|████      | 710/1772 [08:15<11:26,  1.55it/s, running training loss:  1.09075]\u001b[A\n",
            "Training:  40%|████      | 710/1772 [08:16<11:26,  1.55it/s, running training loss:  1.12427]\u001b[A\n",
            "Training:  40%|████      | 711/1772 [08:16<11:39,  1.52it/s, running training loss:  1.12427]\u001b[A\n",
            "Training:  40%|████      | 711/1772 [08:16<11:39,  1.52it/s, running training loss:  1.12077]\u001b[A\n",
            "Training:  40%|████      | 712/1772 [08:16<11:14,  1.57it/s, running training loss:  1.12077]\u001b[A\n",
            "Training:  40%|████      | 712/1772 [08:17<11:14,  1.57it/s, running training loss:  1.04413]\u001b[A\n",
            "Training:  40%|████      | 713/1772 [08:17<11:05,  1.59it/s, running training loss:  1.04413]\u001b[A\n",
            "Training:  40%|████      | 713/1772 [08:17<11:05,  1.59it/s, running training loss:  0.90672]\u001b[A\n",
            "Training:  40%|████      | 714/1772 [08:17<10:50,  1.63it/s, running training loss:  0.90672]\u001b[A\n",
            "Training:  40%|████      | 714/1772 [08:18<10:50,  1.63it/s, running training loss:  0.97071]\u001b[A\n",
            "Training:  40%|████      | 715/1772 [08:18<10:50,  1.63it/s, running training loss:  0.97071]\u001b[A\n",
            "Training:  40%|████      | 715/1772 [08:19<10:50,  1.63it/s, running training loss:  1.01016]\u001b[A\n",
            "Training:  40%|████      | 716/1772 [08:19<10:50,  1.62it/s, running training loss:  1.01016]\u001b[A\n",
            "Training:  40%|████      | 716/1772 [08:19<10:50,  1.62it/s, running training loss:  0.90438]\u001b[A\n",
            "Training:  40%|████      | 717/1772 [08:19<10:20,  1.70it/s, running training loss:  0.90438]\u001b[A\n",
            "Training:  40%|████      | 717/1772 [08:20<10:20,  1.70it/s, running training loss:  0.96206]\u001b[A\n",
            "Training:  41%|████      | 718/1772 [08:20<10:21,  1.70it/s, running training loss:  0.96206]\u001b[A\n",
            "Training:  41%|████      | 718/1772 [08:20<10:21,  1.70it/s, running training loss:  0.74878]\u001b[A\n",
            "Training:  41%|████      | 719/1772 [08:20<10:27,  1.68it/s, running training loss:  0.74878]\u001b[A\n",
            "Training:  41%|████      | 719/1772 [08:21<10:27,  1.68it/s, running training loss:  0.94479]\u001b[A\n",
            "Training:  41%|████      | 720/1772 [08:21<09:57,  1.76it/s, running training loss:  0.94479]\u001b[A\n",
            "Training:  41%|████      | 720/1772 [08:21<09:57,  1.76it/s, running training loss:  0.86682]\u001b[A\n",
            "Training:  41%|████      | 721/1772 [08:21<10:18,  1.70it/s, running training loss:  0.86682]\u001b[A\n",
            "Training:  41%|████      | 721/1772 [08:22<10:18,  1.70it/s, running training loss:  1.09920]\u001b[A\n",
            "Training:  41%|████      | 722/1772 [08:22<10:47,  1.62it/s, running training loss:  1.09920]\u001b[A\n",
            "Training:  41%|████      | 722/1772 [08:23<10:47,  1.62it/s, running training loss:  1.22293]\u001b[A\n",
            "Training:  41%|████      | 723/1772 [08:23<10:25,  1.68it/s, running training loss:  1.22293]\u001b[A\n",
            "Training:  41%|████      | 723/1772 [08:23<10:25,  1.68it/s, running training loss:  1.02663]\u001b[A\n",
            "Training:  41%|████      | 724/1772 [08:23<09:47,  1.78it/s, running training loss:  1.02663]\u001b[A\n",
            "Training:  41%|████      | 724/1772 [08:24<09:47,  1.78it/s, running training loss:  1.14862]\u001b[A\n",
            "Training:  41%|████      | 725/1772 [08:24<09:58,  1.75it/s, running training loss:  1.14862]\u001b[A\n",
            "Training:  41%|████      | 725/1772 [08:24<09:58,  1.75it/s, running training loss:  0.97761]\u001b[A\n",
            "Training:  41%|████      | 726/1772 [08:24<09:46,  1.78it/s, running training loss:  0.97761]\u001b[A\n",
            "Training:  41%|████      | 726/1772 [08:25<09:46,  1.78it/s, running training loss:  1.14022]\u001b[A\n",
            "Training:  41%|████      | 727/1772 [08:25<09:53,  1.76it/s, running training loss:  1.14022]\u001b[A\n",
            "Training:  41%|████      | 727/1772 [08:25<09:53,  1.76it/s, running training loss:  0.85473]\u001b[A\n",
            "Training:  41%|████      | 728/1772 [08:25<09:48,  1.78it/s, running training loss:  0.85473]\u001b[A\n",
            "Training:  41%|████      | 728/1772 [08:26<09:48,  1.78it/s, running training loss:  0.82781]\u001b[A\n",
            "Training:  41%|████      | 729/1772 [08:26<09:31,  1.82it/s, running training loss:  0.82781]\u001b[A\n",
            "Training:  41%|████      | 729/1772 [08:27<09:31,  1.82it/s, running training loss:  0.96622]\u001b[A\n",
            "Training:  41%|████      | 730/1772 [08:27<10:08,  1.71it/s, running training loss:  0.96622]\u001b[A\n",
            "Training:  41%|████      | 730/1772 [08:27<10:08,  1.71it/s, running training loss:  1.01394]\u001b[A\n",
            "Training:  41%|████▏     | 731/1772 [08:27<10:01,  1.73it/s, running training loss:  1.01394]\u001b[A\n",
            "Training:  41%|████▏     | 731/1772 [08:28<10:01,  1.73it/s, running training loss:  1.27413]\u001b[A\n",
            "Training:  41%|████▏     | 732/1772 [08:28<11:07,  1.56it/s, running training loss:  1.27413]\u001b[A\n",
            "Training:  41%|████▏     | 732/1772 [08:29<11:07,  1.56it/s, running training loss:  0.99914]\u001b[A\n",
            "Training:  41%|████▏     | 733/1772 [08:29<11:29,  1.51it/s, running training loss:  0.99914]\u001b[A\n",
            "Training:  41%|████▏     | 733/1772 [08:29<11:29,  1.51it/s, running training loss:  0.94227]\u001b[A\n",
            "Training:  41%|████▏     | 734/1772 [08:29<11:23,  1.52it/s, running training loss:  0.94227]\u001b[A\n",
            "Training:  41%|████▏     | 734/1772 [08:30<11:23,  1.52it/s, running training loss:  0.93294]\u001b[A\n",
            "Training:  41%|████▏     | 735/1772 [08:30<10:51,  1.59it/s, running training loss:  0.93294]\u001b[A\n",
            "Training:  41%|████▏     | 735/1772 [08:30<10:51,  1.59it/s, running training loss:  0.80682]\u001b[A\n",
            "Training:  42%|████▏     | 736/1772 [08:30<10:02,  1.72it/s, running training loss:  0.80682]\u001b[A\n",
            "Training:  42%|████▏     | 736/1772 [08:31<10:02,  1.72it/s, running training loss:  1.14574]\u001b[A\n",
            "Training:  42%|████▏     | 737/1772 [08:31<10:12,  1.69it/s, running training loss:  1.14574]\u001b[A\n",
            "Training:  42%|████▏     | 737/1772 [08:32<10:12,  1.69it/s, running training loss:  0.81427]\u001b[A\n",
            "Training:  42%|████▏     | 738/1772 [08:32<10:14,  1.68it/s, running training loss:  0.81427]\u001b[A\n",
            "Training:  42%|████▏     | 738/1772 [08:32<10:14,  1.68it/s, running training loss:  1.62521]\u001b[A\n",
            "Training:  42%|████▏     | 739/1772 [08:32<10:47,  1.60it/s, running training loss:  1.62521]\u001b[A\n",
            "Training:  42%|████▏     | 739/1772 [08:33<10:47,  1.60it/s, running training loss:  1.07408]\u001b[A\n",
            "Training:  42%|████▏     | 740/1772 [08:33<11:16,  1.52it/s, running training loss:  1.07408]\u001b[A\n",
            "Training:  42%|████▏     | 740/1772 [08:34<11:16,  1.52it/s, running training loss:  1.14781]\u001b[A\n",
            "Training:  42%|████▏     | 741/1772 [08:34<12:04,  1.42it/s, running training loss:  1.14781]\u001b[A\n",
            "Training:  42%|████▏     | 741/1772 [08:34<12:04,  1.42it/s, running training loss:  1.13314]\u001b[A\n",
            "Training:  42%|████▏     | 742/1772 [08:34<11:35,  1.48it/s, running training loss:  1.13314]\u001b[A\n",
            "Training:  42%|████▏     | 742/1772 [08:35<11:35,  1.48it/s, running training loss:  1.15511]\u001b[A\n",
            "Training:  42%|████▏     | 743/1772 [08:35<10:53,  1.58it/s, running training loss:  1.15511]\u001b[A\n",
            "Training:  42%|████▏     | 743/1772 [08:36<10:53,  1.58it/s, running training loss:  1.48543]\u001b[A\n",
            "Training:  42%|████▏     | 744/1772 [08:36<11:21,  1.51it/s, running training loss:  1.48543]\u001b[A\n",
            "Training:  42%|████▏     | 744/1772 [08:36<11:21,  1.51it/s, running training loss:  1.00596]\u001b[A\n",
            "Training:  42%|████▏     | 745/1772 [08:36<11:02,  1.55it/s, running training loss:  1.00596]\u001b[A\n",
            "Training:  42%|████▏     | 745/1772 [08:37<11:02,  1.55it/s, running training loss:  1.25076]\u001b[A\n",
            "Training:  42%|████▏     | 746/1772 [08:37<11:50,  1.44it/s, running training loss:  1.25076]\u001b[A\n",
            "Training:  42%|████▏     | 746/1772 [08:38<11:50,  1.44it/s, running training loss:  0.99675]\u001b[A\n",
            "Training:  42%|████▏     | 747/1772 [08:38<12:41,  1.35it/s, running training loss:  0.99675]\u001b[A\n",
            "Training:  42%|████▏     | 747/1772 [08:39<12:41,  1.35it/s, running training loss:  1.04537]\u001b[A\n",
            "Training:  42%|████▏     | 748/1772 [08:39<12:00,  1.42it/s, running training loss:  1.04537]\u001b[A\n",
            "Training:  42%|████▏     | 748/1772 [08:39<12:00,  1.42it/s, running training loss:  0.87203]\u001b[A\n",
            "Training:  42%|████▏     | 749/1772 [08:39<10:55,  1.56it/s, running training loss:  0.87203]\u001b[A\n",
            "Training:  42%|████▏     | 749/1772 [08:40<10:55,  1.56it/s, running training loss:  0.98683]\u001b[A\n",
            "Training:  42%|████▏     | 750/1772 [08:40<10:56,  1.56it/s, running training loss:  0.98683]\u001b[A\n",
            "Training:  42%|████▏     | 750/1772 [08:40<10:56,  1.56it/s, running training loss:  0.75316]\u001b[A\n",
            "Training:  42%|████▏     | 751/1772 [08:40<10:23,  1.64it/s, running training loss:  0.75316]\u001b[A\n",
            "Training:  42%|████▏     | 751/1772 [08:41<10:23,  1.64it/s, running training loss:  0.87107]\u001b[A\n",
            "Training:  42%|████▏     | 752/1772 [08:41<10:04,  1.69it/s, running training loss:  0.87107]\u001b[A\n",
            "Training:  42%|████▏     | 752/1772 [08:41<10:04,  1.69it/s, running training loss:  1.40601]\u001b[A\n",
            "Training:  42%|████▏     | 753/1772 [08:42<10:33,  1.61it/s, running training loss:  1.40601]\u001b[A\n",
            "Training:  42%|████▏     | 753/1772 [08:42<10:33,  1.61it/s, running training loss:  1.11159]\u001b[A\n",
            "Training:  43%|████▎     | 754/1772 [08:42<10:06,  1.68it/s, running training loss:  1.11159]\u001b[A\n",
            "Training:  43%|████▎     | 754/1772 [08:43<10:06,  1.68it/s, running training loss:  0.94686]\u001b[A\n",
            "Training:  43%|████▎     | 755/1772 [08:43<10:05,  1.68it/s, running training loss:  0.94686]\u001b[A\n",
            "Training:  43%|████▎     | 755/1772 [08:43<10:05,  1.68it/s, running training loss:  1.11786]\u001b[A\n",
            "Training:  43%|████▎     | 756/1772 [08:43<10:23,  1.63it/s, running training loss:  1.11786]\u001b[A\n",
            "Training:  43%|████▎     | 756/1772 [08:44<10:23,  1.63it/s, running training loss:  1.26840]\u001b[A\n",
            "Training:  43%|████▎     | 757/1772 [08:44<10:40,  1.59it/s, running training loss:  1.26840]\u001b[A\n",
            "Training:  43%|████▎     | 757/1772 [08:45<10:40,  1.59it/s, running training loss:  0.93007]\u001b[A\n",
            "Training:  43%|████▎     | 758/1772 [08:45<10:41,  1.58it/s, running training loss:  0.93007]\u001b[A\n",
            "Training:  43%|████▎     | 758/1772 [08:45<10:41,  1.58it/s, running training loss:  0.95536]\u001b[A\n",
            "Training:  43%|████▎     | 759/1772 [08:45<10:24,  1.62it/s, running training loss:  0.95536]\u001b[A\n",
            "Training:  43%|████▎     | 759/1772 [08:46<10:24,  1.62it/s, running training loss:  0.86554]\u001b[A\n",
            "Training:  43%|████▎     | 760/1772 [08:46<10:24,  1.62it/s, running training loss:  0.86554]\u001b[A\n",
            "Training:  43%|████▎     | 760/1772 [08:46<10:24,  1.62it/s, running training loss:  0.78832]\u001b[A\n",
            "Training:  43%|████▎     | 761/1772 [08:46<10:09,  1.66it/s, running training loss:  0.78832]\u001b[A\n",
            "Training:  43%|████▎     | 761/1772 [08:47<10:09,  1.66it/s, running training loss:  0.87355]\u001b[A\n",
            "Training:  43%|████▎     | 762/1772 [08:47<10:31,  1.60it/s, running training loss:  0.87355]\u001b[A\n",
            "Training:  43%|████▎     | 762/1772 [08:48<10:31,  1.60it/s, running training loss:  0.83437]\u001b[A\n",
            "Training:  43%|████▎     | 763/1772 [08:48<11:10,  1.50it/s, running training loss:  0.83437]\u001b[A\n",
            "Training:  43%|████▎     | 763/1772 [08:49<11:10,  1.50it/s, running training loss:  0.95011]\u001b[A\n",
            "Training:  43%|████▎     | 764/1772 [08:49<11:51,  1.42it/s, running training loss:  0.95011]\u001b[A\n",
            "Training:  43%|████▎     | 764/1772 [08:49<11:51,  1.42it/s, running training loss:  0.90913]\u001b[A\n",
            "Training:  43%|████▎     | 765/1772 [08:49<10:53,  1.54it/s, running training loss:  0.90913]\u001b[A\n",
            "Training:  43%|████▎     | 765/1772 [08:50<10:53,  1.54it/s, running training loss:  0.86424]\u001b[A\n",
            "Training:  43%|████▎     | 766/1772 [08:50<10:55,  1.53it/s, running training loss:  0.86424]\u001b[A\n",
            "Training:  43%|████▎     | 766/1772 [08:50<10:55,  1.53it/s, running training loss:  0.90008]\u001b[A\n",
            "Training:  43%|████▎     | 767/1772 [08:50<10:27,  1.60it/s, running training loss:  0.90008]\u001b[A\n",
            "Training:  43%|████▎     | 767/1772 [08:51<10:27,  1.60it/s, running training loss:  0.84616]\u001b[A\n",
            "Training:  43%|████▎     | 768/1772 [08:51<10:01,  1.67it/s, running training loss:  0.84616]\u001b[A\n",
            "Training:  43%|████▎     | 768/1772 [08:51<10:01,  1.67it/s, running training loss:  0.90718]\u001b[A\n",
            "Training:  43%|████▎     | 769/1772 [08:51<09:38,  1.74it/s, running training loss:  0.90718]\u001b[A\n",
            "Training:  43%|████▎     | 769/1772 [08:52<09:38,  1.74it/s, running training loss:  0.84378]\u001b[A\n",
            "Training:  43%|████▎     | 770/1772 [08:52<11:17,  1.48it/s, running training loss:  0.84378]\u001b[A\n",
            "Training:  43%|████▎     | 770/1772 [08:53<11:17,  1.48it/s, running training loss:  0.98670]\u001b[A\n",
            "Training:  44%|████▎     | 771/1772 [08:53<10:41,  1.56it/s, running training loss:  0.98670]\u001b[A\n",
            "Training:  44%|████▎     | 771/1772 [08:53<10:41,  1.56it/s, running training loss:  1.44262]\u001b[A\n",
            "Training:  44%|████▎     | 772/1772 [08:53<10:24,  1.60it/s, running training loss:  1.44262]\u001b[A\n",
            "Training:  44%|████▎     | 772/1772 [08:54<10:24,  1.60it/s, running training loss:  0.97745]\u001b[A\n",
            "Training:  44%|████▎     | 773/1772 [08:54<09:45,  1.71it/s, running training loss:  0.97745]\u001b[A\n",
            "Training:  44%|████▎     | 773/1772 [08:55<09:45,  1.71it/s, running training loss:  1.06923]\u001b[A\n",
            "Training:  44%|████▎     | 774/1772 [08:55<10:03,  1.65it/s, running training loss:  1.06923]\u001b[A\n",
            "Training:  44%|████▎     | 774/1772 [08:56<10:03,  1.65it/s, running training loss:  1.67377]\u001b[A\n",
            "Training:  44%|████▎     | 775/1772 [08:56<11:37,  1.43it/s, running training loss:  1.67377]\u001b[A\n",
            "Training:  44%|████▎     | 775/1772 [08:56<11:37,  1.43it/s, running training loss:  1.37800]\u001b[A\n",
            "Training:  44%|████▍     | 776/1772 [08:56<11:50,  1.40it/s, running training loss:  1.37800]\u001b[A\n",
            "Training:  44%|████▍     | 776/1772 [08:57<11:50,  1.40it/s, running training loss:  1.49282]\u001b[A\n",
            "Training:  44%|████▍     | 777/1772 [08:57<11:10,  1.48it/s, running training loss:  1.49282]\u001b[A\n",
            "Training:  44%|████▍     | 777/1772 [08:58<11:10,  1.48it/s, running training loss:  1.15154]\u001b[A\n",
            "Training:  44%|████▍     | 778/1772 [08:58<12:06,  1.37it/s, running training loss:  1.15154]\u001b[A\n",
            "Training:  44%|████▍     | 778/1772 [08:58<12:06,  1.37it/s, running training loss:  0.88896]\u001b[A\n",
            "Training:  44%|████▍     | 779/1772 [08:58<11:32,  1.43it/s, running training loss:  0.88896]\u001b[A\n",
            "Training:  44%|████▍     | 779/1772 [08:59<11:32,  1.43it/s, running training loss:  1.02460]\u001b[A\n",
            "Training:  44%|████▍     | 780/1772 [08:59<11:22,  1.45it/s, running training loss:  1.02460]\u001b[A\n",
            "Training:  44%|████▍     | 780/1772 [09:00<11:22,  1.45it/s, running training loss:  0.79588]\u001b[A\n",
            "Training:  44%|████▍     | 781/1772 [09:00<12:03,  1.37it/s, running training loss:  0.79588]\u001b[A\n",
            "Training:  44%|████▍     | 781/1772 [09:00<12:03,  1.37it/s, running training loss:  1.00219]\u001b[A\n",
            "Training:  44%|████▍     | 782/1772 [09:00<11:30,  1.43it/s, running training loss:  1.00219]\u001b[A\n",
            "Training:  44%|████▍     | 782/1772 [09:01<11:30,  1.43it/s, running training loss:  0.94360]\u001b[A\n",
            "Training:  44%|████▍     | 783/1772 [09:01<13:08,  1.25it/s, running training loss:  0.94360]\u001b[A\n",
            "Training:  44%|████▍     | 783/1772 [09:02<13:08,  1.25it/s, running training loss:  0.93418]\u001b[A\n",
            "Training:  44%|████▍     | 784/1772 [09:02<11:43,  1.40it/s, running training loss:  0.93418]\u001b[A\n",
            "Training:  44%|████▍     | 784/1772 [09:03<11:43,  1.40it/s, running training loss:  1.11427]\u001b[A\n",
            "Training:  44%|████▍     | 785/1772 [09:03<12:32,  1.31it/s, running training loss:  1.11427]\u001b[A\n",
            "Training:  44%|████▍     | 785/1772 [09:03<12:32,  1.31it/s, running training loss:  0.77930]\u001b[A\n",
            "Training:  44%|████▍     | 786/1772 [09:03<11:18,  1.45it/s, running training loss:  0.77930]\u001b[A\n",
            "Training:  44%|████▍     | 786/1772 [09:04<11:18,  1.45it/s, running training loss:  0.89046]\u001b[A\n",
            "Training:  44%|████▍     | 787/1772 [09:04<10:53,  1.51it/s, running training loss:  0.89046]\u001b[A\n",
            "Training:  44%|████▍     | 787/1772 [09:05<10:53,  1.51it/s, running training loss:  0.99390]\u001b[A\n",
            "Training:  44%|████▍     | 788/1772 [09:05<10:43,  1.53it/s, running training loss:  0.99390]\u001b[A\n",
            "Training:  44%|████▍     | 788/1772 [09:05<10:43,  1.53it/s, running training loss:  0.81601]\u001b[A\n",
            "Training:  45%|████▍     | 789/1772 [09:05<10:52,  1.51it/s, running training loss:  0.81601]\u001b[A\n",
            "Training:  45%|████▍     | 789/1772 [09:06<10:52,  1.51it/s, running training loss:  0.85918]\u001b[A\n",
            "Training:  45%|████▍     | 790/1772 [09:06<10:17,  1.59it/s, running training loss:  0.85918]\u001b[A\n",
            "Training:  45%|████▍     | 790/1772 [09:06<10:17,  1.59it/s, running training loss:  0.85850]\u001b[A\n",
            "Training:  45%|████▍     | 791/1772 [09:06<10:14,  1.60it/s, running training loss:  0.85850]\u001b[A\n",
            "Training:  45%|████▍     | 791/1772 [09:07<10:14,  1.60it/s, running training loss:  0.89248]\u001b[A\n",
            "Training:  45%|████▍     | 792/1772 [09:07<10:02,  1.63it/s, running training loss:  0.89248]\u001b[A\n",
            "Training:  45%|████▍     | 792/1772 [09:08<10:02,  1.63it/s, running training loss:  0.95297]\u001b[A\n",
            "Training:  45%|████▍     | 793/1772 [09:08<09:53,  1.65it/s, running training loss:  0.95297]\u001b[A\n",
            "Training:  45%|████▍     | 793/1772 [09:08<09:53,  1.65it/s, running training loss:  0.98907]\u001b[A\n",
            "Training:  45%|████▍     | 794/1772 [09:08<10:11,  1.60it/s, running training loss:  0.98907]\u001b[A\n",
            "Training:  45%|████▍     | 794/1772 [09:09<10:11,  1.60it/s, running training loss:  1.28030]\u001b[A\n",
            "Training:  45%|████▍     | 795/1772 [09:09<11:03,  1.47it/s, running training loss:  1.28030]\u001b[A\n",
            "Training:  45%|████▍     | 795/1772 [09:10<11:03,  1.47it/s, running training loss:  1.14201]\u001b[A\n",
            "Training:  45%|████▍     | 796/1772 [09:10<12:13,  1.33it/s, running training loss:  1.14201]\u001b[A\n",
            "Training:  45%|████▍     | 796/1772 [09:11<12:13,  1.33it/s, running training loss:  1.09994]\u001b[A\n",
            "Training:  45%|████▍     | 797/1772 [09:11<12:05,  1.34it/s, running training loss:  1.09994]\u001b[A\n",
            "Training:  45%|████▍     | 797/1772 [09:11<12:05,  1.34it/s, running training loss:  1.28586]\u001b[A\n",
            "Training:  45%|████▌     | 798/1772 [09:11<11:22,  1.43it/s, running training loss:  1.28586]\u001b[A\n",
            "Training:  45%|████▌     | 798/1772 [09:12<11:22,  1.43it/s, running training loss:  0.83707]\u001b[A\n",
            "Training:  45%|████▌     | 799/1772 [09:12<10:34,  1.53it/s, running training loss:  0.83707]\u001b[A\n",
            "Training:  45%|████▌     | 799/1772 [09:13<10:34,  1.53it/s, running training loss:  0.85792]\u001b[A\n",
            "Training:  45%|████▌     | 800/1772 [09:13<10:17,  1.57it/s, running training loss:  0.85792]\u001b[A\n",
            "Training:  45%|████▌     | 800/1772 [09:13<10:17,  1.57it/s, running training loss:  0.81911]\u001b[A\n",
            "Training:  45%|████▌     | 801/1772 [09:13<09:47,  1.65it/s, running training loss:  0.81911]\u001b[A\n",
            "Training:  45%|████▌     | 801/1772 [09:14<09:47,  1.65it/s, running training loss:  0.87674]\u001b[A\n",
            "Training:  45%|████▌     | 802/1772 [09:14<09:47,  1.65it/s, running training loss:  0.87674]\u001b[A\n",
            "Training:  45%|████▌     | 802/1772 [09:14<09:47,  1.65it/s, running training loss:  0.85048]\u001b[A\n",
            "Training:  45%|████▌     | 803/1772 [09:14<09:59,  1.62it/s, running training loss:  0.85048]\u001b[A\n",
            "Training:  45%|████▌     | 803/1772 [09:15<09:59,  1.62it/s, running training loss:  0.93062]\u001b[A\n",
            "Training:  45%|████▌     | 804/1772 [09:15<10:01,  1.61it/s, running training loss:  0.93062]\u001b[A\n",
            "Training:  45%|████▌     | 804/1772 [09:16<10:01,  1.61it/s, running training loss:  0.84185]\u001b[A\n",
            "Training:  45%|████▌     | 805/1772 [09:16<10:29,  1.54it/s, running training loss:  0.84185]\u001b[A\n",
            "Training:  45%|████▌     | 805/1772 [09:17<10:29,  1.54it/s, running training loss:  1.03805]\u001b[A\n",
            "Training:  45%|████▌     | 806/1772 [09:17<11:47,  1.37it/s, running training loss:  1.03805]\u001b[A\n",
            "Training:  45%|████▌     | 806/1772 [09:17<11:47,  1.37it/s, running training loss:  1.02218]\u001b[A\n",
            "Training:  46%|████▌     | 807/1772 [09:17<11:04,  1.45it/s, running training loss:  1.02218]\u001b[A\n",
            "Training:  46%|████▌     | 807/1772 [09:18<11:04,  1.45it/s, running training loss:  0.92388]\u001b[A\n",
            "Training:  46%|████▌     | 808/1772 [09:18<11:38,  1.38it/s, running training loss:  0.92388]\u001b[A\n",
            "Training:  46%|████▌     | 808/1772 [09:19<11:38,  1.38it/s, running training loss:  0.78400]\u001b[A\n",
            "Training:  46%|████▌     | 809/1772 [09:19<10:47,  1.49it/s, running training loss:  0.78400]\u001b[A\n",
            "Training:  46%|████▌     | 809/1772 [09:19<10:47,  1.49it/s, running training loss:  0.90153]\u001b[A\n",
            "Training:  46%|████▌     | 810/1772 [09:19<11:04,  1.45it/s, running training loss:  0.90153]\u001b[A\n",
            "Training:  46%|████▌     | 810/1772 [09:20<11:04,  1.45it/s, running training loss:  0.71720]\u001b[A\n",
            "Training:  46%|████▌     | 811/1772 [09:20<10:19,  1.55it/s, running training loss:  0.71720]\u001b[A\n",
            "Training:  46%|████▌     | 811/1772 [09:20<10:19,  1.55it/s, running training loss:  1.02585]\u001b[A\n",
            "Training:  46%|████▌     | 812/1772 [09:20<09:34,  1.67it/s, running training loss:  1.02585]\u001b[A\n",
            "Training:  46%|████▌     | 812/1772 [09:21<09:34,  1.67it/s, running training loss:  0.94532]\u001b[A\n",
            "Training:  46%|████▌     | 813/1772 [09:21<08:57,  1.78it/s, running training loss:  0.94532]\u001b[A\n",
            "Training:  46%|████▌     | 813/1772 [09:21<08:57,  1.78it/s, running training loss:  0.86879]\u001b[A\n",
            "Training:  46%|████▌     | 814/1772 [09:21<08:49,  1.81it/s, running training loss:  0.86879]\u001b[A\n",
            "Training:  46%|████▌     | 814/1772 [09:22<08:49,  1.81it/s, running training loss:  1.17504]\u001b[A\n",
            "Training:  46%|████▌     | 815/1772 [09:22<09:09,  1.74it/s, running training loss:  1.17504]\u001b[A\n",
            "Training:  46%|████▌     | 815/1772 [09:23<09:09,  1.74it/s, running training loss:  0.86810]\u001b[A\n",
            "Training:  46%|████▌     | 816/1772 [09:23<11:19,  1.41it/s, running training loss:  0.86810]\u001b[A\n",
            "Training:  46%|████▌     | 816/1772 [09:23<11:19,  1.41it/s, running training loss:  1.05245]\u001b[A\n",
            "Training:  46%|████▌     | 817/1772 [09:23<10:05,  1.58it/s, running training loss:  1.05245]\u001b[A\n",
            "Training:  46%|████▌     | 817/1772 [09:24<10:05,  1.58it/s, running training loss:  1.01821]\u001b[A\n",
            "Training:  46%|████▌     | 818/1772 [09:24<10:51,  1.46it/s, running training loss:  1.01821]\u001b[A\n",
            "Training:  46%|████▌     | 818/1772 [09:25<10:51,  1.46it/s, running training loss:  0.80977]\u001b[A\n",
            "Training:  46%|████▌     | 819/1772 [09:25<12:03,  1.32it/s, running training loss:  0.80977]\u001b[A\n",
            "Training:  46%|████▌     | 819/1772 [09:26<12:03,  1.32it/s, running training loss:  0.90493]\u001b[A\n",
            "Training:  46%|████▋     | 820/1772 [09:26<12:06,  1.31it/s, running training loss:  0.90493]\u001b[A\n",
            "Training:  46%|████▋     | 820/1772 [09:27<12:06,  1.31it/s, running training loss:  0.93798]\u001b[A\n",
            "Training:  46%|████▋     | 821/1772 [09:27<12:50,  1.23it/s, running training loss:  0.93798]\u001b[A\n",
            "Training:  46%|████▋     | 821/1772 [09:28<12:50,  1.23it/s, running training loss:  1.13351]\u001b[A\n",
            "Training:  46%|████▋     | 822/1772 [09:28<12:37,  1.25it/s, running training loss:  1.13351]\u001b[A\n",
            "Training:  46%|████▋     | 822/1772 [09:28<12:37,  1.25it/s, running training loss:  0.89546]\u001b[A\n",
            "Training:  46%|████▋     | 823/1772 [09:28<11:27,  1.38it/s, running training loss:  0.89546]\u001b[A\n",
            "Training:  46%|████▋     | 823/1772 [09:29<11:27,  1.38it/s, running training loss:  0.68422]\u001b[A\n",
            "Training:  47%|████▋     | 824/1772 [09:29<10:34,  1.49it/s, running training loss:  0.68422]\u001b[A\n",
            "Training:  47%|████▋     | 824/1772 [09:29<10:34,  1.49it/s, running training loss:  0.89492]\u001b[A\n",
            "Training:  47%|████▋     | 825/1772 [09:29<10:33,  1.50it/s, running training loss:  0.89492]\u001b[A\n",
            "Training:  47%|████▋     | 825/1772 [09:30<10:33,  1.50it/s, running training loss:  0.87930]\u001b[A\n",
            "Training:  47%|████▋     | 826/1772 [09:30<10:11,  1.55it/s, running training loss:  0.87930]\u001b[A\n",
            "Training:  47%|████▋     | 826/1772 [09:31<10:11,  1.55it/s, running training loss:  0.96126]\u001b[A\n",
            "Training:  47%|████▋     | 827/1772 [09:31<09:57,  1.58it/s, running training loss:  0.96126]\u001b[A\n",
            "Training:  47%|████▋     | 827/1772 [09:31<09:57,  1.58it/s, running training loss:  0.84362]\u001b[A\n",
            "Training:  47%|████▋     | 828/1772 [09:31<09:17,  1.69it/s, running training loss:  0.84362]\u001b[A\n",
            "Training:  47%|████▋     | 828/1772 [09:32<09:17,  1.69it/s, running training loss:  0.77217]\u001b[A\n",
            "Training:  47%|████▋     | 829/1772 [09:32<09:04,  1.73it/s, running training loss:  0.77217]\u001b[A\n",
            "Training:  47%|████▋     | 829/1772 [09:32<09:04,  1.73it/s, running training loss:  0.88249]\u001b[A\n",
            "Training:  47%|████▋     | 830/1772 [09:32<09:05,  1.73it/s, running training loss:  0.88249]\u001b[A\n",
            "Training:  47%|████▋     | 830/1772 [09:33<09:05,  1.73it/s, running training loss:  0.88691]\u001b[A\n",
            "Training:  47%|████▋     | 831/1772 [09:33<08:25,  1.86it/s, running training loss:  0.88691]\u001b[A\n",
            "Training:  47%|████▋     | 831/1772 [09:33<08:25,  1.86it/s, running training loss:  0.84264]\u001b[A\n",
            "Training:  47%|████▋     | 832/1772 [09:33<08:35,  1.82it/s, running training loss:  0.84264]\u001b[A\n",
            "Training:  47%|████▋     | 832/1772 [09:34<08:35,  1.82it/s, running training loss:  0.87723]\u001b[A\n",
            "Training:  47%|████▋     | 833/1772 [09:34<08:40,  1.80it/s, running training loss:  0.87723]\u001b[A\n",
            "Training:  47%|████▋     | 833/1772 [09:35<08:40,  1.80it/s, running training loss:  1.98376]\u001b[A\n",
            "Training:  47%|████▋     | 834/1772 [09:35<10:20,  1.51it/s, running training loss:  1.98376]\u001b[A\n",
            "Training:  47%|████▋     | 834/1772 [09:35<10:20,  1.51it/s, running training loss:  1.18788]\u001b[A\n",
            "Training:  47%|████▋     | 835/1772 [09:35<10:44,  1.45it/s, running training loss:  1.18788]\u001b[A\n",
            "Training:  47%|████▋     | 835/1772 [09:36<10:44,  1.45it/s, running training loss:  1.39772]\u001b[A\n",
            "Training:  47%|████▋     | 836/1772 [09:36<10:04,  1.55it/s, running training loss:  1.39772]\u001b[A\n",
            "Training:  47%|████▋     | 836/1772 [09:37<10:04,  1.55it/s, running training loss:  1.02526]\u001b[A\n",
            "Training:  47%|████▋     | 837/1772 [09:37<10:02,  1.55it/s, running training loss:  1.02526]\u001b[A\n",
            "Training:  47%|████▋     | 837/1772 [09:37<10:02,  1.55it/s, running training loss:  0.95741]\u001b[A\n",
            "Training:  47%|████▋     | 838/1772 [09:37<09:45,  1.59it/s, running training loss:  0.95741]\u001b[A\n",
            "Training:  47%|████▋     | 838/1772 [09:38<09:45,  1.59it/s, running training loss:  0.94241]\u001b[A\n",
            "Training:  47%|████▋     | 839/1772 [09:38<10:33,  1.47it/s, running training loss:  0.94241]\u001b[A\n",
            "Training:  47%|████▋     | 839/1772 [09:39<10:33,  1.47it/s, running training loss:  0.91345]\u001b[A\n",
            "Training:  47%|████▋     | 840/1772 [09:39<09:51,  1.58it/s, running training loss:  0.91345]\u001b[A\n",
            "Training:  47%|████▋     | 840/1772 [09:39<09:51,  1.58it/s, running training loss:  0.93221]\u001b[A\n",
            "Training:  47%|████▋     | 841/1772 [09:39<09:20,  1.66it/s, running training loss:  0.93221]\u001b[A\n",
            "Training:  47%|████▋     | 841/1772 [09:40<09:20,  1.66it/s, running training loss:  0.87118]\u001b[A\n",
            "Training:  48%|████▊     | 842/1772 [09:40<09:36,  1.61it/s, running training loss:  0.87118]\u001b[A\n",
            "Training:  48%|████▊     | 842/1772 [09:40<09:36,  1.61it/s, running training loss:  0.74883]\u001b[A\n",
            "Training:  48%|████▊     | 843/1772 [09:40<09:24,  1.64it/s, running training loss:  0.74883]\u001b[A\n",
            "Training:  48%|████▊     | 843/1772 [09:41<09:24,  1.64it/s, running training loss:  0.98111]\u001b[A\n",
            "Training:  48%|████▊     | 844/1772 [09:41<11:11,  1.38it/s, running training loss:  0.98111]\u001b[A\n",
            "Training:  48%|████▊     | 844/1772 [09:42<11:11,  1.38it/s, running training loss:  1.17536]\u001b[A\n",
            "Training:  48%|████▊     | 845/1772 [09:42<10:33,  1.46it/s, running training loss:  1.17536]\u001b[A\n",
            "Training:  48%|████▊     | 845/1772 [09:43<10:33,  1.46it/s, running training loss:  0.99584]\u001b[A\n",
            "Training:  48%|████▊     | 846/1772 [09:43<10:35,  1.46it/s, running training loss:  0.99584]\u001b[A\n",
            "Training:  48%|████▊     | 846/1772 [09:43<10:35,  1.46it/s, running training loss:  0.84395]\u001b[A\n",
            "Training:  48%|████▊     | 847/1772 [09:43<10:22,  1.49it/s, running training loss:  0.84395]\u001b[A\n",
            "Training:  48%|████▊     | 847/1772 [09:44<10:22,  1.49it/s, running training loss:  1.06785]\u001b[A\n",
            "Training:  48%|████▊     | 848/1772 [09:44<11:02,  1.40it/s, running training loss:  1.06785]\u001b[A\n",
            "Training:  48%|████▊     | 848/1772 [09:45<11:02,  1.40it/s, running training loss:  0.79706]\u001b[A\n",
            "Training:  48%|████▊     | 849/1772 [09:45<12:09,  1.26it/s, running training loss:  0.79706]\u001b[A\n",
            "Training:  48%|████▊     | 849/1772 [09:46<12:09,  1.26it/s, running training loss:  0.77700]\u001b[A\n",
            "Training:  48%|████▊     | 850/1772 [09:46<11:49,  1.30it/s, running training loss:  0.77700]\u001b[A\n",
            "Training:  48%|████▊     | 850/1772 [09:46<11:49,  1.30it/s, running training loss:  0.78250]\u001b[A\n",
            "Training:  48%|████▊     | 851/1772 [09:46<11:13,  1.37it/s, running training loss:  0.78250]\u001b[A\n",
            "Training:  48%|████▊     | 851/1772 [09:47<11:13,  1.37it/s, running training loss:  1.39451]\u001b[A\n",
            "Training:  48%|████▊     | 852/1772 [09:47<10:47,  1.42it/s, running training loss:  1.39451]\u001b[A\n",
            "Training:  48%|████▊     | 852/1772 [09:47<10:47,  1.42it/s, running training loss:  0.72204]\u001b[A\n",
            "Training:  48%|████▊     | 853/1772 [09:47<09:50,  1.56it/s, running training loss:  0.72204]\u001b[A\n",
            "Training:  48%|████▊     | 853/1772 [09:48<09:50,  1.56it/s, running training loss:  0.76694]\u001b[A\n",
            "Training:  48%|████▊     | 854/1772 [09:48<09:31,  1.61it/s, running training loss:  0.76694]\u001b[A\n",
            "Training:  48%|████▊     | 854/1772 [09:49<09:31,  1.61it/s, running training loss:  1.00455]\u001b[A\n",
            "Training:  48%|████▊     | 855/1772 [09:49<10:02,  1.52it/s, running training loss:  1.00455]\u001b[A\n",
            "Training:  48%|████▊     | 855/1772 [09:49<10:02,  1.52it/s, running training loss:  0.98804]\u001b[A\n",
            "Training:  48%|████▊     | 856/1772 [09:49<09:58,  1.53it/s, running training loss:  0.98804]\u001b[A\n",
            "Training:  48%|████▊     | 856/1772 [09:50<09:58,  1.53it/s, running training loss:  0.77169]\u001b[A\n",
            "Training:  48%|████▊     | 857/1772 [09:50<09:19,  1.63it/s, running training loss:  0.77169]\u001b[A\n",
            "Training:  48%|████▊     | 857/1772 [09:51<09:19,  1.63it/s, running training loss:  1.01970]\u001b[A\n",
            "Training:  48%|████▊     | 858/1772 [09:51<09:05,  1.68it/s, running training loss:  1.01970]\u001b[A\n",
            "Training:  48%|████▊     | 858/1772 [09:51<09:05,  1.68it/s, running training loss:  0.82778]\u001b[A\n",
            "Training:  48%|████▊     | 859/1772 [09:51<09:43,  1.57it/s, running training loss:  0.82778]\u001b[A\n",
            "Training:  48%|████▊     | 859/1772 [09:52<09:43,  1.57it/s, running training loss:  1.12790]\u001b[A\n",
            "Training:  49%|████▊     | 860/1772 [09:52<09:52,  1.54it/s, running training loss:  1.12790]\u001b[A\n",
            "Training:  49%|████▊     | 860/1772 [09:53<09:52,  1.54it/s, running training loss:  0.82565]\u001b[A\n",
            "Training:  49%|████▊     | 861/1772 [09:53<09:50,  1.54it/s, running training loss:  0.82565]\u001b[A\n",
            "Training:  49%|████▊     | 861/1772 [09:53<09:50,  1.54it/s, running training loss:  0.78135]\u001b[A\n",
            "Training:  49%|████▊     | 862/1772 [09:53<09:50,  1.54it/s, running training loss:  0.78135]\u001b[A\n",
            "Training:  49%|████▊     | 862/1772 [09:54<09:50,  1.54it/s, running training loss:  1.04842]\u001b[A\n",
            "Training:  49%|████▊     | 863/1772 [09:54<10:52,  1.39it/s, running training loss:  1.04842]\u001b[A\n",
            "Training:  49%|████▊     | 863/1772 [09:55<10:52,  1.39it/s, running training loss:  0.89737]\u001b[A\n",
            "Training:  49%|████▉     | 864/1772 [09:55<10:15,  1.48it/s, running training loss:  0.89737]\u001b[A\n",
            "Training:  49%|████▉     | 864/1772 [09:55<10:15,  1.48it/s, running training loss:  0.77314]\u001b[A\n",
            "Training:  49%|████▉     | 865/1772 [09:55<10:00,  1.51it/s, running training loss:  0.77314]\u001b[A\n",
            "Training:  49%|████▉     | 865/1772 [09:56<10:00,  1.51it/s, running training loss:  0.86604]\u001b[A\n",
            "Training:  49%|████▉     | 866/1772 [09:56<09:37,  1.57it/s, running training loss:  0.86604]\u001b[A\n",
            "Training:  49%|████▉     | 866/1772 [09:57<09:37,  1.57it/s, running training loss:  0.82844]\u001b[A\n",
            "Training:  49%|████▉     | 867/1772 [09:57<09:44,  1.55it/s, running training loss:  0.82844]\u001b[A\n",
            "Training:  49%|████▉     | 867/1772 [09:57<09:44,  1.55it/s, running training loss:  0.77237]\u001b[A\n",
            "Training:  49%|████▉     | 868/1772 [09:57<09:24,  1.60it/s, running training loss:  0.77237]\u001b[A\n",
            "Training:  49%|████▉     | 868/1772 [09:58<09:24,  1.60it/s, running training loss:  0.79165]\u001b[A\n",
            "Training:  49%|████▉     | 869/1772 [09:58<09:12,  1.64it/s, running training loss:  0.79165]\u001b[A\n",
            "Training:  49%|████▉     | 869/1772 [09:58<09:12,  1.64it/s, running training loss:  0.83571]\u001b[A\n",
            "Training:  49%|████▉     | 870/1772 [09:58<09:00,  1.67it/s, running training loss:  0.83571]\u001b[A\n",
            "Training:  49%|████▉     | 870/1772 [09:59<09:00,  1.67it/s, running training loss:  0.91179]\u001b[A\n",
            "Training:  49%|████▉     | 871/1772 [09:59<08:22,  1.79it/s, running training loss:  0.91179]\u001b[A\n",
            "Training:  49%|████▉     | 871/1772 [09:59<08:22,  1.79it/s, running training loss:  0.85963]\u001b[A\n",
            "Training:  49%|████▉     | 872/1772 [09:59<08:25,  1.78it/s, running training loss:  0.85963]\u001b[A\n",
            "Training:  49%|████▉     | 872/1772 [10:00<08:25,  1.78it/s, running training loss:  0.86658]\u001b[A\n",
            "Training:  49%|████▉     | 873/1772 [10:00<08:42,  1.72it/s, running training loss:  0.86658]\u001b[A\n",
            "Training:  49%|████▉     | 873/1772 [10:01<08:42,  1.72it/s, running training loss:  1.07032]\u001b[A\n",
            "Training:  49%|████▉     | 874/1772 [10:01<09:15,  1.62it/s, running training loss:  1.07032]\u001b[A\n",
            "Training:  49%|████▉     | 874/1772 [10:01<09:15,  1.62it/s, running training loss:  0.78075]\u001b[A\n",
            "Training:  49%|████▉     | 875/1772 [10:01<08:53,  1.68it/s, running training loss:  0.78075]\u001b[A\n",
            "Training:  49%|████▉     | 875/1772 [10:02<08:53,  1.68it/s, running training loss:  0.92755]\u001b[A\n",
            "Training:  49%|████▉     | 876/1772 [10:02<09:44,  1.53it/s, running training loss:  0.92755]\u001b[A\n",
            "Training:  49%|████▉     | 876/1772 [10:03<09:44,  1.53it/s, running training loss:  0.93893]\u001b[A\n",
            "Training:  49%|████▉     | 877/1772 [10:03<09:39,  1.54it/s, running training loss:  0.93893]\u001b[A\n",
            "Training:  49%|████▉     | 877/1772 [10:03<09:39,  1.54it/s, running training loss:  0.76656]\u001b[A\n",
            "Training:  50%|████▉     | 878/1772 [10:03<09:03,  1.65it/s, running training loss:  0.76656]\u001b[A\n",
            "Training:  50%|████▉     | 878/1772 [10:04<09:03,  1.65it/s, running training loss:  0.94094]\u001b[A\n",
            "Training:  50%|████▉     | 879/1772 [10:04<08:50,  1.68it/s, running training loss:  0.94094]\u001b[A\n",
            "Training:  50%|████▉     | 879/1772 [10:05<08:50,  1.68it/s, running training loss:  1.33479]\u001b[A\n",
            "Training:  50%|████▉     | 880/1772 [10:05<10:02,  1.48it/s, running training loss:  1.33479]\u001b[A\n",
            "Training:  50%|████▉     | 880/1772 [10:05<10:02,  1.48it/s, running training loss:  0.76143]\u001b[A\n",
            "Training:  50%|████▉     | 881/1772 [10:05<09:21,  1.59it/s, running training loss:  0.76143]\u001b[A\n",
            "Training:  50%|████▉     | 881/1772 [10:06<09:21,  1.59it/s, running training loss:  0.74883]\u001b[A\n",
            "Training:  50%|████▉     | 882/1772 [10:06<08:51,  1.67it/s, running training loss:  0.74883]\u001b[A\n",
            "Training:  50%|████▉     | 882/1772 [10:06<08:51,  1.67it/s, running training loss:  0.82283]\u001b[A\n",
            "Training:  50%|████▉     | 883/1772 [10:06<08:25,  1.76it/s, running training loss:  0.82283]\u001b[A\n",
            "Training:  50%|████▉     | 883/1772 [10:07<08:25,  1.76it/s, running training loss:  1.15611]\u001b[A\n",
            "Training:  50%|████▉     | 884/1772 [10:07<08:26,  1.75it/s, running training loss:  1.15611]\u001b[A\n",
            "Training:  50%|████▉     | 884/1772 [10:07<08:26,  1.75it/s, running training loss:  1.07873]\u001b[A\n",
            "Training:  50%|████▉     | 885/1772 [10:07<08:58,  1.65it/s, running training loss:  1.07873]\u001b[A\n",
            "Training:  50%|████▉     | 885/1772 [10:08<08:58,  1.65it/s, running training loss:  1.99272]\u001b[A\n",
            "Training:  50%|█████     | 886/1772 [10:08<10:33,  1.40it/s, running training loss:  1.99272]\u001b[A\n",
            "Training:  50%|█████     | 886/1772 [10:09<10:33,  1.40it/s, running training loss:  2.08670]\u001b[A\n",
            "Training:  50%|█████     | 887/1772 [10:09<10:35,  1.39it/s, running training loss:  2.08670]\u001b[A\n",
            "Training:  50%|█████     | 887/1772 [10:10<10:35,  1.39it/s, running training loss:  0.86280]\u001b[A\n",
            "Training:  50%|█████     | 888/1772 [10:10<10:22,  1.42it/s, running training loss:  0.86280]\u001b[A\n",
            "Training:  50%|█████     | 888/1772 [10:10<10:22,  1.42it/s, running training loss:  0.98851]\u001b[A\n",
            "Training:  50%|█████     | 889/1772 [10:10<09:46,  1.50it/s, running training loss:  0.98851]\u001b[A\n",
            "Training:  50%|█████     | 889/1772 [10:11<09:46,  1.50it/s, running training loss:  1.07678]\u001b[A\n",
            "Training:  50%|█████     | 890/1772 [10:11<09:45,  1.51it/s, running training loss:  1.07678]\u001b[A\n",
            "Training:  50%|█████     | 890/1772 [10:12<09:45,  1.51it/s, running training loss:  1.33711]\u001b[A\n",
            "Training:  50%|█████     | 891/1772 [10:12<09:29,  1.55it/s, running training loss:  1.33711]\u001b[A\n",
            "Training:  50%|█████     | 891/1772 [10:12<09:29,  1.55it/s, running training loss:  1.02665]\u001b[A\n",
            "Training:  50%|█████     | 892/1772 [10:12<09:06,  1.61it/s, running training loss:  1.02665]\u001b[A\n",
            "Training:  50%|█████     | 892/1772 [10:13<09:06,  1.61it/s, running training loss:  0.97592]\u001b[A\n",
            "Training:  50%|█████     | 893/1772 [10:13<09:05,  1.61it/s, running training loss:  0.97592]\u001b[A\n",
            "Training:  50%|█████     | 893/1772 [10:13<09:05,  1.61it/s, running training loss:  0.88400]\u001b[A\n",
            "Training:  50%|█████     | 894/1772 [10:13<08:46,  1.67it/s, running training loss:  0.88400]\u001b[A\n",
            "Training:  50%|█████     | 894/1772 [10:14<08:46,  1.67it/s, running training loss:  0.94576]\u001b[A\n",
            "Training:  51%|█████     | 895/1772 [10:14<08:09,  1.79it/s, running training loss:  0.94576]\u001b[A\n",
            "Training:  51%|█████     | 895/1772 [10:14<08:09,  1.79it/s, running training loss:  1.02076]\u001b[A\n",
            "Training:  51%|█████     | 896/1772 [10:14<08:25,  1.73it/s, running training loss:  1.02076]\u001b[A\n",
            "Training:  51%|█████     | 896/1772 [10:15<08:25,  1.73it/s, running training loss:  1.08473]\u001b[A\n",
            "Training:  51%|█████     | 897/1772 [10:15<08:03,  1.81it/s, running training loss:  1.08473]\u001b[A\n",
            "Training:  51%|█████     | 897/1772 [10:16<08:03,  1.81it/s, running training loss:  0.87925]\u001b[A\n",
            "Training:  51%|█████     | 898/1772 [10:16<08:40,  1.68it/s, running training loss:  0.87925]\u001b[A\n",
            "Training:  51%|█████     | 898/1772 [10:16<08:40,  1.68it/s, running training loss:  0.74709]\u001b[A\n",
            "Training:  51%|█████     | 899/1772 [10:16<08:29,  1.71it/s, running training loss:  0.74709]\u001b[A\n",
            "Training:  51%|█████     | 899/1772 [10:17<08:29,  1.71it/s, running training loss:  0.87535]\u001b[A\n",
            "\n",
            "Evaluation:   0%|          | 0/270 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   0%|          | 1/270 [00:00<01:41,  2.65it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   1%|          | 2/270 [00:00<01:01,  4.39it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   1%|          | 3/270 [00:00<00:47,  5.66it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   1%|▏         | 4/270 [00:00<00:40,  6.63it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   2%|▏         | 5/270 [00:00<00:35,  7.38it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   2%|▏         | 6/270 [00:00<00:33,  7.81it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   3%|▎         | 8/270 [00:01<00:29,  8.83it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   3%|▎         | 9/270 [00:01<00:29,  8.73it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   4%|▍         | 11/270 [00:01<00:26,  9.77it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   5%|▍         | 13/270 [00:01<00:25,  9.90it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   5%|▌         | 14/270 [00:01<00:27,  9.30it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   6%|▌         | 15/270 [00:01<00:27,  9.39it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   6%|▌         | 16/270 [00:01<00:28,  8.91it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   6%|▋         | 17/270 [00:02<00:29,  8.64it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   7%|▋         | 19/270 [00:02<00:27,  9.27it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   7%|▋         | 20/270 [00:02<00:27,  9.09it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   8%|▊         | 22/270 [00:02<00:24, 10.11it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   9%|▊         | 23/270 [00:02<00:24, 10.05it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   9%|▉         | 25/270 [00:02<00:24, 10.10it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  10%|█         | 27/270 [00:03<00:22, 10.66it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  11%|█         | 29/270 [00:03<00:24,  9.88it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  11%|█         | 30/270 [00:03<00:25,  9.56it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  11%|█▏        | 31/270 [00:03<00:25,  9.32it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  12%|█▏        | 33/270 [00:03<00:24,  9.58it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  13%|█▎        | 35/270 [00:03<00:24,  9.77it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  14%|█▎        | 37/270 [00:04<00:22, 10.42it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  14%|█▍        | 39/270 [00:04<00:22, 10.31it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  15%|█▌        | 41/270 [00:04<00:22, 10.09it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  16%|█▌        | 43/270 [00:04<00:23,  9.55it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  16%|█▋        | 44/270 [00:04<00:23,  9.54it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  17%|█▋        | 46/270 [00:05<00:23,  9.70it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  18%|█▊        | 48/270 [00:05<00:21, 10.17it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  19%|█▊        | 50/270 [00:05<00:22,  9.75it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  19%|█▉        | 51/270 [00:05<00:23,  9.26it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  20%|█▉        | 53/270 [00:05<00:22,  9.61it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  20%|██        | 54/270 [00:05<00:22,  9.68it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  21%|██        | 56/270 [00:06<00:22,  9.67it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  21%|██        | 57/270 [00:06<00:22,  9.29it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  21%|██▏       | 58/270 [00:06<00:23,  9.10it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  22%|██▏       | 59/270 [00:06<00:23,  8.91it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  23%|██▎       | 61/270 [00:06<00:22,  9.40it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  23%|██▎       | 62/270 [00:06<00:23,  8.91it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  23%|██▎       | 63/270 [00:06<00:23,  8.73it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  24%|██▍       | 65/270 [00:07<00:21,  9.76it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  24%|██▍       | 66/270 [00:07<00:21,  9.48it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  25%|██▍       | 67/270 [00:07<00:21,  9.43it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  26%|██▌       | 69/270 [00:07<00:19, 10.28it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  26%|██▋       | 71/270 [00:07<00:18, 10.75it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  27%|██▋       | 73/270 [00:07<00:18, 10.41it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  28%|██▊       | 75/270 [00:08<00:18, 10.62it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  29%|██▊       | 77/270 [00:08<00:18, 10.38it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  29%|██▉       | 79/270 [00:08<00:18, 10.37it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  30%|███       | 81/270 [00:08<00:19,  9.90it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  30%|███       | 82/270 [00:08<00:19,  9.55it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  31%|███       | 83/270 [00:08<00:20,  9.26it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  31%|███▏      | 85/270 [00:09<00:19,  9.55it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  32%|███▏      | 87/270 [00:09<00:18,  9.80it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  33%|███▎      | 88/270 [00:09<00:19,  9.44it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  33%|███▎      | 89/270 [00:09<00:19,  9.12it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  33%|███▎      | 90/270 [00:09<00:19,  9.16it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  34%|███▎      | 91/270 [00:09<00:20,  8.85it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  34%|███▍      | 93/270 [00:09<00:18,  9.68it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  35%|███▌      | 95/270 [00:10<00:17, 10.12it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  36%|███▌      | 96/270 [00:10<00:17, 10.08it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  36%|███▌      | 97/270 [00:10<00:17, 10.04it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  37%|███▋      | 99/270 [00:10<00:16, 10.44it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  37%|███▋      | 101/270 [00:10<00:16, 10.40it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  38%|███▊      | 103/270 [00:10<00:15, 10.59it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  39%|███▉      | 105/270 [00:11<00:16,  9.80it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  40%|███▉      | 107/270 [00:11<00:15, 10.23it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  40%|████      | 109/270 [00:11<00:16,  9.89it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  41%|████      | 111/270 [00:11<00:16,  9.87it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  42%|████▏     | 113/270 [00:11<00:15, 10.13it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  43%|████▎     | 115/270 [00:12<00:15,  9.96it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  43%|████▎     | 117/270 [00:12<00:15,  9.68it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  44%|████▍     | 119/270 [00:12<00:15, 10.02it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  45%|████▍     | 121/270 [00:12<00:14, 10.29it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  46%|████▌     | 123/270 [00:12<00:14, 10.50it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  46%|████▋     | 125/270 [00:13<00:14, 10.33it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  47%|████▋     | 127/270 [00:13<00:14,  9.58it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  47%|████▋     | 128/270 [00:13<00:15,  9.30it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  48%|████▊     | 129/270 [00:13<00:15,  9.05it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  49%|████▊     | 131/270 [00:13<00:14,  9.75it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  49%|████▉     | 132/270 [00:13<00:14,  9.21it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  50%|████▉     | 134/270 [00:14<00:14,  9.51it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  50%|█████     | 136/270 [00:14<00:13,  9.97it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  51%|█████     | 138/270 [00:14<00:13,  9.97it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  52%|█████▏    | 140/270 [00:14<00:13, 10.00it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  52%|█████▏    | 141/270 [00:14<00:13,  9.63it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  53%|█████▎    | 142/270 [00:14<00:13,  9.41it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  53%|█████▎    | 144/270 [00:15<00:12, 10.21it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  54%|█████▍    | 146/270 [00:15<00:12,  9.86it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  54%|█████▍    | 147/270 [00:15<00:13,  9.40it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  55%|█████▌    | 149/270 [00:15<00:12,  9.75it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  56%|█████▌    | 151/270 [00:15<00:12,  9.81it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  56%|█████▋    | 152/270 [00:15<00:12,  9.50it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  57%|█████▋    | 153/270 [00:16<00:12,  9.16it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  57%|█████▋    | 155/270 [00:16<00:12,  9.50it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  58%|█████▊    | 156/270 [00:16<00:12,  8.99it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  59%|█████▊    | 158/270 [00:16<00:11, 10.12it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  59%|█████▉    | 159/270 [00:16<00:11,  9.69it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  59%|█████▉    | 160/270 [00:16<00:11,  9.38it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  60%|█████▉    | 161/270 [00:16<00:11,  9.41it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  60%|██████    | 162/270 [00:16<00:11,  9.11it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  60%|██████    | 163/270 [00:17<00:11,  8.95it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  61%|██████    | 164/270 [00:17<00:11,  8.88it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  61%|██████    | 165/270 [00:17<00:11,  8.77it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  61%|██████▏   | 166/270 [00:17<00:11,  9.04it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  62%|██████▏   | 168/270 [00:17<00:10,  9.45it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  63%|██████▎   | 169/270 [00:17<00:11,  9.17it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  63%|██████▎   | 170/270 [00:17<00:10,  9.36it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  63%|██████▎   | 171/270 [00:17<00:10,  9.12it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  64%|██████▎   | 172/270 [00:18<00:10,  8.92it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  64%|██████▍   | 173/270 [00:18<00:11,  8.61it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  64%|██████▍   | 174/270 [00:18<00:11,  8.63it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  65%|██████▍   | 175/270 [00:18<00:10,  8.65it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  65%|██████▌   | 176/270 [00:18<00:11,  8.52it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  66%|██████▌   | 177/270 [00:18<00:10,  8.49it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  66%|██████▋   | 179/270 [00:18<00:09,  9.21it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  67%|██████▋   | 180/270 [00:18<00:10,  8.82it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  67%|██████▋   | 182/270 [00:19<00:09,  9.14it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  68%|██████▊   | 183/270 [00:19<00:09,  9.31it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  68%|██████▊   | 184/270 [00:19<00:09,  9.01it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  69%|██████▊   | 185/270 [00:19<00:09,  8.87it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  69%|██████▉   | 187/270 [00:19<00:08,  9.32it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  70%|██████▉   | 188/270 [00:19<00:09,  8.99it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  70%|███████   | 190/270 [00:20<00:07, 10.12it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  71%|███████   | 191/270 [00:20<00:07, 10.03it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  71%|███████   | 192/270 [00:20<00:08,  9.47it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  72%|███████▏  | 194/270 [00:20<00:07,  9.66it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  72%|███████▏  | 195/270 [00:20<00:08,  9.11it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  73%|███████▎  | 196/270 [00:20<00:08,  8.79it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  73%|███████▎  | 198/270 [00:20<00:07,  9.18it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  74%|███████▎  | 199/270 [00:21<00:08,  8.80it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  74%|███████▍  | 200/270 [00:21<00:08,  8.70it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  74%|███████▍  | 201/270 [00:21<00:08,  8.53it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  75%|███████▍  | 202/270 [00:21<00:08,  8.35it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  76%|███████▌  | 204/270 [00:21<00:06,  9.70it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  76%|███████▋  | 206/270 [00:21<00:06, 10.00it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  77%|███████▋  | 207/270 [00:21<00:06,  9.63it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  77%|███████▋  | 208/270 [00:22<00:06,  9.23it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  77%|███████▋  | 209/270 [00:22<00:06,  8.92it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  78%|███████▊  | 210/270 [00:22<00:06,  8.76it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  79%|███████▊  | 212/270 [00:22<00:06,  9.17it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  79%|███████▉  | 213/270 [00:22<00:06,  9.28it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  80%|███████▉  | 215/270 [00:22<00:05, 10.06it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  80%|████████  | 216/270 [00:22<00:05,  9.35it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  80%|████████  | 217/270 [00:22<00:05,  9.46it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  81%|████████  | 219/270 [00:23<00:05,  9.82it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  81%|████████▏ | 220/270 [00:23<00:05,  9.82it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  82%|████████▏ | 222/270 [00:23<00:04, 10.70it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  83%|████████▎ | 224/270 [00:23<00:04, 10.75it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  84%|████████▎ | 226/270 [00:23<00:04, 10.99it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  84%|████████▍ | 228/270 [00:24<00:04, 10.13it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  85%|████████▌ | 230/270 [00:24<00:04,  9.59it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  86%|████████▌ | 231/270 [00:24<00:04,  9.30it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  86%|████████▋ | 233/270 [00:24<00:03,  9.94it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  87%|████████▋ | 234/270 [00:24<00:03,  9.93it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  87%|████████▋ | 235/270 [00:24<00:03,  9.94it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  87%|████████▋ | 236/270 [00:24<00:03,  9.56it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  88%|████████▊ | 238/270 [00:25<00:03, 10.15it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  89%|████████▉ | 240/270 [00:25<00:03,  9.53it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  89%|████████▉ | 241/270 [00:25<00:03,  9.04it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  90%|█████████ | 243/270 [00:25<00:02, 10.05it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  90%|█████████ | 244/270 [00:25<00:02,  9.65it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  91%|█████████ | 245/270 [00:25<00:02,  9.33it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  91%|█████████ | 246/270 [00:25<00:02,  8.92it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  91%|█████████▏| 247/270 [00:26<00:02,  8.83it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  92%|█████████▏| 248/270 [00:26<00:02,  8.76it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  92%|█████████▏| 249/270 [00:26<00:02,  8.55it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  93%|█████████▎| 250/270 [00:26<00:02,  8.43it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  93%|█████████▎| 251/270 [00:26<00:02,  8.42it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  93%|█████████▎| 252/270 [00:26<00:02,  8.59it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  94%|█████████▎| 253/270 [00:26<00:01,  8.56it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  94%|█████████▍| 254/270 [00:26<00:01,  8.54it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  94%|█████████▍| 255/270 [00:26<00:01,  8.31it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  95%|█████████▍| 256/270 [00:27<00:01,  8.31it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  95%|█████████▌| 257/270 [00:27<00:01,  8.70it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  96%|█████████▌| 259/270 [00:27<00:01,  9.75it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  97%|█████████▋| 261/270 [00:27<00:00, 10.25it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  97%|█████████▋| 263/270 [00:27<00:00,  9.64it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  98%|█████████▊| 264/270 [00:27<00:00,  9.38it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  98%|█████████▊| 265/270 [00:28<00:00,  9.23it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  99%|█████████▊| 266/270 [00:28<00:00,  9.04it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  99%|█████████▉| 268/270 [00:28<00:00,  9.35it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation: 100%|██████████| 270/270 [00:28<00:00,  9.40it/s]\n",
            "\n",
            "Training:  51%|█████     | 900/1772 [10:45<2:13:24,  9.18s/it, running training loss:  0.87535]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            ">>> training loss: 0.988192, valid loss: 0.681092,valid f1: 0.000000, valid acc:0.689991\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  51%|█████     | 900/1772 [10:46<2:13:24,  9.18s/it, running training loss:  0.86700]\u001b[A\n",
            "Training:  51%|█████     | 901/1772 [10:46<1:36:03,  6.62s/it, running training loss:  0.86700]\u001b[A\n",
            "Training:  51%|█████     | 901/1772 [10:47<1:36:03,  6.62s/it, running training loss:  1.01333]\u001b[A\n",
            "Training:  51%|█████     | 902/1772 [10:47<1:09:57,  4.83s/it, running training loss:  1.01333]\u001b[A\n",
            "Training:  51%|█████     | 902/1772 [10:47<1:09:57,  4.83s/it, running training loss:  0.92034]\u001b[A\n",
            "Training:  51%|█████     | 903/1772 [10:47<51:50,  3.58s/it, running training loss:  0.92034]  \u001b[A\n",
            "Training:  51%|█████     | 903/1772 [10:48<51:50,  3.58s/it, running training loss:  0.91686]\u001b[A\n",
            "Training:  51%|█████     | 904/1772 [10:48<38:33,  2.67s/it, running training loss:  0.91686]\u001b[A\n",
            "Training:  51%|█████     | 904/1772 [10:48<38:33,  2.67s/it, running training loss:  0.73845]\u001b[A\n",
            "Training:  51%|█████     | 905/1772 [10:48<29:37,  2.05s/it, running training loss:  0.73845]\u001b[A\n",
            "Training:  51%|█████     | 905/1772 [10:49<29:37,  2.05s/it, running training loss:  0.86365]\u001b[A\n",
            "Training:  51%|█████     | 906/1772 [10:49<23:16,  1.61s/it, running training loss:  0.86365]\u001b[A\n",
            "Training:  51%|█████     | 906/1772 [10:50<23:16,  1.61s/it, running training loss:  0.95857]\u001b[A\n",
            "Training:  51%|█████     | 907/1772 [10:50<19:08,  1.33s/it, running training loss:  0.95857]\u001b[A\n",
            "Training:  51%|█████     | 907/1772 [10:50<19:08,  1.33s/it, running training loss:  1.06480]\u001b[A\n",
            "Training:  51%|█████     | 908/1772 [10:50<15:25,  1.07s/it, running training loss:  1.06480]\u001b[A\n",
            "Training:  51%|█████     | 908/1772 [10:51<15:25,  1.07s/it, running training loss:  1.10058]\u001b[A\n",
            "Training:  51%|█████▏    | 909/1772 [10:51<13:40,  1.05it/s, running training loss:  1.10058]\u001b[A\n",
            "Training:  51%|█████▏    | 909/1772 [10:52<13:40,  1.05it/s, running training loss:  1.18650]\u001b[A\n",
            "Training:  51%|█████▏    | 910/1772 [10:52<12:31,  1.15it/s, running training loss:  1.18650]\u001b[A\n",
            "Training:  51%|█████▏    | 910/1772 [10:52<12:31,  1.15it/s, running training loss:  0.84281]\u001b[A\n",
            "Training:  51%|█████▏    | 911/1772 [10:52<11:07,  1.29it/s, running training loss:  0.84281]\u001b[A\n",
            "Training:  51%|█████▏    | 911/1772 [10:53<11:07,  1.29it/s, running training loss:  1.19859]\u001b[A\n",
            "Training:  51%|█████▏    | 912/1772 [10:53<10:57,  1.31it/s, running training loss:  1.19859]\u001b[A\n",
            "Training:  51%|█████▏    | 912/1772 [10:53<10:57,  1.31it/s, running training loss:  0.90983]\u001b[A\n",
            "Training:  52%|█████▏    | 913/1772 [10:53<09:59,  1.43it/s, running training loss:  0.90983]\u001b[A\n",
            "Training:  52%|█████▏    | 913/1772 [10:54<09:59,  1.43it/s, running training loss:  0.82887]\u001b[A\n",
            "Training:  52%|█████▏    | 914/1772 [10:54<10:39,  1.34it/s, running training loss:  0.82887]\u001b[A\n",
            "Training:  52%|█████▏    | 914/1772 [10:55<10:39,  1.34it/s, running training loss:  0.80366]\u001b[A\n",
            "Training:  52%|█████▏    | 915/1772 [10:55<10:21,  1.38it/s, running training loss:  0.80366]\u001b[A\n",
            "Training:  52%|█████▏    | 915/1772 [10:56<10:21,  1.38it/s, running training loss:  0.83941]\u001b[A\n",
            "Training:  52%|█████▏    | 916/1772 [10:56<10:22,  1.37it/s, running training loss:  0.83941]\u001b[A\n",
            "Training:  52%|█████▏    | 916/1772 [10:56<10:22,  1.37it/s, running training loss:  0.88397]\u001b[A\n",
            "Training:  52%|█████▏    | 917/1772 [10:56<10:12,  1.40it/s, running training loss:  0.88397]\u001b[A\n",
            "Training:  52%|█████▏    | 917/1772 [10:57<10:12,  1.40it/s, running training loss:  0.80599]\u001b[A\n",
            "Training:  52%|█████▏    | 918/1772 [10:57<09:51,  1.44it/s, running training loss:  0.80599]\u001b[A\n",
            "Training:  52%|█████▏    | 918/1772 [10:58<09:51,  1.44it/s, running training loss:  0.82938]\u001b[A\n",
            "Training:  52%|█████▏    | 919/1772 [10:58<09:45,  1.46it/s, running training loss:  0.82938]\u001b[A\n",
            "Training:  52%|█████▏    | 919/1772 [10:59<09:45,  1.46it/s, running training loss:  0.86608]\u001b[A\n",
            "Training:  52%|█████▏    | 920/1772 [10:59<11:15,  1.26it/s, running training loss:  0.86608]\u001b[A\n",
            "Training:  52%|█████▏    | 920/1772 [10:59<11:15,  1.26it/s, running training loss:  0.86831]\u001b[A\n",
            "Training:  52%|█████▏    | 921/1772 [10:59<10:28,  1.35it/s, running training loss:  0.86831]\u001b[A\n",
            "Training:  52%|█████▏    | 921/1772 [11:00<10:28,  1.35it/s, running training loss:  1.16149]\u001b[A\n",
            "Training:  52%|█████▏    | 922/1772 [11:00<10:07,  1.40it/s, running training loss:  1.16149]\u001b[A\n",
            "Training:  52%|█████▏    | 922/1772 [11:01<10:07,  1.40it/s, running training loss:  0.83444]\u001b[A\n",
            "Training:  52%|█████▏    | 923/1772 [11:01<10:14,  1.38it/s, running training loss:  0.83444]\u001b[A\n",
            "Training:  52%|█████▏    | 923/1772 [11:01<10:14,  1.38it/s, running training loss:  1.04142]\u001b[A\n",
            "Training:  52%|█████▏    | 924/1772 [11:01<09:27,  1.49it/s, running training loss:  1.04142]\u001b[A\n",
            "Training:  52%|█████▏    | 924/1772 [11:02<09:27,  1.49it/s, running training loss:  1.10027]\u001b[A\n",
            "Training:  52%|█████▏    | 925/1772 [11:02<09:21,  1.51it/s, running training loss:  1.10027]\u001b[A\n",
            "Training:  52%|█████▏    | 925/1772 [11:02<09:21,  1.51it/s, running training loss:  0.85774]\u001b[A\n",
            "Training:  52%|█████▏    | 926/1772 [11:02<08:35,  1.64it/s, running training loss:  0.85774]\u001b[A\n",
            "Training:  52%|█████▏    | 926/1772 [11:03<08:35,  1.64it/s, running training loss:  1.15994]\u001b[A\n",
            "Training:  52%|█████▏    | 927/1772 [11:03<08:06,  1.74it/s, running training loss:  1.15994]\u001b[A\n",
            "Training:  52%|█████▏    | 927/1772 [11:04<08:06,  1.74it/s, running training loss:  0.91919]\u001b[A\n",
            "Training:  52%|█████▏    | 928/1772 [11:04<10:02,  1.40it/s, running training loss:  0.91919]\u001b[A\n",
            "Training:  52%|█████▏    | 928/1772 [11:05<10:02,  1.40it/s, running training loss:  0.91764]\u001b[A\n",
            "Training:  52%|█████▏    | 929/1772 [11:05<09:29,  1.48it/s, running training loss:  0.91764]\u001b[A\n",
            "Training:  52%|█████▏    | 929/1772 [11:05<09:29,  1.48it/s, running training loss:  0.99496]\u001b[A\n",
            "Training:  52%|█████▏    | 930/1772 [11:05<08:53,  1.58it/s, running training loss:  0.99496]\u001b[A\n",
            "Training:  52%|█████▏    | 930/1772 [11:06<08:53,  1.58it/s, running training loss:  0.83932]\u001b[A\n",
            "Training:  53%|█████▎    | 931/1772 [11:06<08:30,  1.65it/s, running training loss:  0.83932]\u001b[A\n",
            "Training:  53%|█████▎    | 931/1772 [11:06<08:30,  1.65it/s, running training loss:  0.76920]\u001b[A\n",
            "Training:  53%|█████▎    | 932/1772 [11:06<08:22,  1.67it/s, running training loss:  0.76920]\u001b[A\n",
            "Training:  53%|█████▎    | 932/1772 [11:07<08:22,  1.67it/s, running training loss:  0.82216]\u001b[A\n",
            "Training:  53%|█████▎    | 933/1772 [11:07<08:17,  1.69it/s, running training loss:  0.82216]\u001b[A\n",
            "Training:  53%|█████▎    | 933/1772 [11:07<08:17,  1.69it/s, running training loss:  0.99886]\u001b[A\n",
            "Training:  53%|█████▎    | 934/1772 [11:07<08:27,  1.65it/s, running training loss:  0.99886]\u001b[A\n",
            "Training:  53%|█████▎    | 934/1772 [11:08<08:27,  1.65it/s, running training loss:  0.78653]\u001b[A\n",
            "Training:  53%|█████▎    | 935/1772 [11:08<08:21,  1.67it/s, running training loss:  0.78653]\u001b[A\n",
            "Training:  53%|█████▎    | 935/1772 [11:09<08:21,  1.67it/s, running training loss:  0.79982]\u001b[A\n",
            "Training:  53%|█████▎    | 936/1772 [11:09<08:42,  1.60it/s, running training loss:  0.79982]\u001b[A\n",
            "Training:  53%|█████▎    | 936/1772 [11:09<08:42,  1.60it/s, running training loss:  0.74012]\u001b[A\n",
            "Training:  53%|█████▎    | 937/1772 [11:09<08:38,  1.61it/s, running training loss:  0.74012]\u001b[A\n",
            "Training:  53%|█████▎    | 937/1772 [11:10<08:38,  1.61it/s, running training loss:  0.75651]\u001b[A\n",
            "Training:  53%|█████▎    | 938/1772 [11:10<08:25,  1.65it/s, running training loss:  0.75651]\u001b[A\n",
            "Training:  53%|█████▎    | 938/1772 [11:11<08:25,  1.65it/s, running training loss:  1.19040]\u001b[A\n",
            "Training:  53%|█████▎    | 939/1772 [11:11<09:09,  1.52it/s, running training loss:  1.19040]\u001b[A\n",
            "Training:  53%|█████▎    | 939/1772 [11:11<09:09,  1.52it/s, running training loss:  1.17138]\u001b[A\n",
            "Training:  53%|█████▎    | 940/1772 [11:11<09:11,  1.51it/s, running training loss:  1.17138]\u001b[A\n",
            "Training:  53%|█████▎    | 940/1772 [11:12<09:11,  1.51it/s, running training loss:  1.05326]\u001b[A\n",
            "Training:  53%|█████▎    | 941/1772 [11:12<08:59,  1.54it/s, running training loss:  1.05326]\u001b[A\n",
            "Training:  53%|█████▎    | 941/1772 [11:12<08:59,  1.54it/s, running training loss:  0.69827]\u001b[A\n",
            "Training:  53%|█████▎    | 942/1772 [11:12<08:29,  1.63it/s, running training loss:  0.69827]\u001b[A\n",
            "Training:  53%|█████▎    | 942/1772 [11:13<08:29,  1.63it/s, running training loss:  0.74070]\u001b[A\n",
            "Training:  53%|█████▎    | 943/1772 [11:13<08:40,  1.59it/s, running training loss:  0.74070]\u001b[A\n",
            "Training:  53%|█████▎    | 943/1772 [11:14<08:40,  1.59it/s, running training loss:  0.80113]\u001b[A\n",
            "Training:  53%|█████▎    | 944/1772 [11:14<09:32,  1.45it/s, running training loss:  0.80113]\u001b[A\n",
            "Training:  53%|█████▎    | 944/1772 [11:14<09:32,  1.45it/s, running training loss:  0.88389]\u001b[A\n",
            "Training:  53%|█████▎    | 945/1772 [11:14<08:56,  1.54it/s, running training loss:  0.88389]\u001b[A\n",
            "Training:  53%|█████▎    | 945/1772 [11:15<08:56,  1.54it/s, running training loss:  1.18050]\u001b[A\n",
            "Training:  53%|█████▎    | 946/1772 [11:15<08:32,  1.61it/s, running training loss:  1.18050]\u001b[A\n",
            "Training:  53%|█████▎    | 946/1772 [11:16<08:32,  1.61it/s, running training loss:  0.88303]\u001b[A\n",
            "Training:  53%|█████▎    | 947/1772 [11:16<08:44,  1.57it/s, running training loss:  0.88303]\u001b[A\n",
            "Training:  53%|█████▎    | 947/1772 [11:16<08:44,  1.57it/s, running training loss:  0.87905]\u001b[A\n",
            "Training:  53%|█████▎    | 948/1772 [11:16<08:43,  1.58it/s, running training loss:  0.87905]\u001b[A\n",
            "Training:  53%|█████▎    | 948/1772 [11:17<08:43,  1.58it/s, running training loss:  0.83242]\u001b[A\n",
            "Training:  54%|█████▎    | 949/1772 [11:17<08:05,  1.70it/s, running training loss:  0.83242]\u001b[A\n",
            "Training:  54%|█████▎    | 949/1772 [11:17<08:05,  1.70it/s, running training loss:  0.95876]\u001b[A\n",
            "Training:  54%|█████▎    | 950/1772 [11:17<07:40,  1.78it/s, running training loss:  0.95876]\u001b[A\n",
            "Training:  54%|█████▎    | 950/1772 [11:18<07:40,  1.78it/s, running training loss:  1.12029]\u001b[A\n",
            "Training:  54%|█████▎    | 951/1772 [11:18<07:57,  1.72it/s, running training loss:  1.12029]\u001b[A\n",
            "Training:  54%|█████▎    | 951/1772 [11:18<07:57,  1.72it/s, running training loss:  1.15813]\u001b[A\n",
            "Training:  54%|█████▎    | 952/1772 [11:19<07:46,  1.76it/s, running training loss:  1.15813]\u001b[A\n",
            "Training:  54%|█████▎    | 952/1772 [11:19<07:46,  1.76it/s, running training loss:  0.82314]\u001b[A\n",
            "Training:  54%|█████▍    | 953/1772 [11:19<07:40,  1.78it/s, running training loss:  0.82314]\u001b[A\n",
            "Training:  54%|█████▍    | 953/1772 [11:20<07:40,  1.78it/s, running training loss:  0.86834]\u001b[A\n",
            "Training:  54%|█████▍    | 954/1772 [11:20<08:15,  1.65it/s, running training loss:  0.86834]\u001b[A\n",
            "Training:  54%|█████▍    | 954/1772 [11:20<08:15,  1.65it/s, running training loss:  0.78888]\u001b[A\n",
            "Training:  54%|█████▍    | 955/1772 [11:20<07:53,  1.73it/s, running training loss:  0.78888]\u001b[A\n",
            "Training:  54%|█████▍    | 955/1772 [11:21<07:53,  1.73it/s, running training loss:  1.24006]\u001b[A\n",
            "Training:  54%|█████▍    | 956/1772 [11:21<09:01,  1.51it/s, running training loss:  1.24006]\u001b[A\n",
            "Training:  54%|█████▍    | 956/1772 [11:22<09:01,  1.51it/s, running training loss:  0.71457]\u001b[A\n",
            "Training:  54%|█████▍    | 957/1772 [11:22<09:08,  1.48it/s, running training loss:  0.71457]\u001b[A\n",
            "Training:  54%|█████▍    | 957/1772 [11:22<09:08,  1.48it/s, running training loss:  0.73119]\u001b[A\n",
            "Training:  54%|█████▍    | 958/1772 [11:22<08:52,  1.53it/s, running training loss:  0.73119]\u001b[A\n",
            "Training:  54%|█████▍    | 958/1772 [11:23<08:52,  1.53it/s, running training loss:  0.74885]\u001b[A\n",
            "Training:  54%|█████▍    | 959/1772 [11:23<08:34,  1.58it/s, running training loss:  0.74885]\u001b[A\n",
            "Training:  54%|█████▍    | 959/1772 [11:24<08:34,  1.58it/s, running training loss:  0.77406]\u001b[A\n",
            "Training:  54%|█████▍    | 960/1772 [11:24<08:48,  1.54it/s, running training loss:  0.77406]\u001b[A\n",
            "Training:  54%|█████▍    | 960/1772 [11:24<08:48,  1.54it/s, running training loss:  0.77801]\u001b[A\n",
            "Training:  54%|█████▍    | 961/1772 [11:24<08:44,  1.55it/s, running training loss:  0.77801]\u001b[A\n",
            "Training:  54%|█████▍    | 961/1772 [11:25<08:44,  1.55it/s, running training loss:  0.81036]\u001b[A\n",
            "Training:  54%|█████▍    | 962/1772 [11:25<08:20,  1.62it/s, running training loss:  0.81036]\u001b[A\n",
            "Training:  54%|█████▍    | 962/1772 [11:25<08:20,  1.62it/s, running training loss:  0.73956]\u001b[A\n",
            "Training:  54%|█████▍    | 963/1772 [11:25<08:00,  1.68it/s, running training loss:  0.73956]\u001b[A\n",
            "Training:  54%|█████▍    | 963/1772 [11:26<08:00,  1.68it/s, running training loss:  0.74213]\u001b[A\n",
            "Training:  54%|█████▍    | 964/1772 [11:26<07:53,  1.71it/s, running training loss:  0.74213]\u001b[A\n",
            "Training:  54%|█████▍    | 964/1772 [11:27<07:53,  1.71it/s, running training loss:  0.97769]\u001b[A\n",
            "Training:  54%|█████▍    | 965/1772 [11:27<07:58,  1.68it/s, running training loss:  0.97769]\u001b[A\n",
            "Training:  54%|█████▍    | 965/1772 [11:27<07:58,  1.68it/s, running training loss:  0.74629]\u001b[A\n",
            "Training:  55%|█████▍    | 966/1772 [11:27<07:38,  1.76it/s, running training loss:  0.74629]\u001b[A\n",
            "Training:  55%|█████▍    | 966/1772 [11:28<07:38,  1.76it/s, running training loss:  0.73640]\u001b[A\n",
            "Training:  55%|█████▍    | 967/1772 [11:28<07:36,  1.76it/s, running training loss:  0.73640]\u001b[A\n",
            "Training:  55%|█████▍    | 967/1772 [11:28<07:36,  1.76it/s, running training loss:  1.07156]\u001b[A\n",
            "Training:  55%|█████▍    | 968/1772 [11:28<07:55,  1.69it/s, running training loss:  1.07156]\u001b[A\n",
            "Training:  55%|█████▍    | 968/1772 [11:29<07:55,  1.69it/s, running training loss:  1.06759]\u001b[A\n",
            "Training:  55%|█████▍    | 969/1772 [11:29<07:46,  1.72it/s, running training loss:  1.06759]\u001b[A\n",
            "Training:  55%|█████▍    | 969/1772 [11:29<07:46,  1.72it/s, running training loss:  1.02201]\u001b[A\n",
            "Training:  55%|█████▍    | 970/1772 [11:30<07:54,  1.69it/s, running training loss:  1.02201]\u001b[A\n",
            "Training:  55%|█████▍    | 970/1772 [11:30<07:54,  1.69it/s, running training loss:  1.07156]\u001b[A\n",
            "Training:  55%|█████▍    | 971/1772 [11:30<07:45,  1.72it/s, running training loss:  1.07156]\u001b[A\n",
            "Training:  55%|█████▍    | 971/1772 [11:31<07:45,  1.72it/s, running training loss:  0.98160]\u001b[A\n",
            "Training:  55%|█████▍    | 972/1772 [11:31<07:35,  1.75it/s, running training loss:  0.98160]\u001b[A\n",
            "Training:  55%|█████▍    | 972/1772 [11:31<07:35,  1.75it/s, running training loss:  1.00879]\u001b[A\n",
            "Training:  55%|█████▍    | 973/1772 [11:31<07:24,  1.80it/s, running training loss:  1.00879]\u001b[A\n",
            "Training:  55%|█████▍    | 973/1772 [11:32<07:24,  1.80it/s, running training loss:  0.83990]\u001b[A\n",
            "Training:  55%|█████▍    | 974/1772 [11:32<08:15,  1.61it/s, running training loss:  0.83990]\u001b[A\n",
            "Training:  55%|█████▍    | 974/1772 [11:32<08:15,  1.61it/s, running training loss:  0.97674]\u001b[A\n",
            "Training:  55%|█████▌    | 975/1772 [11:32<07:51,  1.69it/s, running training loss:  0.97674]\u001b[A\n",
            "Training:  55%|█████▌    | 975/1772 [11:33<07:51,  1.69it/s, running training loss:  0.78014]\u001b[A\n",
            "Training:  55%|█████▌    | 976/1772 [11:33<08:47,  1.51it/s, running training loss:  0.78014]\u001b[A\n",
            "Training:  55%|█████▌    | 976/1772 [11:34<08:47,  1.51it/s, running training loss:  0.71423]\u001b[A\n",
            "Training:  55%|█████▌    | 977/1772 [11:34<08:38,  1.53it/s, running training loss:  0.71423]\u001b[A\n",
            "Training:  55%|█████▌    | 977/1772 [11:35<08:38,  1.53it/s, running training loss:  0.86814]\u001b[A\n",
            "Training:  55%|█████▌    | 978/1772 [11:35<08:40,  1.52it/s, running training loss:  0.86814]\u001b[A\n",
            "Training:  55%|█████▌    | 978/1772 [11:35<08:40,  1.52it/s, running training loss:  0.76680]\u001b[A\n",
            "Training:  55%|█████▌    | 979/1772 [11:35<08:21,  1.58it/s, running training loss:  0.76680]\u001b[A\n",
            "Training:  55%|█████▌    | 979/1772 [11:36<08:21,  1.58it/s, running training loss:  0.84724]\u001b[A\n",
            "Training:  55%|█████▌    | 980/1772 [11:36<07:54,  1.67it/s, running training loss:  0.84724]\u001b[A\n",
            "Training:  55%|█████▌    | 980/1772 [11:37<07:54,  1.67it/s, running training loss:  1.32218]\u001b[A\n",
            "Training:  55%|█████▌    | 981/1772 [11:37<09:21,  1.41it/s, running training loss:  1.32218]\u001b[A\n",
            "Training:  55%|█████▌    | 981/1772 [11:37<09:21,  1.41it/s, running training loss:  1.29204]\u001b[A\n",
            "Training:  55%|█████▌    | 982/1772 [11:37<08:40,  1.52it/s, running training loss:  1.29204]\u001b[A\n",
            "Training:  55%|█████▌    | 982/1772 [11:38<08:40,  1.52it/s, running training loss:  1.13338]\u001b[A\n",
            "Training:  55%|█████▌    | 983/1772 [11:38<08:24,  1.56it/s, running training loss:  1.13338]\u001b[A\n",
            "Training:  55%|█████▌    | 983/1772 [11:39<08:24,  1.56it/s, running training loss:  1.03368]\u001b[A\n",
            "Training:  56%|█████▌    | 984/1772 [11:39<09:03,  1.45it/s, running training loss:  1.03368]\u001b[A\n",
            "Training:  56%|█████▌    | 984/1772 [11:39<09:03,  1.45it/s, running training loss:  1.23290]\u001b[A\n",
            "Training:  56%|█████▌    | 985/1772 [11:39<08:55,  1.47it/s, running training loss:  1.23290]\u001b[A\n",
            "Training:  56%|█████▌    | 985/1772 [11:40<08:55,  1.47it/s, running training loss:  1.31332]\u001b[A\n",
            "Training:  56%|█████▌    | 986/1772 [11:40<09:40,  1.35it/s, running training loss:  1.31332]\u001b[A\n",
            "Training:  56%|█████▌    | 986/1772 [11:41<09:40,  1.35it/s, running training loss:  0.90087]\u001b[A\n",
            "Training:  56%|█████▌    | 987/1772 [11:41<08:37,  1.52it/s, running training loss:  0.90087]\u001b[A\n",
            "Training:  56%|█████▌    | 987/1772 [11:41<08:37,  1.52it/s, running training loss:  1.06236]\u001b[A\n",
            "Training:  56%|█████▌    | 988/1772 [11:41<08:03,  1.62it/s, running training loss:  1.06236]\u001b[A\n",
            "Training:  56%|█████▌    | 988/1772 [11:42<08:03,  1.62it/s, running training loss:  1.01710]\u001b[A\n",
            "Training:  56%|█████▌    | 989/1772 [11:42<07:32,  1.73it/s, running training loss:  1.01710]\u001b[A\n",
            "Training:  56%|█████▌    | 989/1772 [11:42<07:32,  1.73it/s, running training loss:  0.92143]\u001b[A\n",
            "Training:  56%|█████▌    | 990/1772 [11:42<07:25,  1.75it/s, running training loss:  0.92143]\u001b[A\n",
            "Training:  56%|█████▌    | 990/1772 [11:43<07:25,  1.75it/s, running training loss:  1.25747]\u001b[A\n",
            "Training:  56%|█████▌    | 991/1772 [11:43<07:47,  1.67it/s, running training loss:  1.25747]\u001b[A\n",
            "Training:  56%|█████▌    | 991/1772 [11:43<07:47,  1.67it/s, running training loss:  0.85306]\u001b[A\n",
            "Training:  56%|█████▌    | 992/1772 [11:43<07:39,  1.70it/s, running training loss:  0.85306]\u001b[A\n",
            "Training:  56%|█████▌    | 992/1772 [11:44<07:39,  1.70it/s, running training loss:  0.77455]\u001b[A\n",
            "Training:  56%|█████▌    | 993/1772 [11:44<07:27,  1.74it/s, running training loss:  0.77455]\u001b[A\n",
            "Training:  56%|█████▌    | 993/1772 [11:44<07:27,  1.74it/s, running training loss:  1.40281]\u001b[A\n",
            "Training:  56%|█████▌    | 994/1772 [11:44<07:21,  1.76it/s, running training loss:  1.40281]\u001b[A\n",
            "Training:  56%|█████▌    | 994/1772 [11:45<07:21,  1.76it/s, running training loss:  1.30379]\u001b[A\n",
            "Training:  56%|█████▌    | 995/1772 [11:45<07:48,  1.66it/s, running training loss:  1.30379]\u001b[A\n",
            "Training:  56%|█████▌    | 995/1772 [11:46<07:48,  1.66it/s, running training loss:  0.83022]\u001b[A\n",
            "Training:  56%|█████▌    | 996/1772 [11:46<07:51,  1.65it/s, running training loss:  0.83022]\u001b[A\n",
            "Training:  56%|█████▌    | 996/1772 [11:46<07:51,  1.65it/s, running training loss:  1.14079]\u001b[A\n",
            "Training:  56%|█████▋    | 997/1772 [11:46<07:51,  1.64it/s, running training loss:  1.14079]\u001b[A\n",
            "Training:  56%|█████▋    | 997/1772 [11:47<07:51,  1.64it/s, running training loss:  1.01404]\u001b[A\n",
            "Training:  56%|█████▋    | 998/1772 [11:47<07:33,  1.71it/s, running training loss:  1.01404]\u001b[A\n",
            "Training:  56%|█████▋    | 998/1772 [11:48<07:33,  1.71it/s, running training loss:  0.91653]\u001b[A\n",
            "Training:  56%|█████▋    | 999/1772 [11:48<07:44,  1.67it/s, running training loss:  0.91653]\u001b[A\n",
            "Training:  56%|█████▋    | 999/1772 [11:48<07:44,  1.67it/s, running training loss:  0.93162]\u001b[A\n",
            "Training:  56%|█████▋    | 1000/1772 [11:48<08:03,  1.60it/s, running training loss:  0.93162]\u001b[A\n",
            "Training:  56%|█████▋    | 1000/1772 [11:49<08:03,  1.60it/s, running training loss:  0.79492]\u001b[A\n",
            "Training:  56%|█████▋    | 1001/1772 [11:49<07:55,  1.62it/s, running training loss:  0.79492]\u001b[A\n",
            "Training:  56%|█████▋    | 1001/1772 [11:50<07:55,  1.62it/s, running training loss:  0.73187]\u001b[A\n",
            "Training:  57%|█████▋    | 1002/1772 [11:50<08:35,  1.49it/s, running training loss:  0.73187]\u001b[A\n",
            "Training:  57%|█████▋    | 1002/1772 [11:50<08:35,  1.49it/s, running training loss:  0.76265]\u001b[A\n",
            "Training:  57%|█████▋    | 1003/1772 [11:50<07:56,  1.61it/s, running training loss:  0.76265]\u001b[A\n",
            "Training:  57%|█████▋    | 1003/1772 [11:51<07:56,  1.61it/s, running training loss:  0.81370]\u001b[A\n",
            "Training:  57%|█████▋    | 1004/1772 [11:51<08:17,  1.54it/s, running training loss:  0.81370]\u001b[A\n",
            "Training:  57%|█████▋    | 1004/1772 [11:51<08:17,  1.54it/s, running training loss:  0.84743]\u001b[A\n",
            "Training:  57%|█████▋    | 1005/1772 [11:51<07:50,  1.63it/s, running training loss:  0.84743]\u001b[A\n",
            "Training:  57%|█████▋    | 1005/1772 [11:52<07:50,  1.63it/s, running training loss:  0.75185]\u001b[A\n",
            "Training:  57%|█████▋    | 1006/1772 [11:52<08:11,  1.56it/s, running training loss:  0.75185]\u001b[A\n",
            "Training:  57%|█████▋    | 1006/1772 [11:53<08:11,  1.56it/s, running training loss:  0.98829]\u001b[A\n",
            "Training:  57%|█████▋    | 1007/1772 [11:53<07:47,  1.64it/s, running training loss:  0.98829]\u001b[A\n",
            "Training:  57%|█████▋    | 1007/1772 [11:53<07:47,  1.64it/s, running training loss:  0.95747]\u001b[A\n",
            "Training:  57%|█████▋    | 1008/1772 [11:53<07:50,  1.62it/s, running training loss:  0.95747]\u001b[A\n",
            "Training:  57%|█████▋    | 1008/1772 [11:54<07:50,  1.62it/s, running training loss:  0.80998]\u001b[A\n",
            "Training:  57%|█████▋    | 1009/1772 [11:54<07:44,  1.64it/s, running training loss:  0.80998]\u001b[A\n",
            "Training:  57%|█████▋    | 1009/1772 [11:54<07:44,  1.64it/s, running training loss:  1.23910]\u001b[A\n",
            "Training:  57%|█████▋    | 1010/1772 [11:54<07:41,  1.65it/s, running training loss:  1.23910]\u001b[A\n",
            "Training:  57%|█████▋    | 1010/1772 [11:55<07:41,  1.65it/s, running training loss:  0.83629]\u001b[A\n",
            "Training:  57%|█████▋    | 1011/1772 [11:55<07:35,  1.67it/s, running training loss:  0.83629]\u001b[A\n",
            "Training:  57%|█████▋    | 1011/1772 [11:56<07:35,  1.67it/s, running training loss:  0.75035]\u001b[A\n",
            "Training:  57%|█████▋    | 1012/1772 [11:56<07:27,  1.70it/s, running training loss:  0.75035]\u001b[A\n",
            "Training:  57%|█████▋    | 1012/1772 [11:56<07:27,  1.70it/s, running training loss:  0.70915]\u001b[A\n",
            "Training:  57%|█████▋    | 1013/1772 [11:56<07:02,  1.80it/s, running training loss:  0.70915]\u001b[A\n",
            "Training:  57%|█████▋    | 1013/1772 [11:57<07:02,  1.80it/s, running training loss:  1.24863]\u001b[A\n",
            "Training:  57%|█████▋    | 1014/1772 [11:57<07:05,  1.78it/s, running training loss:  1.24863]\u001b[A\n",
            "Training:  57%|█████▋    | 1014/1772 [11:57<07:05,  1.78it/s, running training loss:  0.96085]\u001b[A\n",
            "Training:  57%|█████▋    | 1015/1772 [11:57<08:11,  1.54it/s, running training loss:  0.96085]\u001b[A\n",
            "Training:  57%|█████▋    | 1015/1772 [11:58<08:11,  1.54it/s, running training loss:  1.04041]\u001b[A\n",
            "Training:  57%|█████▋    | 1016/1772 [11:58<08:21,  1.51it/s, running training loss:  1.04041]\u001b[A\n",
            "Training:  57%|█████▋    | 1016/1772 [11:59<08:21,  1.51it/s, running training loss:  0.85379]\u001b[A\n",
            "Training:  57%|█████▋    | 1017/1772 [11:59<08:00,  1.57it/s, running training loss:  0.85379]\u001b[A\n",
            "Training:  57%|█████▋    | 1017/1772 [12:00<08:00,  1.57it/s, running training loss:  0.82648]\u001b[A\n",
            "Training:  57%|█████▋    | 1018/1772 [12:00<08:57,  1.40it/s, running training loss:  0.82648]\u001b[A\n",
            "Training:  57%|█████▋    | 1018/1772 [12:00<08:57,  1.40it/s, running training loss:  1.28806]\u001b[A\n",
            "Training:  58%|█████▊    | 1019/1772 [12:00<08:28,  1.48it/s, running training loss:  1.28806]\u001b[A\n",
            "Training:  58%|█████▊    | 1019/1772 [12:01<08:28,  1.48it/s, running training loss:  0.70262]\u001b[A\n",
            "Training:  58%|█████▊    | 1020/1772 [12:01<07:52,  1.59it/s, running training loss:  0.70262]\u001b[A\n",
            "Training:  58%|█████▊    | 1020/1772 [12:01<07:52,  1.59it/s, running training loss:  1.09986]\u001b[A\n",
            "Training:  58%|█████▊    | 1021/1772 [12:01<07:39,  1.63it/s, running training loss:  1.09986]\u001b[A\n",
            "Training:  58%|█████▊    | 1021/1772 [12:02<07:39,  1.63it/s, running training loss:  1.12769]\u001b[A\n",
            "Training:  58%|█████▊    | 1022/1772 [12:02<08:00,  1.56it/s, running training loss:  1.12769]\u001b[A\n",
            "Training:  58%|█████▊    | 1022/1772 [12:03<08:00,  1.56it/s, running training loss:  1.22595]\u001b[A\n",
            "Training:  58%|█████▊    | 1023/1772 [12:03<07:43,  1.61it/s, running training loss:  1.22595]\u001b[A\n",
            "Training:  58%|█████▊    | 1023/1772 [12:03<07:43,  1.61it/s, running training loss:  1.32271]\u001b[A\n",
            "Training:  58%|█████▊    | 1024/1772 [12:03<07:30,  1.66it/s, running training loss:  1.32271]\u001b[A\n",
            "Training:  58%|█████▊    | 1024/1772 [12:04<07:30,  1.66it/s, running training loss:  1.04601]\u001b[A\n",
            "Training:  58%|█████▊    | 1025/1772 [12:04<07:34,  1.64it/s, running training loss:  1.04601]\u001b[A\n",
            "Training:  58%|█████▊    | 1025/1772 [12:04<07:34,  1.64it/s, running training loss:  0.93004]\u001b[A\n",
            "Training:  58%|█████▊    | 1026/1772 [12:04<07:34,  1.64it/s, running training loss:  0.93004]\u001b[A\n",
            "Training:  58%|█████▊    | 1026/1772 [12:05<07:34,  1.64it/s, running training loss:  1.03236]\u001b[A\n",
            "Training:  58%|█████▊    | 1027/1772 [12:05<07:28,  1.66it/s, running training loss:  1.03236]\u001b[A\n",
            "Training:  58%|█████▊    | 1027/1772 [12:06<07:28,  1.66it/s, running training loss:  0.95114]\u001b[A\n",
            "Training:  58%|█████▊    | 1028/1772 [12:06<07:38,  1.62it/s, running training loss:  0.95114]\u001b[A\n",
            "Training:  58%|█████▊    | 1028/1772 [12:06<07:38,  1.62it/s, running training loss:  0.96204]\u001b[A\n",
            "Training:  58%|█████▊    | 1029/1772 [12:06<07:51,  1.58it/s, running training loss:  0.96204]\u001b[A\n",
            "Training:  58%|█████▊    | 1029/1772 [12:07<07:51,  1.58it/s, running training loss:  0.87091]\u001b[A\n",
            "Training:  58%|█████▊    | 1030/1772 [12:07<08:34,  1.44it/s, running training loss:  0.87091]\u001b[A\n",
            "Training:  58%|█████▊    | 1030/1772 [12:08<08:34,  1.44it/s, running training loss:  0.96054]\u001b[A\n",
            "Training:  58%|█████▊    | 1031/1772 [12:08<08:23,  1.47it/s, running training loss:  0.96054]\u001b[A\n",
            "Training:  58%|█████▊    | 1031/1772 [12:08<08:23,  1.47it/s, running training loss:  0.88262]\u001b[A\n",
            "Training:  58%|█████▊    | 1032/1772 [12:08<07:49,  1.58it/s, running training loss:  0.88262]\u001b[A\n",
            "Training:  58%|█████▊    | 1032/1772 [12:09<07:49,  1.58it/s, running training loss:  1.01341]\u001b[A\n",
            "Training:  58%|█████▊    | 1033/1772 [12:09<08:11,  1.50it/s, running training loss:  1.01341]\u001b[A\n",
            "Training:  58%|█████▊    | 1033/1772 [12:10<08:11,  1.50it/s, running training loss:  0.73812]\u001b[A\n",
            "Training:  58%|█████▊    | 1034/1772 [12:10<08:12,  1.50it/s, running training loss:  0.73812]\u001b[A\n",
            "Training:  58%|█████▊    | 1034/1772 [12:10<08:12,  1.50it/s, running training loss:  0.99456]\u001b[A\n",
            "Training:  58%|█████▊    | 1035/1772 [12:10<07:45,  1.58it/s, running training loss:  0.99456]\u001b[A\n",
            "Training:  58%|█████▊    | 1035/1772 [12:11<07:45,  1.58it/s, running training loss:  0.84181]\u001b[A\n",
            "Training:  58%|█████▊    | 1036/1772 [12:11<07:52,  1.56it/s, running training loss:  0.84181]\u001b[A\n",
            "Training:  58%|█████▊    | 1036/1772 [12:12<07:52,  1.56it/s, running training loss:  0.77363]\u001b[A\n",
            "Training:  59%|█████▊    | 1037/1772 [12:12<08:39,  1.42it/s, running training loss:  0.77363]\u001b[A\n",
            "Training:  59%|█████▊    | 1037/1772 [12:12<08:39,  1.42it/s, running training loss:  0.88909]\u001b[A\n",
            "Training:  59%|█████▊    | 1038/1772 [12:12<08:01,  1.52it/s, running training loss:  0.88909]\u001b[A\n",
            "Training:  59%|█████▊    | 1038/1772 [12:13<08:01,  1.52it/s, running training loss:  0.77377]\u001b[A\n",
            "Training:  59%|█████▊    | 1039/1772 [12:13<07:22,  1.66it/s, running training loss:  0.77377]\u001b[A\n",
            "Training:  59%|█████▊    | 1039/1772 [12:13<07:22,  1.66it/s, running training loss:  0.79693]\u001b[A\n",
            "Training:  59%|█████▊    | 1040/1772 [12:13<07:11,  1.70it/s, running training loss:  0.79693]\u001b[A\n",
            "Training:  59%|█████▊    | 1040/1772 [12:14<07:11,  1.70it/s, running training loss:  0.75033]\u001b[A\n",
            "Training:  59%|█████▊    | 1041/1772 [12:14<07:12,  1.69it/s, running training loss:  0.75033]\u001b[A\n",
            "Training:  59%|█████▊    | 1041/1772 [12:15<07:12,  1.69it/s, running training loss:  0.78563]\u001b[A\n",
            "Training:  59%|█████▉    | 1042/1772 [12:15<07:30,  1.62it/s, running training loss:  0.78563]\u001b[A\n",
            "Training:  59%|█████▉    | 1042/1772 [12:16<07:30,  1.62it/s, running training loss:  1.02559]\u001b[A\n",
            "Training:  59%|█████▉    | 1043/1772 [12:16<08:42,  1.39it/s, running training loss:  1.02559]\u001b[A\n",
            "Training:  59%|█████▉    | 1043/1772 [12:16<08:42,  1.39it/s, running training loss:  0.76234]\u001b[A\n",
            "Training:  59%|█████▉    | 1044/1772 [12:16<08:02,  1.51it/s, running training loss:  0.76234]\u001b[A\n",
            "Training:  59%|█████▉    | 1044/1772 [12:17<08:02,  1.51it/s, running training loss:  1.13139]\u001b[A\n",
            "Training:  59%|█████▉    | 1045/1772 [12:17<07:38,  1.58it/s, running training loss:  1.13139]\u001b[A\n",
            "Training:  59%|█████▉    | 1045/1772 [12:17<07:38,  1.58it/s, running training loss:  1.03274]\u001b[A\n",
            "Training:  59%|█████▉    | 1046/1772 [12:17<07:42,  1.57it/s, running training loss:  1.03274]\u001b[A\n",
            "Training:  59%|█████▉    | 1046/1772 [12:18<07:42,  1.57it/s, running training loss:  1.18723]\u001b[A\n",
            "Training:  59%|█████▉    | 1047/1772 [12:18<07:08,  1.69it/s, running training loss:  1.18723]\u001b[A\n",
            "Training:  59%|█████▉    | 1047/1772 [12:18<07:08,  1.69it/s, running training loss:  1.37604]\u001b[A\n",
            "Training:  59%|█████▉    | 1048/1772 [12:18<07:10,  1.68it/s, running training loss:  1.37604]\u001b[A\n",
            "Training:  59%|█████▉    | 1048/1772 [12:19<07:10,  1.68it/s, running training loss:  0.95521]\u001b[A\n",
            "Training:  59%|█████▉    | 1049/1772 [12:19<07:20,  1.64it/s, running training loss:  0.95521]\u001b[A\n",
            "Training:  59%|█████▉    | 1049/1772 [12:20<07:20,  1.64it/s, running training loss:  0.87896]\u001b[A\n",
            "Training:  59%|█████▉    | 1050/1772 [12:20<07:22,  1.63it/s, running training loss:  0.87896]\u001b[A\n",
            "Training:  59%|█████▉    | 1050/1772 [12:20<07:22,  1.63it/s, running training loss:  1.07162]\u001b[A\n",
            "Training:  59%|█████▉    | 1051/1772 [12:20<06:55,  1.73it/s, running training loss:  1.07162]\u001b[A\n",
            "Training:  59%|█████▉    | 1051/1772 [12:21<06:55,  1.73it/s, running training loss:  1.11809]\u001b[A\n",
            "Training:  59%|█████▉    | 1052/1772 [12:21<06:50,  1.75it/s, running training loss:  1.11809]\u001b[A\n",
            "Training:  59%|█████▉    | 1052/1772 [12:21<06:50,  1.75it/s, running training loss:  0.90263]\u001b[A\n",
            "Training:  59%|█████▉    | 1053/1772 [12:21<06:48,  1.76it/s, running training loss:  0.90263]\u001b[A\n",
            "Training:  59%|█████▉    | 1053/1772 [12:22<06:48,  1.76it/s, running training loss:  0.76363]\u001b[A\n",
            "Training:  59%|█████▉    | 1054/1772 [12:22<07:01,  1.70it/s, running training loss:  0.76363]\u001b[A\n",
            "Training:  59%|█████▉    | 1054/1772 [12:23<07:01,  1.70it/s, running training loss:  1.10051]\u001b[A\n",
            "Training:  60%|█████▉    | 1055/1772 [12:23<07:13,  1.65it/s, running training loss:  1.10051]\u001b[A\n",
            "Training:  60%|█████▉    | 1055/1772 [12:23<07:13,  1.65it/s, running training loss:  0.76315]\u001b[A\n",
            "Training:  60%|█████▉    | 1056/1772 [12:23<06:54,  1.73it/s, running training loss:  0.76315]\u001b[A\n",
            "Training:  60%|█████▉    | 1056/1772 [12:24<06:54,  1.73it/s, running training loss:  1.28789]\u001b[A\n",
            "Training:  60%|█████▉    | 1057/1772 [12:24<07:24,  1.61it/s, running training loss:  1.28789]\u001b[A\n",
            "Training:  60%|█████▉    | 1057/1772 [12:24<07:24,  1.61it/s, running training loss:  0.88629]\u001b[A\n",
            "Training:  60%|█████▉    | 1058/1772 [12:24<07:10,  1.66it/s, running training loss:  0.88629]\u001b[A\n",
            "Training:  60%|█████▉    | 1058/1772 [12:25<07:10,  1.66it/s, running training loss:  0.85018]\u001b[A\n",
            "Training:  60%|█████▉    | 1059/1772 [12:25<07:14,  1.64it/s, running training loss:  0.85018]\u001b[A\n",
            "Training:  60%|█████▉    | 1059/1772 [12:26<07:14,  1.64it/s, running training loss:  1.23701]\u001b[A\n",
            "Training:  60%|█████▉    | 1060/1772 [12:26<07:33,  1.57it/s, running training loss:  1.23701]\u001b[A\n",
            "Training:  60%|█████▉    | 1060/1772 [12:26<07:33,  1.57it/s, running training loss:  1.04986]\u001b[A\n",
            "Training:  60%|█████▉    | 1061/1772 [12:26<08:02,  1.47it/s, running training loss:  1.04986]\u001b[A\n",
            "Training:  60%|█████▉    | 1061/1772 [12:28<08:02,  1.47it/s, running training loss:  1.06621]\u001b[A\n",
            "Training:  60%|█████▉    | 1062/1772 [12:28<09:18,  1.27it/s, running training loss:  1.06621]\u001b[A\n",
            "Training:  60%|█████▉    | 1062/1772 [12:28<09:18,  1.27it/s, running training loss:  1.34524]\u001b[A\n",
            "Training:  60%|█████▉    | 1063/1772 [12:28<08:42,  1.36it/s, running training loss:  1.34524]\u001b[A\n",
            "Training:  60%|█████▉    | 1063/1772 [12:29<08:42,  1.36it/s, running training loss:  0.97039]\u001b[A\n",
            "Training:  60%|██████    | 1064/1772 [12:29<08:36,  1.37it/s, running training loss:  0.97039]\u001b[A\n",
            "Training:  60%|██████    | 1064/1772 [12:29<08:36,  1.37it/s, running training loss:  0.94376]\u001b[A\n",
            "Training:  60%|██████    | 1065/1772 [12:29<07:56,  1.48it/s, running training loss:  0.94376]\u001b[A\n",
            "Training:  60%|██████    | 1065/1772 [12:30<07:56,  1.48it/s, running training loss:  1.50766]\u001b[A\n",
            "Training:  60%|██████    | 1066/1772 [12:30<08:00,  1.47it/s, running training loss:  1.50766]\u001b[A\n",
            "Training:  60%|██████    | 1066/1772 [12:31<08:00,  1.47it/s, running training loss:  1.41106]\u001b[A\n",
            "Training:  60%|██████    | 1067/1772 [12:31<09:11,  1.28it/s, running training loss:  1.41106]\u001b[A\n",
            "Training:  60%|██████    | 1067/1772 [12:32<09:11,  1.28it/s, running training loss:  1.37968]\u001b[A\n",
            "Training:  60%|██████    | 1068/1772 [12:32<09:18,  1.26it/s, running training loss:  1.37968]\u001b[A\n",
            "Training:  60%|██████    | 1068/1772 [12:32<09:18,  1.26it/s, running training loss:  1.12284]\u001b[A\n",
            "Training:  60%|██████    | 1069/1772 [12:32<08:28,  1.38it/s, running training loss:  1.12284]\u001b[A\n",
            "Training:  60%|██████    | 1069/1772 [12:33<08:28,  1.38it/s, running training loss:  1.92609]\u001b[A\n",
            "Training:  60%|██████    | 1070/1772 [12:33<08:41,  1.35it/s, running training loss:  1.92609]\u001b[A\n",
            "Training:  60%|██████    | 1070/1772 [12:34<08:41,  1.35it/s, running training loss:  0.89165]\u001b[A\n",
            "Training:  60%|██████    | 1071/1772 [12:34<08:30,  1.37it/s, running training loss:  0.89165]\u001b[A\n",
            "Training:  60%|██████    | 1071/1772 [12:35<08:30,  1.37it/s, running training loss:  0.92610]\u001b[A\n",
            "Training:  60%|██████    | 1072/1772 [12:35<08:19,  1.40it/s, running training loss:  0.92610]\u001b[A\n",
            "Training:  60%|██████    | 1072/1772 [12:35<08:19,  1.40it/s, running training loss:  1.17139]\u001b[A\n",
            "Training:  61%|██████    | 1073/1772 [12:35<07:51,  1.48it/s, running training loss:  1.17139]\u001b[A\n",
            "Training:  61%|██████    | 1073/1772 [12:36<07:51,  1.48it/s, running training loss:  1.44974]\u001b[A\n",
            "Training:  61%|██████    | 1074/1772 [12:36<09:04,  1.28it/s, running training loss:  1.44974]\u001b[A\n",
            "Training:  61%|██████    | 1074/1772 [12:37<09:04,  1.28it/s, running training loss:  0.97397]\u001b[A\n",
            "Training:  61%|██████    | 1075/1772 [12:37<08:20,  1.39it/s, running training loss:  0.97397]\u001b[A\n",
            "Training:  61%|██████    | 1075/1772 [12:37<08:20,  1.39it/s, running training loss:  1.17698]\u001b[A\n",
            "Training:  61%|██████    | 1076/1772 [12:37<07:44,  1.50it/s, running training loss:  1.17698]\u001b[A\n",
            "Training:  61%|██████    | 1076/1772 [12:38<07:44,  1.50it/s, running training loss:  1.24548]\u001b[A\n",
            "Training:  61%|██████    | 1077/1772 [12:38<07:23,  1.57it/s, running training loss:  1.24548]\u001b[A\n",
            "Training:  61%|██████    | 1077/1772 [12:39<07:23,  1.57it/s, running training loss:  1.19669]\u001b[A\n",
            "Training:  61%|██████    | 1078/1772 [12:39<07:11,  1.61it/s, running training loss:  1.19669]\u001b[A\n",
            "Training:  61%|██████    | 1078/1772 [12:39<07:11,  1.61it/s, running training loss:  1.26344]\u001b[A\n",
            "Training:  61%|██████    | 1079/1772 [12:39<07:42,  1.50it/s, running training loss:  1.26344]\u001b[A\n",
            "Training:  61%|██████    | 1079/1772 [12:40<07:42,  1.50it/s, running training loss:  1.32615]\u001b[A\n",
            "Training:  61%|██████    | 1080/1772 [12:40<08:06,  1.42it/s, running training loss:  1.32615]\u001b[A\n",
            "Training:  61%|██████    | 1080/1772 [12:41<08:06,  1.42it/s, running training loss:  1.07801]\u001b[A\n",
            "Training:  61%|██████    | 1081/1772 [12:41<07:40,  1.50it/s, running training loss:  1.07801]\u001b[A\n",
            "Training:  61%|██████    | 1081/1772 [12:41<07:40,  1.50it/s, running training loss:  1.20185]\u001b[A\n",
            "Training:  61%|██████    | 1082/1772 [12:41<08:07,  1.42it/s, running training loss:  1.20185]\u001b[A\n",
            "Training:  61%|██████    | 1082/1772 [12:42<08:07,  1.42it/s, running training loss:  1.21806]\u001b[A\n",
            "Training:  61%|██████    | 1083/1772 [12:42<08:23,  1.37it/s, running training loss:  1.21806]\u001b[A\n",
            "Training:  61%|██████    | 1083/1772 [12:43<08:23,  1.37it/s, running training loss:  1.00830]\u001b[A\n",
            "Training:  61%|██████    | 1084/1772 [12:43<08:05,  1.42it/s, running training loss:  1.00830]\u001b[A\n",
            "Training:  61%|██████    | 1084/1772 [12:43<08:05,  1.42it/s, running training loss:  1.10647]\u001b[A\n",
            "Training:  61%|██████    | 1085/1772 [12:43<07:24,  1.54it/s, running training loss:  1.10647]\u001b[A\n",
            "Training:  61%|██████    | 1085/1772 [12:44<07:24,  1.54it/s, running training loss:  0.76272]\u001b[A\n",
            "Training:  61%|██████▏   | 1086/1772 [12:44<07:07,  1.60it/s, running training loss:  0.76272]\u001b[A\n",
            "Training:  61%|██████▏   | 1086/1772 [12:44<07:07,  1.60it/s, running training loss:  0.85611]\u001b[A\n",
            "Training:  61%|██████▏   | 1087/1772 [12:45<06:41,  1.70it/s, running training loss:  0.85611]\u001b[A\n",
            "Training:  61%|██████▏   | 1087/1772 [12:45<06:41,  1.70it/s, running training loss:  0.95988]\u001b[A\n",
            "Training:  61%|██████▏   | 1088/1772 [12:45<06:35,  1.73it/s, running training loss:  0.95988]\u001b[A\n",
            "Training:  61%|██████▏   | 1088/1772 [12:46<06:35,  1.73it/s, running training loss:  1.00712]\u001b[A\n",
            "Training:  61%|██████▏   | 1089/1772 [12:46<06:35,  1.73it/s, running training loss:  1.00712]\u001b[A\n",
            "Training:  61%|██████▏   | 1089/1772 [12:46<06:35,  1.73it/s, running training loss:  0.94048]\u001b[A\n",
            "Training:  62%|██████▏   | 1090/1772 [12:46<06:39,  1.71it/s, running training loss:  0.94048]\u001b[A\n",
            "Training:  62%|██████▏   | 1090/1772 [12:47<06:39,  1.71it/s, running training loss:  1.05654]\u001b[A\n",
            "Training:  62%|██████▏   | 1091/1772 [12:47<07:35,  1.50it/s, running training loss:  1.05654]\u001b[A\n",
            "Training:  62%|██████▏   | 1091/1772 [12:48<07:35,  1.50it/s, running training loss:  0.91680]\u001b[A\n",
            "Training:  62%|██████▏   | 1092/1772 [12:48<07:16,  1.56it/s, running training loss:  0.91680]\u001b[A\n",
            "Training:  62%|██████▏   | 1092/1772 [12:48<07:16,  1.56it/s, running training loss:  0.93577]\u001b[A\n",
            "Training:  62%|██████▏   | 1093/1772 [12:48<07:08,  1.58it/s, running training loss:  0.93577]\u001b[A\n",
            "Training:  62%|██████▏   | 1093/1772 [12:49<07:08,  1.58it/s, running training loss:  1.02908]\u001b[A\n",
            "Training:  62%|██████▏   | 1094/1772 [12:49<07:04,  1.60it/s, running training loss:  1.02908]\u001b[A\n",
            "Training:  62%|██████▏   | 1094/1772 [12:50<07:04,  1.60it/s, running training loss:  1.01098]\u001b[A\n",
            "Training:  62%|██████▏   | 1095/1772 [12:50<08:04,  1.40it/s, running training loss:  1.01098]\u001b[A\n",
            "Training:  62%|██████▏   | 1095/1772 [12:50<08:04,  1.40it/s, running training loss:  1.12733]\u001b[A\n",
            "Training:  62%|██████▏   | 1096/1772 [12:50<07:48,  1.44it/s, running training loss:  1.12733]\u001b[A\n",
            "Training:  62%|██████▏   | 1096/1772 [12:51<07:48,  1.44it/s, running training loss:  0.91955]\u001b[A\n",
            "Training:  62%|██████▏   | 1097/1772 [12:51<07:15,  1.55it/s, running training loss:  0.91955]\u001b[A\n",
            "Training:  62%|██████▏   | 1097/1772 [12:52<07:15,  1.55it/s, running training loss:  1.16244]\u001b[A\n",
            "Training:  62%|██████▏   | 1098/1772 [12:52<06:51,  1.64it/s, running training loss:  1.16244]\u001b[A\n",
            "Training:  62%|██████▏   | 1098/1772 [12:52<06:51,  1.64it/s, running training loss:  1.04751]\u001b[A\n",
            "Training:  62%|██████▏   | 1099/1772 [12:52<07:29,  1.50it/s, running training loss:  1.04751]\u001b[A\n",
            "Training:  62%|██████▏   | 1099/1772 [12:53<07:29,  1.50it/s, running training loss:  0.97221]\u001b[A\n",
            "Training:  62%|██████▏   | 1100/1772 [12:53<06:59,  1.60it/s, running training loss:  0.97221]\u001b[A\n",
            "Training:  62%|██████▏   | 1100/1772 [12:53<06:59,  1.60it/s, running training loss:  0.97977]\u001b[A\n",
            "Training:  62%|██████▏   | 1101/1772 [12:53<07:01,  1.59it/s, running training loss:  0.97977]\u001b[A\n",
            "Training:  62%|██████▏   | 1101/1772 [12:54<07:01,  1.59it/s, running training loss:  1.13401]\u001b[A\n",
            "Training:  62%|██████▏   | 1102/1772 [12:54<06:51,  1.63it/s, running training loss:  1.13401]\u001b[A\n",
            "Training:  62%|██████▏   | 1102/1772 [12:55<06:51,  1.63it/s, running training loss:  0.86290]\u001b[A\n",
            "Training:  62%|██████▏   | 1103/1772 [12:55<07:02,  1.58it/s, running training loss:  0.86290]\u001b[A\n",
            "Training:  62%|██████▏   | 1103/1772 [12:55<07:02,  1.58it/s, running training loss:  0.88682]\u001b[A\n",
            "Training:  62%|██████▏   | 1104/1772 [12:55<06:38,  1.67it/s, running training loss:  0.88682]\u001b[A\n",
            "Training:  62%|██████▏   | 1104/1772 [12:56<06:38,  1.67it/s, running training loss:  1.00376]\u001b[A\n",
            "Training:  62%|██████▏   | 1105/1772 [12:56<06:47,  1.64it/s, running training loss:  1.00376]\u001b[A\n",
            "Training:  62%|██████▏   | 1105/1772 [12:56<06:47,  1.64it/s, running training loss:  0.87681]\u001b[A\n",
            "Training:  62%|██████▏   | 1106/1772 [12:56<06:22,  1.74it/s, running training loss:  0.87681]\u001b[A\n",
            "Training:  62%|██████▏   | 1106/1772 [12:57<06:22,  1.74it/s, running training loss:  0.87130]\u001b[A\n",
            "Training:  62%|██████▏   | 1107/1772 [12:57<07:21,  1.51it/s, running training loss:  0.87130]\u001b[A\n",
            "Training:  62%|██████▏   | 1107/1772 [12:58<07:21,  1.51it/s, running training loss:  0.98953]\u001b[A\n",
            "Training:  63%|██████▎   | 1108/1772 [12:58<07:24,  1.49it/s, running training loss:  0.98953]\u001b[A\n",
            "Training:  63%|██████▎   | 1108/1772 [12:58<07:24,  1.49it/s, running training loss:  0.94996]\u001b[A\n",
            "Training:  63%|██████▎   | 1109/1772 [12:58<06:59,  1.58it/s, running training loss:  0.94996]\u001b[A\n",
            "Training:  63%|██████▎   | 1109/1772 [12:59<06:59,  1.58it/s, running training loss:  1.03679]\u001b[A\n",
            "Training:  63%|██████▎   | 1110/1772 [12:59<06:43,  1.64it/s, running training loss:  1.03679]\u001b[A\n",
            "Training:  63%|██████▎   | 1110/1772 [13:00<06:43,  1.64it/s, running training loss:  1.12724]\u001b[A\n",
            "Training:  63%|██████▎   | 1111/1772 [13:00<06:38,  1.66it/s, running training loss:  1.12724]\u001b[A\n",
            "Training:  63%|██████▎   | 1111/1772 [13:00<06:38,  1.66it/s, running training loss:  1.04758]\u001b[A\n",
            "Training:  63%|██████▎   | 1112/1772 [13:00<06:31,  1.68it/s, running training loss:  1.04758]\u001b[A\n",
            "Training:  63%|██████▎   | 1112/1772 [13:01<06:31,  1.68it/s, running training loss:  1.52315]\u001b[A\n",
            "Training:  63%|██████▎   | 1113/1772 [13:01<07:20,  1.50it/s, running training loss:  1.52315]\u001b[A\n",
            "Training:  63%|██████▎   | 1113/1772 [13:02<07:20,  1.50it/s, running training loss:  1.44740]\u001b[A\n",
            "Training:  63%|██████▎   | 1114/1772 [13:02<07:17,  1.50it/s, running training loss:  1.44740]\u001b[A\n",
            "Training:  63%|██████▎   | 1114/1772 [13:03<07:17,  1.50it/s, running training loss:  1.24108]\u001b[A\n",
            "Training:  63%|██████▎   | 1115/1772 [13:03<08:06,  1.35it/s, running training loss:  1.24108]\u001b[A\n",
            "Training:  63%|██████▎   | 1115/1772 [13:03<08:06,  1.35it/s, running training loss:  1.23708]\u001b[A\n",
            "Training:  63%|██████▎   | 1116/1772 [13:03<07:16,  1.50it/s, running training loss:  1.23708]\u001b[A\n",
            "Training:  63%|██████▎   | 1116/1772 [13:04<07:16,  1.50it/s, running training loss:  1.16247]\u001b[A\n",
            "Training:  63%|██████▎   | 1117/1772 [13:04<06:45,  1.62it/s, running training loss:  1.16247]\u001b[A\n",
            "Training:  63%|██████▎   | 1117/1772 [13:04<06:45,  1.62it/s, running training loss:  0.89930]\u001b[A\n",
            "Training:  63%|██████▎   | 1118/1772 [13:04<06:14,  1.75it/s, running training loss:  0.89930]\u001b[A\n",
            "Training:  63%|██████▎   | 1118/1772 [13:05<06:14,  1.75it/s, running training loss:  1.16957]\u001b[A\n",
            "Training:  63%|██████▎   | 1119/1772 [13:05<06:48,  1.60it/s, running training loss:  1.16957]\u001b[A\n",
            "Training:  63%|██████▎   | 1119/1772 [13:05<06:48,  1.60it/s, running training loss:  1.09967]\u001b[A\n",
            "Training:  63%|██████▎   | 1120/1772 [13:05<06:47,  1.60it/s, running training loss:  1.09967]\u001b[A\n",
            "Training:  63%|██████▎   | 1120/1772 [13:06<06:47,  1.60it/s, running training loss:  0.90070]\u001b[A\n",
            "Training:  63%|██████▎   | 1121/1772 [13:06<07:08,  1.52it/s, running training loss:  0.90070]\u001b[A\n",
            "Training:  63%|██████▎   | 1121/1772 [13:07<07:08,  1.52it/s, running training loss:  1.19503]\u001b[A\n",
            "Training:  63%|██████▎   | 1122/1772 [13:07<07:04,  1.53it/s, running training loss:  1.19503]\u001b[A\n",
            "Training:  63%|██████▎   | 1122/1772 [13:07<07:04,  1.53it/s, running training loss:  0.93369]\u001b[A\n",
            "Training:  63%|██████▎   | 1123/1772 [13:07<06:55,  1.56it/s, running training loss:  0.93369]\u001b[A\n",
            "Training:  63%|██████▎   | 1123/1772 [13:08<06:55,  1.56it/s, running training loss:  0.91273]\u001b[A\n",
            "Training:  63%|██████▎   | 1124/1772 [13:08<06:30,  1.66it/s, running training loss:  0.91273]\u001b[A\n",
            "Training:  63%|██████▎   | 1124/1772 [13:09<06:30,  1.66it/s, running training loss:  0.98481]\u001b[A\n",
            "Training:  63%|██████▎   | 1125/1772 [13:09<06:30,  1.65it/s, running training loss:  0.98481]\u001b[A\n",
            "Training:  63%|██████▎   | 1125/1772 [13:09<06:30,  1.65it/s, running training loss:  1.09901]\u001b[A\n",
            "Training:  64%|██████▎   | 1126/1772 [13:09<07:32,  1.43it/s, running training loss:  1.09901]\u001b[A\n",
            "Training:  64%|██████▎   | 1126/1772 [13:10<07:32,  1.43it/s, running training loss:  0.93563]\u001b[A\n",
            "Training:  64%|██████▎   | 1127/1772 [13:10<06:50,  1.57it/s, running training loss:  0.93563]\u001b[A\n",
            "Training:  64%|██████▎   | 1127/1772 [13:11<06:50,  1.57it/s, running training loss:  1.29200]\u001b[A\n",
            "Training:  64%|██████▎   | 1128/1772 [13:11<06:49,  1.57it/s, running training loss:  1.29200]\u001b[A\n",
            "Training:  64%|██████▎   | 1128/1772 [13:11<06:49,  1.57it/s, running training loss:  0.93677]\u001b[A\n",
            "Training:  64%|██████▎   | 1129/1772 [13:11<06:44,  1.59it/s, running training loss:  0.93677]\u001b[A\n",
            "Training:  64%|██████▎   | 1129/1772 [13:12<06:44,  1.59it/s, running training loss:  0.80567]\u001b[A\n",
            "Training:  64%|██████▍   | 1130/1772 [13:12<06:20,  1.69it/s, running training loss:  0.80567]\u001b[A\n",
            "Training:  64%|██████▍   | 1130/1772 [13:12<06:20,  1.69it/s, running training loss:  1.05516]\u001b[A\n",
            "Training:  64%|██████▍   | 1131/1772 [13:12<06:02,  1.77it/s, running training loss:  1.05516]\u001b[A\n",
            "Training:  64%|██████▍   | 1131/1772 [13:13<06:02,  1.77it/s, running training loss:  0.90907]\u001b[A\n",
            "Training:  64%|██████▍   | 1132/1772 [13:13<06:24,  1.66it/s, running training loss:  0.90907]\u001b[A\n",
            "Training:  64%|██████▍   | 1132/1772 [13:14<06:24,  1.66it/s, running training loss:  1.13521]\u001b[A\n",
            "Training:  64%|██████▍   | 1133/1772 [13:14<06:39,  1.60it/s, running training loss:  1.13521]\u001b[A\n",
            "Training:  64%|██████▍   | 1133/1772 [13:14<06:39,  1.60it/s, running training loss:  1.07900]\u001b[A\n",
            "Training:  64%|██████▍   | 1134/1772 [13:14<06:41,  1.59it/s, running training loss:  1.07900]\u001b[A\n",
            "Training:  64%|██████▍   | 1134/1772 [13:15<06:41,  1.59it/s, running training loss:  0.76586]\u001b[A\n",
            "Training:  64%|██████▍   | 1135/1772 [13:15<06:10,  1.72it/s, running training loss:  0.76586]\u001b[A\n",
            "Training:  64%|██████▍   | 1135/1772 [13:15<06:10,  1.72it/s, running training loss:  0.72116]\u001b[A\n",
            "Training:  64%|██████▍   | 1136/1772 [13:15<06:24,  1.66it/s, running training loss:  0.72116]\u001b[A\n",
            "Training:  64%|██████▍   | 1136/1772 [13:16<06:24,  1.66it/s, running training loss:  1.13646]\u001b[A\n",
            "Training:  64%|██████▍   | 1137/1772 [13:16<06:14,  1.70it/s, running training loss:  1.13646]\u001b[A\n",
            "Training:  64%|██████▍   | 1137/1772 [13:16<06:14,  1.70it/s, running training loss:  0.96313]\u001b[A\n",
            "Training:  64%|██████▍   | 1138/1772 [13:17<06:12,  1.70it/s, running training loss:  0.96313]\u001b[A\n",
            "Training:  64%|██████▍   | 1138/1772 [13:17<06:12,  1.70it/s, running training loss:  1.21976]\u001b[A\n",
            "Training:  64%|██████▍   | 1139/1772 [13:17<06:05,  1.73it/s, running training loss:  1.21976]\u001b[A\n",
            "Training:  64%|██████▍   | 1139/1772 [13:18<06:05,  1.73it/s, running training loss:  0.97270]\u001b[A\n",
            "Training:  64%|██████▍   | 1140/1772 [13:18<05:42,  1.85it/s, running training loss:  0.97270]\u001b[A\n",
            "Training:  64%|██████▍   | 1140/1772 [13:18<05:42,  1.85it/s, running training loss:  1.08264]\u001b[A\n",
            "Training:  64%|██████▍   | 1141/1772 [13:18<05:50,  1.80it/s, running training loss:  1.08264]\u001b[A\n",
            "Training:  64%|██████▍   | 1141/1772 [13:19<05:50,  1.80it/s, running training loss:  1.14888]\u001b[A\n",
            "Training:  64%|██████▍   | 1142/1772 [13:19<05:33,  1.89it/s, running training loss:  1.14888]\u001b[A\n",
            "Training:  64%|██████▍   | 1142/1772 [13:19<05:33,  1.89it/s, running training loss:  0.94529]\u001b[A\n",
            "Training:  65%|██████▍   | 1143/1772 [13:19<05:54,  1.77it/s, running training loss:  0.94529]\u001b[A\n",
            "Training:  65%|██████▍   | 1143/1772 [13:20<05:54,  1.77it/s, running training loss:  1.16586]\u001b[A\n",
            "Training:  65%|██████▍   | 1144/1772 [13:20<06:09,  1.70it/s, running training loss:  1.16586]\u001b[A\n",
            "Training:  65%|██████▍   | 1144/1772 [13:20<06:09,  1.70it/s, running training loss:  1.03725]\u001b[A\n",
            "Training:  65%|██████▍   | 1145/1772 [13:21<06:19,  1.65it/s, running training loss:  1.03725]\u001b[A\n",
            "Training:  65%|██████▍   | 1145/1772 [13:21<06:19,  1.65it/s, running training loss:  0.91132]\u001b[A\n",
            "Training:  65%|██████▍   | 1146/1772 [13:21<06:06,  1.71it/s, running training loss:  0.91132]\u001b[A\n",
            "Training:  65%|██████▍   | 1146/1772 [13:22<06:06,  1.71it/s, running training loss:  1.19259]\u001b[A\n",
            "Training:  65%|██████▍   | 1147/1772 [13:22<05:52,  1.77it/s, running training loss:  1.19259]\u001b[A\n",
            "Training:  65%|██████▍   | 1147/1772 [13:22<05:52,  1.77it/s, running training loss:  0.99106]\u001b[A\n",
            "Training:  65%|██████▍   | 1148/1772 [13:22<05:48,  1.79it/s, running training loss:  0.99106]\u001b[A\n",
            "Training:  65%|██████▍   | 1148/1772 [13:23<05:48,  1.79it/s, running training loss:  1.19723]\u001b[A\n",
            "Training:  65%|██████▍   | 1149/1772 [13:23<05:46,  1.80it/s, running training loss:  1.19723]\u001b[A\n",
            "Training:  65%|██████▍   | 1149/1772 [13:23<05:46,  1.80it/s, running training loss:  0.72083]\u001b[A\n",
            "Training:  65%|██████▍   | 1150/1772 [13:23<05:26,  1.91it/s, running training loss:  0.72083]\u001b[A\n",
            "Training:  65%|██████▍   | 1150/1772 [13:24<05:26,  1.91it/s, running training loss:  1.00306]\u001b[A\n",
            "Training:  65%|██████▍   | 1151/1772 [13:24<05:43,  1.81it/s, running training loss:  1.00306]\u001b[A\n",
            "Training:  65%|██████▍   | 1151/1772 [13:24<05:43,  1.81it/s, running training loss:  0.94947]\u001b[A\n",
            "Training:  65%|██████▌   | 1152/1772 [13:24<05:55,  1.74it/s, running training loss:  0.94947]\u001b[A\n",
            "Training:  65%|██████▌   | 1152/1772 [13:25<05:55,  1.74it/s, running training loss:  0.86496]\u001b[A\n",
            "Training:  65%|██████▌   | 1153/1772 [13:25<05:55,  1.74it/s, running training loss:  0.86496]\u001b[A\n",
            "Training:  65%|██████▌   | 1153/1772 [13:25<05:55,  1.74it/s, running training loss:  0.80009]\u001b[A\n",
            "Training:  65%|██████▌   | 1154/1772 [13:25<05:44,  1.79it/s, running training loss:  0.80009]\u001b[A\n",
            "Training:  65%|██████▌   | 1154/1772 [13:26<05:44,  1.79it/s, running training loss:  0.94711]\u001b[A\n",
            "Training:  65%|██████▌   | 1155/1772 [13:26<06:56,  1.48it/s, running training loss:  0.94711]\u001b[A\n",
            "Training:  65%|██████▌   | 1155/1772 [13:27<06:56,  1.48it/s, running training loss:  0.95478]\u001b[A\n",
            "Training:  65%|██████▌   | 1156/1772 [13:27<06:59,  1.47it/s, running training loss:  0.95478]\u001b[A\n",
            "Training:  65%|██████▌   | 1156/1772 [13:28<06:59,  1.47it/s, running training loss:  0.97061]\u001b[A\n",
            "Training:  65%|██████▌   | 1157/1772 [13:28<07:10,  1.43it/s, running training loss:  0.97061]\u001b[A\n",
            "Training:  65%|██████▌   | 1157/1772 [13:28<07:10,  1.43it/s, running training loss:  0.90947]\u001b[A\n",
            "Training:  65%|██████▌   | 1158/1772 [13:29<07:04,  1.45it/s, running training loss:  0.90947]\u001b[A\n",
            "Training:  65%|██████▌   | 1158/1772 [13:29<07:04,  1.45it/s, running training loss:  0.97466]\u001b[A\n",
            "Training:  65%|██████▌   | 1159/1772 [13:29<06:56,  1.47it/s, running training loss:  0.97466]\u001b[A\n",
            "Training:  65%|██████▌   | 1159/1772 [13:30<06:56,  1.47it/s, running training loss:  0.80206]\u001b[A\n",
            "Training:  65%|██████▌   | 1160/1772 [13:30<06:35,  1.55it/s, running training loss:  0.80206]\u001b[A\n",
            "Training:  65%|██████▌   | 1160/1772 [13:30<06:35,  1.55it/s, running training loss:  1.01029]\u001b[A\n",
            "Training:  66%|██████▌   | 1161/1772 [13:30<06:22,  1.60it/s, running training loss:  1.01029]\u001b[A\n",
            "Training:  66%|██████▌   | 1161/1772 [13:31<06:22,  1.60it/s, running training loss:  0.99831]\u001b[A\n",
            "Training:  66%|██████▌   | 1162/1772 [13:31<06:25,  1.58it/s, running training loss:  0.99831]\u001b[A\n",
            "Training:  66%|██████▌   | 1162/1772 [13:32<06:25,  1.58it/s, running training loss:  1.15797]\u001b[A\n",
            "Training:  66%|██████▌   | 1163/1772 [13:32<06:56,  1.46it/s, running training loss:  1.15797]\u001b[A\n",
            "Training:  66%|██████▌   | 1163/1772 [13:33<06:56,  1.46it/s, running training loss:  1.09145]\u001b[A\n",
            "Training:  66%|██████▌   | 1164/1772 [13:33<07:50,  1.29it/s, running training loss:  1.09145]\u001b[A\n",
            "Training:  66%|██████▌   | 1164/1772 [13:34<07:50,  1.29it/s, running training loss:  0.98242]\u001b[A\n",
            "Training:  66%|██████▌   | 1165/1772 [13:34<08:00,  1.26it/s, running training loss:  0.98242]\u001b[A\n",
            "Training:  66%|██████▌   | 1165/1772 [13:34<08:00,  1.26it/s, running training loss:  0.97510]\u001b[A\n",
            "Training:  66%|██████▌   | 1166/1772 [13:34<07:06,  1.42it/s, running training loss:  0.97510]\u001b[A\n",
            "Training:  66%|██████▌   | 1166/1772 [13:35<07:06,  1.42it/s, running training loss:  1.09580]\u001b[A\n",
            "Training:  66%|██████▌   | 1167/1772 [13:35<07:14,  1.39it/s, running training loss:  1.09580]\u001b[A\n",
            "Training:  66%|██████▌   | 1167/1772 [13:35<07:14,  1.39it/s, running training loss:  1.15740]\u001b[A\n",
            "Training:  66%|██████▌   | 1168/1772 [13:35<06:41,  1.51it/s, running training loss:  1.15740]\u001b[A\n",
            "Training:  66%|██████▌   | 1168/1772 [13:36<06:41,  1.51it/s, running training loss:  1.08999]\u001b[A\n",
            "Training:  66%|██████▌   | 1169/1772 [13:36<06:54,  1.45it/s, running training loss:  1.08999]\u001b[A\n",
            "Training:  66%|██████▌   | 1169/1772 [13:37<06:54,  1.45it/s, running training loss:  0.93944]\u001b[A\n",
            "Training:  66%|██████▌   | 1170/1772 [13:37<06:41,  1.50it/s, running training loss:  0.93944]\u001b[A\n",
            "Training:  66%|██████▌   | 1170/1772 [13:37<06:41,  1.50it/s, running training loss:  0.88293]\u001b[A\n",
            "Training:  66%|██████▌   | 1171/1772 [13:37<06:19,  1.58it/s, running training loss:  0.88293]\u001b[A\n",
            "Training:  66%|██████▌   | 1171/1772 [13:38<06:19,  1.58it/s, running training loss:  1.03249]\u001b[A\n",
            "Training:  66%|██████▌   | 1172/1772 [13:38<05:54,  1.69it/s, running training loss:  1.03249]\u001b[A\n",
            "Training:  66%|██████▌   | 1172/1772 [13:38<05:54,  1.69it/s, running training loss:  1.04139]\u001b[A\n",
            "Training:  66%|██████▌   | 1173/1772 [13:38<06:09,  1.62it/s, running training loss:  1.04139]\u001b[A\n",
            "Training:  66%|██████▌   | 1173/1772 [13:39<06:09,  1.62it/s, running training loss:  0.98495]\u001b[A\n",
            "Training:  66%|██████▋   | 1174/1772 [13:39<06:14,  1.60it/s, running training loss:  0.98495]\u001b[A\n",
            "Training:  66%|██████▋   | 1174/1772 [13:40<06:14,  1.60it/s, running training loss:  1.02372]\u001b[A\n",
            "Training:  66%|██████▋   | 1175/1772 [13:40<05:54,  1.69it/s, running training loss:  1.02372]\u001b[A\n",
            "Training:  66%|██████▋   | 1175/1772 [13:40<05:54,  1.69it/s, running training loss:  0.96268]\u001b[A\n",
            "Training:  66%|██████▋   | 1176/1772 [13:41<06:46,  1.47it/s, running training loss:  0.96268]\u001b[A\n",
            "Training:  66%|██████▋   | 1176/1772 [13:41<06:46,  1.47it/s, running training loss:  1.09436]\u001b[A\n",
            "Training:  66%|██████▋   | 1177/1772 [13:41<06:24,  1.55it/s, running training loss:  1.09436]\u001b[A\n",
            "Training:  66%|██████▋   | 1177/1772 [13:42<06:24,  1.55it/s, running training loss:  1.03423]\u001b[A\n",
            "Training:  66%|██████▋   | 1178/1772 [13:42<06:29,  1.52it/s, running training loss:  1.03423]\u001b[A\n",
            "Training:  66%|██████▋   | 1178/1772 [13:42<06:29,  1.52it/s, running training loss:  1.05229]\u001b[A\n",
            "Training:  67%|██████▋   | 1179/1772 [13:42<06:36,  1.50it/s, running training loss:  1.05229]\u001b[A\n",
            "Training:  67%|██████▋   | 1179/1772 [13:43<06:36,  1.50it/s, running training loss:  0.98389]\u001b[A\n",
            "Training:  67%|██████▋   | 1180/1772 [13:43<06:07,  1.61it/s, running training loss:  0.98389]\u001b[A\n",
            "Training:  67%|██████▋   | 1180/1772 [13:43<06:07,  1.61it/s, running training loss:  0.85891]\u001b[A\n",
            "Training:  67%|██████▋   | 1181/1772 [13:43<05:42,  1.72it/s, running training loss:  0.85891]\u001b[A\n",
            "Training:  67%|██████▋   | 1181/1772 [13:44<05:42,  1.72it/s, running training loss:  0.90034]\u001b[A\n",
            "Training:  67%|██████▋   | 1182/1772 [13:44<05:34,  1.77it/s, running training loss:  0.90034]\u001b[A\n",
            "Training:  67%|██████▋   | 1182/1772 [13:44<05:34,  1.77it/s, running training loss:  0.94214]\u001b[A\n",
            "Training:  67%|██████▋   | 1183/1772 [13:45<05:27,  1.80it/s, running training loss:  0.94214]\u001b[A\n",
            "Training:  67%|██████▋   | 1183/1772 [13:45<05:27,  1.80it/s, running training loss:  0.83667]\u001b[A\n",
            "Training:  67%|██████▋   | 1184/1772 [13:45<05:26,  1.80it/s, running training loss:  0.83667]\u001b[A\n",
            "Training:  67%|██████▋   | 1184/1772 [13:46<05:26,  1.80it/s, running training loss:  0.95112]\u001b[A\n",
            "Training:  67%|██████▋   | 1185/1772 [13:46<05:51,  1.67it/s, running training loss:  0.95112]\u001b[A\n",
            "Training:  67%|██████▋   | 1185/1772 [13:46<05:51,  1.67it/s, running training loss:  1.11456]\u001b[A\n",
            "Training:  67%|██████▋   | 1186/1772 [13:46<05:55,  1.65it/s, running training loss:  1.11456]\u001b[A\n",
            "Training:  67%|██████▋   | 1186/1772 [13:47<05:55,  1.65it/s, running training loss:  0.88782]\u001b[A\n",
            "Training:  67%|██████▋   | 1187/1772 [13:47<05:33,  1.75it/s, running training loss:  0.88782]\u001b[A\n",
            "Training:  67%|██████▋   | 1187/1772 [13:47<05:33,  1.75it/s, running training loss:  0.93040]\u001b[A\n",
            "Training:  67%|██████▋   | 1188/1772 [13:47<05:28,  1.78it/s, running training loss:  0.93040]\u001b[A\n",
            "Training:  67%|██████▋   | 1188/1772 [13:48<05:28,  1.78it/s, running training loss:  0.89686]\u001b[A\n",
            "Training:  67%|██████▋   | 1189/1772 [13:48<05:30,  1.76it/s, running training loss:  0.89686]\u001b[A\n",
            "Training:  67%|██████▋   | 1189/1772 [13:49<05:30,  1.76it/s, running training loss:  0.90990]\u001b[A\n",
            "Training:  67%|██████▋   | 1190/1772 [13:49<05:49,  1.67it/s, running training loss:  0.90990]\u001b[A\n",
            "Training:  67%|██████▋   | 1190/1772 [13:49<05:49,  1.67it/s, running training loss:  0.95550]\u001b[A\n",
            "Training:  67%|██████▋   | 1191/1772 [13:49<05:38,  1.72it/s, running training loss:  0.95550]\u001b[A\n",
            "Training:  67%|██████▋   | 1191/1772 [13:50<05:38,  1.72it/s, running training loss:  0.96372]\u001b[A\n",
            "Training:  67%|██████▋   | 1192/1772 [13:50<05:18,  1.82it/s, running training loss:  0.96372]\u001b[A\n",
            "Training:  67%|██████▋   | 1192/1772 [13:50<05:18,  1.82it/s, running training loss:  1.06146]\u001b[A\n",
            "Training:  67%|██████▋   | 1193/1772 [13:50<05:25,  1.78it/s, running training loss:  1.06146]\u001b[A\n",
            "Training:  67%|██████▋   | 1193/1772 [13:51<05:25,  1.78it/s, running training loss:  0.92838]\u001b[A\n",
            "Training:  67%|██████▋   | 1194/1772 [13:51<05:21,  1.80it/s, running training loss:  0.92838]\u001b[A\n",
            "Training:  67%|██████▋   | 1194/1772 [13:52<05:21,  1.80it/s, running training loss:  0.93210]\u001b[A\n",
            "Training:  67%|██████▋   | 1195/1772 [13:52<05:49,  1.65it/s, running training loss:  0.93210]\u001b[A\n",
            "Training:  67%|██████▋   | 1195/1772 [13:52<05:49,  1.65it/s, running training loss:  0.97044]\u001b[A\n",
            "Training:  67%|██████▋   | 1196/1772 [13:52<06:23,  1.50it/s, running training loss:  0.97044]\u001b[A\n",
            "Training:  67%|██████▋   | 1196/1772 [13:53<06:23,  1.50it/s, running training loss:  0.92004]\u001b[A\n",
            "Training:  68%|██████▊   | 1197/1772 [13:53<06:20,  1.51it/s, running training loss:  0.92004]\u001b[A\n",
            "Training:  68%|██████▊   | 1197/1772 [13:53<06:20,  1.51it/s, running training loss:  1.09791]\u001b[A\n",
            "Training:  68%|██████▊   | 1198/1772 [13:53<05:46,  1.65it/s, running training loss:  1.09791]\u001b[A\n",
            "Training:  68%|██████▊   | 1198/1772 [13:54<05:46,  1.65it/s, running training loss:  1.01232]\u001b[A\n",
            "Training:  68%|██████▊   | 1199/1772 [13:54<05:41,  1.68it/s, running training loss:  1.01232]\u001b[A\n",
            "Training:  68%|██████▊   | 1199/1772 [13:55<05:41,  1.68it/s, running training loss:  1.21199]\u001b[A\n",
            "\n",
            "Evaluation:   0%|          | 0/270 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   0%|          | 1/270 [00:00<01:36,  2.80it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   1%|          | 2/270 [00:00<00:58,  4.56it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   1%|          | 3/270 [00:00<00:44,  5.98it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   1%|▏         | 4/270 [00:00<00:39,  6.73it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   2%|▏         | 5/270 [00:00<00:35,  7.45it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   2%|▏         | 6/270 [00:00<00:34,  7.76it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   3%|▎         | 8/270 [00:01<00:29,  8.88it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   3%|▎         | 9/270 [00:01<00:29,  8.70it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   4%|▍         | 11/270 [00:01<00:26,  9.75it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   5%|▍         | 13/270 [00:01<00:25, 10.03it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   5%|▌         | 14/270 [00:01<00:26,  9.59it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   6%|▌         | 16/270 [00:01<00:26,  9.57it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   6%|▋         | 17/270 [00:02<00:27,  9.17it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   7%|▋         | 19/270 [00:02<00:26,  9.38it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   7%|▋         | 20/270 [00:02<00:27,  9.11it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   8%|▊         | 22/270 [00:02<00:24, 10.23it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   9%|▉         | 24/270 [00:02<00:22, 10.77it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  10%|▉         | 26/270 [00:02<00:23, 10.55it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  10%|█         | 28/270 [00:03<00:23, 10.35it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  11%|█         | 30/270 [00:03<00:24,  9.79it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  11%|█▏        | 31/270 [00:03<00:25,  9.48it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  12%|█▏        | 32/270 [00:03<00:24,  9.55it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  12%|█▏        | 33/270 [00:03<00:25,  9.23it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  13%|█▎        | 35/270 [00:03<00:24,  9.54it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  14%|█▎        | 37/270 [00:04<00:22, 10.27it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  14%|█▍        | 39/270 [00:04<00:22, 10.36it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  15%|█▌        | 41/270 [00:04<00:22, 10.18it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  16%|█▌        | 43/270 [00:04<00:23,  9.51it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  16%|█▋        | 44/270 [00:04<00:23,  9.58it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  17%|█▋        | 45/270 [00:04<00:23,  9.60it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  17%|█▋        | 46/270 [00:05<00:23,  9.36it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  18%|█▊        | 48/270 [00:05<00:21, 10.14it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  19%|█▊        | 50/270 [00:05<00:22,  9.61it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  19%|█▉        | 51/270 [00:05<00:24,  9.10it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  20%|█▉        | 53/270 [00:05<00:22,  9.58it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  20%|██        | 55/270 [00:05<00:21, 10.00it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  21%|██        | 56/270 [00:06<00:22,  9.58it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  21%|██        | 57/270 [00:06<00:23,  9.21it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  21%|██▏       | 58/270 [00:06<00:23,  9.03it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  22%|██▏       | 59/270 [00:06<00:23,  8.85it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  23%|██▎       | 61/270 [00:06<00:22,  9.35it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  23%|██▎       | 62/270 [00:06<00:23,  9.03it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  23%|██▎       | 63/270 [00:06<00:23,  8.81it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  24%|██▍       | 65/270 [00:07<00:21,  9.67it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  25%|██▍       | 67/270 [00:07<00:20,  9.97it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  26%|██▌       | 69/270 [00:07<00:19, 10.44it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  26%|██▋       | 71/270 [00:07<00:18, 10.75it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  27%|██▋       | 73/270 [00:07<00:18, 10.40it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  28%|██▊       | 75/270 [00:07<00:18, 10.57it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  29%|██▊       | 77/270 [00:08<00:18, 10.36it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  29%|██▉       | 79/270 [00:08<00:18, 10.52it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  30%|███       | 81/270 [00:08<00:18, 10.12it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  31%|███       | 83/270 [00:08<00:19,  9.58it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  31%|███▏      | 85/270 [00:08<00:19,  9.65it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  32%|███▏      | 87/270 [00:09<00:18,  9.87it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  33%|███▎      | 88/270 [00:09<00:19,  9.54it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  33%|███▎      | 89/270 [00:09<00:19,  9.31it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  33%|███▎      | 90/270 [00:09<00:19,  9.42it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  34%|███▎      | 91/270 [00:09<00:20,  8.95it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  34%|███▍      | 93/270 [00:09<00:18,  9.78it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  35%|███▌      | 95/270 [00:10<00:17, 10.24it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  36%|███▌      | 97/270 [00:10<00:16, 10.28it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  37%|███▋      | 99/270 [00:10<00:16, 10.20it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  37%|███▋      | 101/270 [00:10<00:16, 10.26it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  38%|███▊      | 103/270 [00:10<00:15, 10.54it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  39%|███▉      | 105/270 [00:10<00:16,  9.88it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  40%|███▉      | 107/270 [00:11<00:15, 10.26it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  40%|████      | 109/270 [00:11<00:16,  9.98it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  41%|████      | 111/270 [00:11<00:15,  9.96it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  42%|████▏     | 113/270 [00:11<00:15, 10.19it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  43%|████▎     | 115/270 [00:11<00:15,  9.99it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  43%|████▎     | 117/270 [00:12<00:15,  9.59it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  44%|████▍     | 119/270 [00:12<00:15,  9.88it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  44%|████▍     | 120/270 [00:12<00:15,  9.71it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  45%|████▌     | 122/270 [00:12<00:14, 10.37it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  46%|████▌     | 124/270 [00:12<00:13, 10.53it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  47%|████▋     | 126/270 [00:13<00:14,  9.69it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  47%|████▋     | 127/270 [00:13<00:15,  9.30it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  47%|████▋     | 128/270 [00:13<00:15,  8.93it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  48%|████▊     | 129/270 [00:13<00:15,  8.91it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  49%|████▊     | 131/270 [00:13<00:14,  9.82it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  49%|████▉     | 132/270 [00:13<00:14,  9.31it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  50%|████▉     | 134/270 [00:13<00:14,  9.51it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  50%|█████     | 136/270 [00:14<00:13,  9.98it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  51%|█████     | 138/270 [00:14<00:13,  9.99it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  52%|█████▏    | 140/270 [00:14<00:12, 10.20it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  53%|█████▎    | 142/270 [00:14<00:13,  9.78it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  53%|█████▎    | 144/270 [00:14<00:12, 10.28it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  54%|█████▍    | 146/270 [00:15<00:12, 10.09it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  55%|█████▍    | 148/270 [00:15<00:12, 10.04it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  56%|█████▌    | 150/270 [00:15<00:11, 10.22it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  56%|█████▋    | 152/270 [00:15<00:12,  9.68it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  57%|█████▋    | 153/270 [00:15<00:12,  9.42it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  57%|█████▋    | 154/270 [00:15<00:12,  9.50it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  57%|█████▋    | 155/270 [00:16<00:12,  9.31it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  58%|█████▊    | 156/270 [00:16<00:13,  8.76it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  59%|█████▊    | 158/270 [00:16<00:11, 10.08it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  59%|█████▉    | 159/270 [00:16<00:11,  9.67it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  59%|█████▉    | 160/270 [00:16<00:11,  9.35it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  60%|█████▉    | 161/270 [00:16<00:11,  9.26it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  60%|██████    | 162/270 [00:16<00:11,  9.20it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  60%|██████    | 163/270 [00:16<00:11,  8.95it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  61%|██████    | 164/270 [00:17<00:11,  9.01it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  61%|██████    | 165/270 [00:17<00:11,  8.86it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  62%|██████▏   | 167/270 [00:17<00:10,  9.65it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  62%|██████▏   | 168/270 [00:17<00:10,  9.38it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  63%|██████▎   | 169/270 [00:17<00:11,  8.89it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  63%|██████▎   | 171/270 [00:17<00:10,  9.34it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  64%|██████▎   | 172/270 [00:17<00:10,  9.13it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  64%|██████▍   | 173/270 [00:18<00:10,  9.01it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  64%|██████▍   | 174/270 [00:18<00:10,  8.90it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  65%|██████▍   | 175/270 [00:18<00:10,  8.88it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  65%|██████▌   | 176/270 [00:18<00:10,  8.62it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  66%|██████▌   | 177/270 [00:18<00:11,  8.34it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  66%|██████▋   | 179/270 [00:18<00:09,  9.14it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  67%|██████▋   | 180/270 [00:18<00:10,  8.92it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  67%|██████▋   | 182/270 [00:19<00:09,  9.09it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  68%|██████▊   | 184/270 [00:19<00:09,  9.37it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  69%|██████▊   | 185/270 [00:19<00:09,  9.22it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  69%|██████▉   | 187/270 [00:19<00:08,  9.49it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  70%|██████▉   | 188/270 [00:19<00:08,  9.25it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  70%|███████   | 190/270 [00:19<00:07, 10.21it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  71%|███████   | 192/270 [00:20<00:07, 10.04it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  72%|███████▏  | 194/270 [00:20<00:07,  9.96it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  72%|███████▏  | 195/270 [00:20<00:07,  9.60it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  73%|███████▎  | 196/270 [00:20<00:08,  9.17it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  73%|███████▎  | 198/270 [00:20<00:07,  9.38it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  74%|███████▎  | 199/270 [00:20<00:07,  9.14it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  74%|███████▍  | 200/270 [00:20<00:07,  8.97it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  74%|███████▍  | 201/270 [00:21<00:07,  8.91it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  75%|███████▍  | 202/270 [00:21<00:07,  8.65it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  76%|███████▌  | 204/270 [00:21<00:06,  9.97it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  76%|███████▋  | 206/270 [00:21<00:06, 10.12it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  77%|███████▋  | 207/270 [00:21<00:06,  9.84it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  77%|███████▋  | 208/270 [00:21<00:06,  9.54it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  77%|███████▋  | 209/270 [00:21<00:06,  9.10it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  78%|███████▊  | 210/270 [00:22<00:06,  8.91it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  79%|███████▊  | 212/270 [00:22<00:06,  9.26it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  79%|███████▉  | 214/270 [00:22<00:05,  9.82it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  80%|████████  | 216/270 [00:22<00:05,  9.58it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  80%|████████  | 217/270 [00:22<00:05,  9.55it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  81%|████████  | 219/270 [00:22<00:05,  9.82it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  82%|████████▏ | 221/270 [00:23<00:04, 10.48it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  83%|████████▎ | 223/270 [00:23<00:04, 10.82it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  83%|████████▎ | 225/270 [00:23<00:04, 10.96it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  84%|████████▍ | 227/270 [00:23<00:04, 10.61it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  85%|████████▍ | 229/270 [00:23<00:04,  9.89it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  86%|████████▌ | 231/270 [00:24<00:04,  9.59it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  86%|████████▋ | 233/270 [00:24<00:03,  9.95it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  87%|████████▋ | 235/270 [00:24<00:03, 10.28it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  88%|████████▊ | 237/270 [00:24<00:03, 10.27it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  89%|████████▊ | 239/270 [00:24<00:03, 10.18it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  89%|████████▉ | 241/270 [00:25<00:03,  9.60it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  90%|█████████ | 243/270 [00:25<00:02, 10.38it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  91%|█████████ | 245/270 [00:25<00:02,  9.91it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  91%|█████████▏| 247/270 [00:25<00:02,  9.50it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  92%|█████████▏| 248/270 [00:25<00:02,  9.20it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  92%|█████████▏| 249/270 [00:25<00:02,  9.05it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  93%|█████████▎| 250/270 [00:26<00:02,  8.80it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  93%|█████████▎| 251/270 [00:26<00:02,  8.62it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  93%|█████████▎| 252/270 [00:26<00:02,  8.61it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  94%|█████████▎| 253/270 [00:26<00:01,  8.52it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  94%|█████████▍| 254/270 [00:26<00:01,  8.47it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  94%|█████████▍| 255/270 [00:26<00:01,  8.31it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  95%|█████████▍| 256/270 [00:26<00:01,  8.40it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  95%|█████████▌| 257/270 [00:26<00:01,  8.67it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  96%|█████████▌| 258/270 [00:27<00:01,  8.98it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  96%|█████████▋| 260/270 [00:27<00:01,  9.96it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  97%|█████████▋| 261/270 [00:27<00:00,  9.72it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  97%|█████████▋| 262/270 [00:27<00:00,  9.37it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  97%|█████████▋| 263/270 [00:27<00:00,  9.11it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  98%|█████████▊| 264/270 [00:27<00:00,  8.85it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  98%|█████████▊| 265/270 [00:27<00:00,  8.77it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  99%|█████████▊| 266/270 [00:27<00:00,  8.51it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  99%|█████████▉| 268/270 [00:28<00:00,  9.13it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation: 100%|██████████| 270/270 [00:28<00:00,  9.49it/s]\n",
            "\n",
            "Training:  68%|██████▊   | 1200/1772 [14:23<1:27:02,  9.13s/it, running training loss:  1.21199]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            ">>> training loss: 0.989552, valid loss: 0.629359,valid f1: 0.000000, valid acc:0.689991\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  68%|██████▊   | 1200/1772 [14:24<1:27:02,  9.13s/it, running training loss:  0.96551]\u001b[A\n",
            "Training:  68%|██████▊   | 1201/1772 [14:24<1:02:38,  6.58s/it, running training loss:  0.96551]\u001b[A\n",
            "Training:  68%|██████▊   | 1201/1772 [14:25<1:02:38,  6.58s/it, running training loss:  1.05619]\u001b[A\n",
            "Training:  68%|██████▊   | 1202/1772 [14:25<46:15,  4.87s/it, running training loss:  1.05619]  \u001b[A\n",
            "Training:  68%|██████▊   | 1202/1772 [14:25<46:15,  4.87s/it, running training loss:  1.02520]\u001b[A\n",
            "Training:  68%|██████▊   | 1203/1772 [14:25<34:01,  3.59s/it, running training loss:  1.02520]\u001b[A\n",
            "Training:  68%|██████▊   | 1203/1772 [14:26<34:01,  3.59s/it, running training loss:  0.96100]\u001b[A\n",
            "Training:  68%|██████▊   | 1204/1772 [14:26<25:23,  2.68s/it, running training loss:  0.96100]\u001b[A\n",
            "Training:  68%|██████▊   | 1204/1772 [14:26<25:23,  2.68s/it, running training loss:  0.95917]\u001b[A\n",
            "Training:  68%|██████▊   | 1205/1772 [14:26<19:11,  2.03s/it, running training loss:  0.95917]\u001b[A\n",
            "Training:  68%|██████▊   | 1205/1772 [14:27<19:11,  2.03s/it, running training loss:  0.99588]\u001b[A\n",
            "Training:  68%|██████▊   | 1206/1772 [14:27<15:59,  1.69s/it, running training loss:  0.99588]\u001b[A\n",
            "Training:  68%|██████▊   | 1206/1772 [14:28<15:59,  1.69s/it, running training loss:  0.87001]\u001b[A\n",
            "Training:  68%|██████▊   | 1207/1772 [14:28<12:47,  1.36s/it, running training loss:  0.87001]\u001b[A\n",
            "Training:  68%|██████▊   | 1207/1772 [14:29<12:47,  1.36s/it, running training loss:  1.13161]\u001b[A\n",
            "Training:  68%|██████▊   | 1208/1772 [14:29<11:12,  1.19s/it, running training loss:  1.13161]\u001b[A\n",
            "Training:  68%|██████▊   | 1208/1772 [14:29<11:12,  1.19s/it, running training loss:  1.10689]\u001b[A\n",
            "Training:  68%|██████▊   | 1209/1772 [14:29<09:44,  1.04s/it, running training loss:  1.10689]\u001b[A\n",
            "Training:  68%|██████▊   | 1209/1772 [14:30<09:44,  1.04s/it, running training loss:  1.02303]\u001b[A\n",
            "Training:  68%|██████▊   | 1210/1772 [14:30<09:43,  1.04s/it, running training loss:  1.02303]\u001b[A\n",
            "Training:  68%|██████▊   | 1210/1772 [14:31<09:43,  1.04s/it, running training loss:  1.21699]\u001b[A\n",
            "Training:  68%|██████▊   | 1211/1772 [14:31<08:28,  1.10it/s, running training loss:  1.21699]\u001b[A\n",
            "Training:  68%|██████▊   | 1211/1772 [14:32<08:28,  1.10it/s, running training loss:  1.11718]\u001b[A\n",
            "Training:  68%|██████▊   | 1212/1772 [14:32<08:48,  1.06it/s, running training loss:  1.11718]\u001b[A\n",
            "Training:  68%|██████▊   | 1212/1772 [14:32<08:48,  1.06it/s, running training loss:  1.01120]\u001b[A\n",
            "Training:  68%|██████▊   | 1213/1772 [14:32<07:41,  1.21it/s, running training loss:  1.01120]\u001b[A\n",
            "Training:  68%|██████▊   | 1213/1772 [14:33<07:41,  1.21it/s, running training loss:  1.11256]\u001b[A\n",
            "Training:  69%|██████▊   | 1214/1772 [14:33<06:55,  1.34it/s, running training loss:  1.11256]\u001b[A\n",
            "Training:  69%|██████▊   | 1214/1772 [14:34<06:55,  1.34it/s, running training loss:  1.11298]\u001b[A\n",
            "Training:  69%|██████▊   | 1215/1772 [14:34<06:53,  1.35it/s, running training loss:  1.11298]\u001b[A\n",
            "Training:  69%|██████▊   | 1215/1772 [14:34<06:53,  1.35it/s, running training loss:  1.15007]\u001b[A\n",
            "Training:  69%|██████▊   | 1216/1772 [14:34<06:24,  1.44it/s, running training loss:  1.15007]\u001b[A\n",
            "Training:  69%|██████▊   | 1216/1772 [14:35<06:24,  1.44it/s, running training loss:  0.91744]\u001b[A\n",
            "Training:  69%|██████▊   | 1217/1772 [14:35<06:16,  1.47it/s, running training loss:  0.91744]\u001b[A\n",
            "Training:  69%|██████▊   | 1217/1772 [14:36<06:16,  1.47it/s, running training loss:  0.80679]\u001b[A\n",
            "Training:  69%|██████▊   | 1218/1772 [14:36<06:12,  1.49it/s, running training loss:  0.80679]\u001b[A\n",
            "Training:  69%|██████▊   | 1218/1772 [14:36<06:12,  1.49it/s, running training loss:  0.89974]\u001b[A\n",
            "Training:  69%|██████▉   | 1219/1772 [14:36<06:18,  1.46it/s, running training loss:  0.89974]\u001b[A\n",
            "Training:  69%|██████▉   | 1219/1772 [14:37<06:18,  1.46it/s, running training loss:  0.79234]\u001b[A\n",
            "Training:  69%|██████▉   | 1220/1772 [14:37<05:57,  1.54it/s, running training loss:  0.79234]\u001b[A\n",
            "Training:  69%|██████▉   | 1220/1772 [14:38<05:57,  1.54it/s, running training loss:  0.84422]\u001b[A\n",
            "Training:  69%|██████▉   | 1221/1772 [14:38<06:08,  1.50it/s, running training loss:  0.84422]\u001b[A\n",
            "Training:  69%|██████▉   | 1221/1772 [14:38<06:08,  1.50it/s, running training loss:  1.13953]\u001b[A\n",
            "Training:  69%|██████▉   | 1222/1772 [14:38<06:28,  1.41it/s, running training loss:  1.13953]\u001b[A\n",
            "Training:  69%|██████▉   | 1222/1772 [14:39<06:28,  1.41it/s, running training loss:  0.99527]\u001b[A\n",
            "Training:  69%|██████▉   | 1223/1772 [14:39<06:22,  1.44it/s, running training loss:  0.99527]\u001b[A\n",
            "Training:  69%|██████▉   | 1223/1772 [14:40<06:22,  1.44it/s, running training loss:  0.96658]\u001b[A\n",
            "Training:  69%|██████▉   | 1224/1772 [14:40<05:54,  1.55it/s, running training loss:  0.96658]\u001b[A\n",
            "Training:  69%|██████▉   | 1224/1772 [14:40<05:54,  1.55it/s, running training loss:  1.04498]\u001b[A\n",
            "Training:  69%|██████▉   | 1225/1772 [14:40<05:51,  1.55it/s, running training loss:  1.04498]\u001b[A\n",
            "Training:  69%|██████▉   | 1225/1772 [14:41<05:51,  1.55it/s, running training loss:  1.06672]\u001b[A\n",
            "Training:  69%|██████▉   | 1226/1772 [14:41<05:32,  1.64it/s, running training loss:  1.06672]\u001b[A\n",
            "Training:  69%|██████▉   | 1226/1772 [14:42<05:32,  1.64it/s, running training loss:  1.01090]\u001b[A\n",
            "Training:  69%|██████▉   | 1227/1772 [14:42<06:10,  1.47it/s, running training loss:  1.01090]\u001b[A\n",
            "Training:  69%|██████▉   | 1227/1772 [14:42<06:10,  1.47it/s, running training loss:  1.04038]\u001b[A\n",
            "Training:  69%|██████▉   | 1228/1772 [14:42<06:13,  1.46it/s, running training loss:  1.04038]\u001b[A\n",
            "Training:  69%|██████▉   | 1228/1772 [14:43<06:13,  1.46it/s, running training loss:  1.10357]\u001b[A\n",
            "Training:  69%|██████▉   | 1229/1772 [14:43<06:09,  1.47it/s, running training loss:  1.10357]\u001b[A\n",
            "Training:  69%|██████▉   | 1229/1772 [14:44<06:09,  1.47it/s, running training loss:  1.10596]\u001b[A\n",
            "Training:  69%|██████▉   | 1230/1772 [14:44<06:17,  1.44it/s, running training loss:  1.10596]\u001b[A\n",
            "Training:  69%|██████▉   | 1230/1772 [14:44<06:17,  1.44it/s, running training loss:  1.01160]\u001b[A\n",
            "Training:  69%|██████▉   | 1231/1772 [14:44<06:08,  1.47it/s, running training loss:  1.01160]\u001b[A\n",
            "Training:  69%|██████▉   | 1231/1772 [14:45<06:08,  1.47it/s, running training loss:  0.98118]\u001b[A\n",
            "Training:  70%|██████▉   | 1232/1772 [14:45<06:45,  1.33it/s, running training loss:  0.98118]\u001b[A\n",
            "Training:  70%|██████▉   | 1232/1772 [14:46<06:45,  1.33it/s, running training loss:  0.99468]\u001b[A\n",
            "Training:  70%|██████▉   | 1233/1772 [14:46<06:07,  1.47it/s, running training loss:  0.99468]\u001b[A\n",
            "Training:  70%|██████▉   | 1233/1772 [14:46<06:07,  1.47it/s, running training loss:  0.98788]\u001b[A\n",
            "Training:  70%|██████▉   | 1234/1772 [14:46<05:47,  1.55it/s, running training loss:  0.98788]\u001b[A\n",
            "Training:  70%|██████▉   | 1234/1772 [14:47<05:47,  1.55it/s, running training loss:  0.92423]\u001b[A\n",
            "Training:  70%|██████▉   | 1235/1772 [14:47<05:55,  1.51it/s, running training loss:  0.92423]\u001b[A\n",
            "Training:  70%|██████▉   | 1235/1772 [14:48<05:55,  1.51it/s, running training loss:  0.99590]\u001b[A\n",
            "Training:  70%|██████▉   | 1236/1772 [14:48<05:54,  1.51it/s, running training loss:  0.99590]\u001b[A\n",
            "Training:  70%|██████▉   | 1236/1772 [14:48<05:54,  1.51it/s, running training loss:  0.84286]\u001b[A\n",
            "Training:  70%|██████▉   | 1237/1772 [14:48<05:45,  1.55it/s, running training loss:  0.84286]\u001b[A\n",
            "Training:  70%|██████▉   | 1237/1772 [14:49<05:45,  1.55it/s, running training loss:  0.90707]\u001b[A\n",
            "Training:  70%|██████▉   | 1238/1772 [14:49<05:52,  1.51it/s, running training loss:  0.90707]\u001b[A\n",
            "Training:  70%|██████▉   | 1238/1772 [14:50<05:52,  1.51it/s, running training loss:  0.82410]\u001b[A\n",
            "Training:  70%|██████▉   | 1239/1772 [14:50<05:55,  1.50it/s, running training loss:  0.82410]\u001b[A\n",
            "Training:  70%|██████▉   | 1239/1772 [14:50<05:55,  1.50it/s, running training loss:  0.93384]\u001b[A\n",
            "Training:  70%|██████▉   | 1240/1772 [14:50<05:41,  1.56it/s, running training loss:  0.93384]\u001b[A\n",
            "Training:  70%|██████▉   | 1240/1772 [14:51<05:41,  1.56it/s, running training loss:  0.90649]\u001b[A\n",
            "Training:  70%|███████   | 1241/1772 [14:51<05:36,  1.58it/s, running training loss:  0.90649]\u001b[A\n",
            "Training:  70%|███████   | 1241/1772 [14:51<05:36,  1.58it/s, running training loss:  0.93120]\u001b[A\n",
            "Training:  70%|███████   | 1242/1772 [14:51<05:20,  1.65it/s, running training loss:  0.93120]\u001b[A\n",
            "Training:  70%|███████   | 1242/1772 [14:52<05:20,  1.65it/s, running training loss:  0.96870]\u001b[A\n",
            "Training:  70%|███████   | 1243/1772 [14:52<04:58,  1.77it/s, running training loss:  0.96870]\u001b[A\n",
            "Training:  70%|███████   | 1243/1772 [14:53<04:58,  1.77it/s, running training loss:  0.80855]\u001b[A\n",
            "Training:  70%|███████   | 1244/1772 [14:53<05:17,  1.66it/s, running training loss:  0.80855]\u001b[A\n",
            "Training:  70%|███████   | 1244/1772 [14:53<05:17,  1.66it/s, running training loss:  0.99584]\u001b[A\n",
            "Training:  70%|███████   | 1245/1772 [14:53<05:08,  1.71it/s, running training loss:  0.99584]\u001b[A\n",
            "Training:  70%|███████   | 1245/1772 [14:54<05:08,  1.71it/s, running training loss:  0.89295]\u001b[A\n",
            "Training:  70%|███████   | 1246/1772 [14:54<06:17,  1.39it/s, running training loss:  0.89295]\u001b[A\n",
            "Training:  70%|███████   | 1246/1772 [14:55<06:17,  1.39it/s, running training loss:  0.82262]\u001b[A\n",
            "Training:  70%|███████   | 1247/1772 [14:55<06:29,  1.35it/s, running training loss:  0.82262]\u001b[A\n",
            "Training:  70%|███████   | 1247/1772 [14:56<06:29,  1.35it/s, running training loss:  1.00401]\u001b[A\n",
            "Training:  70%|███████   | 1248/1772 [14:56<06:03,  1.44it/s, running training loss:  1.00401]\u001b[A\n",
            "Training:  70%|███████   | 1248/1772 [14:56<06:03,  1.44it/s, running training loss:  0.99988]\u001b[A\n",
            "Training:  70%|███████   | 1249/1772 [14:56<05:55,  1.47it/s, running training loss:  0.99988]\u001b[A\n",
            "Training:  70%|███████   | 1249/1772 [14:57<05:55,  1.47it/s, running training loss:  0.96479]\u001b[A\n",
            "Training:  71%|███████   | 1250/1772 [14:57<05:54,  1.47it/s, running training loss:  0.96479]\u001b[A\n",
            "Training:  71%|███████   | 1250/1772 [14:57<05:54,  1.47it/s, running training loss:  0.93000]\u001b[A\n",
            "Training:  71%|███████   | 1251/1772 [14:57<05:35,  1.55it/s, running training loss:  0.93000]\u001b[A\n",
            "Training:  71%|███████   | 1251/1772 [14:58<05:35,  1.55it/s, running training loss:  1.01665]\u001b[A\n",
            "Training:  71%|███████   | 1252/1772 [14:58<05:30,  1.57it/s, running training loss:  1.01665]\u001b[A\n",
            "Training:  71%|███████   | 1252/1772 [14:59<05:30,  1.57it/s, running training loss:  0.93643]\u001b[A\n",
            "Training:  71%|███████   | 1253/1772 [14:59<05:16,  1.64it/s, running training loss:  0.93643]\u001b[A\n",
            "Training:  71%|███████   | 1253/1772 [14:59<05:16,  1.64it/s, running training loss:  1.13136]\u001b[A\n",
            "Training:  71%|███████   | 1254/1772 [14:59<05:27,  1.58it/s, running training loss:  1.13136]\u001b[A\n",
            "Training:  71%|███████   | 1254/1772 [15:00<05:27,  1.58it/s, running training loss:  0.99767]\u001b[A\n",
            "Training:  71%|███████   | 1255/1772 [15:00<05:20,  1.61it/s, running training loss:  0.99767]\u001b[A\n",
            "Training:  71%|███████   | 1255/1772 [15:00<05:20,  1.61it/s, running training loss:  0.73206]\u001b[A\n",
            "Training:  71%|███████   | 1256/1772 [15:00<04:55,  1.75it/s, running training loss:  0.73206]\u001b[A\n",
            "Training:  71%|███████   | 1256/1772 [15:01<04:55,  1.75it/s, running training loss:  0.94363]\u001b[A\n",
            "Training:  71%|███████   | 1257/1772 [15:01<05:08,  1.67it/s, running training loss:  0.94363]\u001b[A\n",
            "Training:  71%|███████   | 1257/1772 [15:02<05:08,  1.67it/s, running training loss:  0.83424]\u001b[A\n",
            "Training:  71%|███████   | 1258/1772 [15:02<05:01,  1.71it/s, running training loss:  0.83424]\u001b[A\n",
            "Training:  71%|███████   | 1258/1772 [15:02<05:01,  1.71it/s, running training loss:  1.06104]\u001b[A\n",
            "Training:  71%|███████   | 1259/1772 [15:02<04:53,  1.75it/s, running training loss:  1.06104]\u001b[A\n",
            "Training:  71%|███████   | 1259/1772 [15:03<04:53,  1.75it/s, running training loss:  0.81866]\u001b[A\n",
            "Training:  71%|███████   | 1260/1772 [15:03<04:50,  1.76it/s, running training loss:  0.81866]\u001b[A\n",
            "Training:  71%|███████   | 1260/1772 [15:03<04:50,  1.76it/s, running training loss:  0.82883]\u001b[A\n",
            "Training:  71%|███████   | 1261/1772 [15:03<04:56,  1.73it/s, running training loss:  0.82883]\u001b[A\n",
            "Training:  71%|███████   | 1261/1772 [15:04<04:56,  1.73it/s, running training loss:  1.10545]\u001b[A\n",
            "Training:  71%|███████   | 1262/1772 [15:04<04:59,  1.70it/s, running training loss:  1.10545]\u001b[A\n",
            "Training:  71%|███████   | 1262/1772 [15:05<04:59,  1.70it/s, running training loss:  1.03905]\u001b[A\n",
            "Training:  71%|███████▏  | 1263/1772 [15:05<05:08,  1.65it/s, running training loss:  1.03905]\u001b[A\n",
            "Training:  71%|███████▏  | 1263/1772 [15:05<05:08,  1.65it/s, running training loss:  1.10865]\u001b[A\n",
            "Training:  71%|███████▏  | 1264/1772 [15:05<04:53,  1.73it/s, running training loss:  1.10865]\u001b[A\n",
            "Training:  71%|███████▏  | 1264/1772 [15:06<04:53,  1.73it/s, running training loss:  1.16699]\u001b[A\n",
            "Training:  71%|███████▏  | 1265/1772 [15:06<05:31,  1.53it/s, running training loss:  1.16699]\u001b[A\n",
            "Training:  71%|███████▏  | 1265/1772 [15:06<05:31,  1.53it/s, running training loss:  0.97721]\u001b[A\n",
            "Training:  71%|███████▏  | 1266/1772 [15:06<05:08,  1.64it/s, running training loss:  0.97721]\u001b[A\n",
            "Training:  71%|███████▏  | 1266/1772 [15:07<05:08,  1.64it/s, running training loss:  0.89337]\u001b[A\n",
            "Training:  72%|███████▏  | 1267/1772 [15:07<05:06,  1.65it/s, running training loss:  0.89337]\u001b[A\n",
            "Training:  72%|███████▏  | 1267/1772 [15:08<05:06,  1.65it/s, running training loss:  0.92684]\u001b[A\n",
            "Training:  72%|███████▏  | 1268/1772 [15:08<05:31,  1.52it/s, running training loss:  0.92684]\u001b[A\n",
            "Training:  72%|███████▏  | 1268/1772 [15:08<05:31,  1.52it/s, running training loss:  1.03848]\u001b[A\n",
            "Training:  72%|███████▏  | 1269/1772 [15:08<05:12,  1.61it/s, running training loss:  1.03848]\u001b[A\n",
            "Training:  72%|███████▏  | 1269/1772 [15:09<05:12,  1.61it/s, running training loss:  1.06676]\u001b[A\n",
            "Training:  72%|███████▏  | 1270/1772 [15:09<05:32,  1.51it/s, running training loss:  1.06676]\u001b[A\n",
            "Training:  72%|███████▏  | 1270/1772 [15:10<05:32,  1.51it/s, running training loss:  1.02867]\u001b[A\n",
            "Training:  72%|███████▏  | 1271/1772 [15:10<05:22,  1.55it/s, running training loss:  1.02867]\u001b[A\n",
            "Training:  72%|███████▏  | 1271/1772 [15:10<05:22,  1.55it/s, running training loss:  0.87092]\u001b[A\n",
            "Training:  72%|███████▏  | 1272/1772 [15:10<05:19,  1.57it/s, running training loss:  0.87092]\u001b[A\n",
            "Training:  72%|███████▏  | 1272/1772 [15:11<05:19,  1.57it/s, running training loss:  0.91916]\u001b[A\n",
            "Training:  72%|███████▏  | 1273/1772 [15:11<05:35,  1.49it/s, running training loss:  0.91916]\u001b[A\n",
            "Training:  72%|███████▏  | 1273/1772 [15:12<05:35,  1.49it/s, running training loss:  0.92953]\u001b[A\n",
            "Training:  72%|███████▏  | 1274/1772 [15:12<05:58,  1.39it/s, running training loss:  0.92953]\u001b[A\n",
            "Training:  72%|███████▏  | 1274/1772 [15:13<05:58,  1.39it/s, running training loss:  0.85610]\u001b[A\n",
            "Training:  72%|███████▏  | 1275/1772 [15:13<05:54,  1.40it/s, running training loss:  0.85610]\u001b[A\n",
            "Training:  72%|███████▏  | 1275/1772 [15:13<05:54,  1.40it/s, running training loss:  1.00409]\u001b[A\n",
            "Training:  72%|███████▏  | 1276/1772 [15:13<06:02,  1.37it/s, running training loss:  1.00409]\u001b[A\n",
            "Training:  72%|███████▏  | 1276/1772 [15:14<06:02,  1.37it/s, running training loss:  0.87790]\u001b[A\n",
            "Training:  72%|███████▏  | 1277/1772 [15:14<05:44,  1.44it/s, running training loss:  0.87790]\u001b[A\n",
            "Training:  72%|███████▏  | 1277/1772 [15:14<05:44,  1.44it/s, running training loss:  0.90368]\u001b[A\n",
            "Training:  72%|███████▏  | 1278/1772 [15:15<05:23,  1.53it/s, running training loss:  0.90368]\u001b[A\n",
            "Training:  72%|███████▏  | 1278/1772 [15:15<05:23,  1.53it/s, running training loss:  1.03978]\u001b[A\n",
            "Training:  72%|███████▏  | 1279/1772 [15:15<05:04,  1.62it/s, running training loss:  1.03978]\u001b[A\n",
            "Training:  72%|███████▏  | 1279/1772 [15:16<05:04,  1.62it/s, running training loss:  1.20349]\u001b[A\n",
            "Training:  72%|███████▏  | 1280/1772 [15:16<05:24,  1.52it/s, running training loss:  1.20349]\u001b[A\n",
            "Training:  72%|███████▏  | 1280/1772 [15:16<05:24,  1.52it/s, running training loss:  1.02860]\u001b[A\n",
            "Training:  72%|███████▏  | 1281/1772 [15:16<05:17,  1.55it/s, running training loss:  1.02860]\u001b[A\n",
            "Training:  72%|███████▏  | 1281/1772 [15:17<05:17,  1.55it/s, running training loss:  1.02657]\u001b[A\n",
            "Training:  72%|███████▏  | 1282/1772 [15:17<05:16,  1.55it/s, running training loss:  1.02657]\u001b[A\n",
            "Training:  72%|███████▏  | 1282/1772 [15:18<05:16,  1.55it/s, running training loss:  0.88890]\u001b[A\n",
            "Training:  72%|███████▏  | 1283/1772 [15:18<05:01,  1.62it/s, running training loss:  0.88890]\u001b[A\n",
            "Training:  72%|███████▏  | 1283/1772 [15:18<05:01,  1.62it/s, running training loss:  0.71424]\u001b[A\n",
            "Training:  72%|███████▏  | 1284/1772 [15:18<04:57,  1.64it/s, running training loss:  0.71424]\u001b[A\n",
            "Training:  72%|███████▏  | 1284/1772 [15:19<04:57,  1.64it/s, running training loss:  1.13883]\u001b[A\n",
            "Training:  73%|███████▎  | 1285/1772 [15:19<05:33,  1.46it/s, running training loss:  1.13883]\u001b[A\n",
            "Training:  73%|███████▎  | 1285/1772 [15:20<05:33,  1.46it/s, running training loss:  1.06457]\u001b[A\n",
            "Training:  73%|███████▎  | 1286/1772 [15:20<05:06,  1.59it/s, running training loss:  1.06457]\u001b[A\n",
            "Training:  73%|███████▎  | 1286/1772 [15:20<05:06,  1.59it/s, running training loss:  0.97494]\u001b[A\n",
            "Training:  73%|███████▎  | 1287/1772 [15:20<05:06,  1.58it/s, running training loss:  0.97494]\u001b[A\n",
            "Training:  73%|███████▎  | 1287/1772 [15:21<05:06,  1.58it/s, running training loss:  1.07692]\u001b[A\n",
            "Training:  73%|███████▎  | 1288/1772 [15:21<05:30,  1.46it/s, running training loss:  1.07692]\u001b[A\n",
            "Training:  73%|███████▎  | 1288/1772 [15:22<05:30,  1.46it/s, running training loss:  1.07016]\u001b[A\n",
            "Training:  73%|███████▎  | 1289/1772 [15:22<05:30,  1.46it/s, running training loss:  1.07016]\u001b[A\n",
            "Training:  73%|███████▎  | 1289/1772 [15:22<05:30,  1.46it/s, running training loss:  0.98644]\u001b[A\n",
            "Training:  73%|███████▎  | 1290/1772 [15:22<05:11,  1.55it/s, running training loss:  0.98644]\u001b[A\n",
            "Training:  73%|███████▎  | 1290/1772 [15:23<05:11,  1.55it/s, running training loss:  1.04550]\u001b[A\n",
            "Training:  73%|███████▎  | 1291/1772 [15:23<05:05,  1.58it/s, running training loss:  1.04550]\u001b[A\n",
            "Training:  73%|███████▎  | 1291/1772 [15:24<05:05,  1.58it/s, running training loss:  1.01374]\u001b[A\n",
            "Training:  73%|███████▎  | 1292/1772 [15:24<05:14,  1.53it/s, running training loss:  1.01374]\u001b[A\n",
            "Training:  73%|███████▎  | 1292/1772 [15:24<05:14,  1.53it/s, running training loss:  1.19149]\u001b[A\n",
            "Training:  73%|███████▎  | 1293/1772 [15:24<05:09,  1.55it/s, running training loss:  1.19149]\u001b[A\n",
            "Training:  73%|███████▎  | 1293/1772 [15:25<05:09,  1.55it/s, running training loss:  1.16086]\u001b[A\n",
            "Training:  73%|███████▎  | 1294/1772 [15:25<05:11,  1.53it/s, running training loss:  1.16086]\u001b[A\n",
            "Training:  73%|███████▎  | 1294/1772 [15:25<05:11,  1.53it/s, running training loss:  0.95943]\u001b[A\n",
            "Training:  73%|███████▎  | 1295/1772 [15:25<04:54,  1.62it/s, running training loss:  0.95943]\u001b[A\n",
            "Training:  73%|███████▎  | 1295/1772 [15:26<04:54,  1.62it/s, running training loss:  0.86832]\u001b[A\n",
            "Training:  73%|███████▎  | 1296/1772 [15:26<04:38,  1.71it/s, running training loss:  0.86832]\u001b[A\n",
            "Training:  73%|███████▎  | 1296/1772 [15:27<04:38,  1.71it/s, running training loss:  0.86351]\u001b[A\n",
            "Training:  73%|███████▎  | 1297/1772 [15:27<05:08,  1.54it/s, running training loss:  0.86351]\u001b[A\n",
            "Training:  73%|███████▎  | 1297/1772 [15:28<05:08,  1.54it/s, running training loss:  0.96041]\u001b[A\n",
            "Training:  73%|███████▎  | 1298/1772 [15:28<05:40,  1.39it/s, running training loss:  0.96041]\u001b[A\n",
            "Training:  73%|███████▎  | 1298/1772 [15:28<05:40,  1.39it/s, running training loss:  0.90537]\u001b[A\n",
            "Training:  73%|███████▎  | 1299/1772 [15:28<05:32,  1.42it/s, running training loss:  0.90537]\u001b[A\n",
            "Training:  73%|███████▎  | 1299/1772 [15:29<05:32,  1.42it/s, running training loss:  1.09014]\u001b[A\n",
            "Training:  73%|███████▎  | 1300/1772 [15:29<05:14,  1.50it/s, running training loss:  1.09014]\u001b[A\n",
            "Training:  73%|███████▎  | 1300/1772 [15:29<05:14,  1.50it/s, running training loss:  0.94959]\u001b[A\n",
            "Training:  73%|███████▎  | 1301/1772 [15:29<04:54,  1.60it/s, running training loss:  0.94959]\u001b[A\n",
            "Training:  73%|███████▎  | 1301/1772 [15:30<04:54,  1.60it/s, running training loss:  0.85766]\u001b[A\n",
            "Training:  73%|███████▎  | 1302/1772 [15:30<04:38,  1.69it/s, running training loss:  0.85766]\u001b[A\n",
            "Training:  73%|███████▎  | 1302/1772 [15:31<04:38,  1.69it/s, running training loss:  1.10626]\u001b[A\n",
            "Training:  74%|███████▎  | 1303/1772 [15:31<05:36,  1.39it/s, running training loss:  1.10626]\u001b[A\n",
            "Training:  74%|███████▎  | 1303/1772 [15:31<05:36,  1.39it/s, running training loss:  0.96493]\u001b[A\n",
            "Training:  74%|███████▎  | 1304/1772 [15:31<05:12,  1.50it/s, running training loss:  0.96493]\u001b[A\n",
            "Training:  74%|███████▎  | 1304/1772 [15:32<05:12,  1.50it/s, running training loss:  1.06930]\u001b[A\n",
            "Training:  74%|███████▎  | 1305/1772 [15:32<05:07,  1.52it/s, running training loss:  1.06930]\u001b[A\n",
            "Training:  74%|███████▎  | 1305/1772 [15:33<05:07,  1.52it/s, running training loss:  1.03590]\u001b[A\n",
            "Training:  74%|███████▎  | 1306/1772 [15:33<04:42,  1.65it/s, running training loss:  1.03590]\u001b[A\n",
            "Training:  74%|███████▎  | 1306/1772 [15:33<04:42,  1.65it/s, running training loss:  1.04642]\u001b[A\n",
            "Training:  74%|███████▍  | 1307/1772 [15:33<04:37,  1.68it/s, running training loss:  1.04642]\u001b[A\n",
            "Training:  74%|███████▍  | 1307/1772 [15:34<04:37,  1.68it/s, running training loss:  0.87641]\u001b[A\n",
            "Training:  74%|███████▍  | 1308/1772 [15:34<04:57,  1.56it/s, running training loss:  0.87641]\u001b[A\n",
            "Training:  74%|███████▍  | 1308/1772 [15:35<04:57,  1.56it/s, running training loss:  1.13570]\u001b[A\n",
            "Training:  74%|███████▍  | 1309/1772 [15:35<05:03,  1.53it/s, running training loss:  1.13570]\u001b[A\n",
            "Training:  74%|███████▍  | 1309/1772 [15:35<05:03,  1.53it/s, running training loss:  0.83124]\u001b[A\n",
            "Training:  74%|███████▍  | 1310/1772 [15:35<04:57,  1.55it/s, running training loss:  0.83124]\u001b[A\n",
            "Training:  74%|███████▍  | 1310/1772 [15:36<04:57,  1.55it/s, running training loss:  0.89794]\u001b[A\n",
            "Training:  74%|███████▍  | 1311/1772 [15:36<04:47,  1.61it/s, running training loss:  0.89794]\u001b[A\n",
            "Training:  74%|███████▍  | 1311/1772 [15:36<04:47,  1.61it/s, running training loss:  0.87714]\u001b[A\n",
            "Training:  74%|███████▍  | 1312/1772 [15:36<04:46,  1.61it/s, running training loss:  0.87714]\u001b[A\n",
            "Training:  74%|███████▍  | 1312/1772 [15:37<04:46,  1.61it/s, running training loss:  0.91765]\u001b[A\n",
            "Training:  74%|███████▍  | 1313/1772 [15:37<05:26,  1.40it/s, running training loss:  0.91765]\u001b[A\n",
            "Training:  74%|███████▍  | 1313/1772 [15:38<05:26,  1.40it/s, running training loss:  0.78877]\u001b[A\n",
            "Training:  74%|███████▍  | 1314/1772 [15:38<05:57,  1.28it/s, running training loss:  0.78877]\u001b[A\n",
            "Training:  74%|███████▍  | 1314/1772 [15:39<05:57,  1.28it/s, running training loss:  0.84498]\u001b[A\n",
            "Training:  74%|███████▍  | 1315/1772 [15:39<05:22,  1.42it/s, running training loss:  0.84498]\u001b[A\n",
            "Training:  74%|███████▍  | 1315/1772 [15:40<05:22,  1.42it/s, running training loss:  0.82519]\u001b[A\n",
            "Training:  74%|███████▍  | 1316/1772 [15:40<05:48,  1.31it/s, running training loss:  0.82519]\u001b[A\n",
            "Training:  74%|███████▍  | 1316/1772 [15:40<05:48,  1.31it/s, running training loss:  0.94132]\u001b[A\n",
            "Training:  74%|███████▍  | 1317/1772 [15:40<05:17,  1.43it/s, running training loss:  0.94132]\u001b[A\n",
            "Training:  74%|███████▍  | 1317/1772 [15:41<05:17,  1.43it/s, running training loss:  1.02102]\u001b[A\n",
            "Training:  74%|███████▍  | 1318/1772 [15:41<04:59,  1.51it/s, running training loss:  1.02102]\u001b[A\n",
            "Training:  74%|███████▍  | 1318/1772 [15:41<04:59,  1.51it/s, running training loss:  0.98308]\u001b[A\n",
            "Training:  74%|███████▍  | 1319/1772 [15:41<04:35,  1.64it/s, running training loss:  0.98308]\u001b[A\n",
            "Training:  74%|███████▍  | 1319/1772 [15:42<04:35,  1.64it/s, running training loss:  1.05660]\u001b[A\n",
            "Training:  74%|███████▍  | 1320/1772 [15:42<04:27,  1.69it/s, running training loss:  1.05660]\u001b[A\n",
            "Training:  74%|███████▍  | 1320/1772 [15:42<04:27,  1.69it/s, running training loss:  0.91708]\u001b[A\n",
            "Training:  75%|███████▍  | 1321/1772 [15:42<04:29,  1.67it/s, running training loss:  0.91708]\u001b[A\n",
            "Training:  75%|███████▍  | 1321/1772 [15:43<04:29,  1.67it/s, running training loss:  1.23752]\u001b[A\n",
            "Training:  75%|███████▍  | 1322/1772 [15:43<04:40,  1.61it/s, running training loss:  1.23752]\u001b[A\n",
            "Training:  75%|███████▍  | 1322/1772 [15:44<04:40,  1.61it/s, running training loss:  1.12763]\u001b[A\n",
            "Training:  75%|███████▍  | 1323/1772 [15:44<04:28,  1.68it/s, running training loss:  1.12763]\u001b[A\n",
            "Training:  75%|███████▍  | 1323/1772 [15:44<04:28,  1.68it/s, running training loss:  1.29306]\u001b[A\n",
            "Training:  75%|███████▍  | 1324/1772 [15:44<04:20,  1.72it/s, running training loss:  1.29306]\u001b[A\n",
            "Training:  75%|███████▍  | 1324/1772 [15:45<04:20,  1.72it/s, running training loss:  1.18515]\u001b[A\n",
            "Training:  75%|███████▍  | 1325/1772 [15:45<04:26,  1.67it/s, running training loss:  1.18515]\u001b[A\n",
            "Training:  75%|███████▍  | 1325/1772 [15:45<04:26,  1.67it/s, running training loss:  1.15735]\u001b[A\n",
            "Training:  75%|███████▍  | 1326/1772 [15:45<04:22,  1.70it/s, running training loss:  1.15735]\u001b[A\n",
            "Training:  75%|███████▍  | 1326/1772 [15:46<04:22,  1.70it/s, running training loss:  1.06183]\u001b[A\n",
            "Training:  75%|███████▍  | 1327/1772 [15:46<04:21,  1.70it/s, running training loss:  1.06183]\u001b[A\n",
            "Training:  75%|███████▍  | 1327/1772 [15:47<04:21,  1.70it/s, running training loss:  1.36793]\u001b[A\n",
            "Training:  75%|███████▍  | 1328/1772 [15:47<04:42,  1.57it/s, running training loss:  1.36793]\u001b[A\n",
            "Training:  75%|███████▍  | 1328/1772 [15:47<04:42,  1.57it/s, running training loss:  1.22841]\u001b[A\n",
            "Training:  75%|███████▌  | 1329/1772 [15:47<04:35,  1.61it/s, running training loss:  1.22841]\u001b[A\n",
            "Training:  75%|███████▌  | 1329/1772 [15:48<04:35,  1.61it/s, running training loss:  0.94943]\u001b[A\n",
            "Training:  75%|███████▌  | 1330/1772 [15:48<04:15,  1.73it/s, running training loss:  0.94943]\u001b[A\n",
            "Training:  75%|███████▌  | 1330/1772 [15:48<04:15,  1.73it/s, running training loss:  0.90862]\u001b[A\n",
            "Training:  75%|███████▌  | 1331/1772 [15:48<04:10,  1.76it/s, running training loss:  0.90862]\u001b[A\n",
            "Training:  75%|███████▌  | 1331/1772 [15:49<04:10,  1.76it/s, running training loss:  0.76185]\u001b[A\n",
            "Training:  75%|███████▌  | 1332/1772 [15:49<04:05,  1.79it/s, running training loss:  0.76185]\u001b[A\n",
            "Training:  75%|███████▌  | 1332/1772 [15:49<04:05,  1.79it/s, running training loss:  1.01723]\u001b[A\n",
            "Training:  75%|███████▌  | 1333/1772 [15:49<04:07,  1.77it/s, running training loss:  1.01723]\u001b[A\n",
            "Training:  75%|███████▌  | 1333/1772 [15:50<04:07,  1.77it/s, running training loss:  0.88354]\u001b[A\n",
            "Training:  75%|███████▌  | 1334/1772 [15:50<04:23,  1.66it/s, running training loss:  0.88354]\u001b[A\n",
            "Training:  75%|███████▌  | 1334/1772 [15:51<04:23,  1.66it/s, running training loss:  0.79440]\u001b[A\n",
            "Training:  75%|███████▌  | 1335/1772 [15:51<04:33,  1.60it/s, running training loss:  0.79440]\u001b[A\n",
            "Training:  75%|███████▌  | 1335/1772 [15:51<04:33,  1.60it/s, running training loss:  0.83148]\u001b[A\n",
            "Training:  75%|███████▌  | 1336/1772 [15:51<04:23,  1.66it/s, running training loss:  0.83148]\u001b[A\n",
            "Training:  75%|███████▌  | 1336/1772 [15:52<04:23,  1.66it/s, running training loss:  0.76415]\u001b[A\n",
            "Training:  75%|███████▌  | 1337/1772 [15:52<04:15,  1.71it/s, running training loss:  0.76415]\u001b[A\n",
            "Training:  75%|███████▌  | 1337/1772 [15:53<04:15,  1.71it/s, running training loss:  1.18053]\u001b[A\n",
            "Training:  76%|███████▌  | 1338/1772 [15:53<04:23,  1.65it/s, running training loss:  1.18053]\u001b[A\n",
            "Training:  76%|███████▌  | 1338/1772 [15:53<04:23,  1.65it/s, running training loss:  1.06376]\u001b[A\n",
            "Training:  76%|███████▌  | 1339/1772 [15:53<04:26,  1.62it/s, running training loss:  1.06376]\u001b[A\n",
            "Training:  76%|███████▌  | 1339/1772 [15:54<04:26,  1.62it/s, running training loss:  1.11313]\u001b[A\n",
            "Training:  76%|███████▌  | 1340/1772 [15:54<04:14,  1.70it/s, running training loss:  1.11313]\u001b[A\n",
            "Training:  76%|███████▌  | 1340/1772 [15:54<04:14,  1.70it/s, running training loss:  1.06743]\u001b[A\n",
            "Training:  76%|███████▌  | 1341/1772 [15:54<04:32,  1.58it/s, running training loss:  1.06743]\u001b[A\n",
            "Training:  76%|███████▌  | 1341/1772 [15:55<04:32,  1.58it/s, running training loss:  1.05848]\u001b[A\n",
            "Training:  76%|███████▌  | 1342/1772 [15:55<04:34,  1.56it/s, running training loss:  1.05848]\u001b[A\n",
            "Training:  76%|███████▌  | 1342/1772 [15:56<04:34,  1.56it/s, running training loss:  1.28453]\u001b[A\n",
            "Training:  76%|███████▌  | 1343/1772 [15:56<04:42,  1.52it/s, running training loss:  1.28453]\u001b[A\n",
            "Training:  76%|███████▌  | 1343/1772 [15:56<04:42,  1.52it/s, running training loss:  0.93929]\u001b[A\n",
            "Training:  76%|███████▌  | 1344/1772 [15:56<04:32,  1.57it/s, running training loss:  0.93929]\u001b[A\n",
            "Training:  76%|███████▌  | 1344/1772 [15:57<04:32,  1.57it/s, running training loss:  1.03019]\u001b[A\n",
            "Training:  76%|███████▌  | 1345/1772 [15:57<04:07,  1.73it/s, running training loss:  1.03019]\u001b[A\n",
            "Training:  76%|███████▌  | 1345/1772 [15:57<04:07,  1.73it/s, running training loss:  1.02365]\u001b[A\n",
            "Training:  76%|███████▌  | 1346/1772 [15:58<04:15,  1.67it/s, running training loss:  1.02365]\u001b[A\n",
            "Training:  76%|███████▌  | 1346/1772 [15:58<04:15,  1.67it/s, running training loss:  0.82948]\u001b[A\n",
            "Training:  76%|███████▌  | 1347/1772 [15:58<04:13,  1.68it/s, running training loss:  0.82948]\u001b[A\n",
            "Training:  76%|███████▌  | 1347/1772 [15:59<04:13,  1.68it/s, running training loss:  0.88641]\u001b[A\n",
            "Training:  76%|███████▌  | 1348/1772 [15:59<04:07,  1.71it/s, running training loss:  0.88641]\u001b[A\n",
            "Training:  76%|███████▌  | 1348/1772 [15:59<04:07,  1.71it/s, running training loss:  0.91070]\u001b[A\n",
            "Training:  76%|███████▌  | 1349/1772 [15:59<04:00,  1.76it/s, running training loss:  0.91070]\u001b[A\n",
            "Training:  76%|███████▌  | 1349/1772 [16:00<04:00,  1.76it/s, running training loss:  0.87398]\u001b[A\n",
            "Training:  76%|███████▌  | 1350/1772 [16:00<04:35,  1.53it/s, running training loss:  0.87398]\u001b[A\n",
            "Training:  76%|███████▌  | 1350/1772 [16:01<04:35,  1.53it/s, running training loss:  0.79336]\u001b[A\n",
            "Training:  76%|███████▌  | 1351/1772 [16:01<04:18,  1.63it/s, running training loss:  0.79336]\u001b[A\n",
            "Training:  76%|███████▌  | 1351/1772 [16:01<04:18,  1.63it/s, running training loss:  0.88833]\u001b[A\n",
            "Training:  76%|███████▋  | 1352/1772 [16:01<04:26,  1.58it/s, running training loss:  0.88833]\u001b[A\n",
            "Training:  76%|███████▋  | 1352/1772 [16:02<04:26,  1.58it/s, running training loss:  0.79892]\u001b[A\n",
            "Training:  76%|███████▋  | 1353/1772 [16:02<04:18,  1.62it/s, running training loss:  0.79892]\u001b[A\n",
            "Training:  76%|███████▋  | 1353/1772 [16:02<04:18,  1.62it/s, running training loss:  1.02705]\u001b[A\n",
            "Training:  76%|███████▋  | 1354/1772 [16:02<04:10,  1.67it/s, running training loss:  1.02705]\u001b[A\n",
            "Training:  76%|███████▋  | 1354/1772 [16:03<04:10,  1.67it/s, running training loss:  0.95074]\u001b[A\n",
            "Training:  76%|███████▋  | 1355/1772 [16:03<04:20,  1.60it/s, running training loss:  0.95074]\u001b[A\n",
            "Training:  76%|███████▋  | 1355/1772 [16:04<04:20,  1.60it/s, running training loss:  1.20527]\u001b[A\n",
            "Training:  77%|███████▋  | 1356/1772 [16:04<04:14,  1.64it/s, running training loss:  1.20527]\u001b[A\n",
            "Training:  77%|███████▋  | 1356/1772 [16:04<04:14,  1.64it/s, running training loss:  1.30284]\u001b[A\n",
            "Training:  77%|███████▋  | 1357/1772 [16:04<04:11,  1.65it/s, running training loss:  1.30284]\u001b[A\n",
            "Training:  77%|███████▋  | 1357/1772 [16:05<04:11,  1.65it/s, running training loss:  0.93332]\u001b[A\n",
            "Training:  77%|███████▋  | 1358/1772 [16:05<04:15,  1.62it/s, running training loss:  0.93332]\u001b[A\n",
            "Training:  77%|███████▋  | 1358/1772 [16:06<04:15,  1.62it/s, running training loss:  1.15071]\u001b[A\n",
            "Training:  77%|███████▋  | 1359/1772 [16:06<04:19,  1.59it/s, running training loss:  1.15071]\u001b[A\n",
            "Training:  77%|███████▋  | 1359/1772 [16:06<04:19,  1.59it/s, running training loss:  0.94485]\u001b[A\n",
            "Training:  77%|███████▋  | 1360/1772 [16:06<04:14,  1.62it/s, running training loss:  0.94485]\u001b[A\n",
            "Training:  77%|███████▋  | 1360/1772 [16:07<04:14,  1.62it/s, running training loss:  0.96562]\u001b[A\n",
            "Training:  77%|███████▋  | 1361/1772 [16:07<04:07,  1.66it/s, running training loss:  0.96562]\u001b[A\n",
            "Training:  77%|███████▋  | 1361/1772 [16:07<04:07,  1.66it/s, running training loss:  1.05954]\u001b[A\n",
            "Training:  77%|███████▋  | 1362/1772 [16:07<04:03,  1.68it/s, running training loss:  1.05954]\u001b[A\n",
            "Training:  77%|███████▋  | 1362/1772 [16:08<04:03,  1.68it/s, running training loss:  1.02368]\u001b[A\n",
            "Training:  77%|███████▋  | 1363/1772 [16:08<04:05,  1.67it/s, running training loss:  1.02368]\u001b[A\n",
            "Training:  77%|███████▋  | 1363/1772 [16:08<04:05,  1.67it/s, running training loss:  0.78908]\u001b[A\n",
            "Training:  77%|███████▋  | 1364/1772 [16:08<03:56,  1.72it/s, running training loss:  0.78908]\u001b[A\n",
            "Training:  77%|███████▋  | 1364/1772 [16:09<03:56,  1.72it/s, running training loss:  1.18239]\u001b[A\n",
            "Training:  77%|███████▋  | 1365/1772 [16:09<04:16,  1.59it/s, running training loss:  1.18239]\u001b[A\n",
            "Training:  77%|███████▋  | 1365/1772 [16:10<04:16,  1.59it/s, running training loss:  0.69724]\u001b[A\n",
            "Training:  77%|███████▋  | 1366/1772 [16:10<04:12,  1.61it/s, running training loss:  0.69724]\u001b[A\n",
            "Training:  77%|███████▋  | 1366/1772 [16:10<04:12,  1.61it/s, running training loss:  0.79685]\u001b[A\n",
            "Training:  77%|███████▋  | 1367/1772 [16:11<04:25,  1.53it/s, running training loss:  0.79685]\u001b[A\n",
            "Training:  77%|███████▋  | 1367/1772 [16:11<04:25,  1.53it/s, running training loss:  1.07249]\u001b[A\n",
            "Training:  77%|███████▋  | 1368/1772 [16:11<04:18,  1.56it/s, running training loss:  1.07249]\u001b[A\n",
            "Training:  77%|███████▋  | 1368/1772 [16:12<04:18,  1.56it/s, running training loss:  0.96177]\u001b[A\n",
            "Training:  77%|███████▋  | 1369/1772 [16:12<04:47,  1.40it/s, running training loss:  0.96177]\u001b[A\n",
            "Training:  77%|███████▋  | 1369/1772 [16:13<04:47,  1.40it/s, running training loss:  0.78948]\u001b[A\n",
            "Training:  77%|███████▋  | 1370/1772 [16:13<04:28,  1.50it/s, running training loss:  0.78948]\u001b[A\n",
            "Training:  77%|███████▋  | 1370/1772 [16:13<04:28,  1.50it/s, running training loss:  0.92774]\u001b[A\n",
            "Training:  77%|███████▋  | 1371/1772 [16:13<04:23,  1.52it/s, running training loss:  0.92774]\u001b[A\n",
            "Training:  77%|███████▋  | 1371/1772 [16:14<04:23,  1.52it/s, running training loss:  0.86399]\u001b[A\n",
            "Training:  77%|███████▋  | 1372/1772 [16:14<05:02,  1.32it/s, running training loss:  0.86399]\u001b[A\n",
            "Training:  77%|███████▋  | 1372/1772 [16:15<05:02,  1.32it/s, running training loss:  0.98641]\u001b[A\n",
            "Training:  77%|███████▋  | 1373/1772 [16:15<04:47,  1.39it/s, running training loss:  0.98641]\u001b[A\n",
            "Training:  77%|███████▋  | 1373/1772 [16:15<04:47,  1.39it/s, running training loss:  0.83198]\u001b[A\n",
            "Training:  78%|███████▊  | 1374/1772 [16:15<04:18,  1.54it/s, running training loss:  0.83198]\u001b[A\n",
            "Training:  78%|███████▊  | 1374/1772 [16:16<04:18,  1.54it/s, running training loss:  0.98410]\u001b[A\n",
            "Training:  78%|███████▊  | 1375/1772 [16:16<04:13,  1.56it/s, running training loss:  0.98410]\u001b[A\n",
            "Training:  78%|███████▊  | 1375/1772 [16:16<04:13,  1.56it/s, running training loss:  0.82118]\u001b[A\n",
            "Training:  78%|███████▊  | 1376/1772 [16:16<04:05,  1.61it/s, running training loss:  0.82118]\u001b[A\n",
            "Training:  78%|███████▊  | 1376/1772 [16:17<04:05,  1.61it/s, running training loss:  1.06105]\u001b[A\n",
            "Training:  78%|███████▊  | 1377/1772 [16:17<04:08,  1.59it/s, running training loss:  1.06105]\u001b[A\n",
            "Training:  78%|███████▊  | 1377/1772 [16:18<04:08,  1.59it/s, running training loss:  1.20502]\u001b[A\n",
            "Training:  78%|███████▊  | 1378/1772 [16:18<04:43,  1.39it/s, running training loss:  1.20502]\u001b[A\n",
            "Training:  78%|███████▊  | 1378/1772 [16:19<04:43,  1.39it/s, running training loss:  1.32445]\u001b[A\n",
            "Training:  78%|███████▊  | 1379/1772 [16:19<04:35,  1.42it/s, running training loss:  1.32445]\u001b[A\n",
            "Training:  78%|███████▊  | 1379/1772 [16:19<04:35,  1.42it/s, running training loss:  0.91104]\u001b[A\n",
            "Training:  78%|███████▊  | 1380/1772 [16:19<04:27,  1.46it/s, running training loss:  0.91104]\u001b[A\n",
            "Training:  78%|███████▊  | 1380/1772 [16:20<04:27,  1.46it/s, running training loss:  1.33570]\u001b[A\n",
            "Training:  78%|███████▊  | 1381/1772 [16:20<04:35,  1.42it/s, running training loss:  1.33570]\u001b[A\n",
            "Training:  78%|███████▊  | 1381/1772 [16:21<04:35,  1.42it/s, running training loss:  1.42934]\u001b[A\n",
            "Training:  78%|███████▊  | 1382/1772 [16:21<04:13,  1.54it/s, running training loss:  1.42934]\u001b[A\n",
            "Training:  78%|███████▊  | 1382/1772 [16:21<04:13,  1.54it/s, running training loss:  1.41673]\u001b[A\n",
            "Training:  78%|███████▊  | 1383/1772 [16:21<04:05,  1.59it/s, running training loss:  1.41673]\u001b[A\n",
            "Training:  78%|███████▊  | 1383/1772 [16:22<04:05,  1.59it/s, running training loss:  1.09021]\u001b[A\n",
            "Training:  78%|███████▊  | 1384/1772 [16:22<04:07,  1.57it/s, running training loss:  1.09021]\u001b[A\n",
            "Training:  78%|███████▊  | 1384/1772 [16:22<04:07,  1.57it/s, running training loss:  1.09292]\u001b[A\n",
            "Training:  78%|███████▊  | 1385/1772 [16:22<03:48,  1.69it/s, running training loss:  1.09292]\u001b[A\n",
            "Training:  78%|███████▊  | 1385/1772 [16:23<03:48,  1.69it/s, running training loss:  1.16432]\u001b[A\n",
            "Training:  78%|███████▊  | 1386/1772 [16:23<03:43,  1.73it/s, running training loss:  1.16432]\u001b[A\n",
            "Training:  78%|███████▊  | 1386/1772 [16:24<03:43,  1.73it/s, running training loss:  1.20447]\u001b[A\n",
            "Training:  78%|███████▊  | 1387/1772 [16:24<03:48,  1.69it/s, running training loss:  1.20447]\u001b[A\n",
            "Training:  78%|███████▊  | 1387/1772 [16:24<03:48,  1.69it/s, running training loss:  0.84246]\u001b[A\n",
            "Training:  78%|███████▊  | 1388/1772 [16:24<03:43,  1.72it/s, running training loss:  0.84246]\u001b[A\n",
            "Training:  78%|███████▊  | 1388/1772 [16:25<03:43,  1.72it/s, running training loss:  0.92345]\u001b[A\n",
            "Training:  78%|███████▊  | 1389/1772 [16:25<03:49,  1.67it/s, running training loss:  0.92345]\u001b[A\n",
            "Training:  78%|███████▊  | 1389/1772 [16:25<03:49,  1.67it/s, running training loss:  0.71886]\u001b[A\n",
            "Training:  78%|███████▊  | 1390/1772 [16:25<03:54,  1.63it/s, running training loss:  0.71886]\u001b[A\n",
            "Training:  78%|███████▊  | 1390/1772 [16:26<03:54,  1.63it/s, running training loss:  0.79180]\u001b[A\n",
            "Training:  78%|███████▊  | 1391/1772 [16:26<03:36,  1.76it/s, running training loss:  0.79180]\u001b[A\n",
            "Training:  78%|███████▊  | 1391/1772 [16:26<03:36,  1.76it/s, running training loss:  1.09478]\u001b[A\n",
            "Training:  79%|███████▊  | 1392/1772 [16:26<03:33,  1.78it/s, running training loss:  1.09478]\u001b[A\n",
            "Training:  79%|███████▊  | 1392/1772 [16:27<03:33,  1.78it/s, running training loss:  0.96709]\u001b[A\n",
            "Training:  79%|███████▊  | 1393/1772 [16:27<03:39,  1.73it/s, running training loss:  0.96709]\u001b[A\n",
            "Training:  79%|███████▊  | 1393/1772 [16:28<03:39,  1.73it/s, running training loss:  0.80175]\u001b[A\n",
            "Training:  79%|███████▊  | 1394/1772 [16:28<04:05,  1.54it/s, running training loss:  0.80175]\u001b[A\n",
            "Training:  79%|███████▊  | 1394/1772 [16:28<04:05,  1.54it/s, running training loss:  0.97627]\u001b[A\n",
            "Training:  79%|███████▊  | 1395/1772 [16:28<03:51,  1.63it/s, running training loss:  0.97627]\u001b[A\n",
            "Training:  79%|███████▊  | 1395/1772 [16:29<03:51,  1.63it/s, running training loss:  1.01719]\u001b[A\n",
            "Training:  79%|███████▉  | 1396/1772 [16:29<03:45,  1.66it/s, running training loss:  1.01719]\u001b[A\n",
            "Training:  79%|███████▉  | 1396/1772 [16:29<03:45,  1.66it/s, running training loss:  1.10573]\u001b[A\n",
            "Training:  79%|███████▉  | 1397/1772 [16:29<03:38,  1.71it/s, running training loss:  1.10573]\u001b[A\n",
            "Training:  79%|███████▉  | 1397/1772 [16:30<03:38,  1.71it/s, running training loss:  1.01604]\u001b[A\n",
            "Training:  79%|███████▉  | 1398/1772 [16:30<03:34,  1.75it/s, running training loss:  1.01604]\u001b[A\n",
            "Training:  79%|███████▉  | 1398/1772 [16:31<03:34,  1.75it/s, running training loss:  0.92918]\u001b[A\n",
            "Training:  79%|███████▉  | 1399/1772 [16:31<03:38,  1.71it/s, running training loss:  0.92918]\u001b[A\n",
            "Training:  79%|███████▉  | 1399/1772 [16:31<03:38,  1.71it/s, running training loss:  0.76391]\u001b[A\n",
            "Training:  79%|███████▉  | 1400/1772 [16:31<03:39,  1.69it/s, running training loss:  0.76391]\u001b[A\n",
            "Training:  79%|███████▉  | 1400/1772 [16:32<03:39,  1.69it/s, running training loss:  0.79895]\u001b[A\n",
            "Training:  79%|███████▉  | 1401/1772 [16:32<03:43,  1.66it/s, running training loss:  0.79895]\u001b[A\n",
            "Training:  79%|███████▉  | 1401/1772 [16:33<03:43,  1.66it/s, running training loss:  0.81586]\u001b[A\n",
            "Training:  79%|███████▉  | 1402/1772 [16:33<03:55,  1.57it/s, running training loss:  0.81586]\u001b[A\n",
            "Training:  79%|███████▉  | 1402/1772 [16:33<03:55,  1.57it/s, running training loss:  0.69354]\u001b[A\n",
            "Training:  79%|███████▉  | 1403/1772 [16:33<03:47,  1.62it/s, running training loss:  0.69354]\u001b[A\n",
            "Training:  79%|███████▉  | 1403/1772 [16:34<03:47,  1.62it/s, running training loss:  0.78132]\u001b[A\n",
            "Training:  79%|███████▉  | 1404/1772 [16:34<03:46,  1.62it/s, running training loss:  0.78132]\u001b[A\n",
            "Training:  79%|███████▉  | 1404/1772 [16:35<03:46,  1.62it/s, running training loss:  0.99416]\u001b[A\n",
            "Training:  79%|███████▉  | 1405/1772 [16:35<04:19,  1.42it/s, running training loss:  0.99416]\u001b[A\n",
            "Training:  79%|███████▉  | 1405/1772 [16:35<04:19,  1.42it/s, running training loss:  1.02565]\u001b[A\n",
            "Training:  79%|███████▉  | 1406/1772 [16:35<04:00,  1.52it/s, running training loss:  1.02565]\u001b[A\n",
            "Training:  79%|███████▉  | 1406/1772 [16:36<04:00,  1.52it/s, running training loss:  1.04916]\u001b[A\n",
            "Training:  79%|███████▉  | 1407/1772 [16:36<04:10,  1.46it/s, running training loss:  1.04916]\u001b[A\n",
            "Training:  79%|███████▉  | 1407/1772 [16:37<04:10,  1.46it/s, running training loss:  0.86571]\u001b[A\n",
            "Training:  79%|███████▉  | 1408/1772 [16:37<04:12,  1.44it/s, running training loss:  0.86571]\u001b[A\n",
            "Training:  79%|███████▉  | 1408/1772 [16:37<04:12,  1.44it/s, running training loss:  0.98354]\u001b[A\n",
            "Training:  80%|███████▉  | 1409/1772 [16:37<04:17,  1.41it/s, running training loss:  0.98354]\u001b[A\n",
            "Training:  80%|███████▉  | 1409/1772 [16:38<04:17,  1.41it/s, running training loss:  0.88401]\u001b[A\n",
            "Training:  80%|███████▉  | 1410/1772 [16:38<04:33,  1.32it/s, running training loss:  0.88401]\u001b[A\n",
            "Training:  80%|███████▉  | 1410/1772 [16:39<04:33,  1.32it/s, running training loss:  1.00290]\u001b[A\n",
            "Training:  80%|███████▉  | 1411/1772 [16:39<04:05,  1.47it/s, running training loss:  1.00290]\u001b[A\n",
            "Training:  80%|███████▉  | 1411/1772 [16:40<04:05,  1.47it/s, running training loss:  0.96021]\u001b[A\n",
            "Training:  80%|███████▉  | 1412/1772 [16:40<04:08,  1.45it/s, running training loss:  0.96021]\u001b[A\n",
            "Training:  80%|███████▉  | 1412/1772 [16:40<04:08,  1.45it/s, running training loss:  1.00062]\u001b[A\n",
            "Training:  80%|███████▉  | 1413/1772 [16:40<04:08,  1.44it/s, running training loss:  1.00062]\u001b[A\n",
            "Training:  80%|███████▉  | 1413/1772 [16:41<04:08,  1.44it/s, running training loss:  0.97068]\u001b[A\n",
            "Training:  80%|███████▉  | 1414/1772 [16:41<03:56,  1.51it/s, running training loss:  0.97068]\u001b[A\n",
            "Training:  80%|███████▉  | 1414/1772 [16:41<03:56,  1.51it/s, running training loss:  0.65343]\u001b[A\n",
            "Training:  80%|███████▉  | 1415/1772 [16:41<03:42,  1.60it/s, running training loss:  0.65343]\u001b[A\n",
            "Training:  80%|███████▉  | 1415/1772 [16:42<03:42,  1.60it/s, running training loss:  1.21856]\u001b[A\n",
            "Training:  80%|███████▉  | 1416/1772 [16:42<03:36,  1.65it/s, running training loss:  1.21856]\u001b[A\n",
            "Training:  80%|███████▉  | 1416/1772 [16:42<03:36,  1.65it/s, running training loss:  0.99589]\u001b[A\n",
            "Training:  80%|███████▉  | 1417/1772 [16:42<03:33,  1.67it/s, running training loss:  0.99589]\u001b[A\n",
            "Training:  80%|███████▉  | 1417/1772 [16:43<03:33,  1.67it/s, running training loss:  0.92110]\u001b[A\n",
            "Training:  80%|████████  | 1418/1772 [16:43<03:24,  1.73it/s, running training loss:  0.92110]\u001b[A\n",
            "Training:  80%|████████  | 1418/1772 [16:44<03:24,  1.73it/s, running training loss:  0.77033]\u001b[A\n",
            "Training:  80%|████████  | 1419/1772 [16:44<03:28,  1.69it/s, running training loss:  0.77033]\u001b[A\n",
            "Training:  80%|████████  | 1419/1772 [16:44<03:28,  1.69it/s, running training loss:  0.73548]\u001b[A\n",
            "Training:  80%|████████  | 1420/1772 [16:44<03:28,  1.69it/s, running training loss:  0.73548]\u001b[A\n",
            "Training:  80%|████████  | 1420/1772 [16:45<03:28,  1.69it/s, running training loss:  1.04752]\u001b[A\n",
            "Training:  80%|████████  | 1421/1772 [16:45<03:29,  1.67it/s, running training loss:  1.04752]\u001b[A\n",
            "Training:  80%|████████  | 1421/1772 [16:45<03:29,  1.67it/s, running training loss:  0.75480]\u001b[A\n",
            "Training:  80%|████████  | 1422/1772 [16:45<03:34,  1.64it/s, running training loss:  0.75480]\u001b[A\n",
            "Training:  80%|████████  | 1422/1772 [16:46<03:34,  1.64it/s, running training loss:  0.75310]\u001b[A\n",
            "Training:  80%|████████  | 1423/1772 [16:46<03:51,  1.51it/s, running training loss:  0.75310]\u001b[A\n",
            "Training:  80%|████████  | 1423/1772 [16:47<03:51,  1.51it/s, running training loss:  0.91407]\u001b[A\n",
            "Training:  80%|████████  | 1424/1772 [16:47<03:48,  1.52it/s, running training loss:  0.91407]\u001b[A\n",
            "Training:  80%|████████  | 1424/1772 [16:48<03:48,  1.52it/s, running training loss:  0.95841]\u001b[A\n",
            "Training:  80%|████████  | 1425/1772 [16:48<03:42,  1.56it/s, running training loss:  0.95841]\u001b[A\n",
            "Training:  80%|████████  | 1425/1772 [16:48<03:42,  1.56it/s, running training loss:  1.21407]\u001b[A\n",
            "Training:  80%|████████  | 1426/1772 [16:48<04:01,  1.43it/s, running training loss:  1.21407]\u001b[A\n",
            "Training:  80%|████████  | 1426/1772 [16:49<04:01,  1.43it/s, running training loss:  1.10696]\u001b[A\n",
            "Training:  81%|████████  | 1427/1772 [16:49<03:55,  1.47it/s, running training loss:  1.10696]\u001b[A\n",
            "Training:  81%|████████  | 1427/1772 [16:50<03:55,  1.47it/s, running training loss:  1.06072]\u001b[A\n",
            "Training:  81%|████████  | 1428/1772 [16:50<03:42,  1.55it/s, running training loss:  1.06072]\u001b[A\n",
            "Training:  81%|████████  | 1428/1772 [16:50<03:42,  1.55it/s, running training loss:  0.84276]\u001b[A\n",
            "Training:  81%|████████  | 1429/1772 [16:50<03:28,  1.65it/s, running training loss:  0.84276]\u001b[A\n",
            "Training:  81%|████████  | 1429/1772 [16:51<03:28,  1.65it/s, running training loss:  1.09511]\u001b[A\n",
            "Training:  81%|████████  | 1430/1772 [16:51<03:21,  1.70it/s, running training loss:  1.09511]\u001b[A\n",
            "Training:  81%|████████  | 1430/1772 [16:51<03:21,  1.70it/s, running training loss:  1.27094]\u001b[A\n",
            "Training:  81%|████████  | 1431/1772 [16:51<03:23,  1.67it/s, running training loss:  1.27094]\u001b[A\n",
            "Training:  81%|████████  | 1431/1772 [16:52<03:23,  1.67it/s, running training loss:  1.05018]\u001b[A\n",
            "Training:  81%|████████  | 1432/1772 [16:52<03:07,  1.81it/s, running training loss:  1.05018]\u001b[A\n",
            "Training:  81%|████████  | 1432/1772 [16:53<03:07,  1.81it/s, running training loss:  0.95637]\u001b[A\n",
            "Training:  81%|████████  | 1433/1772 [16:53<03:56,  1.43it/s, running training loss:  0.95637]\u001b[A\n",
            "Training:  81%|████████  | 1433/1772 [16:53<03:56,  1.43it/s, running training loss:  0.86844]\u001b[A\n",
            "Training:  81%|████████  | 1434/1772 [16:53<03:41,  1.52it/s, running training loss:  0.86844]\u001b[A\n",
            "Training:  81%|████████  | 1434/1772 [16:54<03:41,  1.52it/s, running training loss:  0.82801]\u001b[A\n",
            "Training:  81%|████████  | 1435/1772 [16:54<03:29,  1.61it/s, running training loss:  0.82801]\u001b[A\n",
            "Training:  81%|████████  | 1435/1772 [16:55<03:29,  1.61it/s, running training loss:  0.78470]\u001b[A\n",
            "Training:  81%|████████  | 1436/1772 [16:55<03:40,  1.53it/s, running training loss:  0.78470]\u001b[A\n",
            "Training:  81%|████████  | 1436/1772 [16:55<03:40,  1.53it/s, running training loss:  0.83852]\u001b[A\n",
            "Training:  81%|████████  | 1437/1772 [16:55<03:22,  1.65it/s, running training loss:  0.83852]\u001b[A\n",
            "Training:  81%|████████  | 1437/1772 [16:56<03:22,  1.65it/s, running training loss:  0.71689]\u001b[A\n",
            "Training:  81%|████████  | 1438/1772 [16:56<03:42,  1.50it/s, running training loss:  0.71689]\u001b[A\n",
            "Training:  81%|████████  | 1438/1772 [16:56<03:42,  1.50it/s, running training loss:  0.95033]\u001b[A\n",
            "Training:  81%|████████  | 1439/1772 [16:56<03:29,  1.59it/s, running training loss:  0.95033]\u001b[A\n",
            "Training:  81%|████████  | 1439/1772 [16:57<03:29,  1.59it/s, running training loss:  1.07045]\u001b[A\n",
            "Training:  81%|████████▏ | 1440/1772 [16:57<03:13,  1.72it/s, running training loss:  1.07045]\u001b[A\n",
            "Training:  81%|████████▏ | 1440/1772 [16:57<03:13,  1.72it/s, running training loss:  0.82334]\u001b[A\n",
            "Training:  81%|████████▏ | 1441/1772 [16:57<03:11,  1.72it/s, running training loss:  0.82334]\u001b[A\n",
            "Training:  81%|████████▏ | 1441/1772 [16:58<03:11,  1.72it/s, running training loss:  0.68730]\u001b[A\n",
            "Training:  81%|████████▏ | 1442/1772 [16:58<03:49,  1.44it/s, running training loss:  0.68730]\u001b[A\n",
            "Training:  81%|████████▏ | 1442/1772 [16:59<03:49,  1.44it/s, running training loss:  1.01161]\u001b[A\n",
            "Training:  81%|████████▏ | 1443/1772 [16:59<03:47,  1.45it/s, running training loss:  1.01161]\u001b[A\n",
            "Training:  81%|████████▏ | 1443/1772 [17:00<03:47,  1.45it/s, running training loss:  1.07526]\u001b[A\n",
            "Training:  81%|████████▏ | 1444/1772 [17:00<03:34,  1.53it/s, running training loss:  1.07526]\u001b[A\n",
            "Training:  81%|████████▏ | 1444/1772 [17:00<03:34,  1.53it/s, running training loss:  0.91547]\u001b[A\n",
            "Training:  82%|████████▏ | 1445/1772 [17:00<03:27,  1.57it/s, running training loss:  0.91547]\u001b[A\n",
            "Training:  82%|████████▏ | 1445/1772 [17:01<03:27,  1.57it/s, running training loss:  0.95627]\u001b[A\n",
            "Training:  82%|████████▏ | 1446/1772 [17:01<03:23,  1.61it/s, running training loss:  0.95627]\u001b[A\n",
            "Training:  82%|████████▏ | 1446/1772 [17:01<03:23,  1.61it/s, running training loss:  1.33330]\u001b[A\n",
            "Training:  82%|████████▏ | 1447/1772 [17:01<03:20,  1.62it/s, running training loss:  1.33330]\u001b[A\n",
            "Training:  82%|████████▏ | 1447/1772 [17:02<03:20,  1.62it/s, running training loss:  0.99070]\u001b[A\n",
            "Training:  82%|████████▏ | 1448/1772 [17:02<03:16,  1.65it/s, running training loss:  0.99070]\u001b[A\n",
            "Training:  82%|████████▏ | 1448/1772 [17:03<03:16,  1.65it/s, running training loss:  1.28371]\u001b[A\n",
            "Training:  82%|████████▏ | 1449/1772 [17:03<03:43,  1.45it/s, running training loss:  1.28371]\u001b[A\n",
            "Training:  82%|████████▏ | 1449/1772 [17:03<03:43,  1.45it/s, running training loss:  0.81182]\u001b[A\n",
            "Training:  82%|████████▏ | 1450/1772 [17:03<03:23,  1.58it/s, running training loss:  0.81182]\u001b[A\n",
            "Training:  82%|████████▏ | 1450/1772 [17:04<03:23,  1.58it/s, running training loss:  1.12827]\u001b[A\n",
            "Training:  82%|████████▏ | 1451/1772 [17:04<03:25,  1.56it/s, running training loss:  1.12827]\u001b[A\n",
            "Training:  82%|████████▏ | 1451/1772 [17:05<03:25,  1.56it/s, running training loss:  1.18902]\u001b[A\n",
            "Training:  82%|████████▏ | 1452/1772 [17:05<03:10,  1.68it/s, running training loss:  1.18902]\u001b[A\n",
            "Training:  82%|████████▏ | 1452/1772 [17:05<03:10,  1.68it/s, running training loss:  1.12617]\u001b[A\n",
            "Training:  82%|████████▏ | 1453/1772 [17:05<03:22,  1.57it/s, running training loss:  1.12617]\u001b[A\n",
            "Training:  82%|████████▏ | 1453/1772 [17:06<03:22,  1.57it/s, running training loss:  1.15383]\u001b[A\n",
            "Training:  82%|████████▏ | 1454/1772 [17:06<03:11,  1.66it/s, running training loss:  1.15383]\u001b[A\n",
            "Training:  82%|████████▏ | 1454/1772 [17:06<03:11,  1.66it/s, running training loss:  0.82078]\u001b[A\n",
            "Training:  82%|████████▏ | 1455/1772 [17:06<02:59,  1.77it/s, running training loss:  0.82078]\u001b[A\n",
            "Training:  82%|████████▏ | 1455/1772 [17:07<02:59,  1.77it/s, running training loss:  0.75120]\u001b[A\n",
            "Training:  82%|████████▏ | 1456/1772 [17:07<02:50,  1.85it/s, running training loss:  0.75120]\u001b[A\n",
            "Training:  82%|████████▏ | 1456/1772 [17:07<02:50,  1.85it/s, running training loss:  1.03964]\u001b[A\n",
            "Training:  82%|████████▏ | 1457/1772 [17:07<02:58,  1.76it/s, running training loss:  1.03964]\u001b[A\n",
            "Training:  82%|████████▏ | 1457/1772 [17:08<02:58,  1.76it/s, running training loss:  0.89302]\u001b[A\n",
            "Training:  82%|████████▏ | 1458/1772 [17:08<03:02,  1.72it/s, running training loss:  0.89302]\u001b[A\n",
            "Training:  82%|████████▏ | 1458/1772 [17:09<03:02,  1.72it/s, running training loss:  0.93087]\u001b[A\n",
            "Training:  82%|████████▏ | 1459/1772 [17:09<03:09,  1.65it/s, running training loss:  0.93087]\u001b[A\n",
            "Training:  82%|████████▏ | 1459/1772 [17:09<03:09,  1.65it/s, running training loss:  0.67772]\u001b[A\n",
            "Training:  82%|████████▏ | 1460/1772 [17:09<03:03,  1.70it/s, running training loss:  0.67772]\u001b[A\n",
            "Training:  82%|████████▏ | 1460/1772 [17:10<03:03,  1.70it/s, running training loss:  0.68311]\u001b[A\n",
            "Training:  82%|████████▏ | 1461/1772 [17:10<03:15,  1.59it/s, running training loss:  0.68311]\u001b[A\n",
            "Training:  82%|████████▏ | 1461/1772 [17:11<03:15,  1.59it/s, running training loss:  0.88765]\u001b[A\n",
            "Training:  83%|████████▎ | 1462/1772 [17:11<03:18,  1.56it/s, running training loss:  0.88765]\u001b[A\n",
            "Training:  83%|████████▎ | 1462/1772 [17:11<03:18,  1.56it/s, running training loss:  0.86641]\u001b[A\n",
            "Training:  83%|████████▎ | 1463/1772 [17:11<03:14,  1.59it/s, running training loss:  0.86641]\u001b[A\n",
            "Training:  83%|████████▎ | 1463/1772 [17:12<03:14,  1.59it/s, running training loss:  0.88317]\u001b[A\n",
            "Training:  83%|████████▎ | 1464/1772 [17:12<03:00,  1.71it/s, running training loss:  0.88317]\u001b[A\n",
            "Training:  83%|████████▎ | 1464/1772 [17:12<03:00,  1.71it/s, running training loss:  0.79188]\u001b[A\n",
            "Training:  83%|████████▎ | 1465/1772 [17:12<03:02,  1.68it/s, running training loss:  0.79188]\u001b[A\n",
            "Training:  83%|████████▎ | 1465/1772 [17:13<03:02,  1.68it/s, running training loss:  0.80818]\u001b[A\n",
            "Training:  83%|████████▎ | 1466/1772 [17:13<02:56,  1.73it/s, running training loss:  0.80818]\u001b[A\n",
            "Training:  83%|████████▎ | 1466/1772 [17:13<02:56,  1.73it/s, running training loss:  1.03884]\u001b[A\n",
            "Training:  83%|████████▎ | 1467/1772 [17:13<02:59,  1.70it/s, running training loss:  1.03884]\u001b[A\n",
            "Training:  83%|████████▎ | 1467/1772 [17:14<02:59,  1.70it/s, running training loss:  1.35323]\u001b[A\n",
            "Training:  83%|████████▎ | 1468/1772 [17:14<03:06,  1.63it/s, running training loss:  1.35323]\u001b[A\n",
            "Training:  83%|████████▎ | 1468/1772 [17:15<03:06,  1.63it/s, running training loss:  1.55243]\u001b[A\n",
            "Training:  83%|████████▎ | 1469/1772 [17:15<03:05,  1.63it/s, running training loss:  1.55243]\u001b[A\n",
            "Training:  83%|████████▎ | 1469/1772 [17:15<03:05,  1.63it/s, running training loss:  1.30486]\u001b[A\n",
            "Training:  83%|████████▎ | 1470/1772 [17:15<02:59,  1.69it/s, running training loss:  1.30486]\u001b[A\n",
            "Training:  83%|████████▎ | 1470/1772 [17:16<02:59,  1.69it/s, running training loss:  0.97084]\u001b[A\n",
            "Training:  83%|████████▎ | 1471/1772 [17:16<02:54,  1.72it/s, running training loss:  0.97084]\u001b[A\n",
            "Training:  83%|████████▎ | 1471/1772 [17:17<02:54,  1.72it/s, running training loss:  0.88389]\u001b[A\n",
            "Training:  83%|████████▎ | 1472/1772 [17:17<03:02,  1.64it/s, running training loss:  0.88389]\u001b[A\n",
            "Training:  83%|████████▎ | 1472/1772 [17:17<03:02,  1.64it/s, running training loss:  1.31984]\u001b[A\n",
            "Training:  83%|████████▎ | 1473/1772 [17:17<02:54,  1.71it/s, running training loss:  1.31984]\u001b[A\n",
            "Training:  83%|████████▎ | 1473/1772 [17:18<02:54,  1.71it/s, running training loss:  1.06470]\u001b[A\n",
            "Training:  83%|████████▎ | 1474/1772 [17:18<02:48,  1.77it/s, running training loss:  1.06470]\u001b[A\n",
            "Training:  83%|████████▎ | 1474/1772 [17:18<02:48,  1.77it/s, running training loss:  1.01382]\u001b[A\n",
            "Training:  83%|████████▎ | 1475/1772 [17:18<02:55,  1.69it/s, running training loss:  1.01382]\u001b[A\n",
            "Training:  83%|████████▎ | 1475/1772 [17:19<02:55,  1.69it/s, running training loss:  1.22097]\u001b[A\n",
            "Training:  83%|████████▎ | 1476/1772 [17:19<02:52,  1.71it/s, running training loss:  1.22097]\u001b[A\n",
            "Training:  83%|████████▎ | 1476/1772 [17:19<02:52,  1.71it/s, running training loss:  0.68904]\u001b[A\n",
            "Training:  83%|████████▎ | 1477/1772 [17:19<02:47,  1.76it/s, running training loss:  0.68904]\u001b[A\n",
            "Training:  83%|████████▎ | 1477/1772 [17:20<02:47,  1.76it/s, running training loss:  0.69083]\u001b[A\n",
            "Training:  83%|████████▎ | 1478/1772 [17:20<02:45,  1.78it/s, running training loss:  0.69083]\u001b[A\n",
            "Training:  83%|████████▎ | 1478/1772 [17:21<02:45,  1.78it/s, running training loss:  0.76495]\u001b[A\n",
            "Training:  83%|████████▎ | 1479/1772 [17:21<02:53,  1.68it/s, running training loss:  0.76495]\u001b[A\n",
            "Training:  83%|████████▎ | 1479/1772 [17:21<02:53,  1.68it/s, running training loss:  0.71168]\u001b[A\n",
            "Training:  84%|████████▎ | 1480/1772 [17:21<02:58,  1.64it/s, running training loss:  0.71168]\u001b[A\n",
            "Training:  84%|████████▎ | 1480/1772 [17:22<02:58,  1.64it/s, running training loss:  0.90453]\u001b[A\n",
            "Training:  84%|████████▎ | 1481/1772 [17:22<03:00,  1.61it/s, running training loss:  0.90453]\u001b[A\n",
            "Training:  84%|████████▎ | 1481/1772 [17:23<03:00,  1.61it/s, running training loss:  0.67048]\u001b[A\n",
            "Training:  84%|████████▎ | 1482/1772 [17:23<03:12,  1.51it/s, running training loss:  0.67048]\u001b[A\n",
            "Training:  84%|████████▎ | 1482/1772 [17:23<03:12,  1.51it/s, running training loss:  0.85148]\u001b[A\n",
            "Training:  84%|████████▎ | 1483/1772 [17:23<03:04,  1.56it/s, running training loss:  0.85148]\u001b[A\n",
            "Training:  84%|████████▎ | 1483/1772 [17:24<03:04,  1.56it/s, running training loss:  0.99292]\u001b[A\n",
            "Training:  84%|████████▎ | 1484/1772 [17:24<02:58,  1.61it/s, running training loss:  0.99292]\u001b[A\n",
            "Training:  84%|████████▎ | 1484/1772 [17:24<02:58,  1.61it/s, running training loss:  0.93933]\u001b[A\n",
            "Training:  84%|████████▍ | 1485/1772 [17:24<02:57,  1.61it/s, running training loss:  0.93933]\u001b[A\n",
            "Training:  84%|████████▍ | 1485/1772 [17:25<02:57,  1.61it/s, running training loss:  1.15039]\u001b[A\n",
            "Training:  84%|████████▍ | 1486/1772 [17:25<02:48,  1.70it/s, running training loss:  1.15039]\u001b[A\n",
            "Training:  84%|████████▍ | 1486/1772 [17:25<02:48,  1.70it/s, running training loss:  1.33359]\u001b[A\n",
            "Training:  84%|████████▍ | 1487/1772 [17:25<02:37,  1.81it/s, running training loss:  1.33359]\u001b[A\n",
            "Training:  84%|████████▍ | 1487/1772 [17:26<02:37,  1.81it/s, running training loss:  0.94695]\u001b[A\n",
            "Training:  84%|████████▍ | 1488/1772 [17:26<03:00,  1.58it/s, running training loss:  0.94695]\u001b[A\n",
            "Training:  84%|████████▍ | 1488/1772 [17:27<03:00,  1.58it/s, running training loss:  1.18750]\u001b[A\n",
            "Training:  84%|████████▍ | 1489/1772 [17:27<02:59,  1.57it/s, running training loss:  1.18750]\u001b[A\n",
            "Training:  84%|████████▍ | 1489/1772 [17:27<02:59,  1.57it/s, running training loss:  0.86771]\u001b[A\n",
            "Training:  84%|████████▍ | 1490/1772 [17:28<03:02,  1.54it/s, running training loss:  0.86771]\u001b[A\n",
            "Training:  84%|████████▍ | 1490/1772 [17:28<03:02,  1.54it/s, running training loss:  0.93310]\u001b[A\n",
            "Training:  84%|████████▍ | 1491/1772 [17:28<02:57,  1.59it/s, running training loss:  0.93310]\u001b[A\n",
            "Training:  84%|████████▍ | 1491/1772 [17:29<02:57,  1.59it/s, running training loss:  0.96291]\u001b[A\n",
            "Training:  84%|████████▍ | 1492/1772 [17:29<02:46,  1.68it/s, running training loss:  0.96291]\u001b[A\n",
            "Training:  84%|████████▍ | 1492/1772 [17:29<02:46,  1.68it/s, running training loss:  1.07028]\u001b[A\n",
            "Training:  84%|████████▍ | 1493/1772 [17:29<02:49,  1.65it/s, running training loss:  1.07028]\u001b[A\n",
            "Training:  84%|████████▍ | 1493/1772 [17:30<02:49,  1.65it/s, running training loss:  0.95788]\u001b[A\n",
            "Training:  84%|████████▍ | 1494/1772 [17:30<02:41,  1.72it/s, running training loss:  0.95788]\u001b[A\n",
            "Training:  84%|████████▍ | 1494/1772 [17:30<02:41,  1.72it/s, running training loss:  0.92121]\u001b[A\n",
            "Training:  84%|████████▍ | 1495/1772 [17:30<02:38,  1.75it/s, running training loss:  0.92121]\u001b[A\n",
            "Training:  84%|████████▍ | 1495/1772 [17:31<02:38,  1.75it/s, running training loss:  0.74043]\u001b[A\n",
            "Training:  84%|████████▍ | 1496/1772 [17:31<02:57,  1.55it/s, running training loss:  0.74043]\u001b[A\n",
            "Training:  84%|████████▍ | 1496/1772 [17:32<02:57,  1.55it/s, running training loss:  1.10275]\u001b[A\n",
            "Training:  84%|████████▍ | 1497/1772 [17:32<02:57,  1.55it/s, running training loss:  1.10275]\u001b[A\n",
            "Training:  84%|████████▍ | 1497/1772 [17:32<02:57,  1.55it/s, running training loss:  0.84502]\u001b[A\n",
            "Training:  85%|████████▍ | 1498/1772 [17:32<02:57,  1.55it/s, running training loss:  0.84502]\u001b[A\n",
            "Training:  85%|████████▍ | 1498/1772 [17:33<02:57,  1.55it/s, running training loss:  0.80839]\u001b[A\n",
            "Training:  85%|████████▍ | 1499/1772 [17:33<02:56,  1.55it/s, running training loss:  0.80839]\u001b[A\n",
            "Training:  85%|████████▍ | 1499/1772 [17:34<02:56,  1.55it/s, running training loss:  0.94809]\u001b[A\n",
            "\n",
            "Evaluation:   0%|          | 0/270 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   0%|          | 1/270 [00:00<01:39,  2.70it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   1%|          | 2/270 [00:00<01:02,  4.30it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   1%|          | 3/270 [00:00<00:47,  5.62it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   1%|▏         | 4/270 [00:00<00:41,  6.47it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   2%|▏         | 5/270 [00:00<00:36,  7.18it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   2%|▏         | 6/270 [00:00<00:34,  7.58it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   3%|▎         | 8/270 [00:01<00:29,  8.90it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   3%|▎         | 9/270 [00:01<00:29,  8.76it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   4%|▍         | 11/270 [00:01<00:26,  9.76it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   5%|▍         | 13/270 [00:01<00:26,  9.84it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   5%|▌         | 14/270 [00:01<00:27,  9.25it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   6%|▌         | 16/270 [00:01<00:27,  9.36it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   6%|▋         | 17/270 [00:02<00:28,  9.03it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   7%|▋         | 19/270 [00:02<00:26,  9.32it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   7%|▋         | 20/270 [00:02<00:27,  9.09it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   8%|▊         | 22/270 [00:02<00:24, 10.25it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:   9%|▉         | 24/270 [00:02<00:22, 10.77it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  10%|▉         | 26/270 [00:02<00:23, 10.57it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  10%|█         | 28/270 [00:03<00:23, 10.26it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  11%|█         | 30/270 [00:03<00:24,  9.65it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  11%|█▏        | 31/270 [00:03<00:25,  9.37it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  12%|█▏        | 33/270 [00:03<00:24,  9.63it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  13%|█▎        | 35/270 [00:03<00:24,  9.63it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  14%|█▎        | 37/270 [00:04<00:22, 10.33it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  14%|█▍        | 39/270 [00:04<00:22, 10.20it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  15%|█▌        | 41/270 [00:04<00:22, 10.19it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  16%|█▌        | 43/270 [00:04<00:23,  9.57it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  16%|█▋        | 44/270 [00:04<00:23,  9.48it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  17%|█▋        | 46/270 [00:05<00:23,  9.55it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  18%|█▊        | 48/270 [00:05<00:21, 10.12it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  19%|█▊        | 50/270 [00:05<00:22,  9.69it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  19%|█▉        | 51/270 [00:05<00:24,  9.10it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  20%|█▉        | 53/270 [00:05<00:23,  9.42it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  20%|██        | 55/270 [00:05<00:21,  9.88it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  21%|██        | 56/270 [00:06<00:22,  9.49it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  21%|██        | 57/270 [00:06<00:23,  9.14it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  21%|██▏       | 58/270 [00:06<00:23,  8.91it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  22%|██▏       | 59/270 [00:06<00:24,  8.69it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  23%|██▎       | 61/270 [00:06<00:22,  9.23it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  23%|██▎       | 62/270 [00:06<00:23,  8.99it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  23%|██▎       | 63/270 [00:06<00:23,  8.84it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  24%|██▍       | 65/270 [00:07<00:20,  9.86it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  24%|██▍       | 66/270 [00:07<00:20,  9.82it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  25%|██▍       | 67/270 [00:07<00:21,  9.62it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  26%|██▌       | 69/270 [00:07<00:19, 10.52it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  26%|██▋       | 71/270 [00:07<00:18, 10.72it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  27%|██▋       | 73/270 [00:07<00:19, 10.36it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  28%|██▊       | 75/270 [00:08<00:18, 10.49it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  29%|██▊       | 77/270 [00:08<00:18, 10.35it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  29%|██▉       | 79/270 [00:08<00:18, 10.21it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  30%|███       | 81/270 [00:08<00:19,  9.83it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  30%|███       | 82/270 [00:08<00:19,  9.49it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  31%|███       | 83/270 [00:08<00:20,  9.30it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  31%|███       | 84/270 [00:08<00:19,  9.43it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  31%|███▏      | 85/270 [00:09<00:19,  9.27it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  32%|███▏      | 87/270 [00:09<00:18,  9.80it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  33%|███▎      | 88/270 [00:09<00:19,  9.58it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  33%|███▎      | 89/270 [00:09<00:19,  9.23it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  33%|███▎      | 90/270 [00:09<00:19,  9.27it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  34%|███▎      | 91/270 [00:09<00:20,  8.81it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  34%|███▍      | 93/270 [00:09<00:18,  9.76it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  35%|███▌      | 95/270 [00:10<00:17, 10.18it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  36%|███▌      | 96/270 [00:10<00:17, 10.09it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  36%|███▋      | 98/270 [00:10<00:16, 10.40it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  37%|███▋      | 100/270 [00:10<00:16, 10.21it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  38%|███▊      | 102/270 [00:10<00:15, 10.51it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  39%|███▊      | 104/270 [00:10<00:16, 10.26it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  39%|███▉      | 106/270 [00:11<00:15, 10.29it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  40%|████      | 108/270 [00:11<00:16,  9.90it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  40%|████      | 109/270 [00:11<00:16,  9.86it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  41%|████      | 110/270 [00:11<00:16,  9.83it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  41%|████      | 111/270 [00:11<00:16,  9.50it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  42%|████▏     | 113/270 [00:11<00:15, 10.08it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  43%|████▎     | 115/270 [00:12<00:15, 10.02it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  43%|████▎     | 116/270 [00:12<00:16,  9.55it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  43%|████▎     | 117/270 [00:12<00:16,  9.29it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  44%|████▍     | 119/270 [00:12<00:15,  9.96it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  44%|████▍     | 120/270 [00:12<00:15,  9.56it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  45%|████▌     | 122/270 [00:12<00:14, 10.21it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  46%|████▌     | 124/270 [00:12<00:13, 10.62it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  47%|████▋     | 126/270 [00:13<00:14,  9.72it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  47%|████▋     | 127/270 [00:13<00:15,  9.24it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  47%|████▋     | 128/270 [00:13<00:15,  8.99it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  48%|████▊     | 129/270 [00:13<00:16,  8.72it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  49%|████▊     | 131/270 [00:13<00:14,  9.67it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  49%|████▉     | 132/270 [00:13<00:15,  9.18it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  49%|████▉     | 133/270 [00:13<00:14,  9.31it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  50%|████▉     | 134/270 [00:14<00:14,  9.18it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  50%|█████     | 135/270 [00:14<00:14,  9.34it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  50%|█████     | 136/270 [00:14<00:14,  9.46it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  51%|█████     | 138/270 [00:14<00:13,  9.78it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  52%|█████▏    | 140/270 [00:14<00:12, 10.02it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  52%|█████▏    | 141/270 [00:14<00:13,  9.42it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  53%|█████▎    | 142/270 [00:14<00:13,  9.18it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  53%|█████▎    | 144/270 [00:15<00:12, 10.19it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  54%|█████▎    | 145/270 [00:15<00:12,  9.81it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  54%|█████▍    | 147/270 [00:15<00:12,  9.83it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  55%|█████▌    | 149/270 [00:15<00:12,  9.97it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  56%|█████▌    | 151/270 [00:15<00:11, 10.04it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  56%|█████▋    | 152/270 [00:15<00:12,  9.61it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  57%|█████▋    | 153/270 [00:16<00:12,  9.41it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  57%|█████▋    | 155/270 [00:16<00:11,  9.59it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  58%|█████▊    | 156/270 [00:16<00:12,  9.19it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  59%|█████▊    | 158/270 [00:16<00:10, 10.35it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  59%|█████▉    | 160/270 [00:16<00:11,  9.66it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  60%|█████▉    | 161/270 [00:16<00:11,  9.41it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  60%|██████    | 162/270 [00:17<00:11,  9.16it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  60%|██████    | 163/270 [00:17<00:11,  9.02it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  61%|██████    | 164/270 [00:17<00:11,  8.91it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  61%|██████    | 165/270 [00:17<00:11,  8.84it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  61%|██████▏   | 166/270 [00:17<00:11,  8.90it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  62%|██████▏   | 168/270 [00:17<00:10,  9.37it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  63%|██████▎   | 169/270 [00:17<00:11,  9.10it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  63%|██████▎   | 170/270 [00:17<00:10,  9.19it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  63%|██████▎   | 171/270 [00:18<00:11,  8.95it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  64%|██████▎   | 172/270 [00:18<00:11,  8.81it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  64%|██████▍   | 173/270 [00:18<00:10,  8.83it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  64%|██████▍   | 174/270 [00:18<00:10,  8.77it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  65%|██████▍   | 175/270 [00:18<00:10,  8.79it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  65%|██████▌   | 176/270 [00:18<00:11,  8.49it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  66%|██████▌   | 177/270 [00:18<00:11,  8.34it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  66%|██████▋   | 179/270 [00:18<00:10,  9.07it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  67%|██████▋   | 180/270 [00:19<00:10,  8.83it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  67%|██████▋   | 182/270 [00:19<00:09,  9.12it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  68%|██████▊   | 183/270 [00:19<00:09,  9.12it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  68%|██████▊   | 184/270 [00:19<00:09,  8.95it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  69%|██████▊   | 185/270 [00:19<00:09,  8.91it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  69%|██████▉   | 187/270 [00:19<00:08,  9.31it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  70%|██████▉   | 188/270 [00:19<00:09,  8.99it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  70%|███████   | 190/270 [00:20<00:07, 10.08it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  71%|███████   | 191/270 [00:20<00:08,  9.79it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  71%|███████   | 192/270 [00:20<00:08,  9.51it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  72%|███████▏  | 194/270 [00:20<00:07,  9.62it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  72%|███████▏  | 195/270 [00:20<00:08,  9.27it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  73%|███████▎  | 196/270 [00:20<00:08,  8.88it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  73%|███████▎  | 198/270 [00:20<00:07,  9.31it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  74%|███████▎  | 199/270 [00:21<00:07,  9.09it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  74%|███████▍  | 200/270 [00:21<00:07,  8.91it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  74%|███████▍  | 201/270 [00:21<00:07,  8.74it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  75%|███████▍  | 202/270 [00:21<00:08,  8.47it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  76%|███████▌  | 204/270 [00:21<00:06,  9.86it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  76%|███████▋  | 206/270 [00:21<00:06, 10.06it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  77%|███████▋  | 207/270 [00:21<00:06,  9.70it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  77%|███████▋  | 208/270 [00:22<00:06,  9.34it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  77%|███████▋  | 209/270 [00:22<00:06,  8.95it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  78%|███████▊  | 210/270 [00:22<00:06,  8.87it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  79%|███████▊  | 212/270 [00:22<00:06,  9.29it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  79%|███████▉  | 213/270 [00:22<00:06,  9.30it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  79%|███████▉  | 214/270 [00:22<00:06,  9.31it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  80%|████████  | 216/270 [00:22<00:05,  9.71it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  81%|████████  | 218/270 [00:23<00:04, 10.48it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  81%|████████▏ | 220/270 [00:23<00:04, 10.27it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  82%|████████▏ | 222/270 [00:23<00:04, 10.89it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  83%|████████▎ | 224/270 [00:23<00:04, 10.95it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  84%|████████▎ | 226/270 [00:23<00:03, 11.06it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  84%|████████▍ | 228/270 [00:24<00:04, 10.23it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  85%|████████▌ | 230/270 [00:24<00:04,  9.61it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  86%|████████▌ | 231/270 [00:24<00:04,  9.33it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  86%|████████▋ | 233/270 [00:24<00:03,  9.97it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  87%|████████▋ | 235/270 [00:24<00:03, 10.52it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  88%|████████▊ | 237/270 [00:24<00:03, 10.49it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  89%|████████▊ | 239/270 [00:25<00:03, 10.18it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  89%|████████▉ | 241/270 [00:25<00:03,  9.48it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  90%|█████████ | 243/270 [00:25<00:02, 10.24it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  91%|█████████ | 245/270 [00:25<00:02,  9.72it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  91%|█████████ | 246/270 [00:25<00:02,  9.26it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  91%|█████████▏| 247/270 [00:25<00:02,  8.94it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  92%|█████████▏| 248/270 [00:26<00:02,  8.82it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  92%|█████████▏| 249/270 [00:26<00:02,  8.76it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  93%|█████████▎| 250/270 [00:26<00:02,  8.46it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  93%|█████████▎| 251/270 [00:26<00:02,  8.31it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  93%|█████████▎| 252/270 [00:26<00:02,  8.47it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  94%|█████████▎| 253/270 [00:26<00:02,  8.47it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  94%|█████████▍| 254/270 [00:26<00:01,  8.48it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  94%|█████████▍| 255/270 [00:26<00:01,  8.39it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  95%|█████████▍| 256/270 [00:27<00:01,  8.32it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  96%|█████████▌| 258/270 [00:27<00:01,  9.40it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  96%|█████████▋| 260/270 [00:27<00:00, 10.01it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  97%|█████████▋| 262/270 [00:27<00:00,  9.84it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  97%|█████████▋| 263/270 [00:27<00:00,  9.41it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  98%|█████████▊| 264/270 [00:27<00:00,  9.19it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  98%|█████████▊| 265/270 [00:28<00:00,  9.05it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  99%|█████████▊| 266/270 [00:28<00:00,  8.80it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  99%|█████████▉| 267/270 [00:28<00:00,  9.09it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation:  99%|█████████▉| 268/270 [00:28<00:00,  8.84it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluation: 100%|██████████| 270/270 [00:28<00:00,  9.41it/s]\n",
            "\n",
            "Training:  85%|████████▍ | 1500/1772 [18:03<42:31,  9.38s/it, running training loss:  0.94809]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            ">>> training loss: 0.978700, valid loss: 0.618604,valid f1: 0.000000, valid acc:0.689991\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  85%|████████▍ | 1500/1772 [18:03<42:31,  9.38s/it, running training loss:  0.89692]\u001b[A\n",
            "Training:  85%|████████▍ | 1501/1772 [18:03<30:25,  6.74s/it, running training loss:  0.89692]\u001b[A\n",
            "Training:  85%|████████▍ | 1501/1772 [18:04<30:25,  6.74s/it, running training loss:  0.56682]\u001b[A\n",
            "Training:  85%|████████▍ | 1502/1772 [18:04<21:56,  4.88s/it, running training loss:  0.56682]\u001b[A\n",
            "Training:  85%|████████▍ | 1502/1772 [18:05<21:56,  4.88s/it, running training loss:  0.92157]\u001b[A\n",
            "Training:  85%|████████▍ | 1503/1772 [18:05<16:12,  3.62s/it, running training loss:  0.92157]\u001b[A\n",
            "Training:  85%|████████▍ | 1503/1772 [18:05<16:12,  3.62s/it, running training loss:  0.70881]\u001b[A\n",
            "Training:  85%|████████▍ | 1504/1772 [18:05<12:03,  2.70s/it, running training loss:  0.70881]\u001b[A\n",
            "Training:  85%|████████▍ | 1504/1772 [18:06<12:03,  2.70s/it, running training loss:  1.14420]\u001b[A\n",
            "Training:  85%|████████▍ | 1505/1772 [18:06<09:06,  2.05s/it, running training loss:  1.14420]\u001b[A\n",
            "Training:  85%|████████▍ | 1505/1772 [18:06<09:06,  2.05s/it, running training loss:  0.92224]\u001b[A\n",
            "Training:  85%|████████▍ | 1506/1772 [18:06<07:05,  1.60s/it, running training loss:  0.92224]\u001b[A\n",
            "Training:  85%|████████▍ | 1506/1772 [18:07<07:05,  1.60s/it, running training loss:  1.02883]\u001b[A\n",
            "Training:  85%|████████▌ | 1507/1772 [18:07<05:48,  1.31s/it, running training loss:  1.02883]\u001b[A\n",
            "Training:  85%|████████▌ | 1507/1772 [18:08<05:48,  1.31s/it, running training loss:  0.62747]\u001b[A\n",
            "Training:  85%|████████▌ | 1508/1772 [18:08<04:55,  1.12s/it, running training loss:  0.62747]\u001b[A\n",
            "Training:  85%|████████▌ | 1508/1772 [18:08<04:55,  1.12s/it, running training loss:  1.02947]\u001b[A\n",
            "Training:  85%|████████▌ | 1509/1772 [18:08<04:15,  1.03it/s, running training loss:  1.02947]\u001b[A\n",
            "Training:  85%|████████▌ | 1509/1772 [18:09<04:15,  1.03it/s, running training loss:  1.13040]\u001b[A\n",
            "Training:  85%|████████▌ | 1510/1772 [18:09<03:44,  1.17it/s, running training loss:  1.13040]\u001b[A\n",
            "Training:  85%|████████▌ | 1510/1772 [18:10<03:44,  1.17it/s, running training loss:  0.73858]\u001b[A\n",
            "Training:  85%|████████▌ | 1511/1772 [18:10<03:38,  1.20it/s, running training loss:  0.73858]\u001b[A\n",
            "Training:  85%|████████▌ | 1511/1772 [18:10<03:38,  1.20it/s, running training loss:  0.73390]\u001b[A\n",
            "Training:  85%|████████▌ | 1512/1772 [18:10<03:09,  1.37it/s, running training loss:  0.73390]\u001b[A\n",
            "Training:  85%|████████▌ | 1512/1772 [18:11<03:09,  1.37it/s, running training loss:  0.82130]\u001b[A\n",
            "Training:  85%|████████▌ | 1513/1772 [18:11<02:49,  1.53it/s, running training loss:  0.82130]\u001b[A\n",
            "Training:  85%|████████▌ | 1513/1772 [18:11<02:49,  1.53it/s, running training loss:  0.90004]\u001b[A\n",
            "Training:  85%|████████▌ | 1514/1772 [18:11<02:39,  1.61it/s, running training loss:  0.90004]\u001b[A\n",
            "Training:  85%|████████▌ | 1514/1772 [18:12<02:39,  1.61it/s, running training loss:  1.40949]\u001b[A\n",
            "Training:  85%|████████▌ | 1515/1772 [18:12<02:36,  1.65it/s, running training loss:  1.40949]\u001b[A\n",
            "Training:  85%|████████▌ | 1515/1772 [18:12<02:36,  1.65it/s, running training loss:  0.73810]\u001b[A\n",
            "Training:  86%|████████▌ | 1516/1772 [18:12<02:33,  1.67it/s, running training loss:  0.73810]\u001b[A\n",
            "Training:  86%|████████▌ | 1516/1772 [18:13<02:33,  1.67it/s, running training loss:  1.30171]\u001b[A\n",
            "Training:  86%|████████▌ | 1517/1772 [18:13<02:28,  1.72it/s, running training loss:  1.30171]\u001b[A\n",
            "Training:  86%|████████▌ | 1517/1772 [18:13<02:28,  1.72it/s, running training loss:  1.21317]\u001b[A\n",
            "Training:  86%|████████▌ | 1518/1772 [18:13<02:32,  1.66it/s, running training loss:  1.21317]\u001b[A\n",
            "Training:  86%|████████▌ | 1518/1772 [18:14<02:32,  1.66it/s, running training loss:  1.20807]\u001b[A\n",
            "Training:  86%|████████▌ | 1519/1772 [18:14<02:29,  1.70it/s, running training loss:  1.20807]\u001b[A\n",
            "Training:  86%|████████▌ | 1519/1772 [18:15<02:29,  1.70it/s, running training loss:  1.26917]\u001b[A\n",
            "Training:  86%|████████▌ | 1520/1772 [18:15<02:27,  1.71it/s, running training loss:  1.26917]\u001b[A\n",
            "Training:  86%|████████▌ | 1520/1772 [18:15<02:27,  1.71it/s, running training loss:  1.28838]\u001b[A\n",
            "Training:  86%|████████▌ | 1521/1772 [18:15<02:26,  1.71it/s, running training loss:  1.28838]\u001b[A\n",
            "Training:  86%|████████▌ | 1521/1772 [18:16<02:26,  1.71it/s, running training loss:  1.21798]\u001b[A\n",
            "Training:  86%|████████▌ | 1522/1772 [18:16<02:26,  1.71it/s, running training loss:  1.21798]\u001b[A\n",
            "Training:  86%|████████▌ | 1522/1772 [18:16<02:26,  1.71it/s, running training loss:  0.87327]\u001b[A\n",
            "Training:  86%|████████▌ | 1523/1772 [18:16<02:30,  1.65it/s, running training loss:  0.87327]\u001b[A\n",
            "Training:  86%|████████▌ | 1523/1772 [18:17<02:30,  1.65it/s, running training loss:  0.83874]\u001b[A\n",
            "Training:  86%|████████▌ | 1524/1772 [18:17<02:26,  1.70it/s, running training loss:  0.83874]\u001b[A\n",
            "Training:  86%|████████▌ | 1524/1772 [18:17<02:26,  1.70it/s, running training loss:  0.86722]\u001b[A\n",
            "Training:  86%|████████▌ | 1525/1772 [18:17<02:23,  1.73it/s, running training loss:  0.86722]\u001b[A\n",
            "Training:  86%|████████▌ | 1525/1772 [18:18<02:23,  1.73it/s, running training loss:  0.82448]\u001b[A\n",
            "Training:  86%|████████▌ | 1526/1772 [18:18<02:45,  1.49it/s, running training loss:  0.82448]\u001b[A\n",
            "Training:  86%|████████▌ | 1526/1772 [18:19<02:45,  1.49it/s, running training loss:  0.91172]\u001b[A\n",
            "Training:  86%|████████▌ | 1527/1772 [18:19<02:35,  1.57it/s, running training loss:  0.91172]\u001b[A\n",
            "Training:  86%|████████▌ | 1527/1772 [18:20<02:35,  1.57it/s, running training loss:  0.68845]\u001b[A\n",
            "Training:  86%|████████▌ | 1528/1772 [18:20<02:33,  1.59it/s, running training loss:  0.68845]\u001b[A\n",
            "Training:  86%|████████▌ | 1528/1772 [18:20<02:33,  1.59it/s, running training loss:  0.78305]\u001b[A\n",
            "Training:  86%|████████▋ | 1529/1772 [18:20<02:24,  1.69it/s, running training loss:  0.78305]\u001b[A\n",
            "Training:  86%|████████▋ | 1529/1772 [18:21<02:24,  1.69it/s, running training loss:  0.69377]\u001b[A\n",
            "Training:  86%|████████▋ | 1530/1772 [18:21<02:37,  1.53it/s, running training loss:  0.69377]\u001b[A\n",
            "Training:  86%|████████▋ | 1530/1772 [18:22<02:37,  1.53it/s, running training loss:  0.67947]\u001b[A\n",
            "Training:  86%|████████▋ | 1531/1772 [18:22<02:52,  1.40it/s, running training loss:  0.67947]\u001b[A\n",
            "Training:  86%|████████▋ | 1531/1772 [18:22<02:52,  1.40it/s, running training loss:  0.83263]\u001b[A\n",
            "Training:  86%|████████▋ | 1532/1772 [18:22<02:40,  1.50it/s, running training loss:  0.83263]\u001b[A\n",
            "Training:  86%|████████▋ | 1532/1772 [18:23<02:40,  1.50it/s, running training loss:  0.92072]\u001b[A\n",
            "Training:  87%|████████▋ | 1533/1772 [18:23<02:38,  1.51it/s, running training loss:  0.92072]\u001b[A\n",
            "Training:  87%|████████▋ | 1533/1772 [18:23<02:38,  1.51it/s, running training loss:  0.92241]\u001b[A\n",
            "Training:  87%|████████▋ | 1534/1772 [18:23<02:30,  1.59it/s, running training loss:  0.92241]\u001b[A\n",
            "Training:  87%|████████▋ | 1534/1772 [18:24<02:30,  1.59it/s, running training loss:  1.36854]\u001b[A\n",
            "Training:  87%|████████▋ | 1535/1772 [18:24<02:34,  1.53it/s, running training loss:  1.36854]\u001b[A\n",
            "Training:  87%|████████▋ | 1535/1772 [18:25<02:34,  1.53it/s, running training loss:  1.12806]\u001b[A\n",
            "Training:  87%|████████▋ | 1536/1772 [18:25<02:53,  1.36it/s, running training loss:  1.12806]\u001b[A\n",
            "Training:  87%|████████▋ | 1536/1772 [18:26<02:53,  1.36it/s, running training loss:  1.26826]\u001b[A\n",
            "Training:  87%|████████▋ | 1537/1772 [18:26<02:39,  1.47it/s, running training loss:  1.26826]\u001b[A\n",
            "Training:  87%|████████▋ | 1537/1772 [18:26<02:39,  1.47it/s, running training loss:  1.16712]\u001b[A\n",
            "Training:  87%|████████▋ | 1538/1772 [18:26<02:29,  1.56it/s, running training loss:  1.16712]\u001b[A\n",
            "Training:  87%|████████▋ | 1538/1772 [18:27<02:29,  1.56it/s, running training loss:  1.32670]\u001b[A\n",
            "Training:  87%|████████▋ | 1539/1772 [18:27<02:32,  1.53it/s, running training loss:  1.32670]\u001b[A\n",
            "Training:  87%|████████▋ | 1539/1772 [18:28<02:32,  1.53it/s, running training loss:  0.98354]\u001b[A\n",
            "Training:  87%|████████▋ | 1540/1772 [18:28<02:31,  1.53it/s, running training loss:  0.98354]\u001b[A\n",
            "Training:  87%|████████▋ | 1540/1772 [18:28<02:31,  1.53it/s, running training loss:  0.89322]\u001b[A\n",
            "Training:  87%|████████▋ | 1541/1772 [18:28<02:37,  1.46it/s, running training loss:  0.89322]\u001b[A\n",
            "Training:  87%|████████▋ | 1541/1772 [18:29<02:37,  1.46it/s, running training loss:  1.29627]\u001b[A\n",
            "Training:  87%|████████▋ | 1542/1772 [18:29<02:38,  1.46it/s, running training loss:  1.29627]\u001b[A\n",
            "Training:  87%|████████▋ | 1542/1772 [18:29<02:38,  1.46it/s, running training loss:  1.03607]\u001b[A\n",
            "Training:  87%|████████▋ | 1543/1772 [18:29<02:25,  1.57it/s, running training loss:  1.03607]\u001b[A\n",
            "Training:  87%|████████▋ | 1543/1772 [18:30<02:25,  1.57it/s, running training loss:  0.72228]\u001b[A\n",
            "Training:  87%|████████▋ | 1544/1772 [18:30<02:34,  1.47it/s, running training loss:  0.72228]\u001b[A\n",
            "Training:  87%|████████▋ | 1544/1772 [18:31<02:34,  1.47it/s, running training loss:  0.91570]\u001b[A\n",
            "Training:  87%|████████▋ | 1545/1772 [18:31<02:26,  1.55it/s, running training loss:  0.91570]\u001b[A\n",
            "Training:  87%|████████▋ | 1545/1772 [18:31<02:26,  1.55it/s, running training loss:  0.90135]\u001b[A\n",
            "Training:  87%|████████▋ | 1546/1772 [18:31<02:24,  1.57it/s, running training loss:  0.90135]\u001b[A\n",
            "Training:  87%|████████▋ | 1546/1772 [18:32<02:24,  1.57it/s, running training loss:  0.94687]\u001b[A\n",
            "Training:  87%|████████▋ | 1547/1772 [18:32<02:25,  1.55it/s, running training loss:  0.94687]\u001b[A\n",
            "Training:  87%|████████▋ | 1547/1772 [18:33<02:25,  1.55it/s, running training loss:  0.68220]\u001b[A\n",
            "Training:  87%|████████▋ | 1548/1772 [18:33<02:29,  1.50it/s, running training loss:  0.68220]\u001b[A\n",
            "Training:  87%|████████▋ | 1548/1772 [18:33<02:29,  1.50it/s, running training loss:  0.80529]\u001b[A\n",
            "Training:  87%|████████▋ | 1549/1772 [18:33<02:24,  1.54it/s, running training loss:  0.80529]\u001b[A\n",
            "Training:  87%|████████▋ | 1549/1772 [18:34<02:24,  1.54it/s, running training loss:  0.87033]\u001b[A\n",
            "Training:  87%|████████▋ | 1550/1772 [18:34<02:16,  1.63it/s, running training loss:  0.87033]\u001b[A\n",
            "Training:  87%|████████▋ | 1550/1772 [18:35<02:16,  1.63it/s, running training loss:  0.70223]\u001b[A\n",
            "Training:  88%|████████▊ | 1551/1772 [18:35<02:20,  1.57it/s, running training loss:  0.70223]\u001b[A\n",
            "Training:  88%|████████▊ | 1551/1772 [18:35<02:20,  1.57it/s, running training loss:  0.84297]\u001b[A\n",
            "Training:  88%|████████▊ | 1552/1772 [18:35<02:30,  1.46it/s, running training loss:  0.84297]\u001b[A\n",
            "Training:  88%|████████▊ | 1552/1772 [18:36<02:30,  1.46it/s, running training loss:  0.66315]\u001b[A\n",
            "Training:  88%|████████▊ | 1553/1772 [18:36<02:38,  1.38it/s, running training loss:  0.66315]\u001b[A\n",
            "Training:  88%|████████▊ | 1553/1772 [18:37<02:38,  1.38it/s, running training loss:  1.17375]\u001b[A\n",
            "Training:  88%|████████▊ | 1554/1772 [18:37<02:22,  1.53it/s, running training loss:  1.17375]\u001b[A\n",
            "Training:  88%|████████▊ | 1554/1772 [18:37<02:22,  1.53it/s, running training loss:  0.58598]\u001b[A\n",
            "Training:  88%|████████▊ | 1555/1772 [18:37<02:23,  1.51it/s, running training loss:  0.58598]\u001b[A\n",
            "Training:  88%|████████▊ | 1555/1772 [18:38<02:23,  1.51it/s, running training loss:  1.21468]\u001b[A\n",
            "Training:  88%|████████▊ | 1556/1772 [18:38<02:48,  1.28it/s, running training loss:  1.21468]\u001b[A\n",
            "Training:  88%|████████▊ | 1556/1772 [18:39<02:48,  1.28it/s, running training loss:  1.08131]\u001b[A\n",
            "Training:  88%|████████▊ | 1557/1772 [18:39<02:30,  1.43it/s, running training loss:  1.08131]\u001b[A\n",
            "Training:  88%|████████▊ | 1557/1772 [18:40<02:30,  1.43it/s, running training loss:  1.01656]\u001b[A\n",
            "Training:  88%|████████▊ | 1558/1772 [18:40<02:43,  1.31it/s, running training loss:  1.01656]\u001b[A\n",
            "Training:  88%|████████▊ | 1558/1772 [18:41<02:43,  1.31it/s, running training loss:  1.15712]\u001b[A\n",
            "Training:  88%|████████▊ | 1559/1772 [18:41<02:33,  1.39it/s, running training loss:  1.15712]\u001b[A\n",
            "Training:  88%|████████▊ | 1559/1772 [18:41<02:33,  1.39it/s, running training loss:  0.91544]\u001b[A\n",
            "Training:  88%|████████▊ | 1560/1772 [18:41<02:27,  1.43it/s, running training loss:  0.91544]\u001b[A\n",
            "Training:  88%|████████▊ | 1560/1772 [18:42<02:27,  1.43it/s, running training loss:  0.97839]\u001b[A\n",
            "Training:  88%|████████▊ | 1561/1772 [18:42<02:20,  1.50it/s, running training loss:  0.97839]\u001b[A\n",
            "Training:  88%|████████▊ | 1561/1772 [18:42<02:20,  1.50it/s, running training loss:  1.12031]\u001b[A\n",
            "Training:  88%|████████▊ | 1562/1772 [18:42<02:16,  1.54it/s, running training loss:  1.12031]\u001b[A\n",
            "Training:  88%|████████▊ | 1562/1772 [18:43<02:16,  1.54it/s, running training loss:  1.25175]\u001b[A\n",
            "Training:  88%|████████▊ | 1563/1772 [18:43<02:12,  1.58it/s, running training loss:  1.25175]\u001b[A\n",
            "Training:  88%|████████▊ | 1563/1772 [18:44<02:12,  1.58it/s, running training loss:  0.89534]\u001b[A\n",
            "Training:  88%|████████▊ | 1564/1772 [18:44<02:09,  1.61it/s, running training loss:  0.89534]\u001b[A\n",
            "Training:  88%|████████▊ | 1564/1772 [18:44<02:09,  1.61it/s, running training loss:  0.76522]\u001b[A\n",
            "Training:  88%|████████▊ | 1565/1772 [18:44<02:02,  1.69it/s, running training loss:  0.76522]\u001b[A\n",
            "Training:  88%|████████▊ | 1565/1772 [18:45<02:02,  1.69it/s, running training loss:  0.62833]\u001b[A\n",
            "Training:  88%|████████▊ | 1566/1772 [18:45<02:03,  1.67it/s, running training loss:  0.62833]\u001b[A\n",
            "Training:  88%|████████▊ | 1566/1772 [18:45<02:03,  1.67it/s, running training loss:  0.99147]\u001b[A\n",
            "Training:  88%|████████▊ | 1567/1772 [18:45<02:00,  1.70it/s, running training loss:  0.99147]\u001b[A\n",
            "Training:  88%|████████▊ | 1567/1772 [18:46<02:00,  1.70it/s, running training loss:  0.85436]\u001b[A\n",
            "Training:  88%|████████▊ | 1568/1772 [18:46<02:01,  1.67it/s, running training loss:  0.85436]\u001b[A\n",
            "Training:  88%|████████▊ | 1568/1772 [18:47<02:01,  1.67it/s, running training loss:  0.75211]\u001b[A\n",
            "Training:  89%|████████▊ | 1569/1772 [18:47<02:07,  1.59it/s, running training loss:  0.75211]\u001b[A\n",
            "Training:  89%|████████▊ | 1569/1772 [18:47<02:07,  1.59it/s, running training loss:  0.82091]\u001b[A\n",
            "Training:  89%|████████▊ | 1570/1772 [18:47<02:06,  1.59it/s, running training loss:  0.82091]\u001b[A\n",
            "Training:  89%|████████▊ | 1570/1772 [18:48<02:06,  1.59it/s, running training loss:  1.17548]\u001b[A\n",
            "Training:  89%|████████▊ | 1571/1772 [18:48<02:17,  1.46it/s, running training loss:  1.17548]\u001b[A\n",
            "Training:  89%|████████▊ | 1571/1772 [18:49<02:17,  1.46it/s, running training loss:  0.79813]\u001b[A\n",
            "Training:  89%|████████▊ | 1572/1772 [18:49<02:23,  1.39it/s, running training loss:  0.79813]\u001b[A\n",
            "Training:  89%|████████▊ | 1572/1772 [18:49<02:23,  1.39it/s, running training loss:  0.84091]\u001b[A\n",
            "Training:  89%|████████▉ | 1573/1772 [18:49<02:17,  1.45it/s, running training loss:  0.84091]\u001b[A\n",
            "Training:  89%|████████▉ | 1573/1772 [18:50<02:17,  1.45it/s, running training loss:  0.75429]\u001b[A\n",
            "Training:  89%|████████▉ | 1574/1772 [18:50<02:06,  1.57it/s, running training loss:  0.75429]\u001b[A\n",
            "Training:  89%|████████▉ | 1574/1772 [18:51<02:06,  1.57it/s, running training loss:  0.88736]\u001b[A\n",
            "Training:  89%|████████▉ | 1575/1772 [18:51<02:04,  1.58it/s, running training loss:  0.88736]\u001b[A\n",
            "Training:  89%|████████▉ | 1575/1772 [18:51<02:04,  1.58it/s, running training loss:  1.06502]\u001b[A\n",
            "Training:  89%|████████▉ | 1576/1772 [18:51<02:13,  1.46it/s, running training loss:  1.06502]\u001b[A\n",
            "Training:  89%|████████▉ | 1576/1772 [18:52<02:13,  1.46it/s, running training loss:  0.80940]\u001b[A\n",
            "Training:  89%|████████▉ | 1577/1772 [18:52<02:25,  1.34it/s, running training loss:  0.80940]\u001b[A\n",
            "Training:  89%|████████▉ | 1577/1772 [18:53<02:25,  1.34it/s, running training loss:  0.93048]\u001b[A\n",
            "Training:  89%|████████▉ | 1578/1772 [18:53<02:17,  1.41it/s, running training loss:  0.93048]\u001b[A\n",
            "Training:  89%|████████▉ | 1578/1772 [18:53<02:17,  1.41it/s, running training loss:  0.83772]\u001b[A\n",
            "Training:  89%|████████▉ | 1579/1772 [18:53<02:08,  1.51it/s, running training loss:  0.83772]\u001b[A\n",
            "Training:  89%|████████▉ | 1579/1772 [18:54<02:08,  1.51it/s, running training loss:  1.28123]\u001b[A\n",
            "Training:  89%|████████▉ | 1580/1772 [18:54<01:58,  1.62it/s, running training loss:  1.28123]\u001b[A\n",
            "Training:  89%|████████▉ | 1580/1772 [18:55<01:58,  1.62it/s, running training loss:  1.79883]\u001b[A\n",
            "Training:  89%|████████▉ | 1581/1772 [18:55<02:01,  1.58it/s, running training loss:  1.79883]\u001b[A\n",
            "Training:  89%|████████▉ | 1581/1772 [18:55<02:01,  1.58it/s, running training loss:  1.51486]\u001b[A\n",
            "Training:  89%|████████▉ | 1582/1772 [18:55<02:01,  1.56it/s, running training loss:  1.51486]\u001b[A\n",
            "Training:  89%|████████▉ | 1582/1772 [18:56<02:01,  1.56it/s, running training loss:  1.10682]\u001b[A\n",
            "Training:  89%|████████▉ | 1583/1772 [18:56<02:05,  1.51it/s, running training loss:  1.10682]\u001b[A\n",
            "Training:  89%|████████▉ | 1583/1772 [18:57<02:05,  1.51it/s, running training loss:  0.97585]\u001b[A\n",
            "Training:  89%|████████▉ | 1584/1772 [18:57<02:05,  1.50it/s, running training loss:  0.97585]\u001b[A\n",
            "Training:  89%|████████▉ | 1584/1772 [18:57<02:05,  1.50it/s, running training loss:  0.72082]\u001b[A\n",
            "Training:  89%|████████▉ | 1585/1772 [18:57<02:00,  1.56it/s, running training loss:  0.72082]\u001b[A\n",
            "Training:  89%|████████▉ | 1585/1772 [18:58<02:00,  1.56it/s, running training loss:  0.70694]\u001b[A\n",
            "Training:  90%|████████▉ | 1586/1772 [18:58<01:55,  1.61it/s, running training loss:  0.70694]\u001b[A\n",
            "Training:  90%|████████▉ | 1586/1772 [18:59<01:55,  1.61it/s, running training loss:  0.72276]\u001b[A\n",
            "Training:  90%|████████▉ | 1587/1772 [18:59<02:08,  1.44it/s, running training loss:  0.72276]\u001b[A\n",
            "Training:  90%|████████▉ | 1587/1772 [18:59<02:08,  1.44it/s, running training loss:  1.35773]\u001b[A\n",
            "Training:  90%|████████▉ | 1588/1772 [18:59<02:06,  1.46it/s, running training loss:  1.35773]\u001b[A\n",
            "Training:  90%|████████▉ | 1588/1772 [19:00<02:06,  1.46it/s, running training loss:  0.99634]\u001b[A\n",
            "Training:  90%|████████▉ | 1589/1772 [19:00<02:05,  1.46it/s, running training loss:  0.99634]\u001b[A\n",
            "Training:  90%|████████▉ | 1589/1772 [19:01<02:05,  1.46it/s, running training loss:  0.83149]\u001b[A\n",
            "Training:  90%|████████▉ | 1590/1772 [19:01<01:58,  1.54it/s, running training loss:  0.83149]\u001b[A\n",
            "Training:  90%|████████▉ | 1590/1772 [19:01<01:58,  1.54it/s, running training loss:  1.02641]\u001b[A\n",
            "Training:  90%|████████▉ | 1591/1772 [19:01<02:00,  1.51it/s, running training loss:  1.02641]\u001b[A\n",
            "Training:  90%|████████▉ | 1591/1772 [19:02<02:00,  1.51it/s, running training loss:  1.14251]\u001b[A\n",
            "Training:  90%|████████▉ | 1592/1772 [19:02<01:56,  1.54it/s, running training loss:  1.14251]\u001b[A\n",
            "Training:  90%|████████▉ | 1592/1772 [19:03<01:56,  1.54it/s, running training loss:  0.69821]\u001b[A\n",
            "Training:  90%|████████▉ | 1593/1772 [19:03<02:04,  1.43it/s, running training loss:  0.69821]\u001b[A\n",
            "Training:  90%|████████▉ | 1593/1772 [19:03<02:04,  1.43it/s, running training loss:  0.71512]\u001b[A\n",
            "Training:  90%|████████▉ | 1594/1772 [19:03<02:01,  1.47it/s, running training loss:  0.71512]\u001b[A\n",
            "Training:  90%|████████▉ | 1594/1772 [19:04<02:01,  1.47it/s, running training loss:  1.01013]\u001b[A\n",
            "Training:  90%|█████████ | 1595/1772 [19:04<01:58,  1.49it/s, running training loss:  1.01013]\u001b[A\n",
            "Training:  90%|█████████ | 1595/1772 [19:05<01:58,  1.49it/s, running training loss:  1.06961]\u001b[A\n",
            "Training:  90%|█████████ | 1596/1772 [19:05<02:15,  1.30it/s, running training loss:  1.06961]\u001b[A\n",
            "Training:  90%|█████████ | 1596/1772 [19:06<02:15,  1.30it/s, running training loss:  1.01708]\u001b[A\n",
            "Training:  90%|█████████ | 1597/1772 [19:06<02:04,  1.41it/s, running training loss:  1.01708]\u001b[A\n",
            "Training:  90%|█████████ | 1597/1772 [19:06<02:04,  1.41it/s, running training loss:  0.52165]\u001b[A\n",
            "Training:  90%|█████████ | 1598/1772 [19:06<01:53,  1.53it/s, running training loss:  0.52165]\u001b[A\n",
            "Training:  90%|█████████ | 1598/1772 [19:07<01:53,  1.53it/s, running training loss:  1.02625]\u001b[A\n",
            "Training:  90%|█████████ | 1599/1772 [19:07<01:54,  1.51it/s, running training loss:  1.02625]\u001b[A\n",
            "Training:  90%|█████████ | 1599/1772 [19:07<01:54,  1.51it/s, running training loss:  0.96759]\u001b[A\n",
            "Training:  90%|█████████ | 1600/1772 [19:07<01:49,  1.57it/s, running training loss:  0.96759]\u001b[A\n",
            "Training:  90%|█████████ | 1600/1772 [19:08<01:49,  1.57it/s, running training loss:  0.69030]\u001b[A\n",
            "Training:  90%|█████████ | 1601/1772 [19:08<01:49,  1.56it/s, running training loss:  0.69030]\u001b[A\n",
            "Training:  90%|█████████ | 1601/1772 [19:09<01:49,  1.56it/s, running training loss:  0.97737]\u001b[A\n",
            "Training:  90%|█████████ | 1602/1772 [19:09<02:00,  1.41it/s, running training loss:  0.97737]\u001b[A\n",
            "Training:  90%|█████████ | 1602/1772 [19:09<02:00,  1.41it/s, running training loss:  0.57623]\u001b[A\n",
            "Training:  90%|█████████ | 1603/1772 [19:09<01:52,  1.50it/s, running training loss:  0.57623]\u001b[A\n",
            "Training:  90%|█████████ | 1603/1772 [19:10<01:52,  1.50it/s, running training loss:  0.86801]\u001b[A\n",
            "Training:  91%|█████████ | 1604/1772 [19:10<01:52,  1.49it/s, running training loss:  0.86801]\u001b[A\n",
            "Training:  91%|█████████ | 1604/1772 [19:11<01:52,  1.49it/s, running training loss:  0.90967]\u001b[A\n",
            "Training:  91%|█████████ | 1605/1772 [19:11<01:46,  1.57it/s, running training loss:  0.90967]\u001b[A\n",
            "Training:  91%|█████████ | 1605/1772 [19:11<01:46,  1.57it/s, running training loss:  0.57578]\u001b[A\n",
            "Training:  91%|█████████ | 1606/1772 [19:11<01:50,  1.51it/s, running training loss:  0.57578]\u001b[A\n",
            "Training:  91%|█████████ | 1606/1772 [19:12<01:50,  1.51it/s, running training loss:  0.75044]\u001b[A\n",
            "Training:  91%|█████████ | 1607/1772 [19:12<01:44,  1.58it/s, running training loss:  0.75044]\u001b[A\n",
            "Training:  91%|█████████ | 1607/1772 [19:13<01:44,  1.58it/s, running training loss:  0.85196]\u001b[A\n",
            "Training:  91%|█████████ | 1608/1772 [19:13<01:42,  1.60it/s, running training loss:  0.85196]\u001b[A\n",
            "Training:  91%|█████████ | 1608/1772 [19:13<01:42,  1.60it/s, running training loss:  0.66023]\u001b[A\n",
            "Training:  91%|█████████ | 1609/1772 [19:13<01:51,  1.46it/s, running training loss:  0.66023]\u001b[A\n",
            "Training:  91%|█████████ | 1609/1772 [19:14<01:51,  1.46it/s, running training loss:  0.72674]\u001b[A\n",
            "Training:  91%|█████████ | 1610/1772 [19:14<01:48,  1.49it/s, running training loss:  0.72674]\u001b[A\n",
            "Training:  91%|█████████ | 1610/1772 [19:15<01:48,  1.49it/s, running training loss:  0.81099]\u001b[A\n",
            "Training:  91%|█████████ | 1611/1772 [19:15<01:51,  1.44it/s, running training loss:  0.81099]\u001b[A\n",
            "Training:  91%|█████████ | 1611/1772 [19:15<01:51,  1.44it/s, running training loss:  0.92707]\u001b[A\n",
            "Training:  91%|█████████ | 1612/1772 [19:15<01:49,  1.46it/s, running training loss:  0.92707]\u001b[A\n",
            "Training:  91%|█████████ | 1612/1772 [19:16<01:49,  1.46it/s, running training loss:  1.00010]\u001b[A\n",
            "Training:  91%|█████████ | 1613/1772 [19:16<01:45,  1.50it/s, running training loss:  1.00010]\u001b[A\n",
            "Training:  91%|█████████ | 1613/1772 [19:17<01:45,  1.50it/s, running training loss:  0.35778]\u001b[A\n",
            "Training:  91%|█████████ | 1614/1772 [19:17<01:54,  1.38it/s, running training loss:  0.35778]\u001b[A\n",
            "Training:  91%|█████████ | 1614/1772 [19:18<01:54,  1.38it/s, running training loss:  0.99878]\u001b[A\n",
            "Training:  91%|█████████ | 1615/1772 [19:18<01:54,  1.37it/s, running training loss:  0.99878]\u001b[A\n",
            "Training:  91%|█████████ | 1615/1772 [19:18<01:54,  1.37it/s, running training loss:  1.44417]\u001b[A\n",
            "Training:  91%|█████████ | 1616/1772 [19:18<01:48,  1.44it/s, running training loss:  1.44417]\u001b[A\n",
            "Training:  91%|█████████ | 1616/1772 [19:19<01:48,  1.44it/s, running training loss:  0.35980]\u001b[A\n",
            "Training:  91%|█████████▏| 1617/1772 [19:19<01:42,  1.52it/s, running training loss:  0.35980]\u001b[A\n",
            "Training:  91%|█████████▏| 1617/1772 [19:19<01:42,  1.52it/s, running training loss:  1.25168]\u001b[A\n",
            "Training:  91%|█████████▏| 1618/1772 [19:19<01:35,  1.62it/s, running training loss:  1.25168]\u001b[A\n",
            "Training:  91%|█████████▏| 1618/1772 [19:20<01:35,  1.62it/s, running training loss:  1.20987]\u001b[A\n",
            "Training:  91%|█████████▏| 1619/1772 [19:20<01:36,  1.58it/s, running training loss:  1.20987]\u001b[A\n",
            "Training:  91%|█████████▏| 1619/1772 [19:21<01:36,  1.58it/s, running training loss:  0.65650]\u001b[A\n",
            "Training:  91%|█████████▏| 1620/1772 [19:21<01:34,  1.61it/s, running training loss:  0.65650]\u001b[A\n",
            "Training:  91%|█████████▏| 1620/1772 [19:21<01:34,  1.61it/s, running training loss:  0.95523]\u001b[A\n",
            "Training:  91%|█████████▏| 1621/1772 [19:21<01:31,  1.64it/s, running training loss:  0.95523]\u001b[A\n",
            "Training:  91%|█████████▏| 1621/1772 [19:22<01:31,  1.64it/s, running training loss:  0.50062]\u001b[A\n",
            "Training:  92%|█████████▏| 1622/1772 [19:22<01:31,  1.64it/s, running training loss:  0.50062]\u001b[A\n",
            "Training:  92%|█████████▏| 1622/1772 [19:23<01:31,  1.64it/s, running training loss:  1.66870]\u001b[A\n",
            "Training:  92%|█████████▏| 1623/1772 [19:23<01:33,  1.59it/s, running training loss:  1.66870]\u001b[A\n",
            "Training:  92%|█████████▏| 1623/1772 [19:23<01:33,  1.59it/s, running training loss:  1.42458]\u001b[A\n",
            "Training:  92%|█████████▏| 1624/1772 [19:23<01:45,  1.40it/s, running training loss:  1.42458]\u001b[A\n",
            "Training:  92%|█████████▏| 1624/1772 [19:24<01:45,  1.40it/s, running training loss:  1.04815]\u001b[A\n",
            "Training:  92%|█████████▏| 1625/1772 [19:24<01:42,  1.44it/s, running training loss:  1.04815]\u001b[A\n",
            "Training:  92%|█████████▏| 1625/1772 [19:25<01:42,  1.44it/s, running training loss:  0.86433]\u001b[A\n",
            "Training:  92%|█████████▏| 1626/1772 [19:25<01:37,  1.50it/s, running training loss:  0.86433]\u001b[A\n",
            "Training:  92%|█████████▏| 1626/1772 [19:25<01:37,  1.50it/s, running training loss:  0.86151]\u001b[A\n",
            "Training:  92%|█████████▏| 1627/1772 [19:25<01:29,  1.62it/s, running training loss:  0.86151]\u001b[A\n",
            "Training:  92%|█████████▏| 1627/1772 [19:26<01:29,  1.62it/s, running training loss:  0.72302]\u001b[A\n",
            "Training:  92%|█████████▏| 1628/1772 [19:26<01:27,  1.64it/s, running training loss:  0.72302]\u001b[A\n",
            "Training:  92%|█████████▏| 1628/1772 [19:26<01:27,  1.64it/s, running training loss:  0.98320]\u001b[A\n",
            "Training:  92%|█████████▏| 1629/1772 [19:26<01:26,  1.66it/s, running training loss:  0.98320]\u001b[A\n",
            "Training:  92%|█████████▏| 1629/1772 [19:27<01:26,  1.66it/s, running training loss:  0.90385]\u001b[A\n",
            "Training:  92%|█████████▏| 1630/1772 [19:27<01:24,  1.68it/s, running training loss:  0.90385]\u001b[A\n",
            "Training:  92%|█████████▏| 1630/1772 [19:28<01:24,  1.68it/s, running training loss:  0.82154]\u001b[A\n",
            "Training:  92%|█████████▏| 1631/1772 [19:28<01:26,  1.63it/s, running training loss:  0.82154]\u001b[A\n",
            "Training:  92%|█████████▏| 1631/1772 [19:28<01:26,  1.63it/s, running training loss:  0.60758]\u001b[A\n",
            "Training:  92%|█████████▏| 1632/1772 [19:28<01:21,  1.72it/s, running training loss:  0.60758]\u001b[A\n",
            "Training:  92%|█████████▏| 1632/1772 [19:29<01:21,  1.72it/s, running training loss:  0.72134]\u001b[A\n",
            "Training:  92%|█████████▏| 1633/1772 [19:29<01:32,  1.50it/s, running training loss:  0.72134]\u001b[A\n",
            "Training:  92%|█████████▏| 1633/1772 [19:30<01:32,  1.50it/s, running training loss:  1.17510]\u001b[A\n",
            "Training:  92%|█████████▏| 1634/1772 [19:30<01:27,  1.57it/s, running training loss:  1.17510]\u001b[A\n",
            "Training:  92%|█████████▏| 1634/1772 [19:30<01:27,  1.57it/s, running training loss:  0.98825]\u001b[A\n",
            "Training:  92%|█████████▏| 1635/1772 [19:30<01:22,  1.67it/s, running training loss:  0.98825]\u001b[A\n",
            "Training:  92%|█████████▏| 1635/1772 [19:31<01:22,  1.67it/s, running training loss:  0.95982]\u001b[A\n",
            "Training:  92%|█████████▏| 1636/1772 [19:31<01:16,  1.78it/s, running training loss:  0.95982]\u001b[A\n",
            "Training:  92%|█████████▏| 1636/1772 [19:31<01:16,  1.78it/s, running training loss:  1.18350]\u001b[A\n",
            "Training:  92%|█████████▏| 1637/1772 [19:31<01:15,  1.80it/s, running training loss:  1.18350]\u001b[A\n",
            "Training:  92%|█████████▏| 1637/1772 [19:32<01:15,  1.80it/s, running training loss:  1.11646]\u001b[A\n",
            "Training:  92%|█████████▏| 1638/1772 [19:32<01:13,  1.82it/s, running training loss:  1.11646]\u001b[A\n",
            "Training:  92%|█████████▏| 1638/1772 [19:32<01:13,  1.82it/s, running training loss:  0.79705]\u001b[A\n",
            "Training:  92%|█████████▏| 1639/1772 [19:32<01:15,  1.75it/s, running training loss:  0.79705]\u001b[A\n",
            "Training:  92%|█████████▏| 1639/1772 [19:33<01:15,  1.75it/s, running training loss:  0.87880]\u001b[A\n",
            "Training:  93%|█████████▎| 1640/1772 [19:33<01:14,  1.76it/s, running training loss:  0.87880]\u001b[A\n",
            "Training:  93%|█████████▎| 1640/1772 [19:33<01:14,  1.76it/s, running training loss:  0.63589]\u001b[A\n",
            "Training:  93%|█████████▎| 1641/1772 [19:33<01:18,  1.67it/s, running training loss:  0.63589]\u001b[A\n",
            "Training:  93%|█████████▎| 1641/1772 [19:34<01:18,  1.67it/s, running training loss:  0.84752]\u001b[A\n",
            "Training:  93%|█████████▎| 1642/1772 [19:34<01:13,  1.76it/s, running training loss:  0.84752]\u001b[A\n",
            "Training:  93%|█████████▎| 1642/1772 [19:35<01:13,  1.76it/s, running training loss:  1.06757]\u001b[A\n",
            "Training:  93%|█████████▎| 1643/1772 [19:35<01:14,  1.74it/s, running training loss:  1.06757]\u001b[A\n",
            "Training:  93%|█████████▎| 1643/1772 [19:35<01:14,  1.74it/s, running training loss:  0.76105]\u001b[A\n",
            "Training:  93%|█████████▎| 1644/1772 [19:35<01:18,  1.64it/s, running training loss:  0.76105]\u001b[A\n",
            "Training:  93%|█████████▎| 1644/1772 [19:36<01:18,  1.64it/s, running training loss:  0.78177]\u001b[A\n",
            "Training:  93%|█████████▎| 1645/1772 [19:36<01:16,  1.66it/s, running training loss:  0.78177]\u001b[A\n",
            "Training:  93%|█████████▎| 1645/1772 [19:37<01:16,  1.66it/s, running training loss:  0.60819]\u001b[A\n",
            "Training:  93%|█████████▎| 1646/1772 [19:37<01:20,  1.57it/s, running training loss:  0.60819]\u001b[A\n",
            "Training:  93%|█████████▎| 1646/1772 [19:37<01:20,  1.57it/s, running training loss:  0.68349]\u001b[A\n",
            "Training:  93%|█████████▎| 1647/1772 [19:37<01:17,  1.61it/s, running training loss:  0.68349]\u001b[A\n",
            "Training:  93%|█████████▎| 1647/1772 [19:38<01:17,  1.61it/s, running training loss:  0.64259]\u001b[A\n",
            "Training:  93%|█████████▎| 1648/1772 [19:38<01:19,  1.56it/s, running training loss:  0.64259]\u001b[A\n",
            "Training:  93%|█████████▎| 1648/1772 [19:38<01:19,  1.56it/s, running training loss:  1.14466]\u001b[A\n",
            "Training:  93%|█████████▎| 1649/1772 [19:38<01:14,  1.66it/s, running training loss:  1.14466]\u001b[A\n",
            "Training:  93%|█████████▎| 1649/1772 [19:39<01:14,  1.66it/s, running training loss:  0.62434]\u001b[A\n",
            "Training:  93%|█████████▎| 1650/1772 [19:39<01:12,  1.68it/s, running training loss:  0.62434]\u001b[A\n",
            "Training:  93%|█████████▎| 1650/1772 [19:39<01:12,  1.68it/s, running training loss:  0.85442]\u001b[A\n",
            "Training:  93%|█████████▎| 1651/1772 [19:39<01:09,  1.73it/s, running training loss:  0.85442]\u001b[A\n",
            "Training:  93%|█████████▎| 1651/1772 [19:40<01:09,  1.73it/s, running training loss:  1.03636]\u001b[A\n",
            "Training:  93%|█████████▎| 1652/1772 [19:40<01:10,  1.70it/s, running training loss:  1.03636]\u001b[A\n",
            "Training:  93%|█████████▎| 1652/1772 [19:41<01:10,  1.70it/s, running training loss:  0.64731]\u001b[A\n",
            "Training:  93%|█████████▎| 1653/1772 [19:41<01:25,  1.39it/s, running training loss:  0.64731]\u001b[A\n",
            "Training:  93%|█████████▎| 1653/1772 [19:42<01:25,  1.39it/s, running training loss:  0.77745]\u001b[A\n",
            "Training:  93%|█████████▎| 1654/1772 [19:42<01:23,  1.41it/s, running training loss:  0.77745]\u001b[A\n",
            "Training:  93%|█████████▎| 1654/1772 [19:42<01:23,  1.41it/s, running training loss:  0.86594]\u001b[A\n",
            "Training:  93%|█████████▎| 1655/1772 [19:42<01:19,  1.47it/s, running training loss:  0.86594]\u001b[A\n",
            "Training:  93%|█████████▎| 1655/1772 [19:43<01:19,  1.47it/s, running training loss:  0.91114]\u001b[A\n",
            "Training:  93%|█████████▎| 1656/1772 [19:43<01:15,  1.54it/s, running training loss:  0.91114]\u001b[A\n",
            "Training:  93%|█████████▎| 1656/1772 [19:44<01:15,  1.54it/s, running training loss:  1.00367]\u001b[A\n",
            "Training:  94%|█████████▎| 1657/1772 [19:44<01:11,  1.62it/s, running training loss:  1.00367]\u001b[A\n",
            "Training:  94%|█████████▎| 1657/1772 [19:44<01:11,  1.62it/s, running training loss:  0.79430]\u001b[A\n",
            "Training:  94%|█████████▎| 1658/1772 [19:44<01:12,  1.56it/s, running training loss:  0.79430]\u001b[A\n",
            "Training:  94%|█████████▎| 1658/1772 [19:45<01:12,  1.56it/s, running training loss:  1.02611]\u001b[A\n",
            "Training:  94%|█████████▎| 1659/1772 [19:45<01:14,  1.51it/s, running training loss:  1.02611]\u001b[A\n",
            "Training:  94%|█████████▎| 1659/1772 [19:46<01:14,  1.51it/s, running training loss:  0.62921]\u001b[A\n",
            "Training:  94%|█████████▎| 1660/1772 [19:46<01:13,  1.53it/s, running training loss:  0.62921]\u001b[A\n",
            "Training:  94%|█████████▎| 1660/1772 [19:46<01:13,  1.53it/s, running training loss:  0.90277]\u001b[A\n",
            "Training:  94%|█████████▎| 1661/1772 [19:46<01:08,  1.63it/s, running training loss:  0.90277]\u001b[A\n",
            "Training:  94%|█████████▎| 1661/1772 [19:47<01:08,  1.63it/s, running training loss:  0.66787]\u001b[A\n",
            "Training:  94%|█████████▍| 1662/1772 [19:47<01:06,  1.66it/s, running training loss:  0.66787]\u001b[A\n",
            "Training:  94%|█████████▍| 1662/1772 [19:47<01:06,  1.66it/s, running training loss:  1.08825]\u001b[A\n",
            "Training:  94%|█████████▍| 1663/1772 [19:47<01:08,  1.60it/s, running training loss:  1.08825]\u001b[A\n",
            "Training:  94%|█████████▍| 1663/1772 [19:48<01:08,  1.60it/s, running training loss:  0.85611]\u001b[A\n",
            "Training:  94%|█████████▍| 1664/1772 [19:48<01:08,  1.57it/s, running training loss:  0.85611]\u001b[A\n",
            "Training:  94%|█████████▍| 1664/1772 [19:49<01:08,  1.57it/s, running training loss:  0.80573]\u001b[A\n",
            "Training:  94%|█████████▍| 1665/1772 [19:49<01:05,  1.63it/s, running training loss:  0.80573]\u001b[A\n",
            "Training:  94%|█████████▍| 1665/1772 [19:49<01:05,  1.63it/s, running training loss:  0.82987]\u001b[A\n",
            "Training:  94%|█████████▍| 1666/1772 [19:49<01:03,  1.66it/s, running training loss:  0.82987]\u001b[A\n",
            "Training:  94%|█████████▍| 1666/1772 [19:50<01:03,  1.66it/s, running training loss:  0.82695]\u001b[A\n",
            "Training:  94%|█████████▍| 1667/1772 [19:50<01:01,  1.71it/s, running training loss:  0.82695]\u001b[A\n",
            "Training:  94%|█████████▍| 1667/1772 [19:50<01:01,  1.71it/s, running training loss:  1.11354]\u001b[A\n",
            "Training:  94%|█████████▍| 1668/1772 [19:50<01:06,  1.56it/s, running training loss:  1.11354]\u001b[A\n",
            "Training:  94%|█████████▍| 1668/1772 [19:51<01:06,  1.56it/s, running training loss:  0.90933]\u001b[A\n",
            "Training:  94%|█████████▍| 1669/1772 [19:51<01:04,  1.61it/s, running training loss:  0.90933]\u001b[A\n",
            "Training:  94%|█████████▍| 1669/1772 [19:52<01:04,  1.61it/s, running training loss:  0.83479]\u001b[A\n",
            "Training:  94%|█████████▍| 1670/1772 [19:52<01:07,  1.51it/s, running training loss:  0.83479]\u001b[A\n",
            "Training:  94%|█████████▍| 1670/1772 [19:53<01:07,  1.51it/s, running training loss:  0.69857]\u001b[A\n",
            "Training:  94%|█████████▍| 1671/1772 [19:53<01:12,  1.39it/s, running training loss:  0.69857]\u001b[A\n",
            "Training:  94%|█████████▍| 1671/1772 [19:53<01:12,  1.39it/s, running training loss:  0.59940]\u001b[A\n",
            "Training:  94%|█████████▍| 1672/1772 [19:53<01:11,  1.41it/s, running training loss:  0.59940]\u001b[A\n",
            "Training:  94%|█████████▍| 1672/1772 [19:54<01:11,  1.41it/s, running training loss:  0.59489]\u001b[A\n",
            "Training:  94%|█████████▍| 1673/1772 [19:54<01:11,  1.38it/s, running training loss:  0.59489]\u001b[A\n",
            "Training:  94%|█████████▍| 1673/1772 [19:55<01:11,  1.38it/s, running training loss:  0.99249]\u001b[A\n",
            "Training:  94%|█████████▍| 1674/1772 [19:55<01:12,  1.35it/s, running training loss:  0.99249]\u001b[A\n",
            "Training:  94%|█████████▍| 1674/1772 [19:55<01:12,  1.35it/s, running training loss:  1.33692]\u001b[A\n",
            "Training:  95%|█████████▍| 1675/1772 [19:55<01:06,  1.47it/s, running training loss:  1.33692]\u001b[A\n",
            "Training:  95%|█████████▍| 1675/1772 [19:56<01:06,  1.47it/s, running training loss:  0.89011]\u001b[A\n",
            "Training:  95%|█████████▍| 1676/1772 [19:56<01:08,  1.40it/s, running training loss:  0.89011]\u001b[A\n",
            "Training:  95%|█████████▍| 1676/1772 [19:57<01:08,  1.40it/s, running training loss:  0.75472]\u001b[A\n",
            "Training:  95%|█████████▍| 1677/1772 [19:57<01:01,  1.54it/s, running training loss:  0.75472]\u001b[A\n",
            "Training:  95%|█████████▍| 1677/1772 [19:57<01:01,  1.54it/s, running training loss:  0.89941]\u001b[A\n",
            "Training:  95%|█████████▍| 1678/1772 [19:57<00:58,  1.60it/s, running training loss:  0.89941]\u001b[A\n",
            "Training:  95%|█████████▍| 1678/1772 [19:58<00:58,  1.60it/s, running training loss:  0.82248]\u001b[A\n",
            "Training:  95%|█████████▍| 1679/1772 [19:58<01:00,  1.54it/s, running training loss:  0.82248]\u001b[A\n",
            "Training:  95%|█████████▍| 1679/1772 [19:59<01:00,  1.54it/s, running training loss:  0.67545]\u001b[A\n",
            "Training:  95%|█████████▍| 1680/1772 [19:59<00:57,  1.59it/s, running training loss:  0.67545]\u001b[A\n",
            "Training:  95%|█████████▍| 1680/1772 [19:59<00:57,  1.59it/s, running training loss:  0.70478]\u001b[A\n",
            "Training:  95%|█████████▍| 1681/1772 [19:59<00:56,  1.60it/s, running training loss:  0.70478]\u001b[A\n",
            "Training:  95%|█████████▍| 1681/1772 [20:00<00:56,  1.60it/s, running training loss:  0.84872]\u001b[A\n",
            "Training:  95%|█████████▍| 1682/1772 [20:00<00:54,  1.64it/s, running training loss:  0.84872]\u001b[A\n",
            "Training:  95%|█████████▍| 1682/1772 [20:00<00:54,  1.64it/s, running training loss:  0.88595]\u001b[A\n",
            "Training:  95%|█████████▍| 1683/1772 [20:00<00:52,  1.71it/s, running training loss:  0.88595]\u001b[A\n",
            "Training:  95%|█████████▍| 1683/1772 [20:01<00:52,  1.71it/s, running training loss:  0.85599]\u001b[A\n",
            "Training:  95%|█████████▌| 1684/1772 [20:01<00:59,  1.47it/s, running training loss:  0.85599]\u001b[A\n",
            "Training:  95%|█████████▌| 1684/1772 [20:02<00:59,  1.47it/s, running training loss:  0.71321]\u001b[A\n",
            "Training:  95%|█████████▌| 1685/1772 [20:02<00:57,  1.51it/s, running training loss:  0.71321]\u001b[A\n",
            "Training:  95%|█████████▌| 1685/1772 [20:02<00:57,  1.51it/s, running training loss:  0.81335]\u001b[A\n",
            "Training:  95%|█████████▌| 1686/1772 [20:02<00:53,  1.62it/s, running training loss:  0.81335]\u001b[A\n",
            "Training:  95%|█████████▌| 1686/1772 [20:03<00:53,  1.62it/s, running training loss:  1.05007]\u001b[A\n",
            "Training:  95%|█████████▌| 1687/1772 [20:03<00:57,  1.47it/s, running training loss:  1.05007]\u001b[A\n",
            "Training:  95%|█████████▌| 1687/1772 [20:04<00:57,  1.47it/s, running training loss:  0.50900]\u001b[A\n",
            "Training:  95%|█████████▌| 1688/1772 [20:04<00:56,  1.48it/s, running training loss:  0.50900]\u001b[A\n",
            "Training:  95%|█████████▌| 1688/1772 [20:04<00:56,  1.48it/s, running training loss:  0.83192]\u001b[A\n",
            "Training:  95%|█████████▌| 1689/1772 [20:04<00:53,  1.54it/s, running training loss:  0.83192]\u001b[A\n",
            "Training:  95%|█████████▌| 1689/1772 [20:05<00:53,  1.54it/s, running training loss:  1.07145]\u001b[A\n",
            "Training:  95%|█████████▌| 1690/1772 [20:05<00:53,  1.55it/s, running training loss:  1.07145]\u001b[A\n",
            "Training:  95%|█████████▌| 1690/1772 [20:06<00:53,  1.55it/s, running training loss:  1.14113]\u001b[A\n",
            "Training:  95%|█████████▌| 1691/1772 [20:06<00:50,  1.62it/s, running training loss:  1.14113]\u001b[A\n",
            "Training:  95%|█████████▌| 1691/1772 [20:06<00:50,  1.62it/s, running training loss:  1.07426]\u001b[A\n",
            "Training:  95%|█████████▌| 1692/1772 [20:06<00:49,  1.62it/s, running training loss:  1.07426]\u001b[A\n",
            "Training:  95%|█████████▌| 1692/1772 [20:07<00:49,  1.62it/s, running training loss:  0.78781]\u001b[A\n",
            "Training:  96%|█████████▌| 1693/1772 [20:07<00:49,  1.58it/s, running training loss:  0.78781]\u001b[A\n",
            "Training:  96%|█████████▌| 1693/1772 [20:07<00:49,  1.58it/s, running training loss:  1.00587]\u001b[A\n",
            "Training:  96%|█████████▌| 1694/1772 [20:07<00:48,  1.62it/s, running training loss:  1.00587]\u001b[A\n",
            "Training:  96%|█████████▌| 1694/1772 [20:08<00:48,  1.62it/s, running training loss:  0.62500]\u001b[A\n",
            "Training:  96%|█████████▌| 1695/1772 [20:08<00:49,  1.56it/s, running training loss:  0.62500]\u001b[A\n",
            "Training:  96%|█████████▌| 1695/1772 [20:09<00:49,  1.56it/s, running training loss:  0.66340]\u001b[A\n",
            "Training:  96%|█████████▌| 1696/1772 [20:09<00:52,  1.44it/s, running training loss:  0.66340]\u001b[A\n",
            "Training:  96%|█████████▌| 1696/1772 [20:10<00:52,  1.44it/s, running training loss:  0.71710]\u001b[A\n",
            "Training:  96%|█████████▌| 1697/1772 [20:10<00:58,  1.29it/s, running training loss:  0.71710]\u001b[A\n",
            "Training:  96%|█████████▌| 1697/1772 [20:11<00:58,  1.29it/s, running training loss:  0.96151]\u001b[A\n",
            "Training:  96%|█████████▌| 1698/1772 [20:11<00:54,  1.36it/s, running training loss:  0.96151]\u001b[A\n",
            "Training:  96%|█████████▌| 1698/1772 [20:11<00:54,  1.36it/s, running training loss:  0.68404]\u001b[A\n",
            "Training:  96%|█████████▌| 1699/1772 [20:11<00:51,  1.43it/s, running training loss:  0.68404]\u001b[A\n",
            "Training:  96%|█████████▌| 1699/1772 [20:12<00:51,  1.43it/s, running training loss:  0.72839]\u001b[A\n",
            "Training:  96%|█████████▌| 1700/1772 [20:12<00:45,  1.58it/s, running training loss:  0.72839]\u001b[A\n",
            "Training:  96%|█████████▌| 1700/1772 [20:12<00:45,  1.58it/s, running training loss:  0.80246]\u001b[A\n",
            "Training:  96%|█████████▌| 1701/1772 [20:12<00:43,  1.64it/s, running training loss:  0.80246]\u001b[A\n",
            "Training:  96%|█████████▌| 1701/1772 [20:13<00:43,  1.64it/s, running training loss:  0.62378]\u001b[A\n",
            "Training:  96%|█████████▌| 1702/1772 [20:13<00:42,  1.64it/s, running training loss:  0.62378]\u001b[A\n",
            "Training:  96%|█████████▌| 1702/1772 [20:14<00:42,  1.64it/s, running training loss:  0.95692]\u001b[A\n",
            "Training:  96%|█████████▌| 1703/1772 [20:14<00:49,  1.40it/s, running training loss:  0.95692]\u001b[A\n",
            "Training:  96%|█████████▌| 1703/1772 [20:14<00:49,  1.40it/s, running training loss:  1.12847]\u001b[A\n",
            "Training:  96%|█████████▌| 1704/1772 [20:14<00:43,  1.55it/s, running training loss:  1.12847]\u001b[A\n",
            "Training:  96%|█████████▌| 1704/1772 [20:15<00:43,  1.55it/s, running training loss:  0.91279]\u001b[A\n",
            "Training:  96%|█████████▌| 1705/1772 [20:15<00:43,  1.56it/s, running training loss:  0.91279]\u001b[A\n",
            "Training:  96%|█████████▌| 1705/1772 [20:15<00:43,  1.56it/s, running training loss:  0.70412]\u001b[A\n",
            "Training:  96%|█████████▋| 1706/1772 [20:15<00:39,  1.65it/s, running training loss:  0.70412]\u001b[A\n",
            "Training:  96%|█████████▋| 1706/1772 [20:16<00:39,  1.65it/s, running training loss:  0.82240]\u001b[A\n",
            "Training:  96%|█████████▋| 1707/1772 [20:16<00:38,  1.68it/s, running training loss:  0.82240]\u001b[A\n",
            "Training:  96%|█████████▋| 1707/1772 [20:17<00:38,  1.68it/s, running training loss:  1.03332]\u001b[A\n",
            "Training:  96%|█████████▋| 1708/1772 [20:17<00:43,  1.48it/s, running training loss:  1.03332]\u001b[A\n",
            "Training:  96%|█████████▋| 1708/1772 [20:18<00:43,  1.48it/s, running training loss:  0.79595]\u001b[A\n",
            "Training:  96%|█████████▋| 1709/1772 [20:18<00:41,  1.50it/s, running training loss:  0.79595]\u001b[A\n",
            "Training:  96%|█████████▋| 1709/1772 [20:18<00:41,  1.50it/s, running training loss:  0.80161]\u001b[A\n",
            "Training:  97%|█████████▋| 1710/1772 [20:18<00:39,  1.56it/s, running training loss:  0.80161]\u001b[A\n",
            "Training:  97%|█████████▋| 1710/1772 [20:19<00:39,  1.56it/s, running training loss:  0.71112]\u001b[A\n",
            "Training:  97%|█████████▋| 1711/1772 [20:19<00:40,  1.51it/s, running training loss:  0.71112]\u001b[A\n",
            "Training:  97%|█████████▋| 1711/1772 [20:19<00:40,  1.51it/s, running training loss:  0.73711]\u001b[A\n",
            "Training:  97%|█████████▋| 1712/1772 [20:19<00:40,  1.50it/s, running training loss:  0.73711]\u001b[A\n",
            "Training:  97%|█████████▋| 1712/1772 [20:20<00:40,  1.50it/s, running training loss:  0.78037]\u001b[A\n",
            "Training:  97%|█████████▋| 1713/1772 [20:20<00:37,  1.58it/s, running training loss:  0.78037]\u001b[A\n",
            "Training:  97%|█████████▋| 1713/1772 [20:21<00:37,  1.58it/s, running training loss:  0.48443]\u001b[A\n",
            "Training:  97%|█████████▋| 1714/1772 [20:21<00:37,  1.57it/s, running training loss:  0.48443]\u001b[A\n",
            "Training:  97%|█████████▋| 1714/1772 [20:21<00:37,  1.57it/s, running training loss:  0.79096]\u001b[A\n",
            "Training:  97%|█████████▋| 1715/1772 [20:21<00:36,  1.55it/s, running training loss:  0.79096]\u001b[A\n",
            "Training:  97%|█████████▋| 1715/1772 [20:22<00:36,  1.55it/s, running training loss:  0.81137]\u001b[A\n",
            "Training:  97%|█████████▋| 1716/1772 [20:22<00:36,  1.52it/s, running training loss:  0.81137]\u001b[A\n",
            "Training:  97%|█████████▋| 1716/1772 [20:23<00:36,  1.52it/s, running training loss:  0.37404]\u001b[A\n",
            "Training:  97%|█████████▋| 1717/1772 [20:23<00:35,  1.56it/s, running training loss:  0.37404]\u001b[A\n",
            "Training:  97%|█████████▋| 1717/1772 [20:23<00:35,  1.56it/s, running training loss:  0.92060]\u001b[A\n",
            "Training:  97%|█████████▋| 1718/1772 [20:23<00:32,  1.64it/s, running training loss:  0.92060]\u001b[A\n",
            "Training:  97%|█████████▋| 1718/1772 [20:24<00:32,  1.64it/s, running training loss:  0.87420]\u001b[A\n",
            "Training:  97%|█████████▋| 1719/1772 [20:24<00:32,  1.65it/s, running training loss:  0.87420]\u001b[A\n",
            "Training:  97%|█████████▋| 1719/1772 [20:25<00:32,  1.65it/s, running training loss:  1.04682]\u001b[A\n",
            "Training:  97%|█████████▋| 1720/1772 [20:25<00:36,  1.41it/s, running training loss:  1.04682]\u001b[A\n",
            "Training:  97%|█████████▋| 1720/1772 [20:25<00:36,  1.41it/s, running training loss:  0.39315]\u001b[A\n",
            "Training:  97%|█████████▋| 1721/1772 [20:25<00:33,  1.51it/s, running training loss:  0.39315]\u001b[A\n",
            "Training:  97%|█████████▋| 1721/1772 [20:26<00:33,  1.51it/s, running training loss:  0.62513]\u001b[A\n",
            "Training:  97%|█████████▋| 1722/1772 [20:26<00:30,  1.66it/s, running training loss:  0.62513]\u001b[A\n",
            "Training:  97%|█████████▋| 1722/1772 [20:26<00:30,  1.66it/s, running training loss:  0.92696]\u001b[A\n",
            "Training:  97%|█████████▋| 1723/1772 [20:26<00:27,  1.78it/s, running training loss:  0.92696]\u001b[A\n",
            "Training:  97%|█████████▋| 1723/1772 [20:27<00:27,  1.78it/s, running training loss:  0.71213]\u001b[A\n",
            "Training:  97%|█████████▋| 1724/1772 [20:27<00:25,  1.86it/s, running training loss:  0.71213]\u001b[A\n",
            "Training:  97%|█████████▋| 1724/1772 [20:27<00:25,  1.86it/s, running training loss:  0.90307]\u001b[A\n",
            "Training:  97%|█████████▋| 1725/1772 [20:27<00:25,  1.83it/s, running training loss:  0.90307]\u001b[A\n",
            "Training:  97%|█████████▋| 1725/1772 [20:28<00:25,  1.83it/s, running training loss:  1.11744]\u001b[A\n",
            "Training:  97%|█████████▋| 1726/1772 [20:28<00:26,  1.73it/s, running training loss:  1.11744]\u001b[A\n",
            "Training:  97%|█████████▋| 1726/1772 [20:28<00:26,  1.73it/s, running training loss:  0.83618]\u001b[A\n",
            "Training:  97%|█████████▋| 1727/1772 [20:28<00:25,  1.73it/s, running training loss:  0.83618]\u001b[A\n",
            "Training:  97%|█████████▋| 1727/1772 [20:29<00:25,  1.73it/s, running training loss:  0.66813]\u001b[A\n",
            "Training:  98%|█████████▊| 1728/1772 [20:29<00:30,  1.43it/s, running training loss:  0.66813]\u001b[A\n",
            "Training:  98%|█████████▊| 1728/1772 [20:30<00:30,  1.43it/s, running training loss:  0.83327]\u001b[A\n",
            "Training:  98%|█████████▊| 1729/1772 [20:30<00:27,  1.56it/s, running training loss:  0.83327]\u001b[A\n",
            "Training:  98%|█████████▊| 1729/1772 [20:31<00:27,  1.56it/s, running training loss:  0.72878]\u001b[A\n",
            "Training:  98%|█████████▊| 1730/1772 [20:31<00:27,  1.51it/s, running training loss:  0.72878]\u001b[A\n",
            "Training:  98%|█████████▊| 1730/1772 [20:31<00:27,  1.51it/s, running training loss:  0.93141]\u001b[A\n",
            "Training:  98%|█████████▊| 1731/1772 [20:31<00:28,  1.46it/s, running training loss:  0.93141]\u001b[A\n",
            "Training:  98%|█████████▊| 1731/1772 [20:32<00:28,  1.46it/s, running training loss:  0.59767]\u001b[A\n",
            "Training:  98%|█████████▊| 1732/1772 [20:32<00:27,  1.48it/s, running training loss:  0.59767]\u001b[A\n",
            "Training:  98%|█████████▊| 1732/1772 [20:33<00:27,  1.48it/s, running training loss:  0.95389]\u001b[A\n",
            "Training:  98%|█████████▊| 1733/1772 [20:33<00:26,  1.49it/s, running training loss:  0.95389]\u001b[A\n",
            "Training:  98%|█████████▊| 1733/1772 [20:33<00:26,  1.49it/s, running training loss:  1.10588]\u001b[A\n",
            "Training:  98%|█████████▊| 1734/1772 [20:33<00:26,  1.46it/s, running training loss:  1.10588]\u001b[A\n",
            "Training:  98%|█████████▊| 1734/1772 [20:34<00:26,  1.46it/s, running training loss:  0.88730]\u001b[A\n",
            "Training:  98%|█████████▊| 1735/1772 [20:34<00:25,  1.47it/s, running training loss:  0.88730]\u001b[A\n",
            "Training:  98%|█████████▊| 1735/1772 [20:35<00:25,  1.47it/s, running training loss:  0.93722]\u001b[A\n",
            "Training:  98%|█████████▊| 1736/1772 [20:35<00:23,  1.55it/s, running training loss:  0.93722]\u001b[A\n",
            "Training:  98%|█████████▊| 1736/1772 [20:35<00:23,  1.55it/s, running training loss:  0.63394]\u001b[A\n",
            "Training:  98%|█████████▊| 1737/1772 [20:35<00:21,  1.60it/s, running training loss:  0.63394]\u001b[A\n",
            "Training:  98%|█████████▊| 1737/1772 [20:36<00:21,  1.60it/s, running training loss:  0.68068]\u001b[A\n",
            "Training:  98%|█████████▊| 1738/1772 [20:36<00:20,  1.68it/s, running training loss:  0.68068]\u001b[A\n",
            "Training:  98%|█████████▊| 1738/1772 [20:37<00:20,  1.68it/s, running training loss:  0.50290]\u001b[A\n",
            "Training:  98%|█████████▊| 1739/1772 [20:37<00:21,  1.54it/s, running training loss:  0.50290]\u001b[A\n",
            "Training:  98%|█████████▊| 1739/1772 [20:37<00:21,  1.54it/s, running training loss:  0.61619]\u001b[A\n",
            "Training:  98%|█████████▊| 1740/1772 [20:37<00:22,  1.39it/s, running training loss:  0.61619]\u001b[A\n",
            "Training:  98%|█████████▊| 1740/1772 [20:38<00:22,  1.39it/s, running training loss:  1.11424]\u001b[A\n",
            "Training:  98%|█████████▊| 1741/1772 [20:38<00:22,  1.37it/s, running training loss:  1.11424]\u001b[A\n",
            "Training:  98%|█████████▊| 1741/1772 [20:39<00:22,  1.37it/s, running training loss:  0.47365]\u001b[A\n",
            "Training:  98%|█████████▊| 1742/1772 [20:39<00:20,  1.49it/s, running training loss:  0.47365]\u001b[A\n",
            "Training:  98%|█████████▊| 1742/1772 [20:40<00:20,  1.49it/s, running training loss:  1.18932]\u001b[A\n",
            "Training:  98%|█████████▊| 1743/1772 [20:40<00:20,  1.41it/s, running training loss:  1.18932]\u001b[A\n",
            "Training:  98%|█████████▊| 1743/1772 [20:40<00:20,  1.41it/s, running training loss:  1.03957]\u001b[A\n",
            "Training:  98%|█████████▊| 1744/1772 [20:40<00:18,  1.53it/s, running training loss:  1.03957]\u001b[A\n",
            "Training:  98%|█████████▊| 1744/1772 [20:41<00:18,  1.53it/s, running training loss:  0.70716]\u001b[A\n",
            "Training:  98%|█████████▊| 1745/1772 [20:41<00:17,  1.54it/s, running training loss:  0.70716]\u001b[A\n",
            "Training:  98%|█████████▊| 1745/1772 [20:41<00:17,  1.54it/s, running training loss:  0.68852]\u001b[A\n",
            "Training:  99%|█████████▊| 1746/1772 [20:41<00:17,  1.48it/s, running training loss:  0.68852]\u001b[A\n",
            "Training:  99%|█████████▊| 1746/1772 [20:42<00:17,  1.48it/s, running training loss:  0.86932]\u001b[A\n",
            "Training:  99%|█████████▊| 1747/1772 [20:42<00:19,  1.28it/s, running training loss:  0.86932]\u001b[A\n",
            "Training:  99%|█████████▊| 1747/1772 [20:43<00:19,  1.28it/s, running training loss:  0.60312]\u001b[A\n",
            "Training:  99%|█████████▊| 1748/1772 [20:43<00:16,  1.46it/s, running training loss:  0.60312]\u001b[A\n",
            "Training:  99%|█████████▊| 1748/1772 [20:43<00:16,  1.46it/s, running training loss:  0.58210]\u001b[A\n",
            "Training:  99%|█████████▊| 1749/1772 [20:43<00:14,  1.57it/s, running training loss:  0.58210]\u001b[A\n",
            "Training:  99%|█████████▊| 1749/1772 [20:44<00:14,  1.57it/s, running training loss:  0.67535]\u001b[A\n",
            "Training:  99%|█████████▉| 1750/1772 [20:44<00:13,  1.63it/s, running training loss:  0.67535]\u001b[A\n",
            "Training:  99%|█████████▉| 1750/1772 [20:45<00:13,  1.63it/s, running training loss:  0.72427]\u001b[A\n",
            "Training:  99%|█████████▉| 1751/1772 [20:45<00:12,  1.67it/s, running training loss:  0.72427]\u001b[A\n",
            "Training:  99%|█████████▉| 1751/1772 [20:45<00:12,  1.67it/s, running training loss:  0.45918]\u001b[A\n",
            "Training:  99%|█████████▉| 1752/1772 [20:45<00:12,  1.66it/s, running training loss:  0.45918]\u001b[A\n",
            "Training:  99%|█████████▉| 1752/1772 [20:46<00:12,  1.66it/s, running training loss:  0.56683]\u001b[A\n",
            "Training:  99%|█████████▉| 1753/1772 [20:46<00:11,  1.68it/s, running training loss:  0.56683]\u001b[A\n",
            "Training:  99%|█████████▉| 1753/1772 [20:46<00:11,  1.68it/s, running training loss:  0.81808]\u001b[A\n",
            "Training:  99%|█████████▉| 1754/1772 [20:46<00:10,  1.68it/s, running training loss:  0.81808]\u001b[A\n",
            "Training:  99%|█████████▉| 1754/1772 [20:47<00:10,  1.68it/s, running training loss:  1.01455]\u001b[A\n",
            "Training:  99%|█████████▉| 1755/1772 [20:47<00:09,  1.71it/s, running training loss:  1.01455]\u001b[A\n",
            "Training:  99%|█████████▉| 1755/1772 [20:48<00:09,  1.71it/s, running training loss:  0.74593]\u001b[A\n",
            "Training:  99%|█████████▉| 1756/1772 [20:48<00:10,  1.46it/s, running training loss:  0.74593]\u001b[A\n",
            "Training:  99%|█████████▉| 1756/1772 [20:48<00:10,  1.46it/s, running training loss:  0.74902]\u001b[A\n",
            "Training:  99%|█████████▉| 1757/1772 [20:48<00:10,  1.50it/s, running training loss:  0.74902]\u001b[A\n",
            "Training:  99%|█████████▉| 1757/1772 [20:49<00:10,  1.50it/s, running training loss:  0.69691]\u001b[A\n",
            "Training:  99%|█████████▉| 1758/1772 [20:49<00:09,  1.47it/s, running training loss:  0.69691]\u001b[A\n",
            "Training:  99%|█████████▉| 1758/1772 [20:50<00:09,  1.47it/s, running training loss:  0.97771]\u001b[A\n",
            "Training:  99%|█████████▉| 1759/1772 [20:50<00:09,  1.41it/s, running training loss:  0.97771]\u001b[A\n",
            "Training:  99%|█████████▉| 1759/1772 [20:51<00:09,  1.41it/s, running training loss:  0.82314]\u001b[A\n",
            "Training:  99%|█████████▉| 1760/1772 [20:51<00:08,  1.50it/s, running training loss:  0.82314]\u001b[A\n",
            "Training:  99%|█████████▉| 1760/1772 [20:51<00:08,  1.50it/s, running training loss:  0.83890]\u001b[A\n",
            "Training:  99%|█████████▉| 1761/1772 [20:51<00:06,  1.63it/s, running training loss:  0.83890]\u001b[A\n",
            "Training:  99%|█████████▉| 1761/1772 [20:52<00:06,  1.63it/s, running training loss:  1.14585]\u001b[A\n",
            "Training:  99%|█████████▉| 1762/1772 [20:52<00:05,  1.67it/s, running training loss:  1.14585]\u001b[A\n",
            "Training:  99%|█████████▉| 1762/1772 [20:53<00:05,  1.67it/s, running training loss:  0.80342]\u001b[A\n",
            "Training:  99%|█████████▉| 1763/1772 [20:53<00:06,  1.37it/s, running training loss:  0.80342]\u001b[A\n",
            "Training:  99%|█████████▉| 1763/1772 [20:53<00:06,  1.37it/s, running training loss:  0.70972]\u001b[A\n",
            "Training: 100%|█████████▉| 1764/1772 [20:53<00:05,  1.44it/s, running training loss:  0.70972]\u001b[A\n",
            "Training: 100%|█████████▉| 1764/1772 [20:54<00:05,  1.44it/s, running training loss:  1.15639]\u001b[A\n",
            "Training: 100%|█████████▉| 1765/1772 [20:54<00:04,  1.55it/s, running training loss:  1.15639]\u001b[A\n",
            "Training: 100%|█████████▉| 1765/1772 [20:54<00:04,  1.55it/s, running training loss:  0.66709]\u001b[A\n",
            "Training: 100%|█████████▉| 1766/1772 [20:54<00:03,  1.63it/s, running training loss:  0.66709]\u001b[A\n",
            "Training: 100%|█████████▉| 1766/1772 [20:55<00:03,  1.63it/s, running training loss:  0.79623]\u001b[A\n",
            "Training: 100%|█████████▉| 1767/1772 [20:55<00:03,  1.58it/s, running training loss:  0.79623]\u001b[A\n",
            "Training: 100%|█████████▉| 1767/1772 [20:56<00:03,  1.58it/s, running training loss:  0.74607]\u001b[A\n",
            "Training: 100%|█████████▉| 1768/1772 [20:56<00:02,  1.58it/s, running training loss:  0.74607]\u001b[A\n",
            "Training: 100%|█████████▉| 1768/1772 [20:56<00:02,  1.58it/s, running training loss:  0.75780]\u001b[A\n",
            "Training: 100%|█████████▉| 1769/1772 [20:56<00:02,  1.46it/s, running training loss:  0.75780]\u001b[A\n",
            "Training: 100%|█████████▉| 1769/1772 [20:57<00:02,  1.46it/s, running training loss:  0.46935]\u001b[A\n",
            "Training: 100%|█████████▉| 1770/1772 [20:57<00:01,  1.49it/s, running training loss:  0.46935]\u001b[A\n",
            "Training: 100%|█████████▉| 1770/1772 [20:58<00:01,  1.49it/s, running training loss:  0.83951]\u001b[A\n",
            "Training: 100%|█████████▉| 1771/1772 [20:58<00:00,  1.58it/s, running training loss:  0.83951]\u001b[A\n",
            "Training: 100%|█████████▉| 1771/1772 [20:58<00:00,  1.58it/s, running training loss:  1.03861]\u001b[A\n",
            "Training: 100%|██████████| 1772/1772 [20:58<00:00,  1.41it/s, running training loss:  1.03861]\n",
            "100%|██████████| 1/1 [20:59<00:00, 1259.24s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "def prediction(config, model, test_dataloader):\n",
        "  test_iterator = tqdm(test_dataloader, desc = 'Prediction', total = len(test_dataloader))\n",
        "  test_preds = []\n",
        "  model.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for batch in test_iterator:\n",
        "      batch_cuda = {item: value.to(config['device']) for item, value in list(batch.items())}\n",
        "\n",
        "      logits = model(**batch_cuda)[0]\n",
        "\n",
        "      probs = torch.softmax(logits, dim = -1)\n",
        "\n",
        "      test_preds.append(probs[:, 1].detach().cpu())\n",
        "    test_preds = torch.cat(test_preds)\n",
        "    test_preds = torch.stack(test_preds.split(2), dim = 0).mean(dim = 1).numpy()\n",
        "    submission_path = os.path.join(config['output_path'], 'submission_part2.tsv')\n",
        "    test_df = pd.DataFrame(data = {'prediction': test_preds})\n",
        "    test_df.to_csv(submission_path, index = False, header = False, encoding = 'utf8', sep = '\\t')\n",
        "    with ZipFile(os.path.join(config['output_path'], 'submission_part2.zip'), 'w') as myzip:\n",
        "      myzip.write(submission_path, 'submission_part2.tsv')\n",
        "      "
      ],
      "metadata": {
        "id": "89v_a5pgBhjp"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction(config, model, test_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XxDTgxRH2AA",
        "outputId": "1e3f0d38-74cd-45fe-ab59-26e9d71bdcad"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Prediction: 100%|██████████| 483/483 [00:43<00:00, 11.00it/s]\n"
          ]
        }
      ]
    }
  ]
}